{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, TFDistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "story6y = pd.read_csv(\"6yn.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>dead</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Not Mess Up Your Tech Startup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:01:56+00:00</td>\n",
       "      <td>http://kristinabjoran.com/how-to-not-mess-up-y...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:03:32+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someday you may ditch your two-factor authenti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:04:34+00:00</td>\n",
       "      <td>http://arstechnica.com/security/2013/05/someda...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:05:35+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will State.com become the world's opinion forum?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:05:54+00:00</td>\n",
       "      <td>http://pandodaily.com/2013/05/31/making-sense-...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title text  \\\n",
       "0               How to Not Mess Up Your Tech Startup  NaN   \n",
       "1                                                NaN  NaN   \n",
       "2  Someday you may ditch your two-factor authenti...  NaN   \n",
       "3                                                NaN  NaN   \n",
       "4   Will State.com become the world's opinion forum?  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2013-06-01 00:01:56+00:00   \n",
       "1  2013-06-01 00:03:32+00:00   \n",
       "2  2013-06-01 00:04:34+00:00   \n",
       "3  2013-06-01 00:05:35+00:00   \n",
       "4  2013-06-01 00:05:54+00:00   \n",
       "\n",
       "                                                 url  score  dead deleted  \n",
       "0  http://kristinabjoran.com/how-to-not-mess-up-y...    2.0   NaN     NaN  \n",
       "1                                                NaN    NaN  True    True  \n",
       "2  http://arstechnica.com/security/2013/05/someda...    1.0   NaN     NaN  \n",
       "3                                                NaN    NaN  True    True  \n",
       "4  http://pandodaily.com/2013/05/31/making-sense-...    2.0   NaN     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story6y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to extract the urls, but first clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace non values with nan\n",
    "story6y.fillna(value=np.nan, inplace=True)\n",
    "# filter out delted stories\n",
    "story6y_f = story6y[story6y.deleted.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the series of content, ignoring nan values\n",
    "stories = story6y_f.title.fillna(' ').astype(str) + ' ' + story6y_f.text.fillna(' ').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     How to Not Mess Up Your Tech Startup  \n",
       "2          Someday you may ditch your two-factor authenti...\n",
       "4           Will State.com become the world's opinion for...\n",
       "5          LightUp Teaches Kids Electronics With Augmente...\n",
       "6          Getting Things Done: Why GTD for Sales is the ...\n",
       "                                 ...                        \n",
       "2344431      Italy Follows France in Levying a Digital Tax  \n",
       "2344432    Amazon is looking into tech that can identify ...\n",
       "2344433    Giant Concentric Circles in Granite Springs Va...\n",
       "2344434                          Wyze Data leak 12-26-2019  \n",
       "2344435    4M cards,4K drawersâ€“coalition of book lovers r...\n",
       "Length: 2243679, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract domain names\n",
    "import tldextract\n",
    "domains = story6y_f.url.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          http://kristinabjoran.com/how-to-not-mess-up-y...\n",
       "2          http://arstechnica.com/security/2013/05/someda...\n",
       "4          http://pandodaily.com/2013/05/31/making-sense-...\n",
       "5          http://techcrunch.com/2013/05/31/lightup-helps...\n",
       "6          http://blog.voltagecrm.com/getting-things-done...\n",
       "                                 ...                        \n",
       "2344431    https://www.wsj.com/articles/italy-follows-fra...\n",
       "2344432    https://www.usatoday.com/story/tech/2019/12/27...\n",
       "2344433    https://www.blackrockdesert.org/wiki/index.php...\n",
       "2344434    https://forums.wyzecam.com/t/updated-12-29-19-...\n",
       "2344435    https://www.washingtonpost.com/education/2019/...\n",
       "Name: url, Length: 2243679, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process is slow, use multiple threads\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build domain extraction function\n",
    "def doxtract(df):\n",
    "    dom = df.apply(lambda x: tldextract.extract(x).domain)\n",
    "    return dom\n",
    "# build multithread function\n",
    "def mdoxtract(df,efunc,nj=23):\n",
    "    text_split = np.array_split(df, nj)\n",
    "    pool = Pool(nj)\n",
    "    fd = pd.concat(pool.map(efunc, text_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdomain = mdoxtract(domains, doxtract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_aug = stories + ' ' + mdomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#pickle.dump( stories_aug, open( \"stories_aug.p\", \"wb\" ) )\n",
    "stories_aug = pickle.load( open( \"stories_aug.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_aug = stories_aug.apply(lambda x: x.replace('\\n',' ').replace('\\r', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2243679,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenize using bert tokenizer\n",
    "# also make it multi\n",
    "def tokenizerf(df,tokenizer):\n",
    "    tk = df.apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=200)))\n",
    "    return tk\n",
    "def mpt(text,func,nj=23):\n",
    "    text_split = np.array_split(text, nj)\n",
    "    pool = Pool(nj)\n",
    "    tf = pd.concat(pool.map(func, text_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return tf\n",
    "tf2 = partial(tokenizerf,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized0 = mpt(stories_aug,tf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( tokenized0, open( \"stories_token_bert.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_len = 0\n",
    "for i in tokenized0.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "    \n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized0.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = torch.tensor(padded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build minibatches\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "textiter = DataLoader(input_text, batch_size=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "emb0 = np.zeros([1,768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for _, batch in enumerate(textiter):\n",
    "        attention_mask = np.where(batch != 0, 1, 0)\n",
    "        attention_mask = torch.tensor(attention_mask).to(device)\n",
    "        a1 = batch.to(device)\n",
    "        emo = model(a1, attention_mask=attention_mask)\n",
    "        emb0 = np.append(emb0, emo[0][:,0,:].cpu().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump( emb0, open( \"emb_HN.p\", \"wb\" ) )\n",
    "emb0 = pickle.load(open('emb_HN.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2243679, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the dummy emb\n",
    "emb = emb0[1:]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an autoencoder model for topic categorization\n",
    "# input is already equal length vectors, no need to use LSTM..., will use dense layers + non-linear activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder for topic "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP0",
   "language": "python",
   "name": "nlp0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
