{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "#import tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pding/anaconda3/envs/tdi/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "story6y = pd.read_csv(\"6yn.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>dead</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Not Mess Up Your Tech Startup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:01:56+00:00</td>\n",
       "      <td>http://kristinabjoran.com/how-to-not-mess-up-y...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:03:32+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someday you may ditch your two-factor authenti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:04:34+00:00</td>\n",
       "      <td>http://arstechnica.com/security/2013/05/someda...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:05:35+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will State.com become the world's opinion forum?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-01 00:05:54+00:00</td>\n",
       "      <td>http://pandodaily.com/2013/05/31/making-sense-...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344431</th>\n",
       "      <td>Italy Follows France in Levying a Digital Tax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-29 23:53:49+00:00</td>\n",
       "      <td>https://www.wsj.com/articles/italy-follows-fra...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344432</th>\n",
       "      <td>Amazon is looking into tech that can identify ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-29 23:53:51+00:00</td>\n",
       "      <td>https://www.usatoday.com/story/tech/2019/12/27...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344433</th>\n",
       "      <td>Giant Concentric Circles in Granite Springs Va...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-29 23:54:04+00:00</td>\n",
       "      <td>https://www.blackrockdesert.org/wiki/index.php...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344434</th>\n",
       "      <td>Wyze Data leak 12-26-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-29 23:55:59+00:00</td>\n",
       "      <td>https://forums.wyzecam.com/t/updated-12-29-19-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344435</th>\n",
       "      <td>4M cards,4K drawers–coalition of book lovers r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-29 23:57:19+00:00</td>\n",
       "      <td>https://www.washingtonpost.com/education/2019/...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344436 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title text  \\\n",
       "0                     How to Not Mess Up Your Tech Startup  NaN   \n",
       "1                                                      NaN  NaN   \n",
       "2        Someday you may ditch your two-factor authenti...  NaN   \n",
       "3                                                      NaN  NaN   \n",
       "4         Will State.com become the world's opinion forum?  NaN   \n",
       "...                                                    ...  ...   \n",
       "2344431      Italy Follows France in Levying a Digital Tax  NaN   \n",
       "2344432  Amazon is looking into tech that can identify ...  NaN   \n",
       "2344433  Giant Concentric Circles in Granite Springs Va...  NaN   \n",
       "2344434                          Wyze Data leak 12-26-2019  NaN   \n",
       "2344435  4M cards,4K drawers–coalition of book lovers r...  NaN   \n",
       "\n",
       "                         timestamp  \\\n",
       "0        2013-06-01 00:01:56+00:00   \n",
       "1        2013-06-01 00:03:32+00:00   \n",
       "2        2013-06-01 00:04:34+00:00   \n",
       "3        2013-06-01 00:05:35+00:00   \n",
       "4        2013-06-01 00:05:54+00:00   \n",
       "...                            ...   \n",
       "2344431  2019-12-29 23:53:49+00:00   \n",
       "2344432  2019-12-29 23:53:51+00:00   \n",
       "2344433  2019-12-29 23:54:04+00:00   \n",
       "2344434  2019-12-29 23:55:59+00:00   \n",
       "2344435  2019-12-29 23:57:19+00:00   \n",
       "\n",
       "                                                       url  score  dead  \\\n",
       "0        http://kristinabjoran.com/how-to-not-mess-up-y...    2.0   NaN   \n",
       "1                                                      NaN    NaN  True   \n",
       "2        http://arstechnica.com/security/2013/05/someda...    1.0   NaN   \n",
       "3                                                      NaN    NaN  True   \n",
       "4        http://pandodaily.com/2013/05/31/making-sense-...    2.0   NaN   \n",
       "...                                                    ...    ...   ...   \n",
       "2344431  https://www.wsj.com/articles/italy-follows-fra...    2.0   NaN   \n",
       "2344432  https://www.usatoday.com/story/tech/2019/12/27...    1.0   NaN   \n",
       "2344433  https://www.blackrockdesert.org/wiki/index.php...    2.0   NaN   \n",
       "2344434  https://forums.wyzecam.com/t/updated-12-29-19-...    1.0   NaN   \n",
       "2344435  https://www.washingtonpost.com/education/2019/...    3.0   NaN   \n",
       "\n",
       "        deleted  \n",
       "0           NaN  \n",
       "1          True  \n",
       "2           NaN  \n",
       "3          True  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "2344431     NaN  \n",
       "2344432     NaN  \n",
       "2344433     NaN  \n",
       "2344434     NaN  \n",
       "2344435     NaN  \n",
       "\n",
       "[2344436 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story6y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace non values with nan\n",
    "story6y.fillna(value=np.nan, inplace=True)\n",
    "# filter out delted stories\n",
    "story6y_f = story6y[story6y.deleted.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the series of content, ignoring nan values\n",
    "stories = story6y_f.title.fillna(' ').astype(str) + ' ' + story6y_f.text.fillna(' ').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     How to Not Mess Up Your Tech Startup  \n",
       "2          Someday you may ditch your two-factor authenti...\n",
       "4           Will State.com become the world's opinion for...\n",
       "5          LightUp Teaches Kids Electronics With Augmente...\n",
       "6          Getting Things Done: Why GTD for Sales is the ...\n",
       "                                 ...                        \n",
       "2344431      Italy Follows France in Levying a Digital Tax  \n",
       "2344432    Amazon is looking into tech that can identify ...\n",
       "2344433    Giant Concentric Circles in Granite Springs Va...\n",
       "2344434                          Wyze Data leak 12-26-2019  \n",
       "2344435    4M cards,4K drawers–coalition of book lovers r...\n",
       "Length: 2243679, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract domain as an additional feature\n",
    "domains = story6y_f.url.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindomain = domains.apply(lambda x: tldextract.extract(x).domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15sites = maindomain.value_counts()[1:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "github         104365\n",
       "medium          93788\n",
       "youtube         55132\n",
       "nytimes         39535\n",
       "techcrunch      26840\n",
       "blogspot        23918\n",
       "bbc             22963\n",
       "theguardian     19916\n",
       "arstechnica     19334\n",
       "google          17919\n",
       "bloomberg       17633\n",
       "wikipedia       17264\n",
       "theverge        15273\n",
       "wsj             14189\n",
       "wired           14165\n",
       "Name: url, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top15sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text prepprocessing\n",
    "lemmatizer=WordNetLemmatizer() #For words Lemmatization\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text processing\n",
    "# 1. convert to lower case, clean text of all punctuations\n",
    "# 2. remove stop words\n",
    "# 3. lemmatize\n",
    "\n",
    "def process_text(text):\n",
    "    tokenized_text = word_tokenize(text.lower())\n",
    "    cleaned_text = ' '.join([lemmatizer.lemmatize(t) for t in tokenized_text if t not in stop_words and re.match('[a-zA-Z\\-][a-zA-Z\\-]{2,}', t)])\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_clean = stories.apply(lambda x: process_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15words = stories_clean.apply(lambda x: x.split()).value_counts()[1:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          mess tech startup\n",
       "2          someday may ditch two-factor authenticator ele...\n",
       "4                       state.com become world opinion forum\n",
       "5            lightup teach kid electronics augmented reality\n",
       "6                         getting thing done gtd sale answer\n",
       "                                 ...                        \n",
       "2344431             italy follows france levying digital tax\n",
       "2344432         amazon looking tech identify using vein hand\n",
       "2344433        giant concentric circle granite spring valley\n",
       "2344434                                       wyze data leak\n",
       "2344435    cards,4k drawers–coalition book lover rush sav...\n",
       "Length: 2243679, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add main domain name back to stories\n",
    "stories_aug = stories_clean + ' ' + maindomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           mess tech startup kristinabjoran\n",
       "2          someday may ditch two-factor authenticator ele...\n",
       "4            state.com become world opinion forum pandodaily\n",
       "5          lightup teach kid electronics augmented realit...\n",
       "6              getting thing done gtd sale answer voltagecrm\n",
       "                                 ...                        \n",
       "2344431         italy follows france levying digital tax wsj\n",
       "2344432    amazon looking tech identify using vein hand u...\n",
       "2344433    giant concentric circle granite spring valley ...\n",
       "2344434                               wyze data leak wyzecam\n",
       "2344435    cards,4k drawers–coalition book lover rush sav...\n",
       "Length: 2243679, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_aug.to_csv('saug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As discussed in the first version, an auto encoder should be built here to filter out low quality posts\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure reproductivity\n",
    "SEED = 6745\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding files\n",
    "\n",
    "\n",
    "# import the embeddings\n",
    "EMBEDDING_FILE = '/home/pding/DSP/embed/glove.840B.300d.txt'\n",
    "\n",
    "# Embedding file organized as word, followed by the vector\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': array([-0.082752 ,  0.67204  , -0.14987  , -0.064983 ,  0.056491 ,\n",
       "         0.40228  ,  0.0027747, -0.3311   , -0.30691  ,  2.0817   ,\n",
       "         0.031819 ,  0.013643 ,  0.30265  ,  0.0071297, -0.5819   ,\n",
       "        -0.2774   , -0.062254 ,  1.1451   , -0.24232  ,  0.1235   ,\n",
       "        -0.12243  ,  0.33152  , -0.006162 , -0.30541  , -0.13057  ,\n",
       "        -0.054601 ,  0.037083 , -0.070552 ,  0.5893   , -0.30385  ,\n",
       "         0.2898   , -0.14653  , -0.27052  ,  0.37161  ,  0.32031  ,\n",
       "        -0.29125  ,  0.0052483, -0.13212  , -0.052736 ,  0.087349 ,\n",
       "        -0.26668  , -0.16897  ,  0.015162 , -0.0083746, -0.14871  ,\n",
       "         0.23413  , -0.20719  , -0.091386 ,  0.40075  , -0.17223  ,\n",
       "         0.18145  ,  0.37586  , -0.28682  ,  0.37289  , -0.16185  ,\n",
       "         0.18008  ,  0.3032   , -0.13216  ,  0.18352  ,  0.095759 ,\n",
       "         0.094916 ,  0.008289 ,  0.11761  ,  0.34046  ,  0.03677  ,\n",
       "        -0.29077  ,  0.058303 , -0.027814 ,  0.082941 ,  0.1862   ,\n",
       "        -0.031494 ,  0.27985  , -0.074412 , -0.13762  , -0.21866  ,\n",
       "         0.18138  ,  0.040855 , -0.113    ,  0.24107  ,  0.3657   ,\n",
       "        -0.27525  , -0.05684  ,  0.34872  ,  0.011884 ,  0.14517  ,\n",
       "        -0.71395  ,  0.48497  ,  0.14807  ,  0.62287  ,  0.20599  ,\n",
       "         0.58379  , -0.13438  ,  0.40207  ,  0.18311  ,  0.28021  ,\n",
       "        -0.42349  , -0.25626  ,  0.17715  , -0.54095  ,  0.16596  ,\n",
       "        -0.036058 ,  0.08499  , -0.64989  ,  0.075549 , -0.28831  ,\n",
       "         0.40626  , -0.2802   ,  0.094062 ,  0.32406  ,  0.28437  ,\n",
       "        -0.26341  ,  0.11553  ,  0.071918 , -0.47215  , -0.18366  ,\n",
       "        -0.34709  ,  0.29964  , -0.66514  ,  0.002516 , -0.42333  ,\n",
       "         0.27512  ,  0.36012  ,  0.16311  ,  0.23964  , -0.05923  ,\n",
       "         0.3261   ,  0.20559  ,  0.038677 , -0.045816 ,  0.089764 ,\n",
       "         0.43151  , -0.15954  ,  0.08532  , -0.26572  , -0.15001  ,\n",
       "         0.084286 , -0.16714  , -0.43004  ,  0.060807 ,  0.13121  ,\n",
       "        -0.24112  ,  0.66554  ,  0.4453   , -0.18019  , -0.13919  ,\n",
       "         0.56252  ,  0.21457  , -0.46443  , -0.012211 ,  0.029988 ,\n",
       "        -0.051094 , -0.20135  ,  0.80788  ,  0.47377  , -0.057647 ,\n",
       "         0.46216  ,  0.16084  , -0.20954  , -0.05452  ,  0.15572  ,\n",
       "        -0.13712  ,  0.12972  , -0.011936 , -0.003378 , -0.13595  ,\n",
       "        -0.080711 ,  0.20065  ,  0.054056 ,  0.046816 ,  0.059539 ,\n",
       "         0.046265 ,  0.17754  , -0.31094  ,  0.28119  , -0.24355  ,\n",
       "         0.085252 , -0.21011  , -0.19472  ,  0.0027297, -0.46341  ,\n",
       "         0.14789  , -0.31517  , -0.065939 ,  0.036106 ,  0.42903  ,\n",
       "        -0.33759  ,  0.16432  ,  0.32568  , -0.050392 , -0.054297 ,\n",
       "         0.24074  ,  0.41923  ,  0.13012  , -0.17167  , -0.37808  ,\n",
       "        -0.23089  , -0.019477 , -0.29291  , -0.30824  ,  0.30297  ,\n",
       "        -0.22659  ,  0.081574 , -0.18516  , -0.21408  ,  0.40616  ,\n",
       "        -0.28974  ,  0.074174 , -0.17795  ,  0.28595  , -0.039626 ,\n",
       "        -0.2339   , -0.36054  , -0.067503 , -0.091065 ,  0.23438  ,\n",
       "        -0.0041331,  0.003232 ,  0.0072134,  0.008697 ,  0.21614  ,\n",
       "         0.049904 ,  0.35582  ,  0.13748  ,  0.073361 ,  0.14166  ,\n",
       "         0.2412   , -0.013322 ,  0.15613  ,  0.083381 ,  0.088146 ,\n",
       "        -0.019357 ,  0.43795  ,  0.083961 ,  0.45309  , -0.50489  ,\n",
       "        -0.10865  , -0.2527   , -0.18251  ,  0.20441  ,  0.13319  ,\n",
       "         0.1294   ,  0.050594 , -0.15612  , -0.39543  ,  0.12538  ,\n",
       "         0.24881  , -0.1927   , -0.31847  , -0.12719  ,  0.4341   ,\n",
       "         0.31177  , -0.0040946, -0.2094   , -0.079961 ,  0.1161   ,\n",
       "        -0.050794 ,  0.015266 , -0.2803   , -0.12486  ,  0.23587  ,\n",
       "         0.2339   , -0.14023  ,  0.028462 ,  0.56923  , -0.1649   ,\n",
       "        -0.036429 ,  0.010051 , -0.17107  , -0.042608 ,  0.044965 ,\n",
       "        -0.4393   , -0.26137  ,  0.30088  , -0.060772 , -0.45312  ,\n",
       "        -0.19076  , -0.20288  ,  0.27694  , -0.060888 ,  0.11944  ,\n",
       "         0.62206  , -0.19343  ,  0.47849  , -0.30113  ,  0.059389 ,\n",
       "         0.074901 ,  0.061068 , -0.4662   ,  0.40054  , -0.19099  ,\n",
       "        -0.14331  ,  0.018267 , -0.18643  ,  0.20709  , -0.35598  ,\n",
       "         0.05338  , -0.050821 , -0.1918   , -0.37846  , -0.06589  ],\n",
       "       dtype=float32),\n",
       " '.': array([ 0.012001 ,  0.20751  , -0.12578  , -0.59325  ,  0.12525  ,\n",
       "         0.15975  ,  0.13748  , -0.33157  , -0.13694  ,  1.7893   ,\n",
       "        -0.47094  ,  0.70434  ,  0.26673  , -0.089961 , -0.18168  ,\n",
       "         0.067226 ,  0.053347 ,  1.5595   , -0.2541   ,  0.038413 ,\n",
       "        -0.01409  ,  0.056774 ,  0.023434 ,  0.024042 ,  0.31703  ,\n",
       "         0.19025  , -0.37505  ,  0.035603 ,  0.1181   ,  0.012032 ,\n",
       "        -0.037566 , -0.5046   , -0.049261 ,  0.092351 ,  0.11031  ,\n",
       "        -0.073062 ,  0.33994  ,  0.28239  ,  0.13413  ,  0.070128 ,\n",
       "        -0.022099 , -0.28103  ,  0.49607  , -0.48693  , -0.090964 ,\n",
       "        -0.1538   , -0.38011  , -0.014228 , -0.19392  , -0.11068  ,\n",
       "        -0.014088 , -0.17906  ,  0.24509  , -0.16878  , -0.15351  ,\n",
       "        -0.13808  ,  0.02151  ,  0.13699  ,  0.0068061, -0.14915  ,\n",
       "        -0.38169  ,  0.12727  ,  0.44007  ,  0.32678  , -0.46117  ,\n",
       "         0.068687 ,  0.34747  ,  0.18827  , -0.31837  ,  0.4447   ,\n",
       "        -0.2095   , -0.26987  ,  0.48945  ,  0.15388  ,  0.05295  ,\n",
       "        -0.049831 ,  0.11207  ,  0.14881  , -0.37003  ,  0.30777  ,\n",
       "        -0.33865  ,  0.045149 , -0.18987  ,  0.26634  , -0.26401  ,\n",
       "        -0.47556  ,  0.68381  , -0.30653  ,  0.24606  ,  0.31611  ,\n",
       "        -0.071098 ,  0.030417 ,  0.088119 ,  0.045025 ,  0.20125  ,\n",
       "        -0.21618  , -0.36371  , -0.25948  , -0.42398  , -0.14305  ,\n",
       "        -0.10208  ,  0.21498  , -0.21924  , -0.17935  ,  0.21546  ,\n",
       "         0.13801  ,  0.24504  , -0.2559   ,  0.054815 ,  0.21307  ,\n",
       "         0.2564   , -0.25673  ,  0.17961  , -0.47638  , -0.25181  ,\n",
       "        -0.0091498, -0.054362 , -0.21007  ,  0.12597  , -0.40795  ,\n",
       "        -0.021164 ,  0.20585  ,  0.18925  , -0.0051896, -0.51394  ,\n",
       "         0.28862  , -0.077748 , -0.27676  ,  0.46567  , -0.14225  ,\n",
       "        -0.17879  , -0.4357   , -0.32481  ,  0.15034  , -0.058367 ,\n",
       "         0.49652  ,  0.20472  ,  0.019866 ,  0.13326  ,  0.12823  ,\n",
       "        -1.0177   ,  0.29007  ,  0.28995  ,  0.029994 , -0.10763  ,\n",
       "         0.28665  , -0.24387  ,  0.22905  , -0.26249  , -0.069269 ,\n",
       "        -0.17889  ,  0.21936  ,  0.15146  ,  0.04567  , -0.050497 ,\n",
       "         0.071482 , -0.1027   , -0.080705 ,  0.30296  ,  0.031302 ,\n",
       "         0.26613  , -0.0060951,  0.10313  , -0.39987  , -0.043945 ,\n",
       "        -0.057625 ,  0.08702  , -0.098152 ,  0.22835  , -0.005211 ,\n",
       "         0.038075 ,  0.01591  , -0.20622  ,  0.021853 ,  0.0040426,\n",
       "        -0.043063 , -0.002294 , -0.26097  , -0.25802  , -0.28158  ,\n",
       "        -0.23118  , -0.010404 , -0.30102  , -0.4042   ,  0.014653 ,\n",
       "        -0.10445  ,  0.30377  , -0.20957  ,  0.3119   ,  0.068272 ,\n",
       "         0.1008   ,  0.010423 ,  0.54011  ,  0.29865  ,  0.12653  ,\n",
       "         0.013761 ,  0.21738  , -0.39521  ,  0.066633 ,  0.50327  ,\n",
       "         0.14913  , -0.11554  ,  0.010042 ,  0.095698 ,  0.16607  ,\n",
       "        -0.18808  ,  0.055019 ,  0.026715 , -0.3164   , -0.046583 ,\n",
       "        -0.051591 ,  0.023475 , -0.11007  ,  0.085642 ,  0.28394  ,\n",
       "         0.040497 ,  0.071986 ,  0.14157  , -0.021199 ,  0.44718  ,\n",
       "         0.20088  , -0.12964  , -0.067183 ,  0.47614  ,  0.13394  ,\n",
       "        -0.17287  , -0.37324  , -0.17285  ,  0.02683  , -0.1316   ,\n",
       "         0.09116  , -0.46487  ,  0.1274   , -0.090159 , -0.10552  ,\n",
       "         0.068006 , -0.13381  ,  0.17056  ,  0.089509 , -0.23133  ,\n",
       "        -0.27572  ,  0.061534 , -0.051646 ,  0.28377  ,  0.25286  ,\n",
       "        -0.24139  , -0.19905  ,  0.12049  , -0.1011   ,  0.27392  ,\n",
       "         0.27843  ,  0.26449  , -0.18292  , -0.048961 ,  0.19198  ,\n",
       "         0.17192  ,  0.33659  , -0.20184  , -0.34305  , -0.24553  ,\n",
       "        -0.15399  ,  0.3945   ,  0.22839  , -0.25753  , -0.25675  ,\n",
       "        -0.37332  , -0.23884  , -0.048816 ,  0.78323  ,  0.18851  ,\n",
       "        -0.26477  ,  0.096566 ,  0.062658 , -0.30668  , -0.43334  ,\n",
       "         0.10006  ,  0.21136  ,  0.039459 , -0.11077  ,  0.24421  ,\n",
       "         0.60942  , -0.46646  ,  0.086385 , -0.39702  , -0.23363  ,\n",
       "         0.021307 , -0.10778  , -0.2281   ,  0.50803  ,  0.11567  ,\n",
       "         0.16165  , -0.066737 , -0.29556  ,  0.022612 , -0.28135  ,\n",
       "         0.0635   ,  0.14019  ,  0.13871  , -0.36049  , -0.035    ],\n",
       "       dtype=float32),\n",
       " 'the': array([ 2.7204e-01, -6.2030e-02, -1.8840e-01,  2.3225e-02, -1.8158e-02,\n",
       "         6.7192e-03, -1.3877e-01,  1.7708e-01,  1.7709e-01,  2.5882e+00,\n",
       "        -3.5179e-01, -1.7312e-01,  4.3285e-01, -1.0708e-01,  1.5006e-01,\n",
       "        -1.9982e-01, -1.9093e-01,  1.1871e+00, -1.6207e-01, -2.3538e-01,\n",
       "         3.6640e-03, -1.9156e-01, -8.5662e-02,  3.9199e-02, -6.6449e-02,\n",
       "        -4.2090e-02, -1.9122e-01,  1.1679e-02, -3.7138e-01,  2.1886e-01,\n",
       "         1.1423e-03,  4.3190e-01, -1.4205e-01,  3.8059e-01,  3.0654e-01,\n",
       "         2.0167e-02, -1.8316e-01, -6.5186e-03, -8.0549e-03, -1.2063e-01,\n",
       "         2.7507e-02,  2.9839e-01, -2.2896e-01, -2.2882e-01,  1.4671e-01,\n",
       "        -7.6301e-02, -1.2680e-01, -6.6651e-03, -5.2795e-02,  1.4258e-01,\n",
       "         1.5610e-01,  5.5510e-02, -1.6149e-01,  9.6290e-02, -7.6533e-02,\n",
       "        -4.9971e-02, -1.0195e-02, -4.7641e-02, -1.6679e-01, -2.3940e-01,\n",
       "         5.0141e-03, -4.9175e-02,  1.3338e-02,  4.1923e-01, -1.0104e-01,\n",
       "         1.5111e-02, -7.7706e-02, -1.3471e-01,  1.1900e-01,  1.0802e-01,\n",
       "         2.1061e-01, -5.1904e-02,  1.8527e-01,  1.7856e-01,  4.1293e-02,\n",
       "        -1.4385e-02, -8.2567e-02, -3.5483e-02, -7.6173e-02, -4.5367e-02,\n",
       "         8.9281e-02,  3.3672e-01, -2.2099e-01, -6.7275e-03,  2.3983e-01,\n",
       "        -2.3147e-01, -8.8592e-01,  9.1297e-02, -1.2123e-02,  1.3233e-02,\n",
       "        -2.5799e-01, -2.9720e-02,  1.6754e-02,  1.3690e-02,  3.2377e-01,\n",
       "         3.9546e-02,  4.2114e-02, -8.8243e-02,  3.0318e-01,  8.7747e-02,\n",
       "         1.6346e-01, -4.0485e-01, -4.3845e-02, -4.0697e-02,  2.0936e-01,\n",
       "        -7.7795e-01,  2.9970e-01,  2.3340e-01,  1.4891e-01, -3.9037e-01,\n",
       "        -5.3086e-02,  6.2922e-02,  6.5663e-02, -1.3906e-01,  9.4193e-02,\n",
       "         1.0344e-01, -2.7970e-01,  2.8905e-01, -3.2161e-01,  2.0687e-02,\n",
       "         6.3254e-02, -2.3257e-01, -4.3520e-01, -1.7049e-02, -3.2744e-01,\n",
       "        -4.7064e-02, -7.5149e-02, -1.8788e-01, -1.5017e-02,  2.9342e-02,\n",
       "        -3.5270e-01, -4.4278e-02, -1.3507e-01, -1.1644e-01, -1.0430e-01,\n",
       "         1.3920e-01,  3.9199e-03,  3.7603e-01,  6.7217e-02, -3.7992e-01,\n",
       "        -1.1241e+00, -5.7357e-02, -1.6826e-01,  3.9410e-02,  2.6040e-01,\n",
       "        -2.3866e-02,  1.7963e-01,  1.3553e-01,  2.1390e-01,  5.2633e-02,\n",
       "        -2.5033e-01, -1.1307e-01,  2.2234e-01,  6.6597e-02, -1.1161e-01,\n",
       "         6.2438e-02, -2.7972e-01,  1.9878e-01, -3.6262e-01, -1.0006e-05,\n",
       "        -1.7262e-01,  2.9166e-01, -1.5723e-01,  5.4295e-02,  6.1010e-02,\n",
       "        -3.9165e-01,  2.7660e-01,  5.7816e-02,  3.9709e-01,  2.5229e-02,\n",
       "         2.4672e-01, -8.9050e-02,  1.5683e-01, -2.0960e-01, -2.2196e-01,\n",
       "         5.2394e-02, -1.1360e-02,  5.0417e-02, -1.4023e-01, -4.2825e-02,\n",
       "        -3.1931e-02, -2.1336e-01, -2.0402e-01, -2.3272e-01,  7.4490e-02,\n",
       "         8.8202e-02, -1.1063e-01, -3.3526e-01, -1.4028e-02, -2.9429e-01,\n",
       "        -8.6911e-02, -1.3210e-01, -4.3616e-01,  2.0513e-01,  7.9362e-03,\n",
       "         4.8505e-01,  6.4237e-02,  1.4261e-01, -4.3711e-01,  1.2783e-01,\n",
       "        -1.3111e-01,  2.4673e-01, -2.7496e-01,  1.5896e-01,  4.3314e-01,\n",
       "         9.0286e-02,  2.4662e-01,  6.6463e-02, -2.0099e-01,  1.1010e-01,\n",
       "         3.6440e-02,  1.7359e-01, -1.5689e-01, -8.6328e-02, -1.7316e-01,\n",
       "         3.6975e-01, -4.0317e-01, -6.4814e-02, -3.4166e-02, -1.3773e-02,\n",
       "         6.2854e-02, -1.7183e-01, -1.2366e-01, -3.4663e-02, -2.2793e-01,\n",
       "        -2.3172e-01,  2.3900e-01,  2.7473e-01,  1.5332e-01,  1.0661e-01,\n",
       "        -6.0982e-02, -2.4805e-02, -1.3478e-01,  1.7932e-01, -3.7374e-01,\n",
       "        -2.8930e-02, -1.1142e-01, -8.3890e-02, -5.5932e-02,  6.8039e-02,\n",
       "        -1.0783e-01,  1.4650e-01,  9.4617e-02, -8.4554e-02,  6.7429e-02,\n",
       "        -3.2910e-01,  3.4082e-02, -1.6747e-01, -2.5997e-01, -2.2917e-01,\n",
       "         2.0159e-02, -2.7580e-02,  1.6136e-01, -1.8538e-01,  3.7665e-02,\n",
       "         5.7603e-01,  2.0684e-01,  2.7941e-01,  1.6477e-01, -1.8769e-02,\n",
       "         1.2062e-01,  6.9648e-02,  5.9022e-02, -2.3154e-01,  2.4095e-01,\n",
       "        -3.4710e-01,  4.8540e-02, -5.6502e-02,  4.1566e-01, -4.3194e-01,\n",
       "         4.8230e-01, -5.1759e-02, -2.7285e-01, -2.5893e-01,  1.6555e-01,\n",
       "        -1.8310e-01, -6.7340e-02,  4.2457e-01,  1.0346e-02,  1.4237e-01,\n",
       "         2.5939e-01,  1.7123e-01, -1.3821e-01, -6.6846e-02,  1.5981e-02,\n",
       "        -3.0193e-01,  4.3579e-02, -4.3102e-02,  3.5025e-01, -1.9681e-01,\n",
       "        -4.2810e-01,  1.6899e-01,  2.2511e-01, -2.8557e-01, -1.0280e-01,\n",
       "        -1.8168e-02,  1.1407e-01,  1.3015e-01, -1.8317e-01,  1.3230e-01],\n",
       "       dtype=float32),\n",
       " 'and': array([-1.8567e-01,  6.6008e-02, -2.5209e-01, -1.1725e-01,  2.6513e-01,\n",
       "         6.4908e-02,  1.2291e-01, -9.3979e-02,  2.4321e-02,  2.4926e+00,\n",
       "        -1.7916e-02, -7.1218e-02, -2.4782e-01, -2.6237e-01, -2.2460e-01,\n",
       "        -2.1961e-01, -1.2927e-01,  1.0867e+00, -6.6072e-01, -3.1617e-02,\n",
       "        -5.7328e-02,  5.6903e-02, -2.7939e-01, -3.9825e-01,  1.4251e-01,\n",
       "        -8.5146e-02, -1.4779e-01,  5.5067e-02, -2.8687e-03, -2.0917e-01,\n",
       "        -7.0735e-02,  2.2577e-01, -1.5881e-01, -1.0395e-01,  9.7110e-02,\n",
       "        -5.6251e-01, -3.2929e-01, -2.0853e-01,  9.8711e-03,  4.9777e-02,\n",
       "         1.4883e-03,  1.5884e-01,  4.2771e-02, -2.6956e-03, -2.4620e-02,\n",
       "        -1.9213e-01, -2.2556e-01,  1.0838e-01,  9.0086e-02, -1.3291e-01,\n",
       "         3.2559e-01, -1.7038e-01, -1.0990e-01, -2.3986e-01, -2.4289e-02,\n",
       "         1.4656e-02, -2.3700e-01,  8.4828e-02, -3.5982e-01, -7.6746e-02,\n",
       "         4.8909e-02,  1.1431e-01, -2.1013e-01,  2.4765e-01, -1.7531e-02,\n",
       "        -1.4028e-01,  4.6191e-02,  2.2972e-01,  1.1750e-01,  1.2724e-01,\n",
       "         1.2992e-02,  4.5870e-01,  4.1085e-01,  3.9106e-02,  1.5713e-01,\n",
       "        -1.8376e-01,  2.6834e-01,  5.6662e-02,  1.6844e-01, -5.3788e-02,\n",
       "        -9.1892e-02,  1.1193e-01, -8.6810e-02, -1.3324e-01,  1.5062e-01,\n",
       "        -3.1733e-01, -2.2078e-01,  2.5038e-01,  3.4131e-01,  3.6419e-01,\n",
       "        -8.9514e-02, -2.2193e-01,  2.4471e-01,  4.0091e-02,  4.7798e-01,\n",
       "        -2.9996e-02,  1.9212e-03,  6.3511e-02, -2.0417e-01, -2.6478e-01,\n",
       "         2.0649e-01,  1.5573e-02, -2.7722e-01, -1.8861e-01, -1.0289e-01,\n",
       "        -4.9773e-01,  1.4986e-01, -1.0877e-02,  2.5085e-01, -2.8117e-01,\n",
       "         1.8966e-01, -6.5879e-02,  9.4753e-02, -1.5338e-01, -5.5071e-02,\n",
       "        -3.6747e-01,  2.4993e-01,  9.6527e-02,  2.3538e-01,  1.8405e-01,\n",
       "         5.2859e-02,  2.2967e-01,  1.2582e-01,  1.5536e-01, -1.7275e-01,\n",
       "         3.3946e-01, -1.0049e-01,  7.4948e-02, -9.3575e-02, -4.0490e-02,\n",
       "        -1.6922e-02, -5.8039e-03, -1.8108e-01,  1.9537e-01,  4.5178e-01,\n",
       "         1.0965e-01,  2.3370e-01, -9.9050e-02, -7.8633e-02,  2.1678e-01,\n",
       "        -7.1231e-01, -9.9759e-02,  3.3333e-01, -1.6460e-01, -9.1688e-02,\n",
       "         2.1056e-01,  2.3669e-02,  2.8922e-02,  1.1990e-01, -1.2512e-01,\n",
       "        -2.6037e-02, -6.2217e-02,  5.5816e-01,  5.0273e-03, -3.0888e-01,\n",
       "         3.8611e-02,  1.7568e-01, -1.1163e-01, -1.0815e-01, -1.9444e-01,\n",
       "         2.9433e-01,  1.4519e-01, -4.2878e-02,  1.8534e-01,  1.8891e-02,\n",
       "        -6.1883e-01,  1.3352e-01,  3.6007e-02,  3.3995e-01,  2.2109e-01,\n",
       "        -7.9328e-02,  7.1319e-02,  1.7678e-01,  1.6378e-01, -2.3142e-01,\n",
       "        -1.4340e-01, -9.8122e-02, -1.9286e-02,  2.3560e-01, -3.4013e-01,\n",
       "        -6.1007e-02, -2.3208e-01, -3.1152e-01,  1.0063e-01, -1.5957e-01,\n",
       "         2.0183e-01, -1.6345e-02, -1.2303e-01,  2.2667e-02, -2.0986e-01,\n",
       "        -2.0127e-01, -8.7883e-02,  6.4731e-02,  1.0195e-01, -1.7860e-01,\n",
       "         3.3056e-01,  2.1407e-01, -3.2165e-01, -1.7106e-01,  1.9407e-01,\n",
       "        -3.8618e-01, -2.1480e-01, -5.2254e-02,  2.3175e-02,  4.7389e-01,\n",
       "         1.8612e-01,  1.2711e-01,  2.0855e-01, -1.0256e-01, -1.2016e-01,\n",
       "        -4.0488e-01,  2.9695e-02, -2.7419e-02, -8.5227e-03, -1.1415e-01,\n",
       "         8.1134e-02, -1.7228e-01,  1.9142e-01,  2.6514e-02,  4.3789e-02,\n",
       "        -1.2399e-01,  1.3354e-01,  1.0112e-01,  8.1682e-02, -1.5085e-01,\n",
       "         7.5806e-03, -1.8971e-01,  2.4669e-01,  2.2491e-01,  3.5553e-01,\n",
       "        -3.2770e-01, -2.1821e-01,  1.4020e-01,  2.8604e-01,  5.5226e-02,\n",
       "        -8.6544e-02,  2.1110e-02, -1.9236e-01,  7.4245e-02,  7.6782e-02,\n",
       "         8.1666e-04,  3.4097e-02, -5.7719e-01,  1.0657e-01,  2.8134e-01,\n",
       "        -1.1964e-01, -6.8281e-01, -3.2893e-01, -2.4442e-01, -2.5847e-02,\n",
       "         9.1273e-03,  2.0250e-01, -5.0959e-02, -1.1042e-01,  1.0962e-02,\n",
       "         7.6773e-02,  4.0048e-01, -4.0739e-01, -4.4773e-01,  3.1954e-01,\n",
       "        -3.6326e-02, -1.2789e-02, -1.7282e-01,  1.4760e-01,  2.3560e-01,\n",
       "         8.0642e-02, -3.6528e-01, -8.3443e-03,  6.2390e-01, -2.4379e-01,\n",
       "         1.9917e-02, -2.8803e-01, -1.0494e-02,  3.8412e-02, -1.1718e-01,\n",
       "        -7.2462e-02,  1.6381e-01,  3.8488e-01, -2.9783e-02,  2.3444e-01,\n",
       "         4.5320e-01,  1.4815e-01, -2.7021e-02, -7.3181e-02, -1.1470e-01,\n",
       "        -5.4545e-03,  4.7796e-01,  9.0912e-02,  9.4489e-02, -3.6882e-01,\n",
       "        -5.9396e-01, -9.7729e-02,  2.0072e-01,  1.7055e-01, -4.7356e-03,\n",
       "        -3.9709e-02,  3.2498e-01, -2.3452e-02,  1.2302e-01,  3.3120e-01],\n",
       "       dtype=float32),\n",
       " 'to': array([ 3.1924e-01,  6.3160e-02, -2.7858e-01,  2.6120e-01,  7.9248e-02,\n",
       "        -2.1462e-01, -1.0495e-01,  1.5495e-01, -3.3530e-02,  2.4834e+00,\n",
       "        -5.0904e-01,  8.7490e-02,  2.1426e-01,  2.2151e-01, -2.5234e-01,\n",
       "        -9.7544e-02, -1.9270e-01,  1.3606e+00, -1.1592e-01, -1.0383e-01,\n",
       "         2.1929e-01,  1.1997e-01, -1.1063e-01,  1.4212e-01, -1.6643e-01,\n",
       "         2.1815e-01,  4.2086e-03, -7.0012e-02, -2.3532e-01, -2.6518e-01,\n",
       "         3.1248e-02,  1.6669e-01, -8.9777e-02,  2.0059e-01,  3.1614e-01,\n",
       "        -5.5830e-01,  7.5735e-02,  2.7635e-01,  1.2741e-01, -1.8185e-01,\n",
       "        -1.2722e-01,  2.4686e-02, -7.7233e-02, -4.8998e-01,  2.0355e-02,\n",
       "         3.9164e-03,  1.2150e-01,  8.9723e-02, -7.8975e-02,  8.1443e-02,\n",
       "        -9.9087e-02, -5.5621e-02,  1.0737e-01, -4.4042e-03,  4.8496e-01,\n",
       "         1.1717e-01, -1.7329e-02,  1.0900e-01, -3.5558e-01,  5.1084e-02,\n",
       "         1.5714e-01,  1.7961e-01, -2.9711e-01,  3.3645e-02, -2.5792e-02,\n",
       "        -1.3931e-02, -2.3000e-01, -4.0306e-02,  2.2282e-01, -1.3544e-02,\n",
       "         1.1554e-02,  3.9110e-01,  2.6533e-01, -3.1012e-01,  4.0539e-01,\n",
       "        -4.2975e-02,  2.0811e-02, -3.3033e-01,  1.9573e-01, -3.7958e-02,\n",
       "         1.0274e-01, -1.3581e-03, -4.4505e-01,  7.7886e-02,  8.5110e-02,\n",
       "        -2.0285e-01, -1.9481e-01,  5.6933e-02,  5.3105e-01,  3.4154e-02,\n",
       "        -5.6996e-01, -1.8469e-01,  9.3403e-02,  2.8044e-01, -2.3349e-01,\n",
       "         1.0938e-01, -1.4288e-02, -2.7400e-01,  3.4196e-02, -9.8479e-02,\n",
       "         1.3268e-01,  1.9437e-01,  1.3463e-01, -9.9059e-02,  4.0324e-02,\n",
       "        -6.6272e-01,  3.5710e-01,  1.5429e-01,  1.8598e-01,  8.7542e-02,\n",
       "         8.0538e-02, -2.5121e-01,  2.4155e-01,  1.7830e-01,  3.6011e-02,\n",
       "        -2.7677e-02,  2.1161e-01, -2.9107e-01, -8.3456e-03,  1.1317e-01,\n",
       "         3.1064e-01, -1.0693e-01, -2.7367e-01, -3.9785e-02,  3.9881e-02,\n",
       "         3.4462e-02, -1.6518e-01,  1.6115e-01,  6.0826e-02,  3.0750e-01,\n",
       "        -2.2398e-01,  1.4619e-01, -2.6610e-01,  4.9732e-01, -1.3996e-01,\n",
       "        -2.4287e-01,  3.9469e-02, -8.4495e-02, -2.4315e-01,  7.0701e-02,\n",
       "        -1.0136e+00, -2.1733e-01, -3.6878e-01, -2.4973e-01,  1.7472e-01,\n",
       "        -1.1592e-02,  6.8561e-02, -9.0411e-02,  2.1878e-01, -2.6390e-01,\n",
       "         1.1904e-01,  1.4285e-01, -1.8707e-01, -1.3474e-01, -1.3232e-01,\n",
       "        -2.6553e-01,  2.2947e-01, -1.8215e-02,  6.7383e-03, -1.0190e-01,\n",
       "         1.0053e-01, -1.1270e-01, -1.3295e-01,  1.5951e-01,  1.4906e-01,\n",
       "        -9.5578e-02,  2.6992e-01,  1.1057e-02,  5.6568e-02,  2.1386e-02,\n",
       "         2.0215e-01,  4.8589e-04,  5.3360e-01, -2.2947e-01,  2.9275e-01,\n",
       "         1.7378e-01,  2.5423e-01, -1.0976e-01,  5.8816e-02,  1.4616e-02,\n",
       "        -4.3060e-02,  1.0732e-01, -2.8149e-02, -1.9181e-01,  1.0250e-01,\n",
       "        -6.3892e-02,  1.2737e-02, -1.2913e-01,  1.5037e-02,  2.6562e-01,\n",
       "        -1.7049e-02, -6.0716e-02, -9.4919e-02,  1.7775e-02,  1.3221e-01,\n",
       "         1.6830e-01, -1.9323e-01, -1.7612e-01,  7.5506e-02,  1.8939e-01,\n",
       "         1.2508e-01, -1.9880e-01, -1.6017e-01, -2.1092e-01,  4.6933e-01,\n",
       "         4.4747e-02,  9.8349e-02,  1.1637e-02,  2.2281e-01, -1.0837e-02,\n",
       "        -4.8330e-02, -4.7335e-01, -3.6811e-01, -1.3592e-01, -1.5086e-01,\n",
       "         2.5416e-01,  6.9531e-02,  1.4211e-01, -2.6703e-01, -1.2590e-01,\n",
       "         1.2076e-01, -2.6117e-01,  3.3024e-02, -3.4398e-02, -1.3968e-01,\n",
       "         1.3446e-01, -1.6709e-01,  1.5002e-01, -1.3724e-01,  9.1226e-02,\n",
       "        -2.7718e-01,  2.0098e-02,  2.6919e-01,  4.3016e-01,  9.4019e-02,\n",
       "        -8.5496e-02, -2.5192e-01, -1.1645e-01, -3.9734e-02,  4.6738e-03,\n",
       "         5.4178e-01, -1.6636e-01,  3.4546e-01,  9.8501e-02,  4.7819e-01,\n",
       "        -3.8428e-01, -3.2380e-01, -1.4822e-01, -4.7817e-01,  1.6704e-01,\n",
       "        -6.4505e-02,  1.1834e-01, -3.4480e-01,  9.6891e-02,  3.2309e-01,\n",
       "         4.1471e-01,  1.9463e-01, -2.0891e-01, -1.2223e-01, -5.8298e-02,\n",
       "        -2.0268e-01,  2.9480e-01,  4.3397e-02,  1.0112e-01,  2.7177e-01,\n",
       "        -5.2124e-01, -7.3794e-02,  4.4808e-02,  4.1388e-01,  8.8782e-02,\n",
       "         6.2255e-01, -7.2391e-02,  9.0129e-02,  1.5428e-01,  2.3163e-02,\n",
       "        -1.3028e-01,  6.1762e-02,  3.3803e-01, -9.1581e-02,  2.1039e-01,\n",
       "         5.1080e-02,  1.9184e-01,  1.0444e-01,  2.1380e-01, -3.5091e-01,\n",
       "        -2.3702e-01,  3.8399e-02, -1.0031e-01,  1.8359e-01,  2.5178e-02,\n",
       "        -1.2977e-01,  3.7130e-01,  1.8888e-01, -4.2738e-03, -1.0645e-01,\n",
       "        -2.5810e-01, -4.4629e-02,  8.2745e-02,  9.7801e-02,  2.5045e-01],\n",
       "       dtype=float32),\n",
       " 'of': array([ 6.0216e-02,  2.1799e-01, -4.2490e-02, -3.8618e-01, -1.5388e-01,\n",
       "         3.4635e-02,  2.2243e-01,  2.1718e-01,  6.8483e-03,  2.4375e+00,\n",
       "        -2.7418e-01,  1.3572e-01,  3.1086e-01, -6.3206e-02,  3.8225e-04,\n",
       "        -1.8597e-01, -1.9333e-01,  1.4447e+00, -3.8541e-01, -2.8549e-01,\n",
       "         7.5627e-02, -3.6799e-02, -4.6068e-01, -1.6835e-02,  1.9821e-01,\n",
       "        -9.2746e-02,  1.8954e-01, -3.2648e-04, -1.7081e-01,  5.0359e-01,\n",
       "         4.6256e-01,  2.6901e-01, -1.2256e-01,  2.4713e-01,  6.9305e-02,\n",
       "        -2.0777e-01, -4.4560e-01,  3.0223e-01, -9.8344e-03,  3.2772e-01,\n",
       "         1.1038e-01,  4.1271e-01, -1.5854e-01, -5.6983e-02,  3.8918e-01,\n",
       "        -2.1158e-01, -1.3307e-01,  4.0406e-01,  1.7490e-01,  5.3949e-02,\n",
       "         1.0984e-01, -1.8476e-01, -5.4014e-02,  4.0112e-02, -1.0175e-01,\n",
       "         1.2662e-01,  6.9709e-02, -2.4071e-01, -2.0995e-01, -5.1381e-02,\n",
       "         2.8219e-01,  1.8598e-01, -5.0180e-01,  2.7572e-01, -1.8497e-01,\n",
       "        -1.8399e-01,  1.5696e-01, -3.8444e-02, -5.2238e-01,  2.2753e-01,\n",
       "         4.8672e-02, -7.8837e-02,  6.5448e-02,  1.8399e-01,  4.0211e-01,\n",
       "        -1.2745e-01, -1.2302e-01,  3.1072e-01,  9.9588e-02,  3.6047e-02,\n",
       "        -2.5946e-01,  3.6128e-01,  1.2748e-01, -1.8667e-01,  1.6502e-01,\n",
       "        -3.9120e-01, -6.7549e-01,  1.1291e-01,  4.0743e-02,  3.4973e-02,\n",
       "        -4.0910e-02, -3.9791e-02, -4.0544e-01, -1.5867e-02,  1.0239e-01,\n",
       "         4.6868e-02, -8.2776e-02,  1.5132e-02, -1.4899e-01, -2.5125e-01,\n",
       "         2.5244e-01, -1.1851e-01, -3.4127e-01,  1.6516e-02,  3.0405e-01,\n",
       "        -5.4100e-01,  3.0500e-01,  3.9065e-01,  4.2362e-01, -4.1721e-01,\n",
       "        -5.4247e-02, -2.6014e-01, -1.4048e-01, -1.4166e-01, -2.1050e-02,\n",
       "         5.0822e-02, -7.8053e-02,  4.5922e-01,  1.7598e-01, -1.5700e-02,\n",
       "         9.1180e-02,  3.4263e-02, -4.9995e-01,  2.8574e-02,  1.2068e-01,\n",
       "         1.9781e-01, -1.3025e-02, -2.2418e-01,  1.2503e-01,  1.4653e-01,\n",
       "        -2.3085e-01,  2.1987e-01, -5.9321e-02, -8.8169e-02, -1.2520e-01,\n",
       "         7.5112e-03, -2.2421e-01,  6.2140e-01,  2.0090e-01, -2.8990e-02,\n",
       "        -6.5073e-01,  5.3506e-03, -1.2073e-01,  2.0988e-01, -1.6840e-01,\n",
       "         4.1826e-02,  5.4582e-02,  3.5247e-01,  2.0060e-01,  3.1903e-02,\n",
       "        -5.3307e-02, -4.4009e-01,  2.2495e-01, -3.0616e-01, -3.2855e-01,\n",
       "        -1.5779e-02, -1.3913e-01,  3.4309e-01, -1.3569e-01, -2.2276e-01,\n",
       "         1.4295e-01,  5.5010e-02, -1.0616e-01,  2.3597e-01, -2.0701e-01,\n",
       "        -3.0963e-01,  1.3528e-01, -1.6144e-01,  2.9108e-01,  1.2301e-01,\n",
       "         2.3650e-01, -2.6153e-01,  3.1022e-01,  2.0612e-01, -1.9885e-01,\n",
       "         1.0971e-01, -1.8054e-03,  1.4621e-01,  1.5177e-01, -4.4680e-01,\n",
       "         6.7433e-03, -2.8784e-02,  1.3821e-01, -1.6566e-01, -4.5517e-01,\n",
       "         1.6623e-02,  1.0703e-01, -4.8399e-01,  4.0033e-02,  4.9625e-02,\n",
       "        -2.6454e-01, -1.4680e-01,  1.3651e-01,  1.5261e-01,  6.7522e-02,\n",
       "         5.0405e-01, -1.8848e-01,  1.5256e-01, -2.6997e-01,  5.5578e-02,\n",
       "         4.7077e-02, -1.7848e-01, -3.3567e-01, -3.1480e-02,  1.9107e-01,\n",
       "         1.8818e-01,  1.8778e-01,  1.8313e-01, -3.6400e-01, -5.4127e-03,\n",
       "        -1.5763e-01,  1.6386e-01, -8.4828e-02, -1.9838e-01, -4.0454e-01,\n",
       "         4.1031e-01, -4.1393e-01,  2.9771e-02,  1.0544e-01, -1.1295e-01,\n",
       "        -6.8076e-02, -2.2372e-01, -1.9084e-01, -8.0269e-02, -3.8345e-01,\n",
       "         6.4712e-02,  2.3111e-01,  2.1408e-01,  2.8038e-01,  1.4221e-01,\n",
       "        -2.0696e-01,  1.5874e-02, -1.4112e-01,  8.9859e-02, -2.1533e-01,\n",
       "        -2.0105e-02,  2.2703e-01,  8.3425e-02, -2.9580e-01,  1.8036e-02,\n",
       "         1.9885e-01,  1.7794e-01,  1.3688e-01, -1.0302e-01,  2.9651e-02,\n",
       "         5.1271e-02, -1.4787e-01, -4.1824e-01,  1.9828e-02, -2.6385e-01,\n",
       "        -7.4654e-02, -1.5718e-02,  4.8094e-01,  1.2492e-01, -1.1409e-01,\n",
       "         5.8127e-01,  9.5836e-02, -9.5912e-02, -5.7435e-02,  1.3883e-01,\n",
       "         1.0307e-01,  8.1362e-02, -4.6690e-01,  5.0705e-01,  2.1685e-02,\n",
       "        -7.1623e-02, -6.3827e-02, -1.1154e-01,  6.1792e-01, -5.6329e-01,\n",
       "         2.3565e-02,  1.8041e-01, -2.5780e-01, -5.0956e-01,  1.4737e-01,\n",
       "        -3.3317e-02, -3.7053e-02,  2.4062e-01,  1.2641e-01, -2.7091e-02,\n",
       "         4.0390e-01, -2.8360e-02, -2.2235e-02, -1.1493e-01, -2.2850e-01,\n",
       "        -5.7460e-02,  2.9520e-01, -2.1914e-01, -1.3307e-01, -2.3647e-01,\n",
       "        -4.2484e-01,  1.1606e-01,  4.8131e-03, -3.9629e-01, -2.6823e-01,\n",
       "         3.2920e-01, -1.7597e-01,  1.1709e-01, -1.6692e-01, -9.4085e-02],\n",
       "       dtype=float32),\n",
       " 'a': array([ 4.3798e-02,  2.4779e-02, -2.0937e-01,  4.9745e-01,  3.6019e-01,\n",
       "        -3.7503e-01, -5.2078e-02, -6.0555e-01,  3.6744e-02,  2.2085e+00,\n",
       "        -2.3389e-01, -6.8360e-02, -2.2355e-01, -5.3989e-02, -1.5198e-01,\n",
       "        -1.7319e-01,  5.3355e-02,  1.6485e+00, -4.7991e-02, -8.5311e-02,\n",
       "        -1.5712e-01, -6.4425e-01, -3.9819e-01,  2.7800e-01,  1.5364e-01,\n",
       "         3.1678e-02,  5.5414e-02,  1.5939e-02,  3.1851e-01, -5.8979e-02,\n",
       "         3.8584e-02,  1.0770e-01,  1.0410e-01, -7.7346e-02,  3.7396e-01,\n",
       "        -2.1482e-01,  3.8320e-01, -2.7737e-01, -1.8352e-01, -8.3838e-01,\n",
       "         3.4124e-01,  5.8164e-01,  1.8543e-01, -3.1028e-01,  1.7666e-01,\n",
       "        -6.9421e-02, -3.4422e-01, -1.3665e-01, -1.0823e-01,  2.3637e-01,\n",
       "        -3.2923e-01,  6.1348e-01,  1.9720e-01,  8.7123e-02,  1.0785e-01,\n",
       "         3.0730e-01,  1.3757e-01,  3.0809e-01,  2.4331e-01, -2.9422e-01,\n",
       "        -9.8214e-03,  5.5675e-01, -4.8880e-02,  9.9468e-02,  3.0543e-01,\n",
       "        -3.7597e-01, -1.9525e-01,  4.6246e-02, -3.6675e-02,  3.4023e-01,\n",
       "         1.4905e-01,  9.7800e-02, -2.6664e-01,  5.6834e-02, -4.3201e-02,\n",
       "        -2.3338e-01,  1.3111e-01, -3.5742e-01, -3.6070e-01,  3.0997e-01,\n",
       "        -1.9727e-01, -1.4320e-01, -1.6747e-01,  4.2435e-04, -1.5120e-01,\n",
       "         6.7562e-02, -3.8644e-01,  2.5349e-02,  2.4918e-01, -2.3955e-01,\n",
       "        -1.5615e-01,  4.9868e-01,  8.2758e-03, -1.9120e-01, -1.4906e-01,\n",
       "         4.8757e-01, -1.5281e-02,  1.0196e-02,  3.7642e-01, -1.9460e-02,\n",
       "        -2.7835e-01,  1.6355e-01, -2.4127e-01, -2.1405e-01, -2.1562e-01,\n",
       "        -7.9697e-01,  3.4321e-01,  9.3209e-02,  7.3977e-02, -2.7147e-01,\n",
       "         2.0539e-01,  1.5061e-01,  2.0734e-02,  1.1267e-01,  2.8714e-02,\n",
       "         2.9670e-01, -2.1267e-01,  4.3214e-01,  1.2788e-01,  2.9249e-01,\n",
       "         1.9056e-01, -2.9113e-01, -1.1382e-01, -3.8242e-02, -2.0290e-01,\n",
       "         1.8301e-01, -1.6661e-01, -2.7116e-01,  1.2685e-03,  7.1704e-02,\n",
       "        -1.8583e-01,  8.9850e-02, -3.9895e-02,  3.9479e-01,  5.3211e-03,\n",
       "        -6.1548e-04, -2.7082e-01, -8.9782e-02, -2.8790e-01, -1.4865e-01,\n",
       "        -1.3746e+00,  1.6515e-01,  2.0598e-01,  1.5252e-01,  3.4723e-02,\n",
       "        -3.8531e-01, -9.4574e-02, -1.9871e-01,  5.0239e-01, -2.8702e-01,\n",
       "        -8.8727e-02,  5.6881e-02,  1.3634e-01,  1.9034e-01, -1.9353e-01,\n",
       "         4.0506e-01, -1.9317e-01,  2.2908e-01,  1.0055e-01, -2.6895e-01,\n",
       "        -3.4727e-02, -8.4010e-02,  5.7806e-02,  1.1076e-02, -4.3349e-02,\n",
       "        -2.6917e-01, -1.9333e-01,  2.2181e-01,  2.6123e-01, -1.1761e-01,\n",
       "         1.0092e-01, -1.5078e-01,  4.7153e-01,  1.1253e-01, -2.6749e-01,\n",
       "        -3.8785e-02, -3.6520e-02, -8.9248e-02, -2.4427e-01, -4.1381e-02,\n",
       "        -2.1785e-02, -3.5738e-01, -6.3409e-02, -5.3983e-01, -1.0112e-02,\n",
       "         4.1238e-04, -9.7049e-02,  4.2628e-01, -2.1349e-01, -4.1055e-01,\n",
       "        -2.4940e-01, -3.3571e-02, -4.9540e-01,  1.5557e-01,  1.9882e-01,\n",
       "         1.0498e-01, -2.4372e-01,  1.1429e-01, -3.9279e-02, -3.6258e-01,\n",
       "         1.0318e-01,  1.2900e-01, -4.1785e-01, -4.1607e-02,  3.3522e-01,\n",
       "         7.3186e-02,  1.3362e-01,  1.0812e-02,  5.2645e-02,  1.8801e-01,\n",
       "        -3.0185e-01,  2.0333e-01, -3.2258e-01, -2.4673e-01,  2.1124e-01,\n",
       "         7.9132e-01, -4.1539e-01,  3.6220e-01,  9.9852e-02, -3.5378e-02,\n",
       "        -4.1900e-02, -1.3851e-01, -6.3255e-02,  1.3635e-01,  9.0863e-02,\n",
       "        -3.9940e-01,  9.9062e-02,  3.2210e-01, -1.2256e-01, -8.5906e-02,\n",
       "        -1.0218e-01,  2.6350e-01, -1.8689e-01, -1.8560e-01, -4.3923e-01,\n",
       "        -3.2500e-01, -1.9910e-01,  1.7831e-01, -2.7283e-01,  3.3473e-01,\n",
       "         8.2382e-02,  1.2825e-01,  3.9275e-01, -3.4929e-02,  1.6148e-01,\n",
       "        -2.6713e-02,  4.0129e-01, -3.9503e-01, -6.4823e-02, -8.9820e-02,\n",
       "        -6.6592e-02, -3.4537e-01,  4.6283e-02,  3.6837e-01, -2.4573e-02,\n",
       "         3.2213e-01,  3.0641e-01, -2.8112e-01,  6.6449e-03,  8.7743e-02,\n",
       "        -3.4170e-02,  6.0373e-01,  4.2120e-01, -7.3349e-02,  2.6682e-01,\n",
       "        -1.5860e-01,  2.3765e-01, -6.2604e-03,  1.5236e-01, -2.3409e-01,\n",
       "         3.1634e-01, -8.7860e-02, -1.5747e-01, -2.4955e-01, -1.8766e-01,\n",
       "        -9.6743e-02, -2.7994e-01, -2.4334e-01,  3.2643e-01,  2.9906e-01,\n",
       "         4.2763e-01,  2.2266e-01, -1.7464e-01, -1.9916e-02, -3.1206e-01,\n",
       "        -3.4009e-01, -1.4993e-01, -2.8818e-01,  1.4750e-01, -4.0503e-02,\n",
       "        -1.0347e-01,  3.3634e-03,  2.1760e-01, -2.0409e-01,  9.2415e-02,\n",
       "         8.0421e-02, -6.1246e-02, -3.0099e-01, -1.4584e-01,  2.8188e-01],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(embeddings_index.items())[0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.tokenizer removes all the punct\n",
    "# numbers are represented as #, ##, ..(according to their length) in glove\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintitle = stories_aug.apply(lambda x: clean_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           mess tech startup kristinabjoran\n",
       "2          someday may ditch two-factor authenticator ele...\n",
       "4            state.com become world opinion forum pandodaily\n",
       "5          lightup teach kid electronics augmented realit...\n",
       "6              getting thing done gtd sale answer voltagecrm\n",
       "                                 ...                        \n",
       "2344431         italy follows france levying digital tax wsj\n",
       "2344432    amazon looking tech identify using vein hand u...\n",
       "2344433    giant concentric circle granite spring valley ...\n",
       "2344434                               wyze data leak wyzecam\n",
       "2344435    cards,4k drawers–coalition book lover rush sav...\n",
       "Length: 2243679, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pding/anaconda3/envs/tdi/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#traintitle.to_csv('traintae.csv')\n",
    "traintitle = pd.read_csv(\"traintae.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintitle = traintitle['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(traintitle))\n",
    "train_X = tokenizer.texts_to_sequences(traintitle)\n",
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430422"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(i) for i in train_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.243679e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.971123e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.498883e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.113000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  2.243679e+06\n",
       "mean   8.971123e+00\n",
       "std    1.498883e+01\n",
       "min    0.000000e+00\n",
       "25%    5.000000e+00\n",
       "50%    6.000000e+00\n",
       "75%    8.000000e+00\n",
       "max    2.113000e+03"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lengths).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that most of the titles+texts have very little words, and the longest posts are much longer than the average ones. This is probably\n",
    "# Because most of the posts only contain a title and no other contents\n",
    "maxlen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pad the sentences (same length input), texts_to_matrix would be too large\n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2243679, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0,      0,      0,      0,   2884,     46,\n",
       "            16, 213854],\n",
       "       [     0,  10945,    147,   3978,    175,   1269,  10588,   1923,\n",
       "          5339,    121],\n",
       "       [     0,      0,      0,    182,     13,    362,     36,    958,\n",
       "          1229,   6815],\n",
       "       [     0,      0,      0, 146017,    928,    397,   2123,   2188,\n",
       "           503,     63],\n",
       "       [     0,      0,      0,    180,     54,    403,  11329,    228,\n",
       "           531, 213855]], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.as_tensor(train_X, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use local rtx 2080\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the embedding matrix\n",
    "# load the embeddings\n",
    "all_embs = np.stack(list(embeddings_index.values()))\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "nb_words = len(word_index)\n",
    "\n",
    "# build embedding matrix, for words not in glove use random vectors\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "# build embedding matrix\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430422, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedwts = torch.tensor(embedding_matrix, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build input iterator, create minibatches\n",
    "trn = {'batch_size': 256,\n",
    "          'shuffle': True}\n",
    "evl = {'batch_size': 256,\n",
    "          'shuffle': False}\n",
    "\n",
    "trainiter = DataLoader(train_X, **trn)\n",
    "#next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model separately, wiht endocer, decoder and the whole model\n",
    "\n",
    "class Enc0(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, tin):\n",
    "        \n",
    "        \n",
    "        embedded = self.dropout(self.embedding(tin))        \n",
    "       \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "              \n",
    "        return embedded, outputs, hidden, cell\n",
    "\n",
    "# in this version use the pretrained embeddings\n",
    "class Enc1(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, tin):\n",
    "        \n",
    "        \n",
    "        embedded = self.dropout(self.embedding(tin))        \n",
    "       \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "              \n",
    "        return embedded, outputs, hidden, cell\n",
    "\n",
    "\n",
    "class Dec0(nn.Module):\n",
    "    def __init__(self, output_dim, input_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "             \n",
    "        self.rnn = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout, batch_first=True)\n",
    "        \n",
    "        #self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "    def forward(self, zve, hidden, cell):\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(zve, (hidden, cell))\n",
    "        \n",
    "        #use the output as the basis of recontruction\n",
    "        prediction = output\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "# add a dense layer to the decoder, so that the hid_dim does not need to be 300\n",
    "\n",
    "class Dec1(nn.Module):\n",
    "    def __init__(self, output_dim, input_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "             \n",
    "        self.rnn = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout, batch_first=True)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "    def forward(self, zve, hidden, cell):\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(zve, (hidden, cell))\n",
    "        \n",
    "        #use the output as the basis of recontruction\n",
    "        prediction = self.fc_out(output)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "class AE0(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, tin, maxlen):\n",
    "        embedded, outputs, hidden, cell = self.encoder(tin)\n",
    "        # replicate outputs as the new input to the decoer model\n",
    "        hiddeni = hidden.transpose(1,0).repeat(1,maxlen,1).to(self.device)\n",
    "        #hiddeni = hidden.repeat(1,maxlen, 1)\n",
    "        recons = self.decoder(hiddeni, hidden, cell)\n",
    "        \n",
    "        return embedded, recons      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = maxlen\n",
    "N_EMB = 430422+1\n",
    "#0 is a reserved index that won't be assigned to any word.\n",
    "EMB_DIM = 300\n",
    "OUTPUT_DIM = 300\n",
    "HID_DIM_E = 20\n",
    "HID_DIM_D = 20\n",
    "N_LAYERS = 1\n",
    "ENC_DROPOUT = 0\n",
    "DEC_DROPOUT = 0\n",
    "\n",
    "enc = Enc0(N_EMB, EMB_DIM, HID_DIM_E, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Dec1(OUTPUT_DIM, HID_DIM_E, HID_DIM_D, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model0 = AE0(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model0.parameters())\n",
    "criterion  = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, device, maxlen):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        tin = batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        target, recons = model(tin, maxlen)\n",
    "        \n",
    "        loss = criterion(recons, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        #print(f'Batch：{i+1} | Loss: {loss.item()}')\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：1 | Loss: 1.02158522605896\n",
      "Batch：2 | Loss: 1.019858479499817\n",
      "Batch：3 | Loss: 1.0142536163330078\n",
      "Batch：4 | Loss: 1.0087846517562866\n",
      "Batch：5 | Loss: 1.0112082958221436\n",
      "Batch：6 | Loss: 1.0088019371032715\n",
      "Batch：7 | Loss: 1.0052598714828491\n",
      "Batch：8 | Loss: 1.0015226602554321\n",
      "Batch：9 | Loss: 1.0041788816452026\n",
      "Batch：10 | Loss: 0.9973664283752441\n",
      "Batch：11 | Loss: 0.9957917928695679\n",
      "Batch：12 | Loss: 0.9938660264015198\n",
      "Batch：13 | Loss: 0.9925559759140015\n",
      "Batch：14 | Loss: 0.9886940717697144\n",
      "Batch：15 | Loss: 0.9843347668647766\n",
      "Batch：16 | Loss: 0.9855119585990906\n",
      "Batch：17 | Loss: 0.9815331697463989\n",
      "Batch：18 | Loss: 0.984406590461731\n",
      "Batch：19 | Loss: 0.9788204431533813\n",
      "Batch：20 | Loss: 0.9729545712471008\n",
      "Batch：21 | Loss: 0.9689456224441528\n",
      "Batch：22 | Loss: 0.968106746673584\n",
      "Batch：23 | Loss: 0.9678791165351868\n",
      "Batch：24 | Loss: 0.9569656252861023\n",
      "Batch：25 | Loss: 0.95974200963974\n",
      "Batch：26 | Loss: 0.9613344073295593\n",
      "Batch：27 | Loss: 0.9561877250671387\n",
      "Batch：28 | Loss: 0.9529245495796204\n",
      "Batch：29 | Loss: 0.945080578327179\n",
      "Batch：30 | Loss: 0.9528906345367432\n",
      "Batch：31 | Loss: 0.9376038908958435\n",
      "Batch：32 | Loss: 0.9324793815612793\n",
      "Batch：33 | Loss: 0.9320193529129028\n",
      "Batch：34 | Loss: 0.9359797239303589\n",
      "Batch：35 | Loss: 0.9260640144348145\n",
      "Batch：36 | Loss: 0.9206725358963013\n",
      "Batch：37 | Loss: 0.916015625\n",
      "Batch：38 | Loss: 0.9198965430259705\n",
      "Batch：39 | Loss: 0.9014241695404053\n",
      "Batch：40 | Loss: 0.9150622487068176\n",
      "Batch：41 | Loss: 0.9090442657470703\n",
      "Batch：42 | Loss: 0.9159964323043823\n",
      "Batch：43 | Loss: 0.8965048789978027\n",
      "Batch：44 | Loss: 0.8893972635269165\n",
      "Batch：45 | Loss: 0.8953946828842163\n",
      "Batch：46 | Loss: 0.8969869613647461\n",
      "Batch：47 | Loss: 0.887241542339325\n",
      "Batch：48 | Loss: 0.87801593542099\n",
      "Batch：49 | Loss: 0.8741030097007751\n",
      "Batch：50 | Loss: 0.8777586817741394\n",
      "Batch：51 | Loss: 0.8813502788543701\n",
      "Batch：52 | Loss: 0.8761109113693237\n",
      "Batch：53 | Loss: 0.8852537870407104\n",
      "Batch：54 | Loss: 0.8693114519119263\n",
      "Batch：55 | Loss: 0.8692070245742798\n",
      "Batch：56 | Loss: 0.8571668267250061\n",
      "Batch：57 | Loss: 0.8530756831169128\n",
      "Batch：58 | Loss: 0.8618574738502502\n",
      "Batch：59 | Loss: 0.8598016500473022\n",
      "Batch：60 | Loss: 0.8551892042160034\n",
      "Batch：61 | Loss: 0.855035662651062\n",
      "Batch：62 | Loss: 0.8418907523155212\n",
      "Batch：63 | Loss: 0.8368960618972778\n",
      "Batch：64 | Loss: 0.8447203636169434\n",
      "Batch：65 | Loss: 0.837973952293396\n",
      "Batch：66 | Loss: 0.8293042182922363\n",
      "Batch：67 | Loss: 0.8267187476158142\n",
      "Batch：68 | Loss: 0.8317776322364807\n",
      "Batch：69 | Loss: 0.8146453499794006\n",
      "Batch：70 | Loss: 0.8110512495040894\n",
      "Batch：71 | Loss: 0.8132680058479309\n",
      "Batch：72 | Loss: 0.8012840151786804\n",
      "Batch：73 | Loss: 0.7914034724235535\n",
      "Batch：74 | Loss: 0.7924386262893677\n",
      "Batch：75 | Loss: 0.7994059920310974\n",
      "Batch：76 | Loss: 0.7763341665267944\n",
      "Batch：77 | Loss: 0.784263014793396\n",
      "Batch：78 | Loss: 0.8010278940200806\n",
      "Batch：79 | Loss: 0.7979947924613953\n",
      "Batch：80 | Loss: 0.7814949750900269\n",
      "Batch：81 | Loss: 0.7533886432647705\n",
      "Batch：82 | Loss: 0.732215404510498\n",
      "Batch：83 | Loss: 0.7257880568504333\n",
      "Batch：84 | Loss: 0.7825391888618469\n",
      "Batch：85 | Loss: 0.7476617097854614\n",
      "Batch：86 | Loss: 0.7331756353378296\n",
      "Batch：87 | Loss: 0.7306689620018005\n",
      "Batch：88 | Loss: 0.7210981249809265\n",
      "Batch：89 | Loss: 0.7215948700904846\n",
      "Batch：90 | Loss: 0.721940279006958\n",
      "Batch：91 | Loss: 0.7254024744033813\n",
      "Batch：92 | Loss: 0.7323933839797974\n",
      "Batch：93 | Loss: 0.7172985672950745\n",
      "Batch：94 | Loss: 0.6959121823310852\n",
      "Batch：95 | Loss: 0.7274425625801086\n",
      "Batch：96 | Loss: 0.7295019626617432\n",
      "Batch：97 | Loss: 0.727178692817688\n",
      "Batch：98 | Loss: 0.7170010209083557\n",
      "Batch：99 | Loss: 0.7107767462730408\n",
      "Batch：100 | Loss: 0.7017806172370911\n",
      "Batch：101 | Loss: 0.7176358103752136\n",
      "Batch：102 | Loss: 0.6847002506256104\n",
      "Batch：103 | Loss: 0.7152941226959229\n",
      "Batch：104 | Loss: 0.7042631506919861\n",
      "Batch：105 | Loss: 0.6818505525588989\n",
      "Batch：106 | Loss: 0.6926611065864563\n",
      "Batch：107 | Loss: 0.7182081341743469\n",
      "Batch：108 | Loss: 0.6702924966812134\n",
      "Batch：109 | Loss: 0.6715049743652344\n",
      "Batch：110 | Loss: 0.6743877530097961\n",
      "Batch：111 | Loss: 0.6658239364624023\n",
      "Batch：112 | Loss: 0.7066131234169006\n",
      "Batch：113 | Loss: 0.685071587562561\n",
      "Batch：114 | Loss: 0.6854732036590576\n",
      "Batch：115 | Loss: 0.6960250735282898\n",
      "Batch：116 | Loss: 0.7186479568481445\n",
      "Batch：117 | Loss: 0.6807751655578613\n",
      "Batch：118 | Loss: 0.668364942073822\n",
      "Batch：119 | Loss: 0.7084284424781799\n",
      "Batch：120 | Loss: 0.6760342717170715\n",
      "Batch：121 | Loss: 0.6606325507164001\n",
      "Batch：122 | Loss: 0.6574972867965698\n",
      "Batch：123 | Loss: 0.651746928691864\n",
      "Batch：124 | Loss: 0.6771038174629211\n",
      "Batch：125 | Loss: 0.6470462679862976\n",
      "Batch：126 | Loss: 0.6819511651992798\n",
      "Batch：127 | Loss: 0.6589314937591553\n",
      "Batch：128 | Loss: 0.6482642292976379\n",
      "Batch：129 | Loss: 0.6859278678894043\n",
      "Batch：130 | Loss: 0.6824869513511658\n",
      "Batch：131 | Loss: 0.642406165599823\n",
      "Batch：132 | Loss: 0.6662544012069702\n",
      "Batch：133 | Loss: 0.6496330499649048\n",
      "Batch：134 | Loss: 0.6628679037094116\n",
      "Batch：135 | Loss: 0.6349906325340271\n",
      "Batch：136 | Loss: 0.663963794708252\n",
      "Batch：137 | Loss: 0.6376813650131226\n",
      "Batch：138 | Loss: 0.6455156803131104\n",
      "Batch：139 | Loss: 0.6580803394317627\n",
      "Batch：140 | Loss: 0.6500080227851868\n",
      "Batch：141 | Loss: 0.6554880738258362\n",
      "Batch：142 | Loss: 0.6917762756347656\n",
      "Batch：143 | Loss: 0.6751099228858948\n",
      "Batch：144 | Loss: 0.629217267036438\n",
      "Batch：145 | Loss: 0.6110133528709412\n",
      "Batch：146 | Loss: 0.6299298405647278\n",
      "Batch：147 | Loss: 0.6313218474388123\n",
      "Batch：148 | Loss: 0.6665599942207336\n",
      "Batch：149 | Loss: 0.6351876854896545\n",
      "Batch：150 | Loss: 0.6243512034416199\n",
      "Batch：151 | Loss: 0.6040278673171997\n",
      "Batch：152 | Loss: 0.6358001828193665\n",
      "Batch：153 | Loss: 0.672209620475769\n",
      "Batch：154 | Loss: 0.6613248586654663\n",
      "Batch：155 | Loss: 0.6405786275863647\n",
      "Batch：156 | Loss: 0.6505694389343262\n",
      "Batch：157 | Loss: 0.6388722062110901\n",
      "Batch：158 | Loss: 0.6171392798423767\n",
      "Batch：159 | Loss: 0.634557843208313\n",
      "Batch：160 | Loss: 0.6628631353378296\n",
      "Batch：161 | Loss: 0.6412193179130554\n",
      "Batch：162 | Loss: 0.6298412084579468\n",
      "Batch：163 | Loss: 0.6325607299804688\n",
      "Batch：164 | Loss: 0.645219624042511\n",
      "Batch：165 | Loss: 0.6253270506858826\n",
      "Batch：166 | Loss: 0.6358400583267212\n",
      "Batch：167 | Loss: 0.6300091743469238\n",
      "Batch：168 | Loss: 0.6233909726142883\n",
      "Batch：169 | Loss: 0.6251309514045715\n",
      "Batch：170 | Loss: 0.6414684057235718\n",
      "Batch：171 | Loss: 0.6470129489898682\n",
      "Batch：172 | Loss: 0.6115993857383728\n",
      "Batch：173 | Loss: 0.6079874634742737\n",
      "Batch：174 | Loss: 0.6294540166854858\n",
      "Batch：175 | Loss: 0.6325799226760864\n",
      "Batch：176 | Loss: 0.6230184435844421\n",
      "Batch：177 | Loss: 0.6298904418945312\n",
      "Batch：178 | Loss: 0.6354494690895081\n",
      "Batch：179 | Loss: 0.6254714727401733\n",
      "Batch：180 | Loss: 0.6303574442863464\n",
      "Batch：181 | Loss: 0.6142852902412415\n",
      "Batch：182 | Loss: 0.620835542678833\n",
      "Batch：183 | Loss: 0.6335534453392029\n",
      "Batch：184 | Loss: 0.6207227110862732\n",
      "Batch：185 | Loss: 0.6102771162986755\n",
      "Batch：186 | Loss: 0.6181692481040955\n",
      "Batch：187 | Loss: 0.6297813653945923\n",
      "Batch：188 | Loss: 0.6068564057350159\n",
      "Batch：189 | Loss: 0.6248508095741272\n",
      "Batch：190 | Loss: 0.6059545278549194\n",
      "Batch：191 | Loss: 0.6196149587631226\n",
      "Batch：192 | Loss: 0.6431374549865723\n",
      "Batch：193 | Loss: 0.5953487753868103\n",
      "Batch：194 | Loss: 0.5949442386627197\n",
      "Batch：195 | Loss: 0.6295589208602905\n",
      "Batch：196 | Loss: 0.6125820875167847\n",
      "Batch：197 | Loss: 0.6127904057502747\n",
      "Batch：198 | Loss: 0.6133253574371338\n",
      "Batch：199 | Loss: 0.6188258528709412\n",
      "Batch：200 | Loss: 0.6323748826980591\n",
      "Batch：201 | Loss: 0.6131709218025208\n",
      "Batch：202 | Loss: 0.6221980452537537\n",
      "Batch：203 | Loss: 0.6189940571784973\n",
      "Batch：204 | Loss: 0.6085562109947205\n",
      "Batch：205 | Loss: 0.5981797575950623\n",
      "Batch：206 | Loss: 0.5915554761886597\n",
      "Batch：207 | Loss: 0.6227766275405884\n",
      "Batch：208 | Loss: 0.5790644288063049\n",
      "Batch：209 | Loss: 0.615338921546936\n",
      "Batch：210 | Loss: 0.6339663863182068\n",
      "Batch：211 | Loss: 0.5845257639884949\n",
      "Batch：212 | Loss: 0.5830930471420288\n",
      "Batch：213 | Loss: 0.6219351291656494\n",
      "Batch：214 | Loss: 0.5840643048286438\n",
      "Batch：215 | Loss: 0.6103984713554382\n",
      "Batch：216 | Loss: 0.5987514853477478\n",
      "Batch：217 | Loss: 0.6227090358734131\n",
      "Batch：218 | Loss: 0.6246328949928284\n",
      "Batch：219 | Loss: 0.5869426131248474\n",
      "Batch：220 | Loss: 0.5850170850753784\n",
      "Batch：221 | Loss: 0.635400116443634\n",
      "Batch：222 | Loss: 0.6219005584716797\n",
      "Batch：223 | Loss: 0.5823604464530945\n",
      "Batch：224 | Loss: 0.6027225852012634\n",
      "Batch：225 | Loss: 0.5909109115600586\n",
      "Batch：226 | Loss: 0.5934292078018188\n",
      "Batch：227 | Loss: 0.5951941013336182\n",
      "Batch：228 | Loss: 0.602276086807251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：229 | Loss: 0.5979296565055847\n",
      "Batch：230 | Loss: 0.6030871868133545\n",
      "Batch：231 | Loss: 0.6086776852607727\n",
      "Batch：232 | Loss: 0.6104727387428284\n",
      "Batch：233 | Loss: 0.5759015083312988\n",
      "Batch：234 | Loss: 0.6116357445716858\n",
      "Batch：235 | Loss: 0.6134580373764038\n",
      "Batch：236 | Loss: 0.6119598150253296\n",
      "Batch：237 | Loss: 0.6121341586112976\n",
      "Batch：238 | Loss: 0.5693818926811218\n",
      "Batch：239 | Loss: 0.5825315713882446\n",
      "Batch：240 | Loss: 0.5559849143028259\n",
      "Batch：241 | Loss: 0.5999267101287842\n",
      "Batch：242 | Loss: 0.600415825843811\n",
      "Batch：243 | Loss: 0.5857189893722534\n",
      "Batch：244 | Loss: 0.5993841290473938\n",
      "Batch：245 | Loss: 0.5880527496337891\n",
      "Batch：246 | Loss: 0.620638906955719\n",
      "Batch：247 | Loss: 0.6035984754562378\n",
      "Batch：248 | Loss: 0.5952376127243042\n",
      "Batch：249 | Loss: 0.6073822975158691\n",
      "Batch：250 | Loss: 0.6155564785003662\n",
      "Batch：251 | Loss: 0.5900826454162598\n",
      "Batch：252 | Loss: 0.6012860536575317\n",
      "Batch：253 | Loss: 0.586810827255249\n",
      "Batch：254 | Loss: 0.5885868668556213\n",
      "Batch：255 | Loss: 0.5845849514007568\n",
      "Batch：256 | Loss: 0.600989580154419\n",
      "Batch：257 | Loss: 0.5944011211395264\n",
      "Batch：258 | Loss: 0.58282870054245\n",
      "Batch：259 | Loss: 0.6137815713882446\n",
      "Batch：260 | Loss: 0.5923194289207458\n",
      "Batch：261 | Loss: 0.5624141097068787\n",
      "Batch：262 | Loss: 0.5866758227348328\n",
      "Batch：263 | Loss: 0.5894128084182739\n",
      "Batch：264 | Loss: 0.5884407758712769\n",
      "Batch：265 | Loss: 0.58542400598526\n",
      "Batch：266 | Loss: 0.5867401957511902\n",
      "Batch：267 | Loss: 0.5609786510467529\n",
      "Batch：268 | Loss: 0.5778833627700806\n",
      "Batch：269 | Loss: 0.5776457190513611\n",
      "Batch：270 | Loss: 0.5646964311599731\n",
      "Batch：271 | Loss: 0.5858764052391052\n",
      "Batch：272 | Loss: 0.581002414226532\n",
      "Batch：273 | Loss: 0.6001615524291992\n",
      "Batch：274 | Loss: 0.6004153490066528\n",
      "Batch：275 | Loss: 0.5931395888328552\n",
      "Batch：276 | Loss: 0.5496099591255188\n",
      "Batch：277 | Loss: 0.5987629890441895\n",
      "Batch：278 | Loss: 0.6111418604850769\n",
      "Batch：279 | Loss: 0.5659676194190979\n",
      "Batch：280 | Loss: 0.5826337933540344\n",
      "Batch：281 | Loss: 0.5705060958862305\n",
      "Batch：282 | Loss: 0.5857632756233215\n",
      "Batch：283 | Loss: 0.5625094771385193\n",
      "Batch：284 | Loss: 0.615933895111084\n",
      "Batch：285 | Loss: 0.5828129649162292\n",
      "Batch：286 | Loss: 0.6020739078521729\n",
      "Batch：287 | Loss: 0.5491639971733093\n",
      "Batch：288 | Loss: 0.5828260183334351\n",
      "Batch：289 | Loss: 0.5649002194404602\n",
      "Batch：290 | Loss: 0.592252254486084\n",
      "Batch：291 | Loss: 0.5951603651046753\n",
      "Batch：292 | Loss: 0.5729705691337585\n",
      "Batch：293 | Loss: 0.5466983914375305\n",
      "Batch：294 | Loss: 0.576080858707428\n",
      "Batch：295 | Loss: 0.5637754797935486\n",
      "Batch：296 | Loss: 0.5820578336715698\n",
      "Batch：297 | Loss: 0.5698238611221313\n",
      "Batch：298 | Loss: 0.5813769698143005\n",
      "Batch：299 | Loss: 0.587824285030365\n",
      "Batch：300 | Loss: 0.58653724193573\n",
      "Batch：301 | Loss: 0.5707274079322815\n",
      "Batch：302 | Loss: 0.588209867477417\n",
      "Batch：303 | Loss: 0.5790431499481201\n",
      "Batch：304 | Loss: 0.5773022174835205\n",
      "Batch：305 | Loss: 0.5739995241165161\n",
      "Batch：306 | Loss: 0.5738508105278015\n",
      "Batch：307 | Loss: 0.5845579504966736\n",
      "Batch：308 | Loss: 0.5655539035797119\n",
      "Batch：309 | Loss: 0.5789999961853027\n",
      "Batch：310 | Loss: 0.5800689458847046\n",
      "Batch：311 | Loss: 0.5999505519866943\n",
      "Batch：312 | Loss: 0.5261725783348083\n",
      "Batch：313 | Loss: 0.5529189109802246\n",
      "Batch：314 | Loss: 0.5575922727584839\n",
      "Batch：315 | Loss: 0.5623282194137573\n",
      "Batch：316 | Loss: 0.5687934756278992\n",
      "Batch：317 | Loss: 0.5801775455474854\n",
      "Batch：318 | Loss: 0.5521676540374756\n",
      "Batch：319 | Loss: 0.5824501514434814\n",
      "Batch：320 | Loss: 0.5623643398284912\n",
      "Batch：321 | Loss: 0.5562838315963745\n",
      "Batch：322 | Loss: 0.5514074563980103\n",
      "Batch：323 | Loss: 0.5921672582626343\n",
      "Batch：324 | Loss: 0.5472342371940613\n",
      "Batch：325 | Loss: 0.5405352115631104\n",
      "Batch：326 | Loss: 0.5728942155838013\n",
      "Batch：327 | Loss: 0.552361011505127\n",
      "Batch：328 | Loss: 0.5842021703720093\n",
      "Batch：329 | Loss: 0.534957766532898\n",
      "Batch：330 | Loss: 0.5533717274665833\n",
      "Batch：331 | Loss: 0.5441045761108398\n",
      "Batch：332 | Loss: 0.5752182006835938\n",
      "Batch：333 | Loss: 0.521966278553009\n",
      "Batch：334 | Loss: 0.5474565625190735\n",
      "Batch：335 | Loss: 0.5478054881095886\n",
      "Batch：336 | Loss: 0.5655511617660522\n",
      "Batch：337 | Loss: 0.5430482625961304\n",
      "Batch：338 | Loss: 0.5615879893302917\n",
      "Batch：339 | Loss: 0.5754753947257996\n",
      "Batch：340 | Loss: 0.5873154401779175\n",
      "Batch：341 | Loss: 0.5465957522392273\n",
      "Batch：342 | Loss: 0.5573025345802307\n",
      "Batch：343 | Loss: 0.5764899253845215\n",
      "Batch：344 | Loss: 0.5404680967330933\n",
      "Batch：345 | Loss: 0.5165489912033081\n",
      "Batch：346 | Loss: 0.5604080557823181\n",
      "Batch：347 | Loss: 0.5718047022819519\n",
      "Batch：348 | Loss: 0.5347945690155029\n",
      "Batch：349 | Loss: 0.5732210278511047\n",
      "Batch：350 | Loss: 0.5606866478919983\n",
      "Batch：351 | Loss: 0.5402479767799377\n",
      "Batch：352 | Loss: 0.5366117358207703\n",
      "Batch：353 | Loss: 0.546186625957489\n",
      "Batch：354 | Loss: 0.5393605828285217\n",
      "Batch：355 | Loss: 0.543495774269104\n",
      "Batch：356 | Loss: 0.5244706869125366\n",
      "Batch：357 | Loss: 0.5501368045806885\n",
      "Batch：358 | Loss: 0.5493730902671814\n",
      "Batch：359 | Loss: 0.5679379105567932\n",
      "Batch：360 | Loss: 0.5406948328018188\n",
      "Batch：361 | Loss: 0.5474403500556946\n",
      "Batch：362 | Loss: 0.5441133379936218\n",
      "Batch：363 | Loss: 0.5087225437164307\n",
      "Batch：364 | Loss: 0.5007138848304749\n",
      "Batch：365 | Loss: 0.5789705514907837\n",
      "Batch：366 | Loss: 0.5419842600822449\n",
      "Batch：367 | Loss: 0.5513741970062256\n",
      "Batch：368 | Loss: 0.5356903672218323\n",
      "Batch：369 | Loss: 0.5566145181655884\n",
      "Batch：370 | Loss: 0.5414979457855225\n",
      "Batch：371 | Loss: 0.520661473274231\n",
      "Batch：372 | Loss: 0.5241303443908691\n",
      "Batch：373 | Loss: 0.5518510937690735\n",
      "Batch：374 | Loss: 0.5590755939483643\n",
      "Batch：375 | Loss: 0.5328623056411743\n",
      "Batch：376 | Loss: 0.5528437495231628\n",
      "Batch：377 | Loss: 0.5448073744773865\n",
      "Batch：378 | Loss: 0.5345016121864319\n",
      "Batch：379 | Loss: 0.5454781651496887\n",
      "Batch：380 | Loss: 0.5455372929573059\n",
      "Batch：381 | Loss: 0.4963929355144501\n",
      "Batch：382 | Loss: 0.5437132120132446\n",
      "Batch：383 | Loss: 0.5761345028877258\n",
      "Batch：384 | Loss: 0.555569589138031\n",
      "Batch：385 | Loss: 0.529671847820282\n",
      "Batch：386 | Loss: 0.5589380860328674\n",
      "Batch：387 | Loss: 0.5288621187210083\n",
      "Batch：388 | Loss: 0.5455504655838013\n",
      "Batch：389 | Loss: 0.5609470009803772\n",
      "Batch：390 | Loss: 0.5489519834518433\n",
      "Batch：391 | Loss: 0.5405718684196472\n",
      "Batch：392 | Loss: 0.5697557926177979\n",
      "Batch：393 | Loss: 0.5497903823852539\n",
      "Batch：394 | Loss: 0.5482908487319946\n",
      "Batch：395 | Loss: 0.5166851878166199\n",
      "Batch：396 | Loss: 0.5188233256340027\n",
      "Batch：397 | Loss: 0.5294908881187439\n",
      "Batch：398 | Loss: 0.5188695192337036\n",
      "Batch：399 | Loss: 0.545868456363678\n",
      "Batch：400 | Loss: 0.5517051815986633\n",
      "Batch：401 | Loss: 0.5665298700332642\n",
      "Batch：402 | Loss: 0.5434603095054626\n",
      "Batch：403 | Loss: 0.510986864566803\n",
      "Batch：404 | Loss: 0.5397748947143555\n",
      "Batch：405 | Loss: 0.5254723429679871\n",
      "Batch：406 | Loss: 0.5538644790649414\n",
      "Batch：407 | Loss: 0.5490756034851074\n",
      "Batch：408 | Loss: 0.5082636475563049\n",
      "Batch：409 | Loss: 0.5383958220481873\n",
      "Batch：410 | Loss: 0.5474885702133179\n",
      "Batch：411 | Loss: 0.5489716529846191\n",
      "Batch：412 | Loss: 0.5368303656578064\n",
      "Batch：413 | Loss: 0.5432710647583008\n",
      "Batch：414 | Loss: 0.5356378555297852\n",
      "Batch：415 | Loss: 0.526324987411499\n",
      "Batch：416 | Loss: 0.5313548445701599\n",
      "Batch：417 | Loss: 0.528715968132019\n",
      "Batch：418 | Loss: 0.543251633644104\n",
      "Batch：419 | Loss: 0.5336010456085205\n",
      "Batch：420 | Loss: 0.5139836072921753\n",
      "Batch：421 | Loss: 0.5274158716201782\n",
      "Batch：422 | Loss: 0.5122676491737366\n",
      "Batch：423 | Loss: 0.5113123059272766\n",
      "Batch：424 | Loss: 0.533017098903656\n",
      "Batch：425 | Loss: 0.5375681519508362\n",
      "Batch：426 | Loss: 0.5442972779273987\n",
      "Batch：427 | Loss: 0.5458565354347229\n",
      "Batch：428 | Loss: 0.5198240280151367\n",
      "Batch：429 | Loss: 0.5230336785316467\n",
      "Batch：430 | Loss: 0.5411001443862915\n",
      "Batch：431 | Loss: 0.5183724164962769\n",
      "Batch：432 | Loss: 0.5373712182044983\n",
      "Batch：433 | Loss: 0.5432553887367249\n",
      "Batch：434 | Loss: 0.5335538387298584\n",
      "Batch：435 | Loss: 0.5416478514671326\n",
      "Batch：436 | Loss: 0.5443015098571777\n",
      "Batch：437 | Loss: 0.529747486114502\n",
      "Batch：438 | Loss: 0.5391916632652283\n",
      "Batch：439 | Loss: 0.5500911474227905\n",
      "Batch：440 | Loss: 0.5171590447425842\n",
      "Batch：441 | Loss: 0.5144274234771729\n",
      "Batch：442 | Loss: 0.5121744871139526\n",
      "Batch：443 | Loss: 0.531715452671051\n",
      "Batch：444 | Loss: 0.5355601906776428\n",
      "Batch：445 | Loss: 0.5221821069717407\n",
      "Batch：446 | Loss: 0.5224218964576721\n",
      "Batch：447 | Loss: 0.5116788744926453\n",
      "Batch：448 | Loss: 0.5327858924865723\n",
      "Batch：449 | Loss: 0.5127018690109253\n",
      "Batch：450 | Loss: 0.5051087737083435\n",
      "Batch：451 | Loss: 0.539181649684906\n",
      "Batch：452 | Loss: 0.5481619238853455\n",
      "Batch：453 | Loss: 0.514612078666687\n",
      "Batch：454 | Loss: 0.5285899043083191\n",
      "Batch：455 | Loss: 0.5236996412277222\n",
      "Batch：456 | Loss: 0.5114073157310486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：457 | Loss: 0.5191094279289246\n",
      "Batch：458 | Loss: 0.5086175203323364\n",
      "Batch：459 | Loss: 0.49493408203125\n",
      "Batch：460 | Loss: 0.5203951597213745\n",
      "Batch：461 | Loss: 0.5394601225852966\n",
      "Batch：462 | Loss: 0.5152324438095093\n",
      "Batch：463 | Loss: 0.5145617127418518\n",
      "Batch：464 | Loss: 0.5167538523674011\n",
      "Batch：465 | Loss: 0.4810032844543457\n",
      "Batch：466 | Loss: 0.5065934658050537\n",
      "Batch：467 | Loss: 0.5212317109107971\n",
      "Batch：468 | Loss: 0.5207380056381226\n",
      "Batch：469 | Loss: 0.519683837890625\n",
      "Batch：470 | Loss: 0.5297590494155884\n",
      "Batch：471 | Loss: 0.5312735438346863\n",
      "Batch：472 | Loss: 0.5055584907531738\n",
      "Batch：473 | Loss: 0.5427882671356201\n",
      "Batch：474 | Loss: 0.5000283122062683\n",
      "Batch：475 | Loss: 0.5273486971855164\n",
      "Batch：476 | Loss: 0.5110967755317688\n",
      "Batch：477 | Loss: 0.5111074447631836\n",
      "Batch：478 | Loss: 0.5242206454277039\n",
      "Batch：479 | Loss: 0.5102086663246155\n",
      "Batch：480 | Loss: 0.5098307728767395\n",
      "Batch：481 | Loss: 0.5120172500610352\n",
      "Batch：482 | Loss: 0.5092320442199707\n",
      "Batch：483 | Loss: 0.5319249629974365\n",
      "Batch：484 | Loss: 0.5248464345932007\n",
      "Batch：485 | Loss: 0.5084869861602783\n",
      "Batch：486 | Loss: 0.5084353089332581\n",
      "Batch：487 | Loss: 0.5227224230766296\n",
      "Batch：488 | Loss: 0.5225237607955933\n",
      "Batch：489 | Loss: 0.5222988724708557\n",
      "Batch：490 | Loss: 0.5010837316513062\n",
      "Batch：491 | Loss: 0.5129283666610718\n",
      "Batch：492 | Loss: 0.49654850363731384\n",
      "Batch：493 | Loss: 0.5011661648750305\n",
      "Batch：494 | Loss: 0.49230602383613586\n",
      "Batch：495 | Loss: 0.4981061518192291\n",
      "Batch：496 | Loss: 0.5201826691627502\n",
      "Batch：497 | Loss: 0.48858869075775146\n",
      "Batch：498 | Loss: 0.4875777065753937\n",
      "Batch：499 | Loss: 0.5005588531494141\n",
      "Batch：500 | Loss: 0.5097915530204773\n",
      "Batch：501 | Loss: 0.5270315408706665\n",
      "Batch：502 | Loss: 0.49390655755996704\n",
      "Batch：503 | Loss: 0.494121789932251\n",
      "Batch：504 | Loss: 0.5003172755241394\n",
      "Batch：505 | Loss: 0.5294082164764404\n",
      "Batch：506 | Loss: 0.5040010213851929\n",
      "Batch：507 | Loss: 0.5333004593849182\n",
      "Batch：508 | Loss: 0.5029380917549133\n",
      "Batch：509 | Loss: 0.49680089950561523\n",
      "Batch：510 | Loss: 0.5196022391319275\n",
      "Batch：511 | Loss: 0.5252925753593445\n",
      "Batch：512 | Loss: 0.506367564201355\n",
      "Batch：513 | Loss: 0.47869575023651123\n",
      "Batch：514 | Loss: 0.49835124611854553\n",
      "Batch：515 | Loss: 0.49520793557167053\n",
      "Batch：516 | Loss: 0.5307623147964478\n",
      "Batch：517 | Loss: 0.5140897035598755\n",
      "Batch：518 | Loss: 0.48752787709236145\n",
      "Batch：519 | Loss: 0.5052791833877563\n",
      "Batch：520 | Loss: 0.5041724443435669\n",
      "Batch：521 | Loss: 0.5039835572242737\n",
      "Batch：522 | Loss: 0.510384202003479\n",
      "Batch：523 | Loss: 0.5112706422805786\n",
      "Batch：524 | Loss: 0.5141222476959229\n",
      "Batch：525 | Loss: 0.5128511786460876\n",
      "Batch：526 | Loss: 0.5196751356124878\n",
      "Batch：527 | Loss: 0.5005185604095459\n",
      "Batch：528 | Loss: 0.49197614192962646\n",
      "Batch：529 | Loss: 0.4961055517196655\n",
      "Batch：530 | Loss: 0.49481672048568726\n",
      "Batch：531 | Loss: 0.5012879371643066\n",
      "Batch：532 | Loss: 0.49474990367889404\n",
      "Batch：533 | Loss: 0.5199354887008667\n",
      "Batch：534 | Loss: 0.5098169445991516\n",
      "Batch：535 | Loss: 0.48152899742126465\n",
      "Batch：536 | Loss: 0.5193870663642883\n",
      "Batch：537 | Loss: 0.5254222750663757\n",
      "Batch：538 | Loss: 0.4792664349079132\n",
      "Batch：539 | Loss: 0.4959104061126709\n",
      "Batch：540 | Loss: 0.47927603125572205\n",
      "Batch：541 | Loss: 0.49376463890075684\n",
      "Batch：542 | Loss: 0.501535177230835\n",
      "Batch：543 | Loss: 0.5001027584075928\n",
      "Batch：544 | Loss: 0.4793354570865631\n",
      "Batch：545 | Loss: 0.49360978603363037\n",
      "Batch：546 | Loss: 0.5021995306015015\n",
      "Batch：547 | Loss: 0.477658212184906\n",
      "Batch：548 | Loss: 0.49603471159935\n",
      "Batch：549 | Loss: 0.5004152655601501\n",
      "Batch：550 | Loss: 0.5008620619773865\n",
      "Batch：551 | Loss: 0.4907819330692291\n",
      "Batch：552 | Loss: 0.5008071660995483\n",
      "Batch：553 | Loss: 0.49460676312446594\n",
      "Batch：554 | Loss: 0.5224242210388184\n",
      "Batch：555 | Loss: 0.5037856101989746\n",
      "Batch：556 | Loss: 0.5034189224243164\n",
      "Batch：557 | Loss: 0.47976216673851013\n",
      "Batch：558 | Loss: 0.49246495962142944\n",
      "Batch：559 | Loss: 0.4876050651073456\n",
      "Batch：560 | Loss: 0.4748072326183319\n",
      "Batch：561 | Loss: 0.49063190817832947\n",
      "Batch：562 | Loss: 0.494392991065979\n",
      "Batch：563 | Loss: 0.4975763261318207\n",
      "Batch：564 | Loss: 0.4609736204147339\n",
      "Batch：565 | Loss: 0.5023061633110046\n",
      "Batch：566 | Loss: 0.5065415501594543\n",
      "Batch：567 | Loss: 0.4817635118961334\n",
      "Batch：568 | Loss: 0.49732106924057007\n",
      "Batch：569 | Loss: 0.48430711030960083\n",
      "Batch：570 | Loss: 0.5179974436759949\n",
      "Batch：571 | Loss: 0.4905984103679657\n",
      "Batch：572 | Loss: 0.4906265437602997\n",
      "Batch：573 | Loss: 0.4645881652832031\n",
      "Batch：574 | Loss: 0.504170298576355\n",
      "Batch：575 | Loss: 0.5068960189819336\n",
      "Batch：576 | Loss: 0.514727771282196\n",
      "Batch：577 | Loss: 0.4669904410839081\n",
      "Batch：578 | Loss: 0.49197614192962646\n",
      "Batch：579 | Loss: 0.46942174434661865\n",
      "Batch：580 | Loss: 0.491548091173172\n",
      "Batch：581 | Loss: 0.4754200875759125\n",
      "Batch：582 | Loss: 0.4970846176147461\n",
      "Batch：583 | Loss: 0.5092883110046387\n",
      "Batch：584 | Loss: 0.4766021966934204\n",
      "Batch：585 | Loss: 0.48925963044166565\n",
      "Batch：586 | Loss: 0.4834662079811096\n",
      "Batch：587 | Loss: 0.4648575484752655\n",
      "Batch：588 | Loss: 0.4907204806804657\n",
      "Batch：589 | Loss: 0.4872484505176544\n",
      "Batch：590 | Loss: 0.46900659799575806\n",
      "Batch：591 | Loss: 0.4736117422580719\n",
      "Batch：592 | Loss: 0.5099988579750061\n",
      "Batch：593 | Loss: 0.48758941888809204\n",
      "Batch：594 | Loss: 0.49065518379211426\n",
      "Batch：595 | Loss: 0.48098787665367126\n",
      "Batch：596 | Loss: 0.47734329104423523\n",
      "Batch：597 | Loss: 0.4764550030231476\n",
      "Batch：598 | Loss: 0.5049890875816345\n",
      "Batch：599 | Loss: 0.49709975719451904\n",
      "Batch：600 | Loss: 0.46103623509407043\n",
      "Batch：601 | Loss: 0.5161002278327942\n",
      "Batch：602 | Loss: 0.47774967551231384\n",
      "Batch：603 | Loss: 0.4855535924434662\n",
      "Batch：604 | Loss: 0.4653906226158142\n",
      "Batch：605 | Loss: 0.4761897623538971\n",
      "Batch：606 | Loss: 0.4617764353752136\n",
      "Batch：607 | Loss: 0.4925009608268738\n",
      "Batch：608 | Loss: 0.4732629656791687\n",
      "Batch：609 | Loss: 0.471184104681015\n",
      "Batch：610 | Loss: 0.4612412750720978\n",
      "Batch：611 | Loss: 0.4942178428173065\n",
      "Batch：612 | Loss: 0.4686123728752136\n",
      "Batch：613 | Loss: 0.48451387882232666\n",
      "Batch：614 | Loss: 0.4822961390018463\n",
      "Batch：615 | Loss: 0.49719810485839844\n",
      "Batch：616 | Loss: 0.4895724952220917\n",
      "Batch：617 | Loss: 0.49388134479522705\n",
      "Batch：618 | Loss: 0.4857054650783539\n",
      "Batch：619 | Loss: 0.5111544728279114\n",
      "Batch：620 | Loss: 0.48338523507118225\n",
      "Batch：621 | Loss: 0.4832729399204254\n",
      "Batch：622 | Loss: 0.5180298686027527\n",
      "Batch：623 | Loss: 0.4828960597515106\n",
      "Batch：624 | Loss: 0.49976858496665955\n",
      "Batch：625 | Loss: 0.49360203742980957\n",
      "Batch：626 | Loss: 0.477613240480423\n",
      "Batch：627 | Loss: 0.4551525413990021\n",
      "Batch：628 | Loss: 0.48789697885513306\n",
      "Batch：629 | Loss: 0.4560454189777374\n",
      "Batch：630 | Loss: 0.4633741080760956\n",
      "Batch：631 | Loss: 0.45587193965911865\n",
      "Batch：632 | Loss: 0.5142393112182617\n",
      "Batch：633 | Loss: 0.45023828744888306\n",
      "Batch：634 | Loss: 0.45351696014404297\n",
      "Batch：635 | Loss: 0.4740355610847473\n",
      "Batch：636 | Loss: 0.4666967988014221\n",
      "Batch：637 | Loss: 0.48568880558013916\n",
      "Batch：638 | Loss: 0.49119833111763\n",
      "Batch：639 | Loss: 0.481105774641037\n",
      "Batch：640 | Loss: 0.4712386727333069\n",
      "Batch：641 | Loss: 0.4769754707813263\n",
      "Batch：642 | Loss: 0.4752110540866852\n",
      "Batch：643 | Loss: 0.4872507154941559\n",
      "Batch：644 | Loss: 0.5059008598327637\n",
      "Batch：645 | Loss: 0.47491586208343506\n",
      "Batch：646 | Loss: 0.4701881408691406\n",
      "Batch：647 | Loss: 0.48969775438308716\n",
      "Batch：648 | Loss: 0.48722952604293823\n",
      "Batch：649 | Loss: 0.46382755041122437\n",
      "Batch：650 | Loss: 0.4643280804157257\n",
      "Batch：651 | Loss: 0.47332650423049927\n",
      "Batch：652 | Loss: 0.4787865877151489\n",
      "Batch：653 | Loss: 0.47953617572784424\n",
      "Batch：654 | Loss: 0.5026715993881226\n",
      "Batch：655 | Loss: 0.4639868438243866\n",
      "Batch：656 | Loss: 0.4771796762943268\n",
      "Batch：657 | Loss: 0.43854406476020813\n",
      "Batch：658 | Loss: 0.45026370882987976\n",
      "Batch：659 | Loss: 0.4665978252887726\n",
      "Batch：660 | Loss: 0.45963385701179504\n",
      "Batch：661 | Loss: 0.4491422474384308\n",
      "Batch：662 | Loss: 0.4847220480442047\n",
      "Batch：663 | Loss: 0.4521220624446869\n",
      "Batch：664 | Loss: 0.4680284857749939\n",
      "Batch：665 | Loss: 0.4656848907470703\n",
      "Batch：666 | Loss: 0.49000608921051025\n",
      "Batch：667 | Loss: 0.473162442445755\n",
      "Batch：668 | Loss: 0.4751116633415222\n",
      "Batch：669 | Loss: 0.47526463866233826\n",
      "Batch：670 | Loss: 0.4684641361236572\n",
      "Batch：671 | Loss: 0.4731884002685547\n",
      "Batch：672 | Loss: 0.45435938239097595\n",
      "Batch：673 | Loss: 0.4627547264099121\n",
      "Batch：674 | Loss: 0.48312872648239136\n",
      "Batch：675 | Loss: 0.4557562470436096\n",
      "Batch：676 | Loss: 0.4711097776889801\n",
      "Batch：677 | Loss: 0.4699274003505707\n",
      "Batch：678 | Loss: 0.4794321358203888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：679 | Loss: 0.4898419678211212\n",
      "Batch：680 | Loss: 0.4430593252182007\n",
      "Batch：681 | Loss: 0.42987191677093506\n",
      "Batch：682 | Loss: 0.46600544452667236\n",
      "Batch：683 | Loss: 0.4777469038963318\n",
      "Batch：684 | Loss: 0.4810750186443329\n",
      "Batch：685 | Loss: 0.45145025849342346\n",
      "Batch：686 | Loss: 0.4679495096206665\n",
      "Batch：687 | Loss: 0.46108654141426086\n",
      "Batch：688 | Loss: 0.4676845669746399\n",
      "Batch：689 | Loss: 0.46208614110946655\n",
      "Batch：690 | Loss: 0.4525373578071594\n",
      "Batch：691 | Loss: 0.4554130733013153\n",
      "Batch：692 | Loss: 0.47062498331069946\n",
      "Batch：693 | Loss: 0.4698718190193176\n",
      "Batch：694 | Loss: 0.4503346383571625\n",
      "Batch：695 | Loss: 0.4542345404624939\n",
      "Batch：696 | Loss: 0.4530605375766754\n",
      "Batch：697 | Loss: 0.4848295748233795\n",
      "Batch：698 | Loss: 0.4368501305580139\n",
      "Batch：699 | Loss: 0.4644647538661957\n",
      "Batch：700 | Loss: 0.4477221965789795\n",
      "Batch：701 | Loss: 0.46524015069007874\n",
      "Batch：702 | Loss: 0.4589376449584961\n",
      "Batch：703 | Loss: 0.4716220200061798\n",
      "Batch：704 | Loss: 0.45000454783439636\n",
      "Batch：705 | Loss: 0.45676282048225403\n",
      "Batch：706 | Loss: 0.44871291518211365\n",
      "Batch：707 | Loss: 0.46501487493515015\n",
      "Batch：708 | Loss: 0.45189714431762695\n",
      "Batch：709 | Loss: 0.47821900248527527\n",
      "Batch：710 | Loss: 0.4565495252609253\n",
      "Batch：711 | Loss: 0.42554745078086853\n",
      "Batch：712 | Loss: 0.48486945033073425\n",
      "Batch：713 | Loss: 0.43783804774284363\n",
      "Batch：714 | Loss: 0.48020756244659424\n",
      "Batch：715 | Loss: 0.45615196228027344\n",
      "Batch：716 | Loss: 0.4505700170993805\n",
      "Batch：717 | Loss: 0.44256657361984253\n",
      "Batch：718 | Loss: 0.457868754863739\n",
      "Batch：719 | Loss: 0.4563949406147003\n",
      "Batch：720 | Loss: 0.44484037160873413\n",
      "Batch：721 | Loss: 0.44323238730430603\n",
      "Batch：722 | Loss: 0.43324702978134155\n",
      "Batch：723 | Loss: 0.4476434588432312\n",
      "Batch：724 | Loss: 0.45276880264282227\n",
      "Batch：725 | Loss: 0.4578826427459717\n",
      "Batch：726 | Loss: 0.44439616799354553\n",
      "Batch：727 | Loss: 0.4365267753601074\n",
      "Batch：728 | Loss: 0.4739549458026886\n",
      "Batch：729 | Loss: 0.454397588968277\n",
      "Batch：730 | Loss: 0.4395638108253479\n",
      "Batch：731 | Loss: 0.44664812088012695\n",
      "Batch：732 | Loss: 0.4591240882873535\n",
      "Batch：733 | Loss: 0.4713001251220703\n",
      "Batch：734 | Loss: 0.4711607098579407\n",
      "Batch：735 | Loss: 0.48043498396873474\n",
      "Batch：736 | Loss: 0.44763094186782837\n",
      "Batch：737 | Loss: 0.4347473978996277\n",
      "Batch：738 | Loss: 0.4651975929737091\n",
      "Batch：739 | Loss: 0.4402470290660858\n",
      "Batch：740 | Loss: 0.42576512694358826\n",
      "Batch：741 | Loss: 0.43480825424194336\n",
      "Batch：742 | Loss: 0.44205930829048157\n",
      "Batch：743 | Loss: 0.4647919535636902\n",
      "Batch：744 | Loss: 0.44974756240844727\n",
      "Batch：745 | Loss: 0.46197375655174255\n",
      "Batch：746 | Loss: 0.4597332179546356\n",
      "Batch：747 | Loss: 0.45100975036621094\n",
      "Batch：748 | Loss: 0.45187482237815857\n",
      "Batch：749 | Loss: 0.44393888115882874\n",
      "Batch：750 | Loss: 0.423137903213501\n",
      "Batch：751 | Loss: 0.4498010277748108\n",
      "Batch：752 | Loss: 0.42223596572875977\n",
      "Batch：753 | Loss: 0.44372013211250305\n",
      "Batch：754 | Loss: 0.45137718319892883\n",
      "Batch：755 | Loss: 0.45601505041122437\n",
      "Batch：756 | Loss: 0.4684292674064636\n",
      "Batch：757 | Loss: 0.4641536772251129\n",
      "Batch：758 | Loss: 0.4410318434238434\n",
      "Batch：759 | Loss: 0.4531934857368469\n",
      "Batch：760 | Loss: 0.4737807512283325\n",
      "Batch：761 | Loss: 0.4696035385131836\n",
      "Batch：762 | Loss: 0.44220271706581116\n",
      "Batch：763 | Loss: 0.43682730197906494\n",
      "Batch：764 | Loss: 0.47481411695480347\n",
      "Batch：765 | Loss: 0.43627962470054626\n",
      "Batch：766 | Loss: 0.4830769896507263\n",
      "Batch：767 | Loss: 0.4333260953426361\n",
      "Batch：768 | Loss: 0.4454823434352875\n",
      "Batch：769 | Loss: 0.45868805050849915\n",
      "Batch：770 | Loss: 0.4480404555797577\n",
      "Batch：771 | Loss: 0.43923094868659973\n",
      "Batch：772 | Loss: 0.42321234941482544\n",
      "Batch：773 | Loss: 0.4563719928264618\n",
      "Batch：774 | Loss: 0.44068416953086853\n",
      "Batch：775 | Loss: 0.43992534279823303\n",
      "Batch：776 | Loss: 0.4538488984107971\n",
      "Batch：777 | Loss: 0.4485926032066345\n",
      "Batch：778 | Loss: 0.4334131181240082\n",
      "Batch：779 | Loss: 0.4502246081829071\n",
      "Batch：780 | Loss: 0.4130572974681854\n",
      "Batch：781 | Loss: 0.44489750266075134\n",
      "Batch：782 | Loss: 0.4339565932750702\n",
      "Batch：783 | Loss: 0.4191249907016754\n",
      "Batch：784 | Loss: 0.44480136036872864\n",
      "Batch：785 | Loss: 0.41518500447273254\n",
      "Batch：786 | Loss: 0.4659532308578491\n",
      "Batch：787 | Loss: 0.43674567341804504\n",
      "Batch：788 | Loss: 0.4313780963420868\n",
      "Batch：789 | Loss: 0.4636395573616028\n",
      "Batch：790 | Loss: 0.44343945384025574\n",
      "Batch：791 | Loss: 0.4649946987628937\n",
      "Batch：792 | Loss: 0.41268301010131836\n",
      "Batch：793 | Loss: 0.42312246561050415\n",
      "Batch：794 | Loss: 0.4487263858318329\n",
      "Batch：795 | Loss: 0.46950504183769226\n",
      "Batch：796 | Loss: 0.4284481108188629\n",
      "Batch：797 | Loss: 0.43749675154685974\n",
      "Batch：798 | Loss: 0.4584493637084961\n",
      "Batch：799 | Loss: 0.43043211102485657\n",
      "Batch：800 | Loss: 0.4192997217178345\n",
      "Batch：801 | Loss: 0.42790332436561584\n",
      "Batch：802 | Loss: 0.4308303892612457\n",
      "Batch：803 | Loss: 0.4615801274776459\n",
      "Batch：804 | Loss: 0.4632391631603241\n",
      "Batch：805 | Loss: 0.42640623450279236\n",
      "Batch：806 | Loss: 0.41976961493492126\n",
      "Batch：807 | Loss: 0.4448031485080719\n",
      "Batch：808 | Loss: 0.4288649559020996\n",
      "Batch：809 | Loss: 0.4409647583961487\n",
      "Batch：810 | Loss: 0.43513166904449463\n",
      "Batch：811 | Loss: 0.4281975328922272\n",
      "Batch：812 | Loss: 0.43901097774505615\n",
      "Batch：813 | Loss: 0.4445945918560028\n",
      "Batch：814 | Loss: 0.4499310553073883\n",
      "Batch：815 | Loss: 0.459343820810318\n",
      "Batch：816 | Loss: 0.42711034417152405\n",
      "Batch：817 | Loss: 0.4513168931007385\n",
      "Batch：818 | Loss: 0.44127964973449707\n",
      "Batch：819 | Loss: 0.42443281412124634\n",
      "Batch：820 | Loss: 0.43287670612335205\n",
      "Batch：821 | Loss: 0.4250846207141876\n",
      "Batch：822 | Loss: 0.43777644634246826\n",
      "Batch：823 | Loss: 0.4305056929588318\n",
      "Batch：824 | Loss: 0.4272002577781677\n",
      "Batch：825 | Loss: 0.43301212787628174\n",
      "Batch：826 | Loss: 0.42840346693992615\n",
      "Batch：827 | Loss: 0.43316560983657837\n",
      "Batch：828 | Loss: 0.44029897451400757\n",
      "Batch：829 | Loss: 0.4373862147331238\n",
      "Batch：830 | Loss: 0.43167996406555176\n",
      "Batch：831 | Loss: 0.46743232011795044\n",
      "Batch：832 | Loss: 0.4310884177684784\n",
      "Batch：833 | Loss: 0.4263871908187866\n",
      "Batch：834 | Loss: 0.43878304958343506\n",
      "Batch：835 | Loss: 0.43719786405563354\n",
      "Batch：836 | Loss: 0.46009334921836853\n",
      "Batch：837 | Loss: 0.43545329570770264\n",
      "Batch：838 | Loss: 0.433595210313797\n",
      "Batch：839 | Loss: 0.4315735697746277\n",
      "Batch：840 | Loss: 0.41798070073127747\n",
      "Batch：841 | Loss: 0.4395085275173187\n",
      "Batch：842 | Loss: 0.45060622692108154\n",
      "Batch：843 | Loss: 0.4379044473171234\n",
      "Batch：844 | Loss: 0.4557036757469177\n",
      "Batch：845 | Loss: 0.4335552453994751\n",
      "Batch：846 | Loss: 0.46189600229263306\n",
      "Batch：847 | Loss: 0.41526472568511963\n",
      "Batch：848 | Loss: 0.449442982673645\n",
      "Batch：849 | Loss: 0.43049654364585876\n",
      "Batch：850 | Loss: 0.41808557510375977\n",
      "Batch：851 | Loss: 0.4105866551399231\n",
      "Batch：852 | Loss: 0.4491022825241089\n",
      "Batch：853 | Loss: 0.4293062388896942\n",
      "Batch：854 | Loss: 0.42415180802345276\n",
      "Batch：855 | Loss: 0.42589566111564636\n",
      "Batch：856 | Loss: 0.4318413734436035\n",
      "Batch：857 | Loss: 0.4376061260700226\n",
      "Batch：858 | Loss: 0.43396875262260437\n",
      "Batch：859 | Loss: 0.4314495325088501\n",
      "Batch：860 | Loss: 0.4220050275325775\n",
      "Batch：861 | Loss: 0.42918774485588074\n",
      "Batch：862 | Loss: 0.41043975949287415\n",
      "Batch：863 | Loss: 0.45001742243766785\n",
      "Batch：864 | Loss: 0.4452063739299774\n",
      "Batch：865 | Loss: 0.41472476720809937\n",
      "Batch：866 | Loss: 0.40284407138824463\n",
      "Batch：867 | Loss: 0.44021153450012207\n",
      "Batch：868 | Loss: 0.4533310830593109\n",
      "Batch：869 | Loss: 0.4330219626426697\n",
      "Batch：870 | Loss: 0.429934561252594\n",
      "Batch：871 | Loss: 0.4249343276023865\n",
      "Batch：872 | Loss: 0.4470173418521881\n",
      "Batch：873 | Loss: 0.4133368730545044\n",
      "Batch：874 | Loss: 0.43417251110076904\n",
      "Batch：875 | Loss: 0.44071638584136963\n",
      "Batch：876 | Loss: 0.41240042448043823\n",
      "Batch：877 | Loss: 0.42477384209632874\n",
      "Batch：878 | Loss: 0.4181787073612213\n",
      "Batch：879 | Loss: 0.4347342550754547\n",
      "Batch：880 | Loss: 0.41637304425239563\n",
      "Batch：881 | Loss: 0.43194490671157837\n",
      "Batch：882 | Loss: 0.4458337724208832\n",
      "Batch：883 | Loss: 0.404314249753952\n",
      "Batch：884 | Loss: 0.4096892476081848\n",
      "Batch：885 | Loss: 0.4302234947681427\n",
      "Batch：886 | Loss: 0.41040152311325073\n",
      "Batch：887 | Loss: 0.4267904460430145\n",
      "Batch：888 | Loss: 0.4165622889995575\n",
      "Batch：889 | Loss: 0.4235934913158417\n",
      "Batch：890 | Loss: 0.448701411485672\n",
      "Batch：891 | Loss: 0.4226802885532379\n",
      "Batch：892 | Loss: 0.3830917477607727\n",
      "Batch：893 | Loss: 0.42337357997894287\n",
      "Batch：894 | Loss: 0.412823885679245\n",
      "Batch：895 | Loss: 0.40671369433403015\n",
      "Batch：896 | Loss: 0.40358543395996094\n",
      "Batch：897 | Loss: 0.4069339632987976\n",
      "Batch：898 | Loss: 0.43341609835624695\n",
      "Batch：899 | Loss: 0.43123966455459595\n",
      "Batch：900 | Loss: 0.43146881461143494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：901 | Loss: 0.42370492219924927\n",
      "Batch：902 | Loss: 0.3964269459247589\n",
      "Batch：903 | Loss: 0.43700385093688965\n",
      "Batch：904 | Loss: 0.40931737422943115\n",
      "Batch：905 | Loss: 0.4212374985218048\n",
      "Batch：906 | Loss: 0.4109145402908325\n",
      "Batch：907 | Loss: 0.40279126167297363\n",
      "Batch：908 | Loss: 0.43291234970092773\n",
      "Batch：909 | Loss: 0.41975006461143494\n",
      "Batch：910 | Loss: 0.41169074177742004\n",
      "Batch：911 | Loss: 0.42123839259147644\n",
      "Batch：912 | Loss: 0.41586023569107056\n",
      "Batch：913 | Loss: 0.38403743505477905\n",
      "Batch：914 | Loss: 0.4149063229560852\n",
      "Batch：915 | Loss: 0.4227246940135956\n",
      "Batch：916 | Loss: 0.413831502199173\n",
      "Batch：917 | Loss: 0.4056617021560669\n",
      "Batch：918 | Loss: 0.4051320254802704\n",
      "Batch：919 | Loss: 0.4147071838378906\n",
      "Batch：920 | Loss: 0.44267821311950684\n",
      "Batch：921 | Loss: 0.40124088525772095\n",
      "Batch：922 | Loss: 0.4161314368247986\n",
      "Batch：923 | Loss: 0.41838133335113525\n",
      "Batch：924 | Loss: 0.4182308614253998\n",
      "Batch：925 | Loss: 0.4141588509082794\n",
      "Batch：926 | Loss: 0.4290342926979065\n",
      "Batch：927 | Loss: 0.40909698605537415\n",
      "Batch：928 | Loss: 0.41926661133766174\n",
      "Batch：929 | Loss: 0.4384731352329254\n",
      "Batch：930 | Loss: 0.41971537470817566\n",
      "Batch：931 | Loss: 0.4162750542163849\n",
      "Batch：932 | Loss: 0.4078746736049652\n",
      "Batch：933 | Loss: 0.4085642099380493\n",
      "Batch：934 | Loss: 0.4233952462673187\n",
      "Batch：935 | Loss: 0.4180282652378082\n",
      "Batch：936 | Loss: 0.40178409218788147\n",
      "Batch：937 | Loss: 0.41292619705200195\n",
      "Batch：938 | Loss: 0.4190945625305176\n",
      "Batch：939 | Loss: 0.4274773597717285\n",
      "Batch：940 | Loss: 0.4100824296474457\n",
      "Batch：941 | Loss: 0.4254629611968994\n",
      "Batch：942 | Loss: 0.4051936864852905\n",
      "Batch：943 | Loss: 0.41253554821014404\n",
      "Batch：944 | Loss: 0.40982532501220703\n",
      "Batch：945 | Loss: 0.4124414920806885\n",
      "Batch：946 | Loss: 0.42215070128440857\n",
      "Batch：947 | Loss: 0.4176020324230194\n",
      "Batch：948 | Loss: 0.43047505617141724\n",
      "Batch：949 | Loss: 0.41114363074302673\n",
      "Batch：950 | Loss: 0.4249461889266968\n",
      "Batch：951 | Loss: 0.4053539037704468\n",
      "Batch：952 | Loss: 0.40210074186325073\n",
      "Batch：953 | Loss: 0.4107111096382141\n",
      "Batch：954 | Loss: 0.42299383878707886\n",
      "Batch：955 | Loss: 0.4198915958404541\n",
      "Batch：956 | Loss: 0.4157065451145172\n",
      "Batch：957 | Loss: 0.40793824195861816\n",
      "Batch：958 | Loss: 0.3868386149406433\n",
      "Batch：959 | Loss: 0.41221028566360474\n",
      "Batch：960 | Loss: 0.3856390416622162\n",
      "Batch：961 | Loss: 0.41918855905532837\n",
      "Batch：962 | Loss: 0.39074888825416565\n",
      "Batch：963 | Loss: 0.4183151125907898\n",
      "Batch：964 | Loss: 0.4078255295753479\n",
      "Batch：965 | Loss: 0.4107532501220703\n",
      "Batch：966 | Loss: 0.4072859585285187\n",
      "Batch：967 | Loss: 0.39835935831069946\n",
      "Batch：968 | Loss: 0.39288321137428284\n",
      "Batch：969 | Loss: 0.40615782141685486\n",
      "Batch：970 | Loss: 0.4209306240081787\n",
      "Batch：971 | Loss: 0.3879900574684143\n",
      "Batch：972 | Loss: 0.42121535539627075\n",
      "Batch：973 | Loss: 0.4219764471054077\n",
      "Batch：974 | Loss: 0.3841918408870697\n",
      "Batch：975 | Loss: 0.3974747657775879\n",
      "Batch：976 | Loss: 0.3957816958427429\n",
      "Batch：977 | Loss: 0.4154910147190094\n",
      "Batch：978 | Loss: 0.3848744332790375\n",
      "Batch：979 | Loss: 0.3988180160522461\n",
      "Batch：980 | Loss: 0.38853180408477783\n",
      "Batch：981 | Loss: 0.4008622169494629\n",
      "Batch：982 | Loss: 0.3916512727737427\n",
      "Batch：983 | Loss: 0.41006457805633545\n",
      "Batch：984 | Loss: 0.39998358488082886\n",
      "Batch：985 | Loss: 0.38252702355384827\n",
      "Batch：986 | Loss: 0.4038282036781311\n",
      "Batch：987 | Loss: 0.403818279504776\n",
      "Batch：988 | Loss: 0.4058772027492523\n",
      "Batch：989 | Loss: 0.4078369140625\n",
      "Batch：990 | Loss: 0.39715641736984253\n",
      "Batch：991 | Loss: 0.39085760712623596\n",
      "Batch：992 | Loss: 0.39494433999061584\n",
      "Batch：993 | Loss: 0.40472516417503357\n",
      "Batch：994 | Loss: 0.4152020514011383\n",
      "Batch：995 | Loss: 0.4090648591518402\n",
      "Batch：996 | Loss: 0.38150760531425476\n",
      "Batch：997 | Loss: 0.38635265827178955\n",
      "Batch：998 | Loss: 0.4173087477684021\n",
      "Batch：999 | Loss: 0.4223827123641968\n",
      "Batch：1000 | Loss: 0.4108535051345825\n",
      "Batch：1001 | Loss: 0.40897831320762634\n",
      "Batch：1002 | Loss: 0.39929845929145813\n",
      "Batch：1003 | Loss: 0.39954036474227905\n",
      "Batch：1004 | Loss: 0.41813406348228455\n",
      "Batch：1005 | Loss: 0.4156210124492645\n",
      "Batch：1006 | Loss: 0.3901643455028534\n",
      "Batch：1007 | Loss: 0.4087459146976471\n",
      "Batch：1008 | Loss: 0.3882644772529602\n",
      "Batch：1009 | Loss: 0.3822746276855469\n",
      "Batch：1010 | Loss: 0.41285139322280884\n",
      "Batch：1011 | Loss: 0.3776167035102844\n",
      "Batch：1012 | Loss: 0.4019877016544342\n",
      "Batch：1013 | Loss: 0.4076162576675415\n",
      "Batch：1014 | Loss: 0.3986268937587738\n",
      "Batch：1015 | Loss: 0.40278249979019165\n",
      "Batch：1016 | Loss: 0.41802099347114563\n",
      "Batch：1017 | Loss: 0.39986905455589294\n",
      "Batch：1018 | Loss: 0.4012737274169922\n",
      "Batch：1019 | Loss: 0.40015900135040283\n",
      "Batch：1020 | Loss: 0.3832731544971466\n",
      "Batch：1021 | Loss: 0.4175589680671692\n",
      "Batch：1022 | Loss: 0.3965645432472229\n",
      "Batch：1023 | Loss: 0.3991158902645111\n",
      "Batch：1024 | Loss: 0.4028759002685547\n",
      "Batch：1025 | Loss: 0.4014037251472473\n",
      "Batch：1026 | Loss: 0.40184253454208374\n",
      "Batch：1027 | Loss: 0.4085865914821625\n",
      "Batch：1028 | Loss: 0.3885711133480072\n",
      "Batch：1029 | Loss: 0.38978496193885803\n",
      "Batch：1030 | Loss: 0.39292407035827637\n",
      "Batch：1031 | Loss: 0.3882092237472534\n",
      "Batch：1032 | Loss: 0.40517953038215637\n",
      "Batch：1033 | Loss: 0.38593432307243347\n",
      "Batch：1034 | Loss: 0.3996776044368744\n",
      "Batch：1035 | Loss: 0.40657076239585876\n",
      "Batch：1036 | Loss: 0.3893175423145294\n",
      "Batch：1037 | Loss: 0.4094341993331909\n",
      "Batch：1038 | Loss: 0.4197821319103241\n",
      "Batch：1039 | Loss: 0.3944077789783478\n",
      "Batch：1040 | Loss: 0.3951544463634491\n",
      "Batch：1041 | Loss: 0.4033036530017853\n",
      "Batch：1042 | Loss: 0.43108779191970825\n",
      "Batch：1043 | Loss: 0.40928393602371216\n",
      "Batch：1044 | Loss: 0.398027628660202\n",
      "Batch：1045 | Loss: 0.3757098317146301\n",
      "Batch：1046 | Loss: 0.39529645442962646\n",
      "Batch：1047 | Loss: 0.3857364058494568\n",
      "Batch：1048 | Loss: 0.3983854055404663\n",
      "Batch：1049 | Loss: 0.3933503031730652\n",
      "Batch：1050 | Loss: 0.3932037651538849\n",
      "Batch：1051 | Loss: 0.3800681233406067\n",
      "Batch：1052 | Loss: 0.3815755546092987\n",
      "Batch：1053 | Loss: 0.38843998312950134\n",
      "Batch：1054 | Loss: 0.3827139139175415\n",
      "Batch：1055 | Loss: 0.38065603375434875\n",
      "Batch：1056 | Loss: 0.3860548436641693\n",
      "Batch：1057 | Loss: 0.3965321481227875\n",
      "Batch：1058 | Loss: 0.3766173720359802\n",
      "Batch：1059 | Loss: 0.4069455564022064\n",
      "Batch：1060 | Loss: 0.39330822229385376\n",
      "Batch：1061 | Loss: 0.3975142240524292\n",
      "Batch：1062 | Loss: 0.39143988490104675\n",
      "Batch：1063 | Loss: 0.4263092279434204\n",
      "Batch：1064 | Loss: 0.38080379366874695\n",
      "Batch：1065 | Loss: 0.3905726671218872\n",
      "Batch：1066 | Loss: 0.412447988986969\n",
      "Batch：1067 | Loss: 0.3871009051799774\n",
      "Batch：1068 | Loss: 0.4083513617515564\n",
      "Batch：1069 | Loss: 0.39104312658309937\n",
      "Batch：1070 | Loss: 0.3946809768676758\n",
      "Batch：1071 | Loss: 0.39805713295936584\n",
      "Batch：1072 | Loss: 0.4047833979129791\n",
      "Batch：1073 | Loss: 0.3721318244934082\n",
      "Batch：1074 | Loss: 0.36315208673477173\n",
      "Batch：1075 | Loss: 0.38637658953666687\n",
      "Batch：1076 | Loss: 0.38731440901756287\n",
      "Batch：1077 | Loss: 0.40843817591667175\n",
      "Batch：1078 | Loss: 0.3943799138069153\n",
      "Batch：1079 | Loss: 0.3916502296924591\n",
      "Batch：1080 | Loss: 0.38761743903160095\n",
      "Batch：1081 | Loss: 0.39052578806877136\n",
      "Batch：1082 | Loss: 0.3749457895755768\n",
      "Batch：1083 | Loss: 0.374582976102829\n",
      "Batch：1084 | Loss: 0.37517619132995605\n",
      "Batch：1085 | Loss: 0.39357173442840576\n",
      "Batch：1086 | Loss: 0.39925482869148254\n",
      "Batch：1087 | Loss: 0.38386741280555725\n",
      "Batch：1088 | Loss: 0.3825027644634247\n",
      "Batch：1089 | Loss: 0.3723287582397461\n",
      "Batch：1090 | Loss: 0.38706105947494507\n",
      "Batch：1091 | Loss: 0.38102301955223083\n",
      "Batch：1092 | Loss: 0.41447195410728455\n",
      "Batch：1093 | Loss: 0.3919541835784912\n",
      "Batch：1094 | Loss: 0.38026243448257446\n",
      "Batch：1095 | Loss: 0.39098435640335083\n",
      "Batch：1096 | Loss: 0.3687763512134552\n",
      "Batch：1097 | Loss: 0.38194090127944946\n",
      "Batch：1098 | Loss: 0.39257559180259705\n",
      "Batch：1099 | Loss: 0.3787749707698822\n",
      "Batch：1100 | Loss: 0.3797719180583954\n",
      "Batch：1101 | Loss: 0.39003652334213257\n",
      "Batch：1102 | Loss: 0.3856918215751648\n",
      "Batch：1103 | Loss: 0.392458438873291\n",
      "Batch：1104 | Loss: 0.3740120530128479\n",
      "Batch：1105 | Loss: 0.40426522493362427\n",
      "Batch：1106 | Loss: 0.3954281508922577\n",
      "Batch：1107 | Loss: 0.3913056552410126\n",
      "Batch：1108 | Loss: 0.4052918255329132\n",
      "Batch：1109 | Loss: 0.3721369206905365\n",
      "Batch：1110 | Loss: 0.37353992462158203\n",
      "Batch：1111 | Loss: 0.3584328591823578\n",
      "Batch：1112 | Loss: 0.4010952115058899\n",
      "Batch：1113 | Loss: 0.39567023515701294\n",
      "Batch：1114 | Loss: 0.3914785385131836\n",
      "Batch：1115 | Loss: 0.38856565952301025\n",
      "Batch：1116 | Loss: 0.36579108238220215\n",
      "Batch：1117 | Loss: 0.3947586119174957\n",
      "Batch：1118 | Loss: 0.3903653621673584\n",
      "Batch：1119 | Loss: 0.3762495219707489\n",
      "Batch：1120 | Loss: 0.3730924725532532\n",
      "Batch：1121 | Loss: 0.37422624230384827\n",
      "Batch：1122 | Loss: 0.3932173252105713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：1123 | Loss: 0.3772287666797638\n",
      "Batch：1124 | Loss: 0.358015775680542\n",
      "Batch：1125 | Loss: 0.36571204662323\n",
      "Batch：1126 | Loss: 0.3702494204044342\n",
      "Batch：1127 | Loss: 0.3755597770214081\n",
      "Batch：1128 | Loss: 0.3704755902290344\n",
      "Batch：1129 | Loss: 0.391069620847702\n",
      "Batch：1130 | Loss: 0.37558040022850037\n",
      "Batch：1131 | Loss: 0.35812827944755554\n",
      "Batch：1132 | Loss: 0.3693925738334656\n",
      "Batch：1133 | Loss: 0.36839720606803894\n",
      "Batch：1134 | Loss: 0.3740403652191162\n",
      "Batch：1135 | Loss: 0.3591840863227844\n",
      "Batch：1136 | Loss: 0.3838653564453125\n",
      "Batch：1137 | Loss: 0.38580790162086487\n",
      "Batch：1138 | Loss: 0.38452431559562683\n",
      "Batch：1139 | Loss: 0.35861071944236755\n",
      "Batch：1140 | Loss: 0.3911516070365906\n",
      "Batch：1141 | Loss: 0.3946855962276459\n",
      "Batch：1142 | Loss: 0.36290478706359863\n",
      "Batch：1143 | Loss: 0.387259840965271\n",
      "Batch：1144 | Loss: 0.36985066533088684\n",
      "Batch：1145 | Loss: 0.3671320676803589\n",
      "Batch：1146 | Loss: 0.3693144619464874\n",
      "Batch：1147 | Loss: 0.3773161470890045\n",
      "Batch：1148 | Loss: 0.3823179006576538\n",
      "Batch：1149 | Loss: 0.3625238835811615\n",
      "Batch：1150 | Loss: 0.3854674696922302\n",
      "Batch：1151 | Loss: 0.3663787841796875\n",
      "Batch：1152 | Loss: 0.3833892047405243\n",
      "Batch：1153 | Loss: 0.3810245394706726\n",
      "Batch：1154 | Loss: 0.3970716893672943\n",
      "Batch：1155 | Loss: 0.3789592981338501\n",
      "Batch：1156 | Loss: 0.38903820514678955\n",
      "Batch：1157 | Loss: 0.3876563310623169\n",
      "Batch：1158 | Loss: 0.38242149353027344\n",
      "Batch：1159 | Loss: 0.3751853406429291\n",
      "Batch：1160 | Loss: 0.36989542841911316\n",
      "Batch：1161 | Loss: 0.3533731698989868\n",
      "Batch：1162 | Loss: 0.3852038085460663\n",
      "Batch：1163 | Loss: 0.38735732436180115\n",
      "Batch：1164 | Loss: 0.38136017322540283\n",
      "Batch：1165 | Loss: 0.36896079778671265\n",
      "Batch：1166 | Loss: 0.37344643473625183\n",
      "Batch：1167 | Loss: 0.34031328558921814\n",
      "Batch：1168 | Loss: 0.3780665695667267\n",
      "Batch：1169 | Loss: 0.38006502389907837\n",
      "Batch：1170 | Loss: 0.3664983808994293\n",
      "Batch：1171 | Loss: 0.3709186911582947\n",
      "Batch：1172 | Loss: 0.3579581379890442\n",
      "Batch：1173 | Loss: 0.3833153545856476\n",
      "Batch：1174 | Loss: 0.3622269630432129\n",
      "Batch：1175 | Loss: 0.3580041825771332\n",
      "Batch：1176 | Loss: 0.37161579728126526\n",
      "Batch：1177 | Loss: 0.37486934661865234\n",
      "Batch：1178 | Loss: 0.3665715754032135\n",
      "Batch：1179 | Loss: 0.3713653087615967\n",
      "Batch：1180 | Loss: 0.36251139640808105\n",
      "Batch：1181 | Loss: 0.35199087858200073\n",
      "Batch：1182 | Loss: 0.36878636479377747\n",
      "Batch：1183 | Loss: 0.3696332275867462\n",
      "Batch：1184 | Loss: 0.3826901912689209\n",
      "Batch：1185 | Loss: 0.37500008940696716\n",
      "Batch：1186 | Loss: 0.3600776791572571\n",
      "Batch：1187 | Loss: 0.37213659286499023\n",
      "Batch：1188 | Loss: 0.36063387989997864\n",
      "Batch：1189 | Loss: 0.3678032457828522\n",
      "Batch：1190 | Loss: 0.385717511177063\n",
      "Batch：1191 | Loss: 0.37843167781829834\n",
      "Batch：1192 | Loss: 0.3722573220729828\n",
      "Batch：1193 | Loss: 0.3587043285369873\n",
      "Batch：1194 | Loss: 0.36748698353767395\n",
      "Batch：1195 | Loss: 0.3416801691055298\n",
      "Batch：1196 | Loss: 0.35360637307167053\n",
      "Batch：1197 | Loss: 0.3703294098377228\n",
      "Batch：1198 | Loss: 0.3813672363758087\n",
      "Batch：1199 | Loss: 0.36022695899009705\n",
      "Batch：1200 | Loss: 0.3898963928222656\n",
      "Batch：1201 | Loss: 0.35209155082702637\n",
      "Batch：1202 | Loss: 0.3680286407470703\n",
      "Batch：1203 | Loss: 0.38890713453292847\n",
      "Batch：1204 | Loss: 0.3787735104560852\n",
      "Batch：1205 | Loss: 0.3674277365207672\n",
      "Batch：1206 | Loss: 0.36151227355003357\n",
      "Batch：1207 | Loss: 0.37175804376602173\n",
      "Batch：1208 | Loss: 0.3655184209346771\n",
      "Batch：1209 | Loss: 0.35056108236312866\n",
      "Batch：1210 | Loss: 0.3659329414367676\n",
      "Batch：1211 | Loss: 0.3470407724380493\n",
      "Batch：1212 | Loss: 0.3643206059932709\n",
      "Batch：1213 | Loss: 0.36427009105682373\n",
      "Batch：1214 | Loss: 0.3677060604095459\n",
      "Batch：1215 | Loss: 0.3518812656402588\n",
      "Batch：1216 | Loss: 0.3580344319343567\n",
      "Batch：1217 | Loss: 0.35974887013435364\n",
      "Batch：1218 | Loss: 0.37236523628234863\n",
      "Batch：1219 | Loss: 0.35764753818511963\n",
      "Batch：1220 | Loss: 0.3679525852203369\n",
      "Batch：1221 | Loss: 0.3651689887046814\n",
      "Batch：1222 | Loss: 0.3679471015930176\n",
      "Batch：1223 | Loss: 0.364633709192276\n",
      "Batch：1224 | Loss: 0.378289133310318\n",
      "Batch：1225 | Loss: 0.3602519631385803\n",
      "Batch：1226 | Loss: 0.3704003095626831\n",
      "Batch：1227 | Loss: 0.3490680754184723\n",
      "Batch：1228 | Loss: 0.3739464581012726\n",
      "Batch：1229 | Loss: 0.35806652903556824\n",
      "Batch：1230 | Loss: 0.3485117256641388\n",
      "Batch：1231 | Loss: 0.36461713910102844\n",
      "Batch：1232 | Loss: 0.3635978102684021\n",
      "Batch：1233 | Loss: 0.3794762194156647\n",
      "Batch：1234 | Loss: 0.36273595690727234\n",
      "Batch：1235 | Loss: 0.3654896318912506\n",
      "Batch：1236 | Loss: 0.34825634956359863\n",
      "Batch：1237 | Loss: 0.350165456533432\n",
      "Batch：1238 | Loss: 0.3810103237628937\n",
      "Batch：1239 | Loss: 0.36446788907051086\n",
      "Batch：1240 | Loss: 0.3629678785800934\n",
      "Batch：1241 | Loss: 0.36240673065185547\n",
      "Batch：1242 | Loss: 0.3576468825340271\n",
      "Batch：1243 | Loss: 0.38297557830810547\n",
      "Batch：1244 | Loss: 0.36472398042678833\n",
      "Batch：1245 | Loss: 0.37034252285957336\n",
      "Batch：1246 | Loss: 0.3733506500720978\n",
      "Batch：1247 | Loss: 0.36760348081588745\n",
      "Batch：1248 | Loss: 0.35549628734588623\n",
      "Batch：1249 | Loss: 0.3490678668022156\n",
      "Batch：1250 | Loss: 0.3632049858570099\n",
      "Batch：1251 | Loss: 0.34811538457870483\n",
      "Batch：1252 | Loss: 0.3517214357852936\n",
      "Batch：1253 | Loss: 0.3468957543373108\n",
      "Batch：1254 | Loss: 0.36821117997169495\n",
      "Batch：1255 | Loss: 0.3746730089187622\n",
      "Batch：1256 | Loss: 0.34651440382003784\n",
      "Batch：1257 | Loss: 0.37034621834754944\n",
      "Batch：1258 | Loss: 0.36443784832954407\n",
      "Batch：1259 | Loss: 0.36281588673591614\n",
      "Batch：1260 | Loss: 0.36048632860183716\n",
      "Batch：1261 | Loss: 0.3465600907802582\n",
      "Batch：1262 | Loss: 0.3666554391384125\n",
      "Batch：1263 | Loss: 0.38145744800567627\n",
      "Batch：1264 | Loss: 0.3674003779888153\n",
      "Batch：1265 | Loss: 0.3582543134689331\n",
      "Batch：1266 | Loss: 0.34252986311912537\n",
      "Batch：1267 | Loss: 0.3685685992240906\n",
      "Batch：1268 | Loss: 0.36153626441955566\n",
      "Batch：1269 | Loss: 0.3716796040534973\n",
      "Batch：1270 | Loss: 0.3665696680545807\n",
      "Batch：1271 | Loss: 0.36626628041267395\n",
      "Batch：1272 | Loss: 0.3729511797428131\n",
      "Batch：1273 | Loss: 0.3468807637691498\n",
      "Batch：1274 | Loss: 0.35574689507484436\n",
      "Batch：1275 | Loss: 0.35386350750923157\n",
      "Batch：1276 | Loss: 0.34335148334503174\n",
      "Batch：1277 | Loss: 0.37870368361473083\n",
      "Batch：1278 | Loss: 0.35764598846435547\n",
      "Batch：1279 | Loss: 0.352997362613678\n",
      "Batch：1280 | Loss: 0.3703978955745697\n",
      "Batch：1281 | Loss: 0.3665825128555298\n",
      "Batch：1282 | Loss: 0.34938716888427734\n",
      "Batch：1283 | Loss: 0.3660605847835541\n",
      "Batch：1284 | Loss: 0.3447413742542267\n",
      "Batch：1285 | Loss: 0.34269335865974426\n",
      "Batch：1286 | Loss: 0.34808430075645447\n",
      "Batch：1287 | Loss: 0.3729771673679352\n",
      "Batch：1288 | Loss: 0.3511711657047272\n",
      "Batch：1289 | Loss: 0.3688642680644989\n",
      "Batch：1290 | Loss: 0.3557299077510834\n",
      "Batch：1291 | Loss: 0.35407811403274536\n",
      "Batch：1292 | Loss: 0.362633615732193\n",
      "Batch：1293 | Loss: 0.3358913064002991\n",
      "Batch：1294 | Loss: 0.32923978567123413\n",
      "Batch：1295 | Loss: 0.3440469801425934\n",
      "Batch：1296 | Loss: 0.345320463180542\n",
      "Batch：1297 | Loss: 0.36309725046157837\n",
      "Batch：1298 | Loss: 0.37473413348197937\n",
      "Batch：1299 | Loss: 0.36491161584854126\n",
      "Batch：1300 | Loss: 0.3692437410354614\n",
      "Batch：1301 | Loss: 0.35021451115608215\n",
      "Batch：1302 | Loss: 0.3551466464996338\n",
      "Batch：1303 | Loss: 0.34006163477897644\n",
      "Batch：1304 | Loss: 0.36979740858078003\n",
      "Batch：1305 | Loss: 0.37791648507118225\n",
      "Batch：1306 | Loss: 0.3469814360141754\n",
      "Batch：1307 | Loss: 0.3525083065032959\n",
      "Batch：1308 | Loss: 0.34592676162719727\n",
      "Batch：1309 | Loss: 0.35982879996299744\n",
      "Batch：1310 | Loss: 0.3605785369873047\n",
      "Batch：1311 | Loss: 0.345091313123703\n",
      "Batch：1312 | Loss: 0.35467618703842163\n",
      "Batch：1313 | Loss: 0.3590727150440216\n",
      "Batch：1314 | Loss: 0.336945116519928\n",
      "Batch：1315 | Loss: 0.35170096158981323\n",
      "Batch：1316 | Loss: 0.36673474311828613\n",
      "Batch：1317 | Loss: 0.36040204763412476\n",
      "Batch：1318 | Loss: 0.3516812324523926\n",
      "Batch：1319 | Loss: 0.33783894777297974\n",
      "Batch：1320 | Loss: 0.3338894546031952\n",
      "Batch：1321 | Loss: 0.33645278215408325\n",
      "Batch：1322 | Loss: 0.3487470746040344\n",
      "Batch：1323 | Loss: 0.3334820866584778\n",
      "Batch：1324 | Loss: 0.3649587035179138\n",
      "Batch：1325 | Loss: 0.3475077152252197\n",
      "Batch：1326 | Loss: 0.3467252850532532\n",
      "Batch：1327 | Loss: 0.35751476883888245\n",
      "Batch：1328 | Loss: 0.34116166830062866\n",
      "Batch：1329 | Loss: 0.3591971695423126\n",
      "Batch：1330 | Loss: 0.3461962938308716\n",
      "Batch：1331 | Loss: 0.3612356185913086\n",
      "Batch：1332 | Loss: 0.34780851006507874\n",
      "Batch：1333 | Loss: 0.33887720108032227\n",
      "Batch：1334 | Loss: 0.35210028290748596\n",
      "Batch：1335 | Loss: 0.3418826758861542\n",
      "Batch：1336 | Loss: 0.3285905420780182\n",
      "Batch：1337 | Loss: 0.36381012201309204\n",
      "Batch：1338 | Loss: 0.3602086901664734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：1339 | Loss: 0.3494361639022827\n",
      "Batch：1340 | Loss: 0.3436334729194641\n",
      "Batch：1341 | Loss: 0.3337326943874359\n",
      "Batch：1342 | Loss: 0.3344247341156006\n",
      "Batch：1343 | Loss: 0.36517781019210815\n",
      "Batch：1344 | Loss: 0.3173755705356598\n",
      "Batch：1345 | Loss: 0.3432271182537079\n",
      "Batch：1346 | Loss: 0.3384455442428589\n",
      "Batch：1347 | Loss: 0.3665195405483246\n",
      "Batch：1348 | Loss: 0.3463173508644104\n",
      "Batch：1349 | Loss: 0.3597503900527954\n",
      "Batch：1350 | Loss: 0.35892391204833984\n",
      "Batch：1351 | Loss: 0.343657910823822\n",
      "Batch：1352 | Loss: 0.33001708984375\n",
      "Batch：1353 | Loss: 0.3247331380844116\n",
      "Batch：1354 | Loss: 0.35009586811065674\n",
      "Batch：1355 | Loss: 0.3416588008403778\n",
      "Batch：1356 | Loss: 0.32707735896110535\n",
      "Batch：1357 | Loss: 0.3609892427921295\n",
      "Batch：1358 | Loss: 0.329769492149353\n",
      "Batch：1359 | Loss: 0.35358479619026184\n",
      "Batch：1360 | Loss: 0.33824050426483154\n",
      "Batch：1361 | Loss: 0.3428172171115875\n",
      "Batch：1362 | Loss: 0.34770601987838745\n",
      "Batch：1363 | Loss: 0.34577327966690063\n",
      "Batch：1364 | Loss: 0.332127183675766\n",
      "Batch：1365 | Loss: 0.33697980642318726\n",
      "Batch：1366 | Loss: 0.35066449642181396\n",
      "Batch：1367 | Loss: 0.33688411116600037\n",
      "Batch：1368 | Loss: 0.3377680480480194\n",
      "Batch：1369 | Loss: 0.3392777144908905\n",
      "Batch：1370 | Loss: 0.3581923842430115\n",
      "Batch：1371 | Loss: 0.337812215089798\n",
      "Batch：1372 | Loss: 0.3247356414794922\n",
      "Batch：1373 | Loss: 0.3402550518512726\n",
      "Batch：1374 | Loss: 0.33886104822158813\n",
      "Batch：1375 | Loss: 0.3314208388328552\n",
      "Batch：1376 | Loss: 0.340478777885437\n",
      "Batch：1377 | Loss: 0.3393670916557312\n",
      "Batch：1378 | Loss: 0.3305162787437439\n",
      "Batch：1379 | Loss: 0.3370950520038605\n",
      "Batch：1380 | Loss: 0.3411139249801636\n",
      "Batch：1381 | Loss: 0.3483952581882477\n",
      "Batch：1382 | Loss: 0.3512052297592163\n",
      "Batch：1383 | Loss: 0.3406938314437866\n",
      "Batch：1384 | Loss: 0.3197585940361023\n",
      "Batch：1385 | Loss: 0.3379870057106018\n",
      "Batch：1386 | Loss: 0.3529422879219055\n",
      "Batch：1387 | Loss: 0.33483532071113586\n",
      "Batch：1388 | Loss: 0.32751744985580444\n",
      "Batch：1389 | Loss: 0.3416478633880615\n",
      "Batch：1390 | Loss: 0.3171556293964386\n",
      "Batch：1391 | Loss: 0.3457466959953308\n",
      "Batch：1392 | Loss: 0.3405095636844635\n",
      "Batch：1393 | Loss: 0.33597782254219055\n",
      "Batch：1394 | Loss: 0.34380683302879333\n",
      "Batch：1395 | Loss: 0.31380265951156616\n",
      "Batch：1396 | Loss: 0.3388729691505432\n",
      "Batch：1397 | Loss: 0.328509658575058\n",
      "Batch：1398 | Loss: 0.343820720911026\n",
      "Batch：1399 | Loss: 0.3385695219039917\n",
      "Batch：1400 | Loss: 0.33858197927474976\n",
      "Batch：1401 | Loss: 0.36018726229667664\n",
      "Batch：1402 | Loss: 0.3517106771469116\n",
      "Batch：1403 | Loss: 0.34267958998680115\n",
      "Batch：1404 | Loss: 0.3381984531879425\n",
      "Batch：1405 | Loss: 0.3388744592666626\n",
      "Batch：1406 | Loss: 0.3384711444377899\n",
      "Batch：1407 | Loss: 0.3236779272556305\n",
      "Batch：1408 | Loss: 0.34421849250793457\n",
      "Batch：1409 | Loss: 0.33187156915664673\n",
      "Batch：1410 | Loss: 0.3375439941883087\n",
      "Batch：1411 | Loss: 0.3316288888454437\n",
      "Batch：1412 | Loss: 0.33153584599494934\n",
      "Batch：1413 | Loss: 0.3522908389568329\n",
      "Batch：1414 | Loss: 0.33693623542785645\n",
      "Batch：1415 | Loss: 0.342948853969574\n",
      "Batch：1416 | Loss: 0.33752015233039856\n",
      "Batch：1417 | Loss: 0.34973835945129395\n",
      "Batch：1418 | Loss: 0.3250194787979126\n",
      "Batch：1419 | Loss: 0.35162442922592163\n",
      "Batch：1420 | Loss: 0.33354315161705017\n",
      "Batch：1421 | Loss: 0.34506306052207947\n",
      "Batch：1422 | Loss: 0.34719574451446533\n",
      "Batch：1423 | Loss: 0.3366451859474182\n",
      "Batch：1424 | Loss: 0.34739047288894653\n",
      "Batch：1425 | Loss: 0.3266865611076355\n",
      "Batch：1426 | Loss: 0.3339642584323883\n",
      "Batch：1427 | Loss: 0.3315921723842621\n",
      "Batch：1428 | Loss: 0.35155174136161804\n",
      "Batch：1429 | Loss: 0.33416229486465454\n",
      "Batch：1430 | Loss: 0.32175299525260925\n",
      "Batch：1431 | Loss: 0.33964675664901733\n",
      "Batch：1432 | Loss: 0.32747992873191833\n",
      "Batch：1433 | Loss: 0.32533907890319824\n",
      "Batch：1434 | Loss: 0.32865673303604126\n",
      "Batch：1435 | Loss: 0.33151254057884216\n",
      "Batch：1436 | Loss: 0.3340149223804474\n",
      "Batch：1437 | Loss: 0.32521218061447144\n",
      "Batch：1438 | Loss: 0.3434900641441345\n",
      "Batch：1439 | Loss: 0.3156578838825226\n",
      "Batch：1440 | Loss: 0.33540984988212585\n",
      "Batch：1441 | Loss: 0.3363023102283478\n",
      "Batch：1442 | Loss: 0.33693820238113403\n",
      "Batch：1443 | Loss: 0.3617236316204071\n",
      "Batch：1444 | Loss: 0.34853434562683105\n",
      "Batch：1445 | Loss: 0.3300636410713196\n",
      "Batch：1446 | Loss: 0.3337600529193878\n",
      "Batch：1447 | Loss: 0.32141411304473877\n",
      "Batch：1448 | Loss: 0.3286275267601013\n",
      "Batch：1449 | Loss: 0.2961682081222534\n",
      "Batch：1450 | Loss: 0.3439927399158478\n",
      "Batch：1451 | Loss: 0.3437800705432892\n",
      "Batch：1452 | Loss: 0.3227785527706146\n",
      "Batch：1453 | Loss: 0.3396777808666229\n",
      "Batch：1454 | Loss: 0.32822227478027344\n",
      "Batch：1455 | Loss: 0.3460627496242523\n",
      "Batch：1456 | Loss: 0.30789437890052795\n",
      "Batch：1457 | Loss: 0.3231433629989624\n",
      "Batch：1458 | Loss: 0.32590457797050476\n",
      "Batch：1459 | Loss: 0.32140880823135376\n",
      "Batch：1460 | Loss: 0.33975663781166077\n",
      "Batch：1461 | Loss: 0.32516390085220337\n",
      "Batch：1462 | Loss: 0.3148540258407593\n",
      "Batch：1463 | Loss: 0.3250746726989746\n",
      "Batch：1464 | Loss: 0.3259376287460327\n",
      "Batch：1465 | Loss: 0.3236944079399109\n",
      "Batch：1466 | Loss: 0.3439038395881653\n",
      "Batch：1467 | Loss: 0.335585355758667\n",
      "Batch：1468 | Loss: 0.3462264835834503\n",
      "Batch：1469 | Loss: 0.3008899390697479\n",
      "Batch：1470 | Loss: 0.33826741576194763\n",
      "Batch：1471 | Loss: 0.3489663898944855\n",
      "Batch：1472 | Loss: 0.3111962080001831\n",
      "Batch：1473 | Loss: 0.33660370111465454\n",
      "Batch：1474 | Loss: 0.3229977488517761\n",
      "Batch：1475 | Loss: 0.32472145557403564\n",
      "Batch：1476 | Loss: 0.3226523697376251\n",
      "Batch：1477 | Loss: 0.3209910988807678\n",
      "Batch：1478 | Loss: 0.32721033692359924\n",
      "Batch：1479 | Loss: 0.31721141934394836\n",
      "Batch：1480 | Loss: 0.3188888430595398\n",
      "Batch：1481 | Loss: 0.3062264025211334\n",
      "Batch：1482 | Loss: 0.32466626167297363\n",
      "Batch：1483 | Loss: 0.3376237154006958\n",
      "Batch：1484 | Loss: 0.324688583612442\n",
      "Batch：1485 | Loss: 0.33651092648506165\n",
      "Batch：1486 | Loss: 0.33229225873947144\n",
      "Batch：1487 | Loss: 0.3181133568286896\n",
      "Batch：1488 | Loss: 0.3355126976966858\n",
      "Batch：1489 | Loss: 0.32317960262298584\n",
      "Batch：1490 | Loss: 0.32413312792778015\n",
      "Batch：1491 | Loss: 0.31607043743133545\n",
      "Batch：1492 | Loss: 0.3339652121067047\n",
      "Batch：1493 | Loss: 0.3085903227329254\n",
      "Batch：1494 | Loss: 0.3294128179550171\n",
      "Batch：1495 | Loss: 0.31985530257225037\n",
      "Batch：1496 | Loss: 0.32945460081100464\n",
      "Batch：1497 | Loss: 0.33244624733924866\n",
      "Batch：1498 | Loss: 0.3215506076812744\n",
      "Batch：1499 | Loss: 0.31703078746795654\n",
      "Batch：1500 | Loss: 0.3255051374435425\n",
      "Batch：1501 | Loss: 0.33669158816337585\n",
      "Batch：1502 | Loss: 0.3273927867412567\n",
      "Batch：1503 | Loss: 0.3430348336696625\n",
      "Batch：1504 | Loss: 0.31871309876441956\n",
      "Batch：1505 | Loss: 0.3203321099281311\n",
      "Batch：1506 | Loss: 0.31219619512557983\n",
      "Batch：1507 | Loss: 0.3176264762878418\n",
      "Batch：1508 | Loss: 0.32401105761528015\n",
      "Batch：1509 | Loss: 0.328428715467453\n",
      "Batch：1510 | Loss: 0.32541510462760925\n",
      "Batch：1511 | Loss: 0.32513463497161865\n",
      "Batch：1512 | Loss: 0.32963740825653076\n",
      "Batch：1513 | Loss: 0.32605111598968506\n",
      "Batch：1514 | Loss: 0.3208126723766327\n",
      "Batch：1515 | Loss: 0.3198363482952118\n",
      "Batch：1516 | Loss: 0.30361390113830566\n",
      "Batch：1517 | Loss: 0.33845847845077515\n",
      "Batch：1518 | Loss: 0.3389940857887268\n",
      "Batch：1519 | Loss: 0.332131028175354\n",
      "Batch：1520 | Loss: 0.31917446851730347\n",
      "Batch：1521 | Loss: 0.3151945471763611\n",
      "Batch：1522 | Loss: 0.33168601989746094\n",
      "Batch：1523 | Loss: 0.32766464352607727\n",
      "Batch：1524 | Loss: 0.31757205724716187\n",
      "Batch：1525 | Loss: 0.32030144333839417\n",
      "Batch：1526 | Loss: 0.34709203243255615\n",
      "Batch：1527 | Loss: 0.3367462754249573\n",
      "Batch：1528 | Loss: 0.3300676941871643\n",
      "Batch：1529 | Loss: 0.30168217420578003\n",
      "Batch：1530 | Loss: 0.31439217925071716\n",
      "Batch：1531 | Loss: 0.3048444092273712\n",
      "Batch：1532 | Loss: 0.31032201647758484\n",
      "Batch：1533 | Loss: 0.3248216509819031\n",
      "Batch：1534 | Loss: 0.2988261580467224\n",
      "Batch：1535 | Loss: 0.31768280267715454\n",
      "Batch：1536 | Loss: 0.3292458951473236\n",
      "Batch：1537 | Loss: 0.3243902623653412\n",
      "Batch：1538 | Loss: 0.3215540051460266\n",
      "Batch：1539 | Loss: 0.3372330963611603\n",
      "Batch：1540 | Loss: 0.3182862401008606\n",
      "Batch：1541 | Loss: 0.3234510123729706\n",
      "Batch：1542 | Loss: 0.3235926926136017\n",
      "Batch：1543 | Loss: 0.3258380889892578\n",
      "Batch：1544 | Loss: 0.3359702229499817\n",
      "Batch：1545 | Loss: 0.31724563241004944\n",
      "Batch：1546 | Loss: 0.29908958077430725\n",
      "Batch：1547 | Loss: 0.32682129740715027\n",
      "Batch：1548 | Loss: 0.3272169828414917\n",
      "Batch：1549 | Loss: 0.3292528986930847\n",
      "Batch：1550 | Loss: 0.3188117742538452\n",
      "Batch：1551 | Loss: 0.3129526674747467\n",
      "Batch：1552 | Loss: 0.31311529874801636\n",
      "Batch：1553 | Loss: 0.31215009093284607\n",
      "Batch：1554 | Loss: 0.30263635516166687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：1555 | Loss: 0.31778427958488464\n",
      "Batch：1556 | Loss: 0.3180314600467682\n",
      "Batch：1557 | Loss: 0.33523061871528625\n",
      "Batch：1558 | Loss: 0.3162817656993866\n",
      "Batch：1559 | Loss: 0.3171168565750122\n",
      "Batch：1560 | Loss: 0.30962032079696655\n",
      "Batch：1561 | Loss: 0.3200443983078003\n",
      "Batch：1562 | Loss: 0.3225417137145996\n",
      "Batch：1563 | Loss: 0.35544756054878235\n",
      "Batch：1564 | Loss: 0.30692118406295776\n",
      "Batch：1565 | Loss: 0.324230432510376\n",
      "Batch：1566 | Loss: 0.3135642409324646\n",
      "Batch：1567 | Loss: 0.29695215821266174\n",
      "Batch：1568 | Loss: 0.3136492967605591\n",
      "Batch：1569 | Loss: 0.3245147168636322\n",
      "Batch：1570 | Loss: 0.31523558497428894\n",
      "Batch：1571 | Loss: 0.3237870931625366\n",
      "Batch：1572 | Loss: 0.31261253356933594\n",
      "Batch：1573 | Loss: 0.3166228234767914\n",
      "Batch：1574 | Loss: 0.3189769983291626\n",
      "Batch：1575 | Loss: 0.3184787631034851\n",
      "Batch：1576 | Loss: 0.30549734830856323\n",
      "Batch：1577 | Loss: 0.3179176151752472\n",
      "Batch：1578 | Loss: 0.3021999001502991\n",
      "Batch：1579 | Loss: 0.3226565718650818\n",
      "Batch：1580 | Loss: 0.32536420226097107\n",
      "Batch：1581 | Loss: 0.3058878183364868\n",
      "Batch：1582 | Loss: 0.2998391091823578\n",
      "Batch：1583 | Loss: 0.3269798457622528\n",
      "Batch：1584 | Loss: 0.3113024830818176\n",
      "Batch：1585 | Loss: 0.30691269040107727\n",
      "Batch：1586 | Loss: 0.31934091448783875\n",
      "Batch：1587 | Loss: 0.32822632789611816\n",
      "Batch：1588 | Loss: 0.3298455774784088\n",
      "Batch：1589 | Loss: 0.28505611419677734\n",
      "Batch：1590 | Loss: 0.3085194230079651\n",
      "Batch：1591 | Loss: 0.331366628408432\n",
      "Batch：1592 | Loss: 0.3235863149166107\n",
      "Batch：1593 | Loss: 0.3199968934059143\n",
      "Batch：1594 | Loss: 0.3295971751213074\n",
      "Batch：1595 | Loss: 0.32508230209350586\n",
      "Batch：1596 | Loss: 0.3017069697380066\n",
      "Batch：1597 | Loss: 0.31821203231811523\n",
      "Batch：1598 | Loss: 0.3477579653263092\n",
      "Batch：1599 | Loss: 0.3091791272163391\n",
      "Batch：1600 | Loss: 0.29777613282203674\n",
      "Batch：1601 | Loss: 0.31525668501853943\n",
      "Batch：1602 | Loss: 0.3228476047515869\n",
      "Batch：1603 | Loss: 0.3115696310997009\n",
      "Batch：1604 | Loss: 0.3087104856967926\n",
      "Batch：1605 | Loss: 0.3157289922237396\n",
      "Batch：1606 | Loss: 0.30037593841552734\n",
      "Batch：1607 | Loss: 0.30074819922447205\n",
      "Batch：1608 | Loss: 0.3260502815246582\n",
      "Batch：1609 | Loss: 0.30352747440338135\n",
      "Batch：1610 | Loss: 0.3148300051689148\n",
      "Batch：1611 | Loss: 0.32509371638298035\n",
      "Batch：1612 | Loss: 0.303623765707016\n",
      "Batch：1613 | Loss: 0.29947030544281006\n",
      "Batch：1614 | Loss: 0.32080549001693726\n",
      "Batch：1615 | Loss: 0.3127187490463257\n",
      "Batch：1616 | Loss: 0.3017963469028473\n",
      "Batch：1617 | Loss: 0.32000547647476196\n",
      "Batch：1618 | Loss: 0.2940708100795746\n",
      "Batch：1619 | Loss: 0.3040919005870819\n",
      "Batch：1620 | Loss: 0.31059718132019043\n",
      "Batch：1621 | Loss: 0.3198195695877075\n",
      "Batch：1622 | Loss: 0.3176364004611969\n",
      "Batch：1623 | Loss: 0.32011836767196655\n",
      "Batch：1624 | Loss: 0.31380748748779297\n",
      "Batch：1625 | Loss: 0.31751009821891785\n",
      "Batch：1626 | Loss: 0.3101726472377777\n",
      "Batch：1627 | Loss: 0.31167787313461304\n",
      "Batch：1628 | Loss: 0.2951407730579376\n",
      "Batch：1629 | Loss: 0.3057408034801483\n",
      "Batch：1630 | Loss: 0.31479960680007935\n",
      "Batch：1631 | Loss: 0.29414546489715576\n",
      "Batch：1632 | Loss: 0.30334150791168213\n",
      "Batch：1633 | Loss: 0.2961004078388214\n",
      "Batch：1634 | Loss: 0.307831346988678\n",
      "Batch：1635 | Loss: 0.311008095741272\n",
      "Batch：1636 | Loss: 0.3120865523815155\n",
      "Batch：1637 | Loss: 0.30886322259902954\n",
      "Batch：1638 | Loss: 0.29454100131988525\n",
      "Batch：1639 | Loss: 0.3116215467453003\n",
      "Batch：1640 | Loss: 0.32045191526412964\n",
      "Batch：1641 | Loss: 0.3184940814971924\n",
      "Batch：1642 | Loss: 0.30985987186431885\n",
      "Batch：1643 | Loss: 0.3063628673553467\n",
      "Batch：1644 | Loss: 0.30010271072387695\n",
      "Batch：1645 | Loss: 0.3078707754611969\n",
      "Batch：1646 | Loss: 0.29589635133743286\n",
      "Batch：1647 | Loss: 0.31055858731269836\n",
      "Batch：1648 | Loss: 0.2968246638774872\n",
      "Batch：1649 | Loss: 0.286886990070343\n",
      "Batch：1650 | Loss: 0.32205286622047424\n",
      "Batch：1651 | Loss: 0.2917436361312866\n",
      "Batch：1652 | Loss: 0.31496432423591614\n",
      "Batch：1653 | Loss: 0.296855092048645\n",
      "Batch：1654 | Loss: 0.3030349314212799\n",
      "Batch：1655 | Loss: 0.3124258518218994\n",
      "Batch：1656 | Loss: 0.32164546847343445\n",
      "Batch：1657 | Loss: 0.30666592717170715\n",
      "Batch：1658 | Loss: 0.31444022059440613\n",
      "Batch：1659 | Loss: 0.3096659183502197\n",
      "Batch：1660 | Loss: 0.30378398299217224\n",
      "Batch：1661 | Loss: 0.320191890001297\n",
      "Batch：1662 | Loss: 0.32665932178497314\n",
      "Batch：1663 | Loss: 0.3150140345096588\n",
      "Batch：1664 | Loss: 0.2925362288951874\n",
      "Batch：1665 | Loss: 0.2965191900730133\n",
      "Batch：1666 | Loss: 0.3126795291900635\n",
      "Batch：1667 | Loss: 0.2967970073223114\n",
      "Batch：1668 | Loss: 0.3114869296550751\n",
      "Batch：1669 | Loss: 0.29414671659469604\n",
      "Batch：1670 | Loss: 0.31521281599998474\n",
      "Batch：1671 | Loss: 0.30091777443885803\n",
      "Batch：1672 | Loss: 0.32161930203437805\n",
      "Batch：1673 | Loss: 0.3040696680545807\n",
      "Batch：1674 | Loss: 0.3060036897659302\n",
      "Batch：1675 | Loss: 0.2941652536392212\n",
      "Batch：1676 | Loss: 0.2935241162776947\n",
      "Batch：1677 | Loss: 0.3008325397968292\n",
      "Batch：1678 | Loss: 0.30978819727897644\n",
      "Batch：1679 | Loss: 0.29557961225509644\n",
      "Batch：1680 | Loss: 0.3009693920612335\n",
      "Batch：1681 | Loss: 0.295714795589447\n",
      "Batch：1682 | Loss: 0.311767041683197\n",
      "Batch：1683 | Loss: 0.3023342192173004\n",
      "Batch：1684 | Loss: 0.3043164014816284\n",
      "Batch：1685 | Loss: 0.30504074692726135\n",
      "Batch：1686 | Loss: 0.28809037804603577\n",
      "Batch：1687 | Loss: 0.29130107164382935\n",
      "Batch：1688 | Loss: 0.30802369117736816\n",
      "Batch：1689 | Loss: 0.3113595247268677\n",
      "Batch：1690 | Loss: 0.3022918403148651\n",
      "Batch：1691 | Loss: 0.3028481602668762\n",
      "Batch：1692 | Loss: 0.27210158109664917\n",
      "Batch：1693 | Loss: 0.2959968149662018\n",
      "Batch：1694 | Loss: 0.3112211227416992\n",
      "Batch：1695 | Loss: 0.2880953252315521\n",
      "Batch：1696 | Loss: 0.3172031342983246\n",
      "Batch：1697 | Loss: 0.3115317225456238\n",
      "Batch：1698 | Loss: 0.306591272354126\n",
      "Batch：1699 | Loss: 0.2872898280620575\n",
      "Batch：1700 | Loss: 0.3047187030315399\n",
      "Batch：1701 | Loss: 0.2911373972892761\n",
      "Batch：1702 | Loss: 0.3035416901111603\n",
      "Batch：1703 | Loss: 0.3023695945739746\n",
      "Batch：1704 | Loss: 0.2903877794742584\n",
      "Batch：1705 | Loss: 0.28539296984672546\n",
      "Batch：1706 | Loss: 0.3042341470718384\n",
      "Batch：1707 | Loss: 0.3066878318786621\n",
      "Batch：1708 | Loss: 0.29453495144844055\n",
      "Batch：1709 | Loss: 0.30112794041633606\n",
      "Batch：1710 | Loss: 0.2859492897987366\n",
      "Batch：1711 | Loss: 0.3063643276691437\n",
      "Batch：1712 | Loss: 0.31511953473091125\n",
      "Batch：1713 | Loss: 0.3064228892326355\n",
      "Batch：1714 | Loss: 0.314496248960495\n",
      "Batch：1715 | Loss: 0.3014037311077118\n",
      "Batch：1716 | Loss: 0.29441362619400024\n",
      "Batch：1717 | Loss: 0.29384109377861023\n",
      "Batch：1718 | Loss: 0.30250853300094604\n",
      "Batch：1719 | Loss: 0.2813299894332886\n",
      "Batch：1720 | Loss: 0.29133448004722595\n",
      "Batch：1721 | Loss: 0.28794875741004944\n",
      "Batch：1722 | Loss: 0.30931639671325684\n",
      "Batch：1723 | Loss: 0.3035515546798706\n",
      "Batch：1724 | Loss: 0.31474539637565613\n",
      "Batch：1725 | Loss: 0.28510940074920654\n",
      "Batch：1726 | Loss: 0.30249500274658203\n",
      "Batch：1727 | Loss: 0.2976580262184143\n",
      "Batch：1728 | Loss: 0.3134007155895233\n",
      "Batch：1729 | Loss: 0.29068052768707275\n",
      "Batch：1730 | Loss: 0.29529955983161926\n",
      "Batch：1731 | Loss: 0.29812273383140564\n",
      "Batch：1732 | Loss: 0.30384916067123413\n",
      "Batch：1733 | Loss: 0.3082113265991211\n",
      "Batch：1734 | Loss: 0.30045264959335327\n",
      "Batch：1735 | Loss: 0.2845492959022522\n",
      "Batch：1736 | Loss: 0.2805629372596741\n",
      "Batch：1737 | Loss: 0.29608264565467834\n",
      "Batch：1738 | Loss: 0.30492520332336426\n",
      "Batch：1739 | Loss: 0.28901001811027527\n",
      "Batch：1740 | Loss: 0.29588407278060913\n",
      "Batch：1741 | Loss: 0.2914062440395355\n",
      "Batch：1742 | Loss: 0.2966686189174652\n",
      "Batch：1743 | Loss: 0.31116005778312683\n",
      "Batch：1744 | Loss: 0.30480894446372986\n",
      "Batch：1745 | Loss: 0.30159857869148254\n",
      "Batch：1746 | Loss: 0.2903195917606354\n",
      "Batch：1747 | Loss: 0.2822625935077667\n",
      "Batch：1748 | Loss: 0.2882515490055084\n",
      "Batch：1749 | Loss: 0.2938816547393799\n",
      "Batch：1750 | Loss: 0.3191606104373932\n",
      "Batch：1751 | Loss: 0.29180631041526794\n",
      "Batch：1752 | Loss: 0.31380435824394226\n",
      "Batch：1753 | Loss: 0.2860877513885498\n",
      "Batch：1754 | Loss: 0.31478121876716614\n",
      "Batch：1755 | Loss: 0.3122479319572449\n",
      "Batch：1756 | Loss: 0.31362685561180115\n",
      "Batch：1757 | Loss: 0.28939327597618103\n",
      "Batch：1758 | Loss: 0.30344775319099426\n",
      "Batch：1759 | Loss: 0.30223348736763\n",
      "Batch：1760 | Loss: 0.30011239647865295\n",
      "Batch：1761 | Loss: 0.28979870676994324\n",
      "Batch：1762 | Loss: 0.29334011673927307\n",
      "Batch：1763 | Loss: 0.27084416151046753\n",
      "Batch：1764 | Loss: 0.29722148180007935\n",
      "Batch：1765 | Loss: 0.29752928018569946\n",
      "Batch：1766 | Loss: 0.3080384433269501\n",
      "Batch：1767 | Loss: 0.29489099979400635\n",
      "Batch：1768 | Loss: 0.29598361253738403\n",
      "Batch：1769 | Loss: 0.28545162081718445\n",
      "Batch：1770 | Loss: 0.2946307063102722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：1771 | Loss: 0.29737868905067444\n",
      "Batch：1772 | Loss: 0.27525100111961365\n",
      "Batch：1773 | Loss: 0.29626694321632385\n",
      "Batch：1774 | Loss: 0.2901148796081543\n",
      "Batch：1775 | Loss: 0.30300173163414\n",
      "Batch：1776 | Loss: 0.27286413311958313\n",
      "Batch：1777 | Loss: 0.29573822021484375\n",
      "Batch：1778 | Loss: 0.28231003880500793\n",
      "Batch：1779 | Loss: 0.2867226004600525\n",
      "Batch：1780 | Loss: 0.29946932196617126\n",
      "Batch：1781 | Loss: 0.28898629546165466\n",
      "Batch：1782 | Loss: 0.29700472950935364\n",
      "Batch：1783 | Loss: 0.29066431522369385\n",
      "Batch：1784 | Loss: 0.2873126268386841\n",
      "Batch：1785 | Loss: 0.27295446395874023\n",
      "Batch：1786 | Loss: 0.3108566701412201\n",
      "Batch：1787 | Loss: 0.2902149260044098\n",
      "Batch：1788 | Loss: 0.29567331075668335\n",
      "Batch：1789 | Loss: 0.29917383193969727\n",
      "Batch：1790 | Loss: 0.28380170464515686\n",
      "Batch：1791 | Loss: 0.29155266284942627\n",
      "Batch：1792 | Loss: 0.2908746600151062\n",
      "Batch：1793 | Loss: 0.3025028109550476\n",
      "Batch：1794 | Loss: 0.27152061462402344\n",
      "Batch：1795 | Loss: 0.2817988991737366\n",
      "Batch：1796 | Loss: 0.3020871877670288\n",
      "Batch：1797 | Loss: 0.29542550444602966\n",
      "Batch：1798 | Loss: 0.28823167085647583\n",
      "Batch：1799 | Loss: 0.2901690602302551\n",
      "Batch：1800 | Loss: 0.2881423234939575\n",
      "Batch：1801 | Loss: 0.2948305010795593\n",
      "Batch：1802 | Loss: 0.2908214032649994\n",
      "Batch：1803 | Loss: 0.27931708097457886\n",
      "Batch：1804 | Loss: 0.29810193181037903\n",
      "Batch：1805 | Loss: 0.2955680787563324\n",
      "Batch：1806 | Loss: 0.2966514825820923\n",
      "Batch：1807 | Loss: 0.32083913683891296\n",
      "Batch：1808 | Loss: 0.3021222949028015\n",
      "Batch：1809 | Loss: 0.3103066384792328\n",
      "Batch：1810 | Loss: 0.2952515780925751\n",
      "Batch：1811 | Loss: 0.2898232042789459\n",
      "Batch：1812 | Loss: 0.29067352414131165\n",
      "Batch：1813 | Loss: 0.28990474343299866\n",
      "Batch：1814 | Loss: 0.30605947971343994\n",
      "Batch：1815 | Loss: 0.2787332236766815\n",
      "Batch：1816 | Loss: 0.3093644082546234\n",
      "Batch：1817 | Loss: 0.2803608477115631\n",
      "Batch：1818 | Loss: 0.2846311926841736\n",
      "Batch：1819 | Loss: 0.2860182225704193\n",
      "Batch：1820 | Loss: 0.3024379312992096\n",
      "Batch：1821 | Loss: 0.309903621673584\n",
      "Batch：1822 | Loss: 0.2817353904247284\n",
      "Batch：1823 | Loss: 0.2889210283756256\n",
      "Batch：1824 | Loss: 0.2876778244972229\n",
      "Batch：1825 | Loss: 0.2900135815143585\n",
      "Batch：1826 | Loss: 0.3008778393268585\n",
      "Batch：1827 | Loss: 0.2914957106113434\n",
      "Batch：1828 | Loss: 0.2874510586261749\n",
      "Batch：1829 | Loss: 0.28935566544532776\n",
      "Batch：1830 | Loss: 0.28621727228164673\n",
      "Batch：1831 | Loss: 0.2756991684436798\n",
      "Batch：1832 | Loss: 0.29571425914764404\n",
      "Batch：1833 | Loss: 0.27870699763298035\n",
      "Batch：1834 | Loss: 0.277466356754303\n",
      "Batch：1835 | Loss: 0.2954936623573303\n",
      "Batch：1836 | Loss: 0.27957290410995483\n",
      "Batch：1837 | Loss: 0.2939806580543518\n",
      "Batch：1838 | Loss: 0.2873464822769165\n",
      "Batch：1839 | Loss: 0.27879586815834045\n",
      "Batch：1840 | Loss: 0.2750434875488281\n",
      "Batch：1841 | Loss: 0.2770252525806427\n",
      "Batch：1842 | Loss: 0.2763468325138092\n",
      "Batch：1843 | Loss: 0.2977015972137451\n",
      "Batch：1844 | Loss: 0.286619633436203\n",
      "Batch：1845 | Loss: 0.29811251163482666\n",
      "Batch：1846 | Loss: 0.3018287420272827\n",
      "Batch：1847 | Loss: 0.26907724142074585\n",
      "Batch：1848 | Loss: 0.28253173828125\n",
      "Batch：1849 | Loss: 0.2957208752632141\n",
      "Batch：1850 | Loss: 0.29280075430870056\n",
      "Batch：1851 | Loss: 0.28461799025535583\n",
      "Batch：1852 | Loss: 0.2815030813217163\n",
      "Batch：1853 | Loss: 0.2800233066082001\n",
      "Batch：1854 | Loss: 0.2843807637691498\n",
      "Batch：1855 | Loss: 0.30152627825737\n",
      "Batch：1856 | Loss: 0.29134005308151245\n",
      "Batch：1857 | Loss: 0.29128482937812805\n",
      "Batch：1858 | Loss: 0.2719002962112427\n",
      "Batch：1859 | Loss: 0.26181840896606445\n",
      "Batch：1860 | Loss: 0.28449520468711853\n",
      "Batch：1861 | Loss: 0.28276127576828003\n",
      "Batch：1862 | Loss: 0.3026152551174164\n",
      "Batch：1863 | Loss: 0.29592329263687134\n",
      "Batch：1864 | Loss: 0.27487701177597046\n",
      "Batch：1865 | Loss: 0.28130054473876953\n",
      "Batch：1866 | Loss: 0.270224004983902\n",
      "Batch：1867 | Loss: 0.2950533628463745\n",
      "Batch：1868 | Loss: 0.2901778221130371\n",
      "Batch：1869 | Loss: 0.274135947227478\n",
      "Batch：1870 | Loss: 0.290580689907074\n",
      "Batch：1871 | Loss: 0.2809854745864868\n",
      "Batch：1872 | Loss: 0.2907143235206604\n",
      "Batch：1873 | Loss: 0.30279308557510376\n",
      "Batch：1874 | Loss: 0.26246869564056396\n",
      "Batch：1875 | Loss: 0.2660759687423706\n",
      "Batch：1876 | Loss: 0.2788875102996826\n",
      "Batch：1877 | Loss: 0.28449299931526184\n",
      "Batch：1878 | Loss: 0.2648066282272339\n",
      "Batch：1879 | Loss: 0.25389403104782104\n",
      "Batch：1880 | Loss: 0.28093695640563965\n",
      "Batch：1881 | Loss: 0.28157320618629456\n",
      "Batch：1882 | Loss: 0.2710220217704773\n",
      "Batch：1883 | Loss: 0.27375200390815735\n",
      "Batch：1884 | Loss: 0.29003414511680603\n",
      "Batch：1885 | Loss: 0.250052273273468\n",
      "Batch：1886 | Loss: 0.29196056723594666\n",
      "Batch：1887 | Loss: 0.2780681252479553\n",
      "Batch：1888 | Loss: 0.2858823537826538\n",
      "Batch：1889 | Loss: 0.2772267162799835\n",
      "Batch：1890 | Loss: 0.2828389108181\n",
      "Batch：1891 | Loss: 0.27840864658355713\n",
      "Batch：1892 | Loss: 0.28441423177719116\n",
      "Batch：1893 | Loss: 0.29372650384902954\n",
      "Batch：1894 | Loss: 0.27375853061676025\n",
      "Batch：1895 | Loss: 0.2790626287460327\n",
      "Batch：1896 | Loss: 0.2810637056827545\n",
      "Batch：1897 | Loss: 0.29065123200416565\n",
      "Batch：1898 | Loss: 0.26648783683776855\n",
      "Batch：1899 | Loss: 0.2778837978839874\n",
      "Batch：1900 | Loss: 0.2666890323162079\n",
      "Batch：1901 | Loss: 0.2911364734172821\n",
      "Batch：1902 | Loss: 0.2751938998699188\n",
      "Batch：1903 | Loss: 0.28679293394088745\n",
      "Batch：1904 | Loss: 0.2715189456939697\n",
      "Batch：1905 | Loss: 0.29768380522727966\n",
      "Batch：1906 | Loss: 0.28841546177864075\n",
      "Batch：1907 | Loss: 0.2763575315475464\n",
      "Batch：1908 | Loss: 0.28152287006378174\n",
      "Batch：1909 | Loss: 0.2832484841346741\n",
      "Batch：1910 | Loss: 0.2774890661239624\n",
      "Batch：1911 | Loss: 0.2826560437679291\n",
      "Batch：1912 | Loss: 0.28633755445480347\n",
      "Batch：1913 | Loss: 0.276574045419693\n",
      "Batch：1914 | Loss: 0.2645335793495178\n",
      "Batch：1915 | Loss: 0.2606104612350464\n",
      "Batch：1916 | Loss: 0.27556872367858887\n",
      "Batch：1917 | Loss: 0.28575411438941956\n",
      "Batch：1918 | Loss: 0.2771683931350708\n",
      "Batch：1919 | Loss: 0.2984144389629364\n",
      "Batch：1920 | Loss: 0.26342901587486267\n",
      "Batch：1921 | Loss: 0.2908298075199127\n",
      "Batch：1922 | Loss: 0.28156527876853943\n",
      "Batch：1923 | Loss: 0.2922652065753937\n",
      "Batch：1924 | Loss: 0.25149983167648315\n",
      "Batch：1925 | Loss: 0.256720632314682\n",
      "Batch：1926 | Loss: 0.2801923453807831\n",
      "Batch：1927 | Loss: 0.2703664004802704\n",
      "Batch：1928 | Loss: 0.2740343511104584\n",
      "Batch：1929 | Loss: 0.25393545627593994\n",
      "Batch：1930 | Loss: 0.27271410822868347\n",
      "Batch：1931 | Loss: 0.27827146649360657\n",
      "Batch：1932 | Loss: 0.26996371150016785\n",
      "Batch：1933 | Loss: 0.28498151898384094\n",
      "Batch：1934 | Loss: 0.283194363117218\n",
      "Batch：1935 | Loss: 0.2561280131340027\n",
      "Batch：1936 | Loss: 0.2767709195613861\n",
      "Batch：1937 | Loss: 0.2828805148601532\n",
      "Batch：1938 | Loss: 0.29065802693367004\n",
      "Batch：1939 | Loss: 0.29411908984184265\n",
      "Batch：1940 | Loss: 0.2884688675403595\n",
      "Batch：1941 | Loss: 0.2634715139865875\n",
      "Batch：1942 | Loss: 0.2727135121822357\n",
      "Batch：1943 | Loss: 0.2917274534702301\n",
      "Batch：1944 | Loss: 0.27660617232322693\n",
      "Batch：1945 | Loss: 0.28405699133872986\n",
      "Batch：1946 | Loss: 0.26973241567611694\n",
      "Batch：1947 | Loss: 0.26834866404533386\n",
      "Batch：1948 | Loss: 0.26609817147254944\n",
      "Batch：1949 | Loss: 0.28663861751556396\n",
      "Batch：1950 | Loss: 0.2829788029193878\n",
      "Batch：1951 | Loss: 0.2787172794342041\n",
      "Batch：1952 | Loss: 0.25780463218688965\n",
      "Batch：1953 | Loss: 0.27215880155563354\n",
      "Batch：1954 | Loss: 0.2708004415035248\n",
      "Batch：1955 | Loss: 0.26780468225479126\n",
      "Batch：1956 | Loss: 0.2708103060722351\n",
      "Batch：1957 | Loss: 0.25610384345054626\n",
      "Batch：1958 | Loss: 0.26901015639305115\n",
      "Batch：1959 | Loss: 0.2697228193283081\n",
      "Batch：1960 | Loss: 0.27185335755348206\n",
      "Batch：1961 | Loss: 0.2817729711532593\n",
      "Batch：1962 | Loss: 0.29318469762802124\n",
      "Batch：1963 | Loss: 0.27798977494239807\n",
      "Batch：1964 | Loss: 0.27606454491615295\n",
      "Batch：1965 | Loss: 0.2667401432991028\n",
      "Batch：1966 | Loss: 0.2767378091812134\n",
      "Batch：1967 | Loss: 0.28498315811157227\n",
      "Batch：1968 | Loss: 0.27751481533050537\n",
      "Batch：1969 | Loss: 0.272331178188324\n",
      "Batch：1970 | Loss: 0.2827802002429962\n",
      "Batch：1971 | Loss: 0.26591265201568604\n",
      "Batch：1972 | Loss: 0.2815127670764923\n",
      "Batch：1973 | Loss: 0.26561856269836426\n",
      "Batch：1974 | Loss: 0.27302682399749756\n",
      "Batch：1975 | Loss: 0.27741512656211853\n",
      "Batch：1976 | Loss: 0.27638864517211914\n",
      "Batch：1977 | Loss: 0.2806396782398224\n",
      "Batch：1978 | Loss: 0.2871290147304535\n",
      "Batch：1979 | Loss: 0.26901310682296753\n",
      "Batch：1980 | Loss: 0.2874129116535187\n",
      "Batch：1981 | Loss: 0.2644878923892975\n",
      "Batch：1982 | Loss: 0.27658674120903015\n",
      "Batch：1983 | Loss: 0.25732284784317017\n",
      "Batch：1984 | Loss: 0.2725626230239868\n",
      "Batch：1985 | Loss: 0.25700071454048157\n",
      "Batch：1986 | Loss: 0.2731175124645233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：1987 | Loss: 0.2709907293319702\n",
      "Batch：1988 | Loss: 0.2655205726623535\n",
      "Batch：1989 | Loss: 0.27927786111831665\n",
      "Batch：1990 | Loss: 0.26305699348449707\n",
      "Batch：1991 | Loss: 0.27714452147483826\n",
      "Batch：1992 | Loss: 0.2672976553440094\n",
      "Batch：1993 | Loss: 0.2669421434402466\n",
      "Batch：1994 | Loss: 0.2733018696308136\n",
      "Batch：1995 | Loss: 0.2527102530002594\n",
      "Batch：1996 | Loss: 0.27501752972602844\n",
      "Batch：1997 | Loss: 0.2605602741241455\n",
      "Batch：1998 | Loss: 0.2761668860912323\n",
      "Batch：1999 | Loss: 0.2880895733833313\n",
      "Batch：2000 | Loss: 0.2633917033672333\n",
      "Batch：2001 | Loss: 0.2681841254234314\n",
      "Batch：2002 | Loss: 0.28318414092063904\n",
      "Batch：2003 | Loss: 0.2657753825187683\n",
      "Batch：2004 | Loss: 0.26352784037590027\n",
      "Batch：2005 | Loss: 0.2973802387714386\n",
      "Batch：2006 | Loss: 0.2575621008872986\n",
      "Batch：2007 | Loss: 0.264401376247406\n",
      "Batch：2008 | Loss: 0.27297645807266235\n",
      "Batch：2009 | Loss: 0.282199501991272\n",
      "Batch：2010 | Loss: 0.2753024995326996\n",
      "Batch：2011 | Loss: 0.26394137740135193\n",
      "Batch：2012 | Loss: 0.2758989930152893\n",
      "Batch：2013 | Loss: 0.2700023353099823\n",
      "Batch：2014 | Loss: 0.28339678049087524\n",
      "Batch：2015 | Loss: 0.2778736650943756\n",
      "Batch：2016 | Loss: 0.29328039288520813\n",
      "Batch：2017 | Loss: 0.26964831352233887\n",
      "Batch：2018 | Loss: 0.25501254200935364\n",
      "Batch：2019 | Loss: 0.28059571981430054\n",
      "Batch：2020 | Loss: 0.26578667759895325\n",
      "Batch：2021 | Loss: 0.27175337076187134\n",
      "Batch：2022 | Loss: 0.2777285873889923\n",
      "Batch：2023 | Loss: 0.27112051844596863\n",
      "Batch：2024 | Loss: 0.2690589427947998\n",
      "Batch：2025 | Loss: 0.24991601705551147\n",
      "Batch：2026 | Loss: 0.26208627223968506\n",
      "Batch：2027 | Loss: 0.2710908055305481\n",
      "Batch：2028 | Loss: 0.27068498730659485\n",
      "Batch：2029 | Loss: 0.2755483388900757\n",
      "Batch：2030 | Loss: 0.2829520106315613\n",
      "Batch：2031 | Loss: 0.2576356530189514\n",
      "Batch：2032 | Loss: 0.25811654329299927\n",
      "Batch：2033 | Loss: 0.26055294275283813\n",
      "Batch：2034 | Loss: 0.25080257654190063\n",
      "Batch：2035 | Loss: 0.2702690660953522\n",
      "Batch：2036 | Loss: 0.26816844940185547\n",
      "Batch：2037 | Loss: 0.26205581426620483\n",
      "Batch：2038 | Loss: 0.27434098720550537\n",
      "Batch：2039 | Loss: 0.2554883062839508\n",
      "Batch：2040 | Loss: 0.2440081387758255\n",
      "Batch：2041 | Loss: 0.25733569264411926\n",
      "Batch：2042 | Loss: 0.2634459435939789\n",
      "Batch：2043 | Loss: 0.26999780535697937\n",
      "Batch：2044 | Loss: 0.2685374319553375\n",
      "Batch：2045 | Loss: 0.26640117168426514\n",
      "Batch：2046 | Loss: 0.27432721853256226\n",
      "Batch：2047 | Loss: 0.26600849628448486\n",
      "Batch：2048 | Loss: 0.24655212461948395\n",
      "Batch：2049 | Loss: 0.2541908919811249\n",
      "Batch：2050 | Loss: 0.25555455684661865\n",
      "Batch：2051 | Loss: 0.2533247172832489\n",
      "Batch：2052 | Loss: 0.24945585429668427\n",
      "Batch：2053 | Loss: 0.27569302916526794\n",
      "Batch：2054 | Loss: 0.2624598741531372\n",
      "Batch：2055 | Loss: 0.26446497440338135\n",
      "Batch：2056 | Loss: 0.2641034424304962\n",
      "Batch：2057 | Loss: 0.26460981369018555\n",
      "Batch：2058 | Loss: 0.2700982987880707\n",
      "Batch：2059 | Loss: 0.25481465458869934\n",
      "Batch：2060 | Loss: 0.2614429295063019\n",
      "Batch：2061 | Loss: 0.2808733582496643\n",
      "Batch：2062 | Loss: 0.28779423236846924\n",
      "Batch：2063 | Loss: 0.2592947483062744\n",
      "Batch：2064 | Loss: 0.2872537672519684\n",
      "Batch：2065 | Loss: 0.26696881651878357\n",
      "Batch：2066 | Loss: 0.26638662815093994\n",
      "Batch：2067 | Loss: 0.2632817029953003\n",
      "Batch：2068 | Loss: 0.254583477973938\n",
      "Batch：2069 | Loss: 0.25791114568710327\n",
      "Batch：2070 | Loss: 0.2615046799182892\n",
      "Batch：2071 | Loss: 0.23494037985801697\n",
      "Batch：2072 | Loss: 0.2581717073917389\n",
      "Batch：2073 | Loss: 0.2672143876552582\n",
      "Batch：2074 | Loss: 0.26361414790153503\n",
      "Batch：2075 | Loss: 0.24908936023712158\n",
      "Batch：2076 | Loss: 0.26398107409477234\n",
      "Batch：2077 | Loss: 0.25545939803123474\n",
      "Batch：2078 | Loss: 0.2643187940120697\n",
      "Batch：2079 | Loss: 0.26713308691978455\n",
      "Batch：2080 | Loss: 0.2584249973297119\n",
      "Batch：2081 | Loss: 0.2596844434738159\n",
      "Batch：2082 | Loss: 0.2548042833805084\n",
      "Batch：2083 | Loss: 0.25058671832084656\n",
      "Batch：2084 | Loss: 0.23809997737407684\n",
      "Batch：2085 | Loss: 0.2519671618938446\n",
      "Batch：2086 | Loss: 0.25886744260787964\n",
      "Batch：2087 | Loss: 0.2670036554336548\n",
      "Batch：2088 | Loss: 0.2700628936290741\n",
      "Batch：2089 | Loss: 0.2517409920692444\n",
      "Batch：2090 | Loss: 0.25902727246284485\n",
      "Batch：2091 | Loss: 0.26593226194381714\n",
      "Batch：2092 | Loss: 0.2694665789604187\n",
      "Batch：2093 | Loss: 0.25759077072143555\n",
      "Batch：2094 | Loss: 0.27243906259536743\n",
      "Batch：2095 | Loss: 0.2799525558948517\n",
      "Batch：2096 | Loss: 0.2573187053203583\n",
      "Batch：2097 | Loss: 0.24651102721691132\n",
      "Batch：2098 | Loss: 0.25059694051742554\n",
      "Batch：2099 | Loss: 0.24409781396389008\n",
      "Batch：2100 | Loss: 0.26506680250167847\n",
      "Batch：2101 | Loss: 0.23638403415679932\n",
      "Batch：2102 | Loss: 0.25684142112731934\n",
      "Batch：2103 | Loss: 0.26182079315185547\n",
      "Batch：2104 | Loss: 0.2564930319786072\n",
      "Batch：2105 | Loss: 0.2519100606441498\n",
      "Batch：2106 | Loss: 0.2823355793952942\n",
      "Batch：2107 | Loss: 0.2428075671195984\n",
      "Batch：2108 | Loss: 0.24125412106513977\n",
      "Batch：2109 | Loss: 0.25340619683265686\n",
      "Batch：2110 | Loss: 0.2681400179862976\n",
      "Batch：2111 | Loss: 0.27004125714302063\n",
      "Batch：2112 | Loss: 0.27788251638412476\n",
      "Batch：2113 | Loss: 0.2821117043495178\n",
      "Batch：2114 | Loss: 0.2866017520427704\n",
      "Batch：2115 | Loss: 0.25337865948677063\n",
      "Batch：2116 | Loss: 0.24346023797988892\n",
      "Batch：2117 | Loss: 0.2663462162017822\n",
      "Batch：2118 | Loss: 0.2580626606941223\n",
      "Batch：2119 | Loss: 0.26264718174934387\n",
      "Batch：2120 | Loss: 0.251873254776001\n",
      "Batch：2121 | Loss: 0.2593367099761963\n",
      "Batch：2122 | Loss: 0.24486470222473145\n",
      "Batch：2123 | Loss: 0.2591297924518585\n",
      "Batch：2124 | Loss: 0.26684245467185974\n",
      "Batch：2125 | Loss: 0.26580148935317993\n",
      "Batch：2126 | Loss: 0.2615150213241577\n",
      "Batch：2127 | Loss: 0.26682502031326294\n",
      "Batch：2128 | Loss: 0.24670545756816864\n",
      "Batch：2129 | Loss: 0.26516059041023254\n",
      "Batch：2130 | Loss: 0.2577380836009979\n",
      "Batch：2131 | Loss: 0.2581249475479126\n",
      "Batch：2132 | Loss: 0.2670036256313324\n",
      "Batch：2133 | Loss: 0.2626883387565613\n",
      "Batch：2134 | Loss: 0.2508973479270935\n",
      "Batch：2135 | Loss: 0.25988924503326416\n",
      "Batch：2136 | Loss: 0.26698681712150574\n",
      "Batch：2137 | Loss: 0.25761502981185913\n",
      "Batch：2138 | Loss: 0.2617705762386322\n",
      "Batch：2139 | Loss: 0.24616654217243195\n",
      "Batch：2140 | Loss: 0.2636444568634033\n",
      "Batch：2141 | Loss: 0.2300368696451187\n",
      "Batch：2142 | Loss: 0.2761209011077881\n",
      "Batch：2143 | Loss: 0.24661678075790405\n",
      "Batch：2144 | Loss: 0.23768289387226105\n",
      "Batch：2145 | Loss: 0.2544306516647339\n",
      "Batch：2146 | Loss: 0.2654731869697571\n",
      "Batch：2147 | Loss: 0.2488594800233841\n",
      "Batch：2148 | Loss: 0.26547640562057495\n",
      "Batch：2149 | Loss: 0.2467050999403\n",
      "Batch：2150 | Loss: 0.25092411041259766\n",
      "Batch：2151 | Loss: 0.2368311583995819\n",
      "Batch：2152 | Loss: 0.2540394365787506\n",
      "Batch：2153 | Loss: 0.26185673475265503\n",
      "Batch：2154 | Loss: 0.24106235802173615\n",
      "Batch：2155 | Loss: 0.24103392660617828\n",
      "Batch：2156 | Loss: 0.262117475271225\n",
      "Batch：2157 | Loss: 0.2674769461154938\n",
      "Batch：2158 | Loss: 0.24414019286632538\n",
      "Batch：2159 | Loss: 0.24005790054798126\n",
      "Batch：2160 | Loss: 0.2427871823310852\n",
      "Batch：2161 | Loss: 0.26578855514526367\n",
      "Batch：2162 | Loss: 0.2570352256298065\n",
      "Batch：2163 | Loss: 0.25484251976013184\n",
      "Batch：2164 | Loss: 0.25812479853630066\n",
      "Batch：2165 | Loss: 0.24714042246341705\n",
      "Batch：2166 | Loss: 0.24477870762348175\n",
      "Batch：2167 | Loss: 0.26471835374832153\n",
      "Batch：2168 | Loss: 0.25639477372169495\n",
      "Batch：2169 | Loss: 0.2590022683143616\n",
      "Batch：2170 | Loss: 0.25652769207954407\n",
      "Batch：2171 | Loss: 0.27340784668922424\n",
      "Batch：2172 | Loss: 0.2522183358669281\n",
      "Batch：2173 | Loss: 0.26048755645751953\n",
      "Batch：2174 | Loss: 0.2577171325683594\n",
      "Batch：2175 | Loss: 0.2642247974872589\n",
      "Batch：2176 | Loss: 0.2662973999977112\n",
      "Batch：2177 | Loss: 0.2534474730491638\n",
      "Batch：2178 | Loss: 0.2569289207458496\n",
      "Batch：2179 | Loss: 0.2589836120605469\n",
      "Batch：2180 | Loss: 0.252126544713974\n",
      "Batch：2181 | Loss: 0.2507220506668091\n",
      "Batch：2182 | Loss: 0.242802694439888\n",
      "Batch：2183 | Loss: 0.24323812127113342\n",
      "Batch：2184 | Loss: 0.24398764967918396\n",
      "Batch：2185 | Loss: 0.2615717053413391\n",
      "Batch：2186 | Loss: 0.23932404816150665\n",
      "Batch：2187 | Loss: 0.25715506076812744\n",
      "Batch：2188 | Loss: 0.26811453700065613\n",
      "Batch：2189 | Loss: 0.2562149167060852\n",
      "Batch：2190 | Loss: 0.26122575998306274\n",
      "Batch：2191 | Loss: 0.2498743087053299\n",
      "Batch：2192 | Loss: 0.2412285953760147\n",
      "Batch：2193 | Loss: 0.24590462446212769\n",
      "Batch：2194 | Loss: 0.2553969621658325\n",
      "Batch：2195 | Loss: 0.26303592324256897\n",
      "Batch：2196 | Loss: 0.2740953862667084\n",
      "Batch：2197 | Loss: 0.24632863700389862\n",
      "Batch：2198 | Loss: 0.26303043961524963\n",
      "Batch：2199 | Loss: 0.2627165615558624\n",
      "Batch：2200 | Loss: 0.24462641775608063\n",
      "Batch：2201 | Loss: 0.27617543935775757\n",
      "Batch：2202 | Loss: 0.24926446378231049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：2203 | Loss: 0.25140735507011414\n",
      "Batch：2204 | Loss: 0.2479572892189026\n",
      "Batch：2205 | Loss: 0.24577456712722778\n",
      "Batch：2206 | Loss: 0.254788339138031\n",
      "Batch：2207 | Loss: 0.2662646770477295\n",
      "Batch：2208 | Loss: 0.2710264027118683\n",
      "Batch：2209 | Loss: 0.2447206974029541\n",
      "Batch：2210 | Loss: 0.25228777527809143\n",
      "Batch：2211 | Loss: 0.2481819987297058\n",
      "Batch：2212 | Loss: 0.277605801820755\n",
      "Batch：2213 | Loss: 0.26335787773132324\n",
      "Batch：2214 | Loss: 0.24388563632965088\n",
      "Batch：2215 | Loss: 0.2626532018184662\n",
      "Batch：2216 | Loss: 0.23485726118087769\n",
      "Batch：2217 | Loss: 0.25426167249679565\n",
      "Batch：2218 | Loss: 0.24346332252025604\n",
      "Batch：2219 | Loss: 0.25690755248069763\n",
      "Batch：2220 | Loss: 0.2363012731075287\n",
      "Batch：2221 | Loss: 0.246030792593956\n",
      "Batch：2222 | Loss: 0.2378878891468048\n",
      "Batch：2223 | Loss: 0.26098915934562683\n",
      "Batch：2224 | Loss: 0.24509994685649872\n",
      "Batch：2225 | Loss: 0.2652781009674072\n",
      "Batch：2226 | Loss: 0.24323402345180511\n",
      "Batch：2227 | Loss: 0.2668445110321045\n",
      "Batch：2228 | Loss: 0.26005324721336365\n",
      "Batch：2229 | Loss: 0.2452584058046341\n",
      "Batch：2230 | Loss: 0.24751989543437958\n",
      "Batch：2231 | Loss: 0.2357257902622223\n",
      "Batch：2232 | Loss: 0.26311251521110535\n",
      "Batch：2233 | Loss: 0.24618741869926453\n",
      "Batch：2234 | Loss: 0.24925416707992554\n",
      "Batch：2235 | Loss: 0.2489916980266571\n",
      "Batch：2236 | Loss: 0.2591279149055481\n",
      "Batch：2237 | Loss: 0.2429971843957901\n",
      "Batch：2238 | Loss: 0.24621149897575378\n",
      "Batch：2239 | Loss: 0.24822838604450226\n",
      "Batch：2240 | Loss: 0.23070727288722992\n",
      "Batch：2241 | Loss: 0.22945857048034668\n",
      "Batch：2242 | Loss: 0.24722790718078613\n",
      "Batch：2243 | Loss: 0.2478063553571701\n",
      "Batch：2244 | Loss: 0.24108947813510895\n",
      "Batch：2245 | Loss: 0.25203293561935425\n",
      "Batch：2246 | Loss: 0.24186301231384277\n",
      "Batch：2247 | Loss: 0.2606066167354584\n",
      "Batch：2248 | Loss: 0.2564246654510498\n",
      "Batch：2249 | Loss: 0.24233971536159515\n",
      "Batch：2250 | Loss: 0.24018342792987823\n",
      "Batch：2251 | Loss: 0.24638719856739044\n",
      "Batch：2252 | Loss: 0.25762686133384705\n",
      "Batch：2253 | Loss: 0.25122252106666565\n",
      "Batch：2254 | Loss: 0.2598875164985657\n",
      "Batch：2255 | Loss: 0.24148298799991608\n",
      "Batch：2256 | Loss: 0.24542641639709473\n",
      "Batch：2257 | Loss: 0.2437274307012558\n",
      "Batch：2258 | Loss: 0.2544822096824646\n",
      "Batch：2259 | Loss: 0.2523636519908905\n",
      "Batch：2260 | Loss: 0.2658812701702118\n",
      "Batch：2261 | Loss: 0.2383195161819458\n",
      "Batch：2262 | Loss: 0.24671219289302826\n",
      "Batch：2263 | Loss: 0.24463574588298798\n",
      "Batch：2264 | Loss: 0.24765177071094513\n",
      "Batch：2265 | Loss: 0.24174195528030396\n",
      "Batch：2266 | Loss: 0.24157242476940155\n",
      "Batch：2267 | Loss: 0.2494247555732727\n",
      "Batch：2268 | Loss: 0.2495848387479782\n",
      "Batch：2269 | Loss: 0.25105294585227966\n",
      "Batch：2270 | Loss: 0.26637887954711914\n",
      "Batch：2271 | Loss: 0.2550514340400696\n",
      "Batch：2272 | Loss: 0.238713338971138\n",
      "Batch：2273 | Loss: 0.2411969155073166\n",
      "Batch：2274 | Loss: 0.24951355159282684\n",
      "Batch：2275 | Loss: 0.24396951496601105\n",
      "Batch：2276 | Loss: 0.2568741738796234\n",
      "Batch：2277 | Loss: 0.2464652955532074\n",
      "Batch：2278 | Loss: 0.2470930516719818\n",
      "Batch：2279 | Loss: 0.2473391443490982\n",
      "Batch：2280 | Loss: 0.24101313948631287\n",
      "Batch：2281 | Loss: 0.24534335732460022\n",
      "Batch：2282 | Loss: 0.2306617796421051\n",
      "Batch：2283 | Loss: 0.2421933114528656\n",
      "Batch：2284 | Loss: 0.24779962003231049\n",
      "Batch：2285 | Loss: 0.237882599234581\n",
      "Batch：2286 | Loss: 0.2667941749095917\n",
      "Batch：2287 | Loss: 0.25874271988868713\n",
      "Batch：2288 | Loss: 0.2491311877965927\n",
      "Batch：2289 | Loss: 0.23004484176635742\n",
      "Batch：2290 | Loss: 0.2550860643386841\n",
      "Batch：2291 | Loss: 0.26403892040252686\n",
      "Batch：2292 | Loss: 0.2456004023551941\n",
      "Batch：2293 | Loss: 0.23606379330158234\n",
      "Batch：2294 | Loss: 0.23346714675426483\n",
      "Batch：2295 | Loss: 0.25895315408706665\n",
      "Batch：2296 | Loss: 0.25453847646713257\n",
      "Batch：2297 | Loss: 0.2261728048324585\n",
      "Batch：2298 | Loss: 0.2530193328857422\n",
      "Batch：2299 | Loss: 0.2741446793079376\n",
      "Batch：2300 | Loss: 0.23750416934490204\n",
      "Batch：2301 | Loss: 0.2501717507839203\n",
      "Batch：2302 | Loss: 0.245462566614151\n",
      "Batch：2303 | Loss: 0.2427782416343689\n",
      "Batch：2304 | Loss: 0.2503206431865692\n",
      "Batch：2305 | Loss: 0.25280457735061646\n",
      "Batch：2306 | Loss: 0.2418825626373291\n",
      "Batch：2307 | Loss: 0.24812617897987366\n",
      "Batch：2308 | Loss: 0.23981180787086487\n",
      "Batch：2309 | Loss: 0.24724653363227844\n",
      "Batch：2310 | Loss: 0.2432616949081421\n",
      "Batch：2311 | Loss: 0.24766914546489716\n",
      "Batch：2312 | Loss: 0.23042342066764832\n",
      "Batch：2313 | Loss: 0.22982679307460785\n",
      "Batch：2314 | Loss: 0.23429889976978302\n",
      "Batch：2315 | Loss: 0.22942480444908142\n",
      "Batch：2316 | Loss: 0.25309786200523376\n",
      "Batch：2317 | Loss: 0.236674964427948\n",
      "Batch：2318 | Loss: 0.25729894638061523\n",
      "Batch：2319 | Loss: 0.24593611061573029\n",
      "Batch：2320 | Loss: 0.24387194216251373\n",
      "Batch：2321 | Loss: 0.23287653923034668\n",
      "Batch：2322 | Loss: 0.22362083196640015\n",
      "Batch：2323 | Loss: 0.24030448496341705\n",
      "Batch：2324 | Loss: 0.2232259064912796\n",
      "Batch：2325 | Loss: 0.2503702640533447\n",
      "Batch：2326 | Loss: 0.26618340611457825\n",
      "Batch：2327 | Loss: 0.24562576413154602\n",
      "Batch：2328 | Loss: 0.23822416365146637\n",
      "Batch：2329 | Loss: 0.24361024796962738\n",
      "Batch：2330 | Loss: 0.2209819108247757\n",
      "Batch：2331 | Loss: 0.24918633699417114\n",
      "Batch：2332 | Loss: 0.24180565774440765\n",
      "Batch：2333 | Loss: 0.22681143879890442\n",
      "Batch：2334 | Loss: 0.2200503945350647\n",
      "Batch：2335 | Loss: 0.23870426416397095\n",
      "Batch：2336 | Loss: 0.23885969817638397\n",
      "Batch：2337 | Loss: 0.2323368638753891\n",
      "Batch：2338 | Loss: 0.25027748942375183\n",
      "Batch：2339 | Loss: 0.2576969563961029\n",
      "Batch：2340 | Loss: 0.25961029529571533\n",
      "Batch：2341 | Loss: 0.23609162867069244\n",
      "Batch：2342 | Loss: 0.24961885809898376\n",
      "Batch：2343 | Loss: 0.2354336529970169\n",
      "Batch：2344 | Loss: 0.2474505603313446\n",
      "Batch：2345 | Loss: 0.23376870155334473\n",
      "Batch：2346 | Loss: 0.25213348865509033\n",
      "Batch：2347 | Loss: 0.24462252855300903\n",
      "Batch：2348 | Loss: 0.23267604410648346\n",
      "Batch：2349 | Loss: 0.23690937459468842\n",
      "Batch：2350 | Loss: 0.23943586647510529\n",
      "Batch：2351 | Loss: 0.22678185999393463\n",
      "Batch：2352 | Loss: 0.22393113374710083\n",
      "Batch：2353 | Loss: 0.21746109426021576\n",
      "Batch：2354 | Loss: 0.22315645217895508\n",
      "Batch：2355 | Loss: 0.24137437343597412\n",
      "Batch：2356 | Loss: 0.2444079965353012\n",
      "Batch：2357 | Loss: 0.25249817967414856\n",
      "Batch：2358 | Loss: 0.2416485995054245\n",
      "Batch：2359 | Loss: 0.23663035035133362\n",
      "Batch：2360 | Loss: 0.24921758472919464\n",
      "Batch：2361 | Loss: 0.24252738058567047\n",
      "Batch：2362 | Loss: 0.2349114567041397\n",
      "Batch：2363 | Loss: 0.230342298746109\n",
      "Batch：2364 | Loss: 0.22704735398292542\n",
      "Batch：2365 | Loss: 0.2379344403743744\n",
      "Batch：2366 | Loss: 0.24012678861618042\n",
      "Batch：2367 | Loss: 0.2306118756532669\n",
      "Batch：2368 | Loss: 0.25095003843307495\n",
      "Batch：2369 | Loss: 0.22763174772262573\n",
      "Batch：2370 | Loss: 0.24653153121471405\n",
      "Batch：2371 | Loss: 0.23444484174251556\n",
      "Batch：2372 | Loss: 0.23358722031116486\n",
      "Batch：2373 | Loss: 0.23479731380939484\n",
      "Batch：2374 | Loss: 0.23959636688232422\n",
      "Batch：2375 | Loss: 0.23369388282299042\n",
      "Batch：2376 | Loss: 0.24481865763664246\n",
      "Batch：2377 | Loss: 0.22981111705303192\n",
      "Batch：2378 | Loss: 0.23554573953151703\n",
      "Batch：2379 | Loss: 0.25353768467903137\n",
      "Batch：2380 | Loss: 0.2392427772283554\n",
      "Batch：2381 | Loss: 0.24375391006469727\n",
      "Batch：2382 | Loss: 0.23939262330532074\n",
      "Batch：2383 | Loss: 0.23712480068206787\n",
      "Batch：2384 | Loss: 0.2099359780550003\n",
      "Batch：2385 | Loss: 0.24925215542316437\n",
      "Batch：2386 | Loss: 0.24608834087848663\n",
      "Batch：2387 | Loss: 0.2364434003829956\n",
      "Batch：2388 | Loss: 0.2273617386817932\n",
      "Batch：2389 | Loss: 0.24355393648147583\n",
      "Batch：2390 | Loss: 0.23744221031665802\n",
      "Batch：2391 | Loss: 0.24868769943714142\n",
      "Batch：2392 | Loss: 0.2387535572052002\n",
      "Batch：2393 | Loss: 0.24260640144348145\n",
      "Batch：2394 | Loss: 0.2524566352367401\n",
      "Batch：2395 | Loss: 0.24663899838924408\n",
      "Batch：2396 | Loss: 0.23197485506534576\n",
      "Batch：2397 | Loss: 0.25792044401168823\n",
      "Batch：2398 | Loss: 0.2283802479505539\n",
      "Batch：2399 | Loss: 0.23018914461135864\n",
      "Batch：2400 | Loss: 0.23697568476200104\n",
      "Batch：2401 | Loss: 0.2227969467639923\n",
      "Batch：2402 | Loss: 0.2493167221546173\n",
      "Batch：2403 | Loss: 0.22471503913402557\n",
      "Batch：2404 | Loss: 0.24774987995624542\n",
      "Batch：2405 | Loss: 0.22796475887298584\n",
      "Batch：2406 | Loss: 0.23559673130512238\n",
      "Batch：2407 | Loss: 0.2374071627855301\n",
      "Batch：2408 | Loss: 0.24301619827747345\n",
      "Batch：2409 | Loss: 0.2436874508857727\n",
      "Batch：2410 | Loss: 0.24012818932533264\n",
      "Batch：2411 | Loss: 0.23853273689746857\n",
      "Batch：2412 | Loss: 0.23594553768634796\n",
      "Batch：2413 | Loss: 0.24175679683685303\n",
      "Batch：2414 | Loss: 0.23103894293308258\n",
      "Batch：2415 | Loss: 0.23884634673595428\n",
      "Batch：2416 | Loss: 0.24331088364124298\n",
      "Batch：2417 | Loss: 0.23148168623447418\n",
      "Batch：2418 | Loss: 0.2348235845565796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：2419 | Loss: 0.22247125208377838\n",
      "Batch：2420 | Loss: 0.23991920053958893\n",
      "Batch：2421 | Loss: 0.2447165846824646\n",
      "Batch：2422 | Loss: 0.2293166071176529\n",
      "Batch：2423 | Loss: 0.21779929101467133\n",
      "Batch：2424 | Loss: 0.24390168488025665\n",
      "Batch：2425 | Loss: 0.21890699863433838\n",
      "Batch：2426 | Loss: 0.23186369240283966\n",
      "Batch：2427 | Loss: 0.22928392887115479\n",
      "Batch：2428 | Loss: 0.24161888659000397\n",
      "Batch：2429 | Loss: 0.2572006285190582\n",
      "Batch：2430 | Loss: 0.2285318374633789\n",
      "Batch：2431 | Loss: 0.23860898613929749\n",
      "Batch：2432 | Loss: 0.24103626608848572\n",
      "Batch：2433 | Loss: 0.24637861549854279\n",
      "Batch：2434 | Loss: 0.24246299266815186\n",
      "Batch：2435 | Loss: 0.2390090674161911\n",
      "Batch：2436 | Loss: 0.22662420570850372\n",
      "Batch：2437 | Loss: 0.2337658852338791\n",
      "Batch：2438 | Loss: 0.21720731258392334\n",
      "Batch：2439 | Loss: 0.22695015370845795\n",
      "Batch：2440 | Loss: 0.23582084476947784\n",
      "Batch：2441 | Loss: 0.24825337529182434\n",
      "Batch：2442 | Loss: 0.23886051774024963\n",
      "Batch：2443 | Loss: 0.22842887043952942\n",
      "Batch：2444 | Loss: 0.2331029623746872\n",
      "Batch：2445 | Loss: 0.23176534473896027\n",
      "Batch：2446 | Loss: 0.2538837194442749\n",
      "Batch：2447 | Loss: 0.23903214931488037\n",
      "Batch：2448 | Loss: 0.24265722930431366\n",
      "Batch：2449 | Loss: 0.24227628111839294\n",
      "Batch：2450 | Loss: 0.22177229821681976\n",
      "Batch：2451 | Loss: 0.24879629909992218\n",
      "Batch：2452 | Loss: 0.23658111691474915\n",
      "Batch：2453 | Loss: 0.2219494879245758\n",
      "Batch：2454 | Loss: 0.24226601421833038\n",
      "Batch：2455 | Loss: 0.23315270245075226\n",
      "Batch：2456 | Loss: 0.23210455477237701\n",
      "Batch：2457 | Loss: 0.22230581939220428\n",
      "Batch：2458 | Loss: 0.21596570312976837\n",
      "Batch：2459 | Loss: 0.24439485371112823\n",
      "Batch：2460 | Loss: 0.22250764071941376\n",
      "Batch：2461 | Loss: 0.23426507413387299\n",
      "Batch：2462 | Loss: 0.24058988690376282\n",
      "Batch：2463 | Loss: 0.23464065790176392\n",
      "Batch：2464 | Loss: 0.2345077246427536\n",
      "Batch：2465 | Loss: 0.2412259727716446\n",
      "Batch：2466 | Loss: 0.2244528830051422\n",
      "Batch：2467 | Loss: 0.22623863816261292\n",
      "Batch：2468 | Loss: 0.2610935568809509\n",
      "Batch：2469 | Loss: 0.24857552349567413\n",
      "Batch：2470 | Loss: 0.24600684642791748\n",
      "Batch：2471 | Loss: 0.23430399596691132\n",
      "Batch：2472 | Loss: 0.21363696455955505\n",
      "Batch：2473 | Loss: 0.24788714945316315\n",
      "Batch：2474 | Loss: 0.22569526731967926\n",
      "Batch：2475 | Loss: 0.2503191828727722\n",
      "Batch：2476 | Loss: 0.2246965765953064\n",
      "Batch：2477 | Loss: 0.2356150895357132\n",
      "Batch：2478 | Loss: 0.2294279932975769\n",
      "Batch：2479 | Loss: 0.2380163073539734\n",
      "Batch：2480 | Loss: 0.250806599855423\n",
      "Batch：2481 | Loss: 0.23821015655994415\n",
      "Batch：2482 | Loss: 0.2147468626499176\n",
      "Batch：2483 | Loss: 0.23101873695850372\n",
      "Batch：2484 | Loss: 0.2226209044456482\n",
      "Batch：2485 | Loss: 0.2260451465845108\n",
      "Batch：2486 | Loss: 0.24008890986442566\n",
      "Batch：2487 | Loss: 0.23290744423866272\n",
      "Batch：2488 | Loss: 0.22302135825157166\n",
      "Batch：2489 | Loss: 0.23437367379665375\n",
      "Batch：2490 | Loss: 0.21681976318359375\n",
      "Batch：2491 | Loss: 0.23765519261360168\n",
      "Batch：2492 | Loss: 0.21717846393585205\n",
      "Batch：2493 | Loss: 0.23009882867336273\n",
      "Batch：2494 | Loss: 0.2340860217809677\n",
      "Batch：2495 | Loss: 0.2325712889432907\n",
      "Batch：2496 | Loss: 0.22814489901065826\n",
      "Batch：2497 | Loss: 0.24297823011875153\n",
      "Batch：2498 | Loss: 0.2335413545370102\n",
      "Batch：2499 | Loss: 0.22788511216640472\n",
      "Batch：2500 | Loss: 0.23107987642288208\n",
      "Batch：2501 | Loss: 0.23320752382278442\n",
      "Batch：2502 | Loss: 0.2277546375989914\n",
      "Batch：2503 | Loss: 0.2248421013355255\n",
      "Batch：2504 | Loss: 0.239930659532547\n",
      "Batch：2505 | Loss: 0.23150569200515747\n",
      "Batch：2506 | Loss: 0.23888720571994781\n",
      "Batch：2507 | Loss: 0.22152502834796906\n",
      "Batch：2508 | Loss: 0.2231130748987198\n",
      "Batch：2509 | Loss: 0.19999650120735168\n",
      "Batch：2510 | Loss: 0.21901346743106842\n",
      "Batch：2511 | Loss: 0.23676513135433197\n",
      "Batch：2512 | Loss: 0.23220202326774597\n",
      "Batch：2513 | Loss: 0.23411217331886292\n",
      "Batch：2514 | Loss: 0.22823165357112885\n",
      "Batch：2515 | Loss: 0.23301619291305542\n",
      "Batch：2516 | Loss: 0.23335109651088715\n",
      "Batch：2517 | Loss: 0.213266521692276\n",
      "Batch：2518 | Loss: 0.23059724271297455\n",
      "Batch：2519 | Loss: 0.22676438093185425\n",
      "Batch：2520 | Loss: 0.21948282420635223\n",
      "Batch：2521 | Loss: 0.22954781353473663\n",
      "Batch：2522 | Loss: 0.21685977280139923\n",
      "Batch：2523 | Loss: 0.25068745017051697\n",
      "Batch：2524 | Loss: 0.21865999698638916\n",
      "Batch：2525 | Loss: 0.23445844650268555\n",
      "Batch：2526 | Loss: 0.22779379785060883\n",
      "Batch：2527 | Loss: 0.2224406898021698\n",
      "Batch：2528 | Loss: 0.219435915350914\n",
      "Batch：2529 | Loss: 0.24619832634925842\n",
      "Batch：2530 | Loss: 0.24694854021072388\n",
      "Batch：2531 | Loss: 0.22347894310951233\n",
      "Batch：2532 | Loss: 0.22121836245059967\n",
      "Batch：2533 | Loss: 0.2246045172214508\n",
      "Batch：2534 | Loss: 0.22333931922912598\n",
      "Batch：2535 | Loss: 0.23472683131694794\n",
      "Batch：2536 | Loss: 0.21890294551849365\n",
      "Batch：2537 | Loss: 0.23204541206359863\n",
      "Batch：2538 | Loss: 0.22354866564273834\n",
      "Batch：2539 | Loss: 0.2236350029706955\n",
      "Batch：2540 | Loss: 0.23122462630271912\n",
      "Batch：2541 | Loss: 0.23356257379055023\n",
      "Batch：2542 | Loss: 0.22552049160003662\n",
      "Batch：2543 | Loss: 0.23655521869659424\n",
      "Batch：2544 | Loss: 0.22224943339824677\n",
      "Batch：2545 | Loss: 0.22191491723060608\n",
      "Batch：2546 | Loss: 0.23727945983409882\n",
      "Batch：2547 | Loss: 0.2302045077085495\n",
      "Batch：2548 | Loss: 0.21444128453731537\n",
      "Batch：2549 | Loss: 0.23197120428085327\n",
      "Batch：2550 | Loss: 0.2324695587158203\n",
      "Batch：2551 | Loss: 0.22229982912540436\n",
      "Batch：2552 | Loss: 0.22153456509113312\n",
      "Batch：2553 | Loss: 0.22812557220458984\n",
      "Batch：2554 | Loss: 0.22907568514347076\n",
      "Batch：2555 | Loss: 0.22653226554393768\n",
      "Batch：2556 | Loss: 0.22478452324867249\n",
      "Batch：2557 | Loss: 0.22344380617141724\n",
      "Batch：2558 | Loss: 0.2306542545557022\n",
      "Batch：2559 | Loss: 0.2342066764831543\n",
      "Batch：2560 | Loss: 0.2285822480916977\n",
      "Batch：2561 | Loss: 0.2094327211380005\n",
      "Batch：2562 | Loss: 0.21882566809654236\n",
      "Batch：2563 | Loss: 0.21155975759029388\n",
      "Batch：2564 | Loss: 0.22241827845573425\n",
      "Batch：2565 | Loss: 0.2268977165222168\n",
      "Batch：2566 | Loss: 0.22757311165332794\n",
      "Batch：2567 | Loss: 0.22798658907413483\n",
      "Batch：2568 | Loss: 0.21975453197956085\n",
      "Batch：2569 | Loss: 0.23150211572647095\n",
      "Batch：2570 | Loss: 0.2275867760181427\n",
      "Batch：2571 | Loss: 0.24174298346042633\n",
      "Batch：2572 | Loss: 0.2322206199169159\n",
      "Batch：2573 | Loss: 0.22418905794620514\n",
      "Batch：2574 | Loss: 0.2233402132987976\n",
      "Batch：2575 | Loss: 0.22823333740234375\n",
      "Batch：2576 | Loss: 0.2257755845785141\n",
      "Batch：2577 | Loss: 0.22686165571212769\n",
      "Batch：2578 | Loss: 0.2501372992992401\n",
      "Batch：2579 | Loss: 0.23364852368831635\n",
      "Batch：2580 | Loss: 0.2129422128200531\n",
      "Batch：2581 | Loss: 0.21859106421470642\n",
      "Batch：2582 | Loss: 0.20988687872886658\n",
      "Batch：2583 | Loss: 0.22604572772979736\n",
      "Batch：2584 | Loss: 0.2174837589263916\n",
      "Batch：2585 | Loss: 0.2149394154548645\n",
      "Batch：2586 | Loss: 0.22718067467212677\n",
      "Batch：2587 | Loss: 0.2157604694366455\n",
      "Batch：2588 | Loss: 0.2335023581981659\n",
      "Batch：2589 | Loss: 0.22435835003852844\n",
      "Batch：2590 | Loss: 0.22963769733905792\n",
      "Batch：2591 | Loss: 0.2308182716369629\n",
      "Batch：2592 | Loss: 0.21570385992527008\n",
      "Batch：2593 | Loss: 0.21768970787525177\n",
      "Batch：2594 | Loss: 0.21864697337150574\n",
      "Batch：2595 | Loss: 0.22912390530109406\n",
      "Batch：2596 | Loss: 0.21272817254066467\n",
      "Batch：2597 | Loss: 0.2110445350408554\n",
      "Batch：2598 | Loss: 0.22560597956180573\n",
      "Batch：2599 | Loss: 0.22346504032611847\n",
      "Batch：2600 | Loss: 0.22521089017391205\n",
      "Batch：2601 | Loss: 0.23430639505386353\n",
      "Batch：2602 | Loss: 0.2195998728275299\n",
      "Batch：2603 | Loss: 0.2044832706451416\n",
      "Batch：2604 | Loss: 0.21312111616134644\n",
      "Batch：2605 | Loss: 0.22160445153713226\n",
      "Batch：2606 | Loss: 0.21858902275562286\n",
      "Batch：2607 | Loss: 0.22904928028583527\n",
      "Batch：2608 | Loss: 0.21182958781719208\n",
      "Batch：2609 | Loss: 0.22396187484264374\n",
      "Batch：2610 | Loss: 0.2279440015554428\n",
      "Batch：2611 | Loss: 0.23612964153289795\n",
      "Batch：2612 | Loss: 0.21040251851081848\n",
      "Batch：2613 | Loss: 0.22532881796360016\n",
      "Batch：2614 | Loss: 0.21907413005828857\n",
      "Batch：2615 | Loss: 0.22757704555988312\n",
      "Batch：2616 | Loss: 0.2134367823600769\n",
      "Batch：2617 | Loss: 0.2172580361366272\n",
      "Batch：2618 | Loss: 0.204477459192276\n",
      "Batch：2619 | Loss: 0.23115892708301544\n",
      "Batch：2620 | Loss: 0.2315191626548767\n",
      "Batch：2621 | Loss: 0.22602388262748718\n",
      "Batch：2622 | Loss: 0.22525091469287872\n",
      "Batch：2623 | Loss: 0.23105503618717194\n",
      "Batch：2624 | Loss: 0.21486914157867432\n",
      "Batch：2625 | Loss: 0.2303640991449356\n",
      "Batch：2626 | Loss: 0.2152913361787796\n",
      "Batch：2627 | Loss: 0.22948864102363586\n",
      "Batch：2628 | Loss: 0.2162991464138031\n",
      "Batch：2629 | Loss: 0.21184177696704865\n",
      "Batch：2630 | Loss: 0.21544326841831207\n",
      "Batch：2631 | Loss: 0.22202123701572418\n",
      "Batch：2632 | Loss: 0.22858113050460815\n",
      "Batch：2633 | Loss: 0.23190179467201233\n",
      "Batch：2634 | Loss: 0.23409777879714966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：2635 | Loss: 0.218187615275383\n",
      "Batch：2636 | Loss: 0.20197854936122894\n",
      "Batch：2637 | Loss: 0.21520979702472687\n",
      "Batch：2638 | Loss: 0.21138222515583038\n",
      "Batch：2639 | Loss: 0.2174062728881836\n",
      "Batch：2640 | Loss: 0.22151297330856323\n",
      "Batch：2641 | Loss: 0.22342605888843536\n",
      "Batch：2642 | Loss: 0.2267698496580124\n",
      "Batch：2643 | Loss: 0.22962109744548798\n",
      "Batch：2644 | Loss: 0.2174738198518753\n",
      "Batch：2645 | Loss: 0.22525224089622498\n",
      "Batch：2646 | Loss: 0.22410184144973755\n",
      "Batch：2647 | Loss: 0.21458929777145386\n",
      "Batch：2648 | Loss: 0.212851420044899\n",
      "Batch：2649 | Loss: 0.23211131989955902\n",
      "Batch：2650 | Loss: 0.22508268058300018\n",
      "Batch：2651 | Loss: 0.23005934059619904\n",
      "Batch：2652 | Loss: 0.21306270360946655\n",
      "Batch：2653 | Loss: 0.21129146218299866\n",
      "Batch：2654 | Loss: 0.21275334060192108\n",
      "Batch：2655 | Loss: 0.22835853695869446\n",
      "Batch：2656 | Loss: 0.22481408715248108\n",
      "Batch：2657 | Loss: 0.21810150146484375\n",
      "Batch：2658 | Loss: 0.21165154874324799\n",
      "Batch：2659 | Loss: 0.2118096649646759\n",
      "Batch：2660 | Loss: 0.21020376682281494\n",
      "Batch：2661 | Loss: 0.22381141781806946\n",
      "Batch：2662 | Loss: 0.2074614018201828\n",
      "Batch：2663 | Loss: 0.21867015957832336\n",
      "Batch：2664 | Loss: 0.20680254697799683\n",
      "Batch：2665 | Loss: 0.22549651563167572\n",
      "Batch：2666 | Loss: 0.22146514058113098\n",
      "Batch：2667 | Loss: 0.22252170741558075\n",
      "Batch：2668 | Loss: 0.20789164304733276\n",
      "Batch：2669 | Loss: 0.23262810707092285\n",
      "Batch：2670 | Loss: 0.24016505479812622\n",
      "Batch：2671 | Loss: 0.21789021790027618\n",
      "Batch：2672 | Loss: 0.20320352911949158\n",
      "Batch：2673 | Loss: 0.21231554448604584\n",
      "Batch：2674 | Loss: 0.2133871167898178\n",
      "Batch：2675 | Loss: 0.21838392317295074\n",
      "Batch：2676 | Loss: 0.2153206616640091\n",
      "Batch：2677 | Loss: 0.20476968586444855\n",
      "Batch：2678 | Loss: 0.22577457129955292\n",
      "Batch：2679 | Loss: 0.2256437987089157\n",
      "Batch：2680 | Loss: 0.21670688688755035\n",
      "Batch：2681 | Loss: 0.20881938934326172\n",
      "Batch：2682 | Loss: 0.22335860133171082\n",
      "Batch：2683 | Loss: 0.21604430675506592\n",
      "Batch：2684 | Loss: 0.2129402607679367\n",
      "Batch：2685 | Loss: 0.2130354344844818\n",
      "Batch：2686 | Loss: 0.21029984951019287\n",
      "Batch：2687 | Loss: 0.21203123033046722\n",
      "Batch：2688 | Loss: 0.22083060443401337\n",
      "Batch：2689 | Loss: 0.23848509788513184\n",
      "Batch：2690 | Loss: 0.21356201171875\n",
      "Batch：2691 | Loss: 0.21031434834003448\n",
      "Batch：2692 | Loss: 0.20651662349700928\n",
      "Batch：2693 | Loss: 0.2260478287935257\n",
      "Batch：2694 | Loss: 0.21573802828788757\n",
      "Batch：2695 | Loss: 0.2246590107679367\n",
      "Batch：2696 | Loss: 0.2227828949689865\n",
      "Batch：2697 | Loss: 0.22209742665290833\n",
      "Batch：2698 | Loss: 0.22233805060386658\n",
      "Batch：2699 | Loss: 0.22094392776489258\n",
      "Batch：2700 | Loss: 0.23033736646175385\n",
      "Batch：2701 | Loss: 0.22281436622142792\n",
      "Batch：2702 | Loss: 0.21324706077575684\n",
      "Batch：2703 | Loss: 0.20948225259780884\n",
      "Batch：2704 | Loss: 0.22050604224205017\n",
      "Batch：2705 | Loss: 0.20972086489200592\n",
      "Batch：2706 | Loss: 0.2147747427225113\n",
      "Batch：2707 | Loss: 0.22153055667877197\n",
      "Batch：2708 | Loss: 0.2104818969964981\n",
      "Batch：2709 | Loss: 0.22439292073249817\n",
      "Batch：2710 | Loss: 0.21688313782215118\n",
      "Batch：2711 | Loss: 0.22251161932945251\n",
      "Batch：2712 | Loss: 0.2039361298084259\n",
      "Batch：2713 | Loss: 0.20936588943004608\n",
      "Batch：2714 | Loss: 0.21179217100143433\n",
      "Batch：2715 | Loss: 0.21750251948833466\n",
      "Batch：2716 | Loss: 0.23170344531536102\n",
      "Batch：2717 | Loss: 0.21385054290294647\n",
      "Batch：2718 | Loss: 0.22186274826526642\n",
      "Batch：2719 | Loss: 0.2199295610189438\n",
      "Batch：2720 | Loss: 0.21653999388217926\n",
      "Batch：2721 | Loss: 0.20399019122123718\n",
      "Batch：2722 | Loss: 0.21728895604610443\n",
      "Batch：2723 | Loss: 0.21415913105010986\n",
      "Batch：2724 | Loss: 0.2182854861021042\n",
      "Batch：2725 | Loss: 0.2221190184354782\n",
      "Batch：2726 | Loss: 0.20126517117023468\n",
      "Batch：2727 | Loss: 0.20398852229118347\n",
      "Batch：2728 | Loss: 0.20581167936325073\n",
      "Batch：2729 | Loss: 0.22331489622592926\n",
      "Batch：2730 | Loss: 0.2131807506084442\n",
      "Batch：2731 | Loss: 0.20837046205997467\n",
      "Batch：2732 | Loss: 0.21895328164100647\n",
      "Batch：2733 | Loss: 0.20674853026866913\n",
      "Batch：2734 | Loss: 0.2163006216287613\n",
      "Batch：2735 | Loss: 0.2053857445716858\n",
      "Batch：2736 | Loss: 0.2097322791814804\n",
      "Batch：2737 | Loss: 0.21478290855884552\n",
      "Batch：2738 | Loss: 0.20364558696746826\n",
      "Batch：2739 | Loss: 0.21428385376930237\n",
      "Batch：2740 | Loss: 0.217532217502594\n",
      "Batch：2741 | Loss: 0.21082435548305511\n",
      "Batch：2742 | Loss: 0.21656933426856995\n",
      "Batch：2743 | Loss: 0.21487511694431305\n",
      "Batch：2744 | Loss: 0.21775363385677338\n",
      "Batch：2745 | Loss: 0.2038400024175644\n",
      "Batch：2746 | Loss: 0.20650207996368408\n",
      "Batch：2747 | Loss: 0.2007347047328949\n",
      "Batch：2748 | Loss: 0.2027161419391632\n",
      "Batch：2749 | Loss: 0.2288842350244522\n",
      "Batch：2750 | Loss: 0.21879523992538452\n",
      "Batch：2751 | Loss: 0.21317170560359955\n",
      "Batch：2752 | Loss: 0.20537646114826202\n",
      "Batch：2753 | Loss: 0.21013440191745758\n",
      "Batch：2754 | Loss: 0.21152234077453613\n",
      "Batch：2755 | Loss: 0.2104819267988205\n",
      "Batch：2756 | Loss: 0.2176092565059662\n",
      "Batch：2757 | Loss: 0.21534200012683868\n",
      "Batch：2758 | Loss: 0.2199966162443161\n",
      "Batch：2759 | Loss: 0.21445439755916595\n",
      "Batch：2760 | Loss: 0.20048455893993378\n",
      "Batch：2761 | Loss: 0.22133997082710266\n",
      "Batch：2762 | Loss: 0.20415112376213074\n",
      "Batch：2763 | Loss: 0.20896729826927185\n",
      "Batch：2764 | Loss: 0.215898796916008\n",
      "Batch：2765 | Loss: 0.21794173121452332\n",
      "Batch：2766 | Loss: 0.21988195180892944\n",
      "Batch：2767 | Loss: 0.22689899802207947\n",
      "Batch：2768 | Loss: 0.19939185678958893\n",
      "Batch：2769 | Loss: 0.21771162748336792\n",
      "Batch：2770 | Loss: 0.2064305543899536\n",
      "Batch：2771 | Loss: 0.21021026372909546\n",
      "Batch：2772 | Loss: 0.19472822546958923\n",
      "Batch：2773 | Loss: 0.2235289067029953\n",
      "Batch：2774 | Loss: 0.20681045949459076\n",
      "Batch：2775 | Loss: 0.20304451882839203\n",
      "Batch：2776 | Loss: 0.20384667813777924\n",
      "Batch：2777 | Loss: 0.21114493906497955\n",
      "Batch：2778 | Loss: 0.2020610123872757\n",
      "Batch：2779 | Loss: 0.20461057126522064\n",
      "Batch：2780 | Loss: 0.19325879216194153\n",
      "Batch：2781 | Loss: 0.2077128142118454\n",
      "Batch：2782 | Loss: 0.2258410006761551\n",
      "Batch：2783 | Loss: 0.2251572608947754\n",
      "Batch：2784 | Loss: 0.20740538835525513\n",
      "Batch：2785 | Loss: 0.20738263428211212\n",
      "Batch：2786 | Loss: 0.213282972574234\n",
      "Batch：2787 | Loss: 0.20554712414741516\n",
      "Batch：2788 | Loss: 0.20958653092384338\n",
      "Batch：2789 | Loss: 0.20547173917293549\n",
      "Batch：2790 | Loss: 0.2194792479276657\n",
      "Batch：2791 | Loss: 0.19661647081375122\n",
      "Batch：2792 | Loss: 0.2071944922208786\n",
      "Batch：2793 | Loss: 0.22234037518501282\n",
      "Batch：2794 | Loss: 0.222734734416008\n",
      "Batch：2795 | Loss: 0.21718819439411163\n",
      "Batch：2796 | Loss: 0.2107628732919693\n",
      "Batch：2797 | Loss: 0.2024214267730713\n",
      "Batch：2798 | Loss: 0.2272670865058899\n",
      "Batch：2799 | Loss: 0.20828405022621155\n",
      "Batch：2800 | Loss: 0.21157453954219818\n",
      "Batch：2801 | Loss: 0.20812556147575378\n",
      "Batch：2802 | Loss: 0.21913455426692963\n",
      "Batch：2803 | Loss: 0.2051447331905365\n",
      "Batch：2804 | Loss: 0.20981687307357788\n",
      "Batch：2805 | Loss: 0.2085302770137787\n",
      "Batch：2806 | Loss: 0.20948636531829834\n",
      "Batch：2807 | Loss: 0.20558390021324158\n",
      "Batch：2808 | Loss: 0.21064493060112\n",
      "Batch：2809 | Loss: 0.20357763767242432\n",
      "Batch：2810 | Loss: 0.22162911295890808\n",
      "Batch：2811 | Loss: 0.22123174369335175\n",
      "Batch：2812 | Loss: 0.21474342048168182\n",
      "Batch：2813 | Loss: 0.20790965855121613\n",
      "Batch：2814 | Loss: 0.2177325040102005\n",
      "Batch：2815 | Loss: 0.2265491485595703\n",
      "Batch：2816 | Loss: 0.21073856949806213\n",
      "Batch：2817 | Loss: 0.21057133376598358\n",
      "Batch：2818 | Loss: 0.1975671797990799\n",
      "Batch：2819 | Loss: 0.20661063492298126\n",
      "Batch：2820 | Loss: 0.20785866677761078\n",
      "Batch：2821 | Loss: 0.19037942588329315\n",
      "Batch：2822 | Loss: 0.20447224378585815\n",
      "Batch：2823 | Loss: 0.21043318510055542\n",
      "Batch：2824 | Loss: 0.20391012728214264\n",
      "Batch：2825 | Loss: 0.2181726098060608\n",
      "Batch：2826 | Loss: 0.21671441197395325\n",
      "Batch：2827 | Loss: 0.22177425026893616\n",
      "Batch：2828 | Loss: 0.21208681166172028\n",
      "Batch：2829 | Loss: 0.23318909108638763\n",
      "Batch：2830 | Loss: 0.2027812898159027\n",
      "Batch：2831 | Loss: 0.20746129751205444\n",
      "Batch：2832 | Loss: 0.1960229128599167\n",
      "Batch：2833 | Loss: 0.20893171429634094\n",
      "Batch：2834 | Loss: 0.21577458083629608\n",
      "Batch：2835 | Loss: 0.1910894364118576\n",
      "Batch：2836 | Loss: 0.19860327243804932\n",
      "Batch：2837 | Loss: 0.20729206502437592\n",
      "Batch：2838 | Loss: 0.2106853574514389\n",
      "Batch：2839 | Loss: 0.20372837781906128\n",
      "Batch：2840 | Loss: 0.19707944989204407\n",
      "Batch：2841 | Loss: 0.20797869563102722\n",
      "Batch：2842 | Loss: 0.20409199595451355\n",
      "Batch：2843 | Loss: 0.21280436217784882\n",
      "Batch：2844 | Loss: 0.20731335878372192\n",
      "Batch：2845 | Loss: 0.19286055862903595\n",
      "Batch：2846 | Loss: 0.21697992086410522\n",
      "Batch：2847 | Loss: 0.19201575219631195\n",
      "Batch：2848 | Loss: 0.21569323539733887\n",
      "Batch：2849 | Loss: 0.21023714542388916\n",
      "Batch：2850 | Loss: 0.20102201402187347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：2851 | Loss: 0.2098514437675476\n",
      "Batch：2852 | Loss: 0.20769286155700684\n",
      "Batch：2853 | Loss: 0.20711852610111237\n",
      "Batch：2854 | Loss: 0.21201102435588837\n",
      "Batch：2855 | Loss: 0.22088560461997986\n",
      "Batch：2856 | Loss: 0.20100097358226776\n",
      "Batch：2857 | Loss: 0.1970265507698059\n",
      "Batch：2858 | Loss: 0.19797593355178833\n",
      "Batch：2859 | Loss: 0.20196472108364105\n",
      "Batch：2860 | Loss: 0.20528748631477356\n",
      "Batch：2861 | Loss: 0.21051086485385895\n",
      "Batch：2862 | Loss: 0.19673779606819153\n",
      "Batch：2863 | Loss: 0.20169998705387115\n",
      "Batch：2864 | Loss: 0.2040206342935562\n",
      "Batch：2865 | Loss: 0.206136554479599\n",
      "Batch：2866 | Loss: 0.20384523272514343\n",
      "Batch：2867 | Loss: 0.19837357103824615\n",
      "Batch：2868 | Loss: 0.21194826066493988\n",
      "Batch：2869 | Loss: 0.20104670524597168\n",
      "Batch：2870 | Loss: 0.20452018082141876\n",
      "Batch：2871 | Loss: 0.21486590802669525\n",
      "Batch：2872 | Loss: 0.2047530859708786\n",
      "Batch：2873 | Loss: 0.1996138095855713\n",
      "Batch：2874 | Loss: 0.19902119040489197\n",
      "Batch：2875 | Loss: 0.19269408285617828\n",
      "Batch：2876 | Loss: 0.19592075049877167\n",
      "Batch：2877 | Loss: 0.1988256871700287\n",
      "Batch：2878 | Loss: 0.2183731496334076\n",
      "Batch：2879 | Loss: 0.2093539535999298\n",
      "Batch：2880 | Loss: 0.21223460137844086\n",
      "Batch：2881 | Loss: 0.20238906145095825\n",
      "Batch：2882 | Loss: 0.2055700719356537\n",
      "Batch：2883 | Loss: 0.19460611045360565\n",
      "Batch：2884 | Loss: 0.2064291536808014\n",
      "Batch：2885 | Loss: 0.186661496758461\n",
      "Batch：2886 | Loss: 0.21912118792533875\n",
      "Batch：2887 | Loss: 0.19552923738956451\n",
      "Batch：2888 | Loss: 0.1931123584508896\n",
      "Batch：2889 | Loss: 0.22767610847949982\n",
      "Batch：2890 | Loss: 0.20134735107421875\n",
      "Batch：2891 | Loss: 0.22947899997234344\n",
      "Batch：2892 | Loss: 0.2122955322265625\n",
      "Batch：2893 | Loss: 0.20654407143592834\n",
      "Batch：2894 | Loss: 0.1961526721715927\n",
      "Batch：2895 | Loss: 0.19558197259902954\n",
      "Batch：2896 | Loss: 0.202508345246315\n",
      "Batch：2897 | Loss: 0.19474947452545166\n",
      "Batch：2898 | Loss: 0.2050665318965912\n",
      "Batch：2899 | Loss: 0.19403253495693207\n",
      "Batch：2900 | Loss: 0.18168501555919647\n",
      "Batch：2901 | Loss: 0.205142080783844\n",
      "Batch：2902 | Loss: 0.20272916555404663\n",
      "Batch：2903 | Loss: 0.2074369639158249\n",
      "Batch：2904 | Loss: 0.19939151406288147\n",
      "Batch：2905 | Loss: 0.21092581748962402\n",
      "Batch：2906 | Loss: 0.21411193907260895\n",
      "Batch：2907 | Loss: 0.19098608195781708\n",
      "Batch：2908 | Loss: 0.20329958200454712\n",
      "Batch：2909 | Loss: 0.1981355845928192\n",
      "Batch：2910 | Loss: 0.21230293810367584\n",
      "Batch：2911 | Loss: 0.20557574927806854\n",
      "Batch：2912 | Loss: 0.2168620228767395\n",
      "Batch：2913 | Loss: 0.20953787863254547\n",
      "Batch：2914 | Loss: 0.1999184936285019\n",
      "Batch：2915 | Loss: 0.20211820304393768\n",
      "Batch：2916 | Loss: 0.21139566600322723\n",
      "Batch：2917 | Loss: 0.21443527936935425\n",
      "Batch：2918 | Loss: 0.20023658871650696\n",
      "Batch：2919 | Loss: 0.2005184441804886\n",
      "Batch：2920 | Loss: 0.18770849704742432\n",
      "Batch：2921 | Loss: 0.19020269811153412\n",
      "Batch：2922 | Loss: 0.21350009739398956\n",
      "Batch：2923 | Loss: 0.18652845919132233\n",
      "Batch：2924 | Loss: 0.19747696816921234\n",
      "Batch：2925 | Loss: 0.1974152773618698\n",
      "Batch：2926 | Loss: 0.19145235419273376\n",
      "Batch：2927 | Loss: 0.2005368173122406\n",
      "Batch：2928 | Loss: 0.22249314188957214\n",
      "Batch：2929 | Loss: 0.2065950632095337\n",
      "Batch：2930 | Loss: 0.20007681846618652\n",
      "Batch：2931 | Loss: 0.21256951987743378\n",
      "Batch：2932 | Loss: 0.20086048543453217\n",
      "Batch：2933 | Loss: 0.21682031452655792\n",
      "Batch：2934 | Loss: 0.2074602097272873\n",
      "Batch：2935 | Loss: 0.20369063317775726\n",
      "Batch：2936 | Loss: 0.20310555398464203\n",
      "Batch：2937 | Loss: 0.20561179518699646\n",
      "Batch：2938 | Loss: 0.2272455245256424\n",
      "Batch：2939 | Loss: 0.2090224325656891\n",
      "Batch：2940 | Loss: 0.18993395566940308\n",
      "Batch：2941 | Loss: 0.20481379330158234\n",
      "Batch：2942 | Loss: 0.20398345589637756\n",
      "Batch：2943 | Loss: 0.18856994807720184\n",
      "Batch：2944 | Loss: 0.20934757590293884\n",
      "Batch：2945 | Loss: 0.1985800415277481\n",
      "Batch：2946 | Loss: 0.2183719426393509\n",
      "Batch：2947 | Loss: 0.19799670577049255\n",
      "Batch：2948 | Loss: 0.1975630223751068\n",
      "Batch：2949 | Loss: 0.1944170743227005\n",
      "Batch：2950 | Loss: 0.19655969738960266\n",
      "Batch：2951 | Loss: 0.20891577005386353\n",
      "Batch：2952 | Loss: 0.2066214233636856\n",
      "Batch：2953 | Loss: 0.18282075226306915\n",
      "Batch：2954 | Loss: 0.20710253715515137\n",
      "Batch：2955 | Loss: 0.22683152556419373\n",
      "Batch：2956 | Loss: 0.20117272436618805\n",
      "Batch：2957 | Loss: 0.19545140862464905\n",
      "Batch：2958 | Loss: 0.20319689810276031\n",
      "Batch：2959 | Loss: 0.21017007529735565\n",
      "Batch：2960 | Loss: 0.180235356092453\n",
      "Batch：2961 | Loss: 0.21029531955718994\n",
      "Batch：2962 | Loss: 0.19006316363811493\n",
      "Batch：2963 | Loss: 0.20251862704753876\n",
      "Batch：2964 | Loss: 0.20939859747886658\n",
      "Batch：2965 | Loss: 0.19686885178089142\n",
      "Batch：2966 | Loss: 0.18195483088493347\n",
      "Batch：2967 | Loss: 0.20310352742671967\n",
      "Batch：2968 | Loss: 0.22771887481212616\n",
      "Batch：2969 | Loss: 0.20253649353981018\n",
      "Batch：2970 | Loss: 0.19511999189853668\n",
      "Batch：2971 | Loss: 0.19749940931797028\n",
      "Batch：2972 | Loss: 0.2044278383255005\n",
      "Batch：2973 | Loss: 0.20402398705482483\n",
      "Batch：2974 | Loss: 0.2028820812702179\n",
      "Batch：2975 | Loss: 0.2016133964061737\n",
      "Batch：2976 | Loss: 0.19845889508724213\n",
      "Batch：2977 | Loss: 0.2065781056880951\n",
      "Batch：2978 | Loss: 0.1930111050605774\n",
      "Batch：2979 | Loss: 0.19268354773521423\n",
      "Batch：2980 | Loss: 0.2089708298444748\n",
      "Batch：2981 | Loss: 0.20530281960964203\n",
      "Batch：2982 | Loss: 0.1951673924922943\n",
      "Batch：2983 | Loss: 0.21765047311782837\n",
      "Batch：2984 | Loss: 0.20137953758239746\n",
      "Batch：2985 | Loss: 0.20526748895645142\n",
      "Batch：2986 | Loss: 0.19485001266002655\n",
      "Batch：2987 | Loss: 0.19071292877197266\n",
      "Batch：2988 | Loss: 0.2042028307914734\n",
      "Batch：2989 | Loss: 0.2142036110162735\n",
      "Batch：2990 | Loss: 0.19633212685585022\n",
      "Batch：2991 | Loss: 0.19440141320228577\n",
      "Batch：2992 | Loss: 0.2002907693386078\n",
      "Batch：2993 | Loss: 0.1886027604341507\n",
      "Batch：2994 | Loss: 0.20038211345672607\n",
      "Batch：2995 | Loss: 0.19989749789237976\n",
      "Batch：2996 | Loss: 0.2038792222738266\n",
      "Batch：2997 | Loss: 0.2018582671880722\n",
      "Batch：2998 | Loss: 0.21541479229927063\n",
      "Batch：2999 | Loss: 0.1955648809671402\n",
      "Batch：3000 | Loss: 0.19015374779701233\n",
      "Batch：3001 | Loss: 0.1932150423526764\n",
      "Batch：3002 | Loss: 0.1893143504858017\n",
      "Batch：3003 | Loss: 0.20161788165569305\n",
      "Batch：3004 | Loss: 0.19206982851028442\n",
      "Batch：3005 | Loss: 0.1884346902370453\n",
      "Batch：3006 | Loss: 0.1847866028547287\n",
      "Batch：3007 | Loss: 0.20017018914222717\n",
      "Batch：3008 | Loss: 0.20251303911209106\n",
      "Batch：3009 | Loss: 0.20314621925354004\n",
      "Batch：3010 | Loss: 0.1892087757587433\n",
      "Batch：3011 | Loss: 0.1903487592935562\n",
      "Batch：3012 | Loss: 0.20188991725444794\n",
      "Batch：3013 | Loss: 0.20488372445106506\n",
      "Batch：3014 | Loss: 0.19122543931007385\n",
      "Batch：3015 | Loss: 0.19500085711479187\n",
      "Batch：3016 | Loss: 0.19112001359462738\n",
      "Batch：3017 | Loss: 0.1924283355474472\n",
      "Batch：3018 | Loss: 0.18890254199504852\n",
      "Batch：3019 | Loss: 0.18387556076049805\n",
      "Batch：3020 | Loss: 0.20179878175258636\n",
      "Batch：3021 | Loss: 0.2015654742717743\n",
      "Batch：3022 | Loss: 0.1987394392490387\n",
      "Batch：3023 | Loss: 0.19662213325500488\n",
      "Batch：3024 | Loss: 0.19795218110084534\n",
      "Batch：3025 | Loss: 0.19318106770515442\n",
      "Batch：3026 | Loss: 0.18898306787014008\n",
      "Batch：3027 | Loss: 0.20781217515468597\n",
      "Batch：3028 | Loss: 0.1778605729341507\n",
      "Batch：3029 | Loss: 0.20152905583381653\n",
      "Batch：3030 | Loss: 0.20606355369091034\n",
      "Batch：3031 | Loss: 0.20367883145809174\n",
      "Batch：3032 | Loss: 0.19841715693473816\n",
      "Batch：3033 | Loss: 0.20343635976314545\n",
      "Batch：3034 | Loss: 0.2005336880683899\n",
      "Batch：3035 | Loss: 0.1959485411643982\n",
      "Batch：3036 | Loss: 0.18730370700359344\n",
      "Batch：3037 | Loss: 0.1832723766565323\n",
      "Batch：3038 | Loss: 0.1998688131570816\n",
      "Batch：3039 | Loss: 0.19809794425964355\n",
      "Batch：3040 | Loss: 0.21256528794765472\n",
      "Batch：3041 | Loss: 0.1932300329208374\n",
      "Batch：3042 | Loss: 0.19673508405685425\n",
      "Batch：3043 | Loss: 0.1772736757993698\n",
      "Batch：3044 | Loss: 0.2173488736152649\n",
      "Batch：3045 | Loss: 0.197434201836586\n",
      "Batch：3046 | Loss: 0.19465994834899902\n",
      "Batch：3047 | Loss: 0.19808992743492126\n",
      "Batch：3048 | Loss: 0.19952461123466492\n",
      "Batch：3049 | Loss: 0.19979825615882874\n",
      "Batch：3050 | Loss: 0.19545568525791168\n",
      "Batch：3051 | Loss: 0.18724516034126282\n",
      "Batch：3052 | Loss: 0.1947641521692276\n",
      "Batch：3053 | Loss: 0.1935897022485733\n",
      "Batch：3054 | Loss: 0.1913730502128601\n",
      "Batch：3055 | Loss: 0.18162143230438232\n",
      "Batch：3056 | Loss: 0.19579532742500305\n",
      "Batch：3057 | Loss: 0.2147672474384308\n",
      "Batch：3058 | Loss: 0.1792048066854477\n",
      "Batch：3059 | Loss: 0.21255487203598022\n",
      "Batch：3060 | Loss: 0.1795395016670227\n",
      "Batch：3061 | Loss: 0.18859820067882538\n",
      "Batch：3062 | Loss: 0.18305113911628723\n",
      "Batch：3063 | Loss: 0.21337831020355225\n",
      "Batch：3064 | Loss: 0.18118029832839966\n",
      "Batch：3065 | Loss: 0.1919942945241928\n",
      "Batch：3066 | Loss: 0.19472219049930573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：3067 | Loss: 0.1947227567434311\n",
      "Batch：3068 | Loss: 0.19653655588626862\n",
      "Batch：3069 | Loss: 0.1919371485710144\n",
      "Batch：3070 | Loss: 0.1917780339717865\n",
      "Batch：3071 | Loss: 0.18776020407676697\n",
      "Batch：3072 | Loss: 0.19531774520874023\n",
      "Batch：3073 | Loss: 0.19270405173301697\n",
      "Batch：3074 | Loss: 0.20850640535354614\n",
      "Batch：3075 | Loss: 0.1780581921339035\n",
      "Batch：3076 | Loss: 0.19449003040790558\n",
      "Batch：3077 | Loss: 0.20198380947113037\n",
      "Batch：3078 | Loss: 0.1959695816040039\n",
      "Batch：3079 | Loss: 0.18320314586162567\n",
      "Batch：3080 | Loss: 0.18979677557945251\n",
      "Batch：3081 | Loss: 0.19376179575920105\n",
      "Batch：3082 | Loss: 0.18882043659687042\n",
      "Batch：3083 | Loss: 0.19523832201957703\n",
      "Batch：3084 | Loss: 0.1928657442331314\n",
      "Batch：3085 | Loss: 0.2010994255542755\n",
      "Batch：3086 | Loss: 0.2082906812429428\n",
      "Batch：3087 | Loss: 0.20141641795635223\n",
      "Batch：3088 | Loss: 0.20120206475257874\n",
      "Batch：3089 | Loss: 0.1967349499464035\n",
      "Batch：3090 | Loss: 0.2006809115409851\n",
      "Batch：3091 | Loss: 0.20988543331623077\n",
      "Batch：3092 | Loss: 0.19202518463134766\n",
      "Batch：3093 | Loss: 0.2045276015996933\n",
      "Batch：3094 | Loss: 0.18481452763080597\n",
      "Batch：3095 | Loss: 0.1993732452392578\n",
      "Batch：3096 | Loss: 0.19676163792610168\n",
      "Batch：3097 | Loss: 0.20806418359279633\n",
      "Batch：3098 | Loss: 0.17922185361385345\n",
      "Batch：3099 | Loss: 0.18951088190078735\n",
      "Batch：3100 | Loss: 0.18309606611728668\n",
      "Batch：3101 | Loss: 0.19844235479831696\n",
      "Batch：3102 | Loss: 0.1931757628917694\n",
      "Batch：3103 | Loss: 0.19670633971691132\n",
      "Batch：3104 | Loss: 0.20363232493400574\n",
      "Batch：3105 | Loss: 0.18533797562122345\n",
      "Batch：3106 | Loss: 0.18997681140899658\n",
      "Batch：3107 | Loss: 0.19588391482830048\n",
      "Batch：3108 | Loss: 0.1989843100309372\n",
      "Batch：3109 | Loss: 0.1897248476743698\n",
      "Batch：3110 | Loss: 0.1964220553636551\n",
      "Batch：3111 | Loss: 0.1928555816411972\n",
      "Batch：3112 | Loss: 0.18915487825870514\n",
      "Batch：3113 | Loss: 0.18423078954219818\n",
      "Batch：3114 | Loss: 0.17721976339817047\n",
      "Batch：3115 | Loss: 0.18565380573272705\n",
      "Batch：3116 | Loss: 0.18467116355895996\n",
      "Batch：3117 | Loss: 0.19322791695594788\n",
      "Batch：3118 | Loss: 0.18081288039684296\n",
      "Batch：3119 | Loss: 0.178390771150589\n",
      "Batch：3120 | Loss: 0.18880867958068848\n",
      "Batch：3121 | Loss: 0.18113161623477936\n",
      "Batch：3122 | Loss: 0.20455405116081238\n",
      "Batch：3123 | Loss: 0.2056903839111328\n",
      "Batch：3124 | Loss: 0.21323508024215698\n",
      "Batch：3125 | Loss: 0.18205668032169342\n",
      "Batch：3126 | Loss: 0.19587327539920807\n",
      "Batch：3127 | Loss: 0.1926066130399704\n",
      "Batch：3128 | Loss: 0.1921234130859375\n",
      "Batch：3129 | Loss: 0.1787240207195282\n",
      "Batch：3130 | Loss: 0.18256250023841858\n",
      "Batch：3131 | Loss: 0.1873282492160797\n",
      "Batch：3132 | Loss: 0.18934230506420135\n",
      "Batch：3133 | Loss: 0.1960470974445343\n",
      "Batch：3134 | Loss: 0.2044370025396347\n",
      "Batch：3135 | Loss: 0.19694526493549347\n",
      "Batch：3136 | Loss: 0.19097080826759338\n",
      "Batch：3137 | Loss: 0.18807360529899597\n",
      "Batch：3138 | Loss: 0.1868455410003662\n",
      "Batch：3139 | Loss: 0.1770530641078949\n",
      "Batch：3140 | Loss: 0.19104276597499847\n",
      "Batch：3141 | Loss: 0.17529325187206268\n",
      "Batch：3142 | Loss: 0.20724725723266602\n",
      "Batch：3143 | Loss: 0.17415429651737213\n",
      "Batch：3144 | Loss: 0.19258929789066315\n",
      "Batch：3145 | Loss: 0.18666671216487885\n",
      "Batch：3146 | Loss: 0.1786476969718933\n",
      "Batch：3147 | Loss: 0.18792413175106049\n",
      "Batch：3148 | Loss: 0.2047778069972992\n",
      "Batch：3149 | Loss: 0.17955707013607025\n",
      "Batch：3150 | Loss: 0.1875571310520172\n",
      "Batch：3151 | Loss: 0.19829052686691284\n",
      "Batch：3152 | Loss: 0.1882951706647873\n",
      "Batch：3153 | Loss: 0.17283211648464203\n",
      "Batch：3154 | Loss: 0.18693415820598602\n",
      "Batch：3155 | Loss: 0.193573459982872\n",
      "Batch：3156 | Loss: 0.19469793140888214\n",
      "Batch：3157 | Loss: 0.20316389203071594\n",
      "Batch：3158 | Loss: 0.17841896414756775\n",
      "Batch：3159 | Loss: 0.17186583578586578\n",
      "Batch：3160 | Loss: 0.20087279379367828\n",
      "Batch：3161 | Loss: 0.18547716736793518\n",
      "Batch：3162 | Loss: 0.19526299834251404\n",
      "Batch：3163 | Loss: 0.1935470700263977\n",
      "Batch：3164 | Loss: 0.21201764047145844\n",
      "Batch：3165 | Loss: 0.1890183538198471\n",
      "Batch：3166 | Loss: 0.1744103729724884\n",
      "Batch：3167 | Loss: 0.20044715702533722\n",
      "Batch：3168 | Loss: 0.1992253214120865\n",
      "Batch：3169 | Loss: 0.19198039174079895\n",
      "Batch：3170 | Loss: 0.1907283514738083\n",
      "Batch：3171 | Loss: 0.17909805476665497\n",
      "Batch：3172 | Loss: 0.19671069085597992\n",
      "Batch：3173 | Loss: 0.18824297189712524\n",
      "Batch：3174 | Loss: 0.17908723652362823\n",
      "Batch：3175 | Loss: 0.2032565027475357\n",
      "Batch：3176 | Loss: 0.1906767189502716\n",
      "Batch：3177 | Loss: 0.204392671585083\n",
      "Batch：3178 | Loss: 0.20103448629379272\n",
      "Batch：3179 | Loss: 0.17477943003177643\n",
      "Batch：3180 | Loss: 0.18863867223262787\n",
      "Batch：3181 | Loss: 0.1892917901277542\n",
      "Batch：3182 | Loss: 0.19161401689052582\n",
      "Batch：3183 | Loss: 0.19442932307720184\n",
      "Batch：3184 | Loss: 0.1933119148015976\n",
      "Batch：3185 | Loss: 0.20436584949493408\n",
      "Batch：3186 | Loss: 0.1886393278837204\n",
      "Batch：3187 | Loss: 0.1931033879518509\n",
      "Batch：3188 | Loss: 0.19751468300819397\n",
      "Batch：3189 | Loss: 0.1920987069606781\n",
      "Batch：3190 | Loss: 0.1832902878522873\n",
      "Batch：3191 | Loss: 0.1853504478931427\n",
      "Batch：3192 | Loss: 0.19910265505313873\n",
      "Batch：3193 | Loss: 0.18883463740348816\n",
      "Batch：3194 | Loss: 0.1795402616262436\n",
      "Batch：3195 | Loss: 0.17921783030033112\n",
      "Batch：3196 | Loss: 0.19549907743930817\n",
      "Batch：3197 | Loss: 0.19465845823287964\n",
      "Batch：3198 | Loss: 0.18888148665428162\n",
      "Batch：3199 | Loss: 0.17534494400024414\n",
      "Batch：3200 | Loss: 0.19306038320064545\n",
      "Batch：3201 | Loss: 0.1687229871749878\n",
      "Batch：3202 | Loss: 0.18310724198818207\n",
      "Batch：3203 | Loss: 0.19493035972118378\n",
      "Batch：3204 | Loss: 0.17402319610118866\n",
      "Batch：3205 | Loss: 0.19748073816299438\n",
      "Batch：3206 | Loss: 0.18057291209697723\n",
      "Batch：3207 | Loss: 0.17596080899238586\n",
      "Batch：3208 | Loss: 0.18902292847633362\n",
      "Batch：3209 | Loss: 0.20420514047145844\n",
      "Batch：3210 | Loss: 0.19195060431957245\n",
      "Batch：3211 | Loss: 0.1896877884864807\n",
      "Batch：3212 | Loss: 0.1783556342124939\n",
      "Batch：3213 | Loss: 0.18721352517604828\n",
      "Batch：3214 | Loss: 0.17856581509113312\n",
      "Batch：3215 | Loss: 0.19239689409732819\n",
      "Batch：3216 | Loss: 0.17466746270656586\n",
      "Batch：3217 | Loss: 0.1719616949558258\n",
      "Batch：3218 | Loss: 0.1993580311536789\n",
      "Batch：3219 | Loss: 0.18266287446022034\n",
      "Batch：3220 | Loss: 0.18953543901443481\n",
      "Batch：3221 | Loss: 0.18863879144191742\n",
      "Batch：3222 | Loss: 0.19473770260810852\n",
      "Batch：3223 | Loss: 0.18507368862628937\n",
      "Batch：3224 | Loss: 0.18528591096401215\n",
      "Batch：3225 | Loss: 0.18940886855125427\n",
      "Batch：3226 | Loss: 0.19110219180583954\n",
      "Batch：3227 | Loss: 0.17805953323841095\n",
      "Batch：3228 | Loss: 0.1794660985469818\n",
      "Batch：3229 | Loss: 0.18648433685302734\n",
      "Batch：3230 | Loss: 0.19905850291252136\n",
      "Batch：3231 | Loss: 0.17839489877223969\n",
      "Batch：3232 | Loss: 0.19123435020446777\n",
      "Batch：3233 | Loss: 0.19688650965690613\n",
      "Batch：3234 | Loss: 0.1754457950592041\n",
      "Batch：3235 | Loss: 0.18138127028942108\n",
      "Batch：3236 | Loss: 0.2068825662136078\n",
      "Batch：3237 | Loss: 0.19915170967578888\n",
      "Batch：3238 | Loss: 0.19382987916469574\n",
      "Batch：3239 | Loss: 0.18899235129356384\n",
      "Batch：3240 | Loss: 0.16912277042865753\n",
      "Batch：3241 | Loss: 0.18489882349967957\n",
      "Batch：3242 | Loss: 0.1850867122411728\n",
      "Batch：3243 | Loss: 0.1795753389596939\n",
      "Batch：3244 | Loss: 0.17261891067028046\n",
      "Batch：3245 | Loss: 0.17978455126285553\n",
      "Batch：3246 | Loss: 0.19781212508678436\n",
      "Batch：3247 | Loss: 0.18946878612041473\n",
      "Batch：3248 | Loss: 0.19422009587287903\n",
      "Batch：3249 | Loss: 0.19426801800727844\n",
      "Batch：3250 | Loss: 0.1938333362340927\n",
      "Batch：3251 | Loss: 0.17114196717739105\n",
      "Batch：3252 | Loss: 0.18717895448207855\n",
      "Batch：3253 | Loss: 0.1962699592113495\n",
      "Batch：3254 | Loss: 0.1887224167585373\n",
      "Batch：3255 | Loss: 0.1705654114484787\n",
      "Batch：3256 | Loss: 0.18039186298847198\n",
      "Batch：3257 | Loss: 0.17585520446300507\n",
      "Batch：3258 | Loss: 0.16829246282577515\n",
      "Batch：3259 | Loss: 0.17931059002876282\n",
      "Batch：3260 | Loss: 0.1654028445482254\n",
      "Batch：3261 | Loss: 0.17895278334617615\n",
      "Batch：3262 | Loss: 0.18180890381336212\n",
      "Batch：3263 | Loss: 0.19178877770900726\n",
      "Batch：3264 | Loss: 0.204355388879776\n",
      "Batch：3265 | Loss: 0.18616105616092682\n",
      "Batch：3266 | Loss: 0.1722668707370758\n",
      "Batch：3267 | Loss: 0.18571411073207855\n",
      "Batch：3268 | Loss: 0.19282226264476776\n",
      "Batch：3269 | Loss: 0.18137729167938232\n",
      "Batch：3270 | Loss: 0.1835780143737793\n",
      "Batch：3271 | Loss: 0.189443439245224\n",
      "Batch：3272 | Loss: 0.19417905807495117\n",
      "Batch：3273 | Loss: 0.17677201330661774\n",
      "Batch：3274 | Loss: 0.1887451708316803\n",
      "Batch：3275 | Loss: 0.18150418996810913\n",
      "Batch：3276 | Loss: 0.18053486943244934\n",
      "Batch：3277 | Loss: 0.177779421210289\n",
      "Batch：3278 | Loss: 0.18679386377334595\n",
      "Batch：3279 | Loss: 0.19116121530532837\n",
      "Batch：3280 | Loss: 0.1867516189813614\n",
      "Batch：3281 | Loss: 0.18835367262363434\n",
      "Batch：3282 | Loss: 0.18445537984371185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：3283 | Loss: 0.17469051480293274\n",
      "Batch：3284 | Loss: 0.1816364973783493\n",
      "Batch：3285 | Loss: 0.185408815741539\n",
      "Batch：3286 | Loss: 0.17811474204063416\n",
      "Batch：3287 | Loss: 0.1944536566734314\n",
      "Batch：3288 | Loss: 0.18550994992256165\n",
      "Batch：3289 | Loss: 0.19214631617069244\n",
      "Batch：3290 | Loss: 0.1909150332212448\n",
      "Batch：3291 | Loss: 0.2032308280467987\n",
      "Batch：3292 | Loss: 0.18390245735645294\n",
      "Batch：3293 | Loss: 0.1748867630958557\n",
      "Batch：3294 | Loss: 0.177292600274086\n",
      "Batch：3295 | Loss: 0.1805133819580078\n",
      "Batch：3296 | Loss: 0.19116003811359406\n",
      "Batch：3297 | Loss: 0.17259541153907776\n",
      "Batch：3298 | Loss: 0.19197751581668854\n",
      "Batch：3299 | Loss: 0.17588554322719574\n",
      "Batch：3300 | Loss: 0.1716846525669098\n",
      "Batch：3301 | Loss: 0.18298953771591187\n",
      "Batch：3302 | Loss: 0.1726868748664856\n",
      "Batch：3303 | Loss: 0.1812402456998825\n",
      "Batch：3304 | Loss: 0.1864117830991745\n",
      "Batch：3305 | Loss: 0.19207675755023956\n",
      "Batch：3306 | Loss: 0.17596019804477692\n",
      "Batch：3307 | Loss: 0.18844155967235565\n",
      "Batch：3308 | Loss: 0.1901731789112091\n",
      "Batch：3309 | Loss: 0.16939596831798553\n",
      "Batch：3310 | Loss: 0.16770897805690765\n",
      "Batch：3311 | Loss: 0.1841721534729004\n",
      "Batch：3312 | Loss: 0.1728668063879013\n",
      "Batch：3313 | Loss: 0.18977928161621094\n",
      "Batch：3314 | Loss: 0.1765632927417755\n",
      "Batch：3315 | Loss: 0.18255949020385742\n",
      "Batch：3316 | Loss: 0.17720922827720642\n",
      "Batch：3317 | Loss: 0.18613500893115997\n",
      "Batch：3318 | Loss: 0.17125099897384644\n",
      "Batch：3319 | Loss: 0.17783276736736298\n",
      "Batch：3320 | Loss: 0.17930777370929718\n",
      "Batch：3321 | Loss: 0.18441955745220184\n",
      "Batch：3322 | Loss: 0.17530307173728943\n",
      "Batch：3323 | Loss: 0.18508277833461761\n",
      "Batch：3324 | Loss: 0.18128299713134766\n",
      "Batch：3325 | Loss: 0.18223939836025238\n",
      "Batch：3326 | Loss: 0.1925109475851059\n",
      "Batch：3327 | Loss: 0.18694378435611725\n",
      "Batch：3328 | Loss: 0.197251096367836\n",
      "Batch：3329 | Loss: 0.17320580780506134\n",
      "Batch：3330 | Loss: 0.1972644031047821\n",
      "Batch：3331 | Loss: 0.1916441172361374\n",
      "Batch：3332 | Loss: 0.17465852200984955\n",
      "Batch：3333 | Loss: 0.1996874362230301\n",
      "Batch：3334 | Loss: 0.17224499583244324\n",
      "Batch：3335 | Loss: 0.19043365120887756\n",
      "Batch：3336 | Loss: 0.17983542382717133\n",
      "Batch：3337 | Loss: 0.18417856097221375\n",
      "Batch：3338 | Loss: 0.1920589804649353\n",
      "Batch：3339 | Loss: 0.1915510892868042\n",
      "Batch：3340 | Loss: 0.20463769137859344\n",
      "Batch：3341 | Loss: 0.19280996918678284\n",
      "Batch：3342 | Loss: 0.17713069915771484\n",
      "Batch：3343 | Loss: 0.1933220624923706\n",
      "Batch：3344 | Loss: 0.18108117580413818\n",
      "Batch：3345 | Loss: 0.1798011064529419\n",
      "Batch：3346 | Loss: 0.18570299446582794\n",
      "Batch：3347 | Loss: 0.18433158099651337\n",
      "Batch：3348 | Loss: 0.1759953796863556\n",
      "Batch：3349 | Loss: 0.1856851428747177\n",
      "Batch：3350 | Loss: 0.17658711969852448\n",
      "Batch：3351 | Loss: 0.19658589363098145\n",
      "Batch：3352 | Loss: 0.18279199302196503\n",
      "Batch：3353 | Loss: 0.16735175251960754\n",
      "Batch：3354 | Loss: 0.16663101315498352\n",
      "Batch：3355 | Loss: 0.18298140168190002\n",
      "Batch：3356 | Loss: 0.19674333930015564\n",
      "Batch：3357 | Loss: 0.17644664645195007\n",
      "Batch：3358 | Loss: 0.17152070999145508\n",
      "Batch：3359 | Loss: 0.1877923309803009\n",
      "Batch：3360 | Loss: 0.1770760416984558\n",
      "Batch：3361 | Loss: 0.1729060858488083\n",
      "Batch：3362 | Loss: 0.19863134622573853\n",
      "Batch：3363 | Loss: 0.18886156380176544\n",
      "Batch：3364 | Loss: 0.1772928386926651\n",
      "Batch：3365 | Loss: 0.1632608026266098\n",
      "Batch：3366 | Loss: 0.1848943680524826\n",
      "Batch：3367 | Loss: 0.16886088252067566\n",
      "Batch：3368 | Loss: 0.1855510175228119\n",
      "Batch：3369 | Loss: 0.18152391910552979\n",
      "Batch：3370 | Loss: 0.17487141489982605\n",
      "Batch：3371 | Loss: 0.1760723888874054\n",
      "Batch：3372 | Loss: 0.1668093353509903\n",
      "Batch：3373 | Loss: 0.17076070606708527\n",
      "Batch：3374 | Loss: 0.1829100102186203\n",
      "Batch：3375 | Loss: 0.18577681481838226\n",
      "Batch：3376 | Loss: 0.17271140217781067\n",
      "Batch：3377 | Loss: 0.18065503239631653\n",
      "Batch：3378 | Loss: 0.1779710203409195\n",
      "Batch：3379 | Loss: 0.1815022975206375\n",
      "Batch：3380 | Loss: 0.1917491853237152\n",
      "Batch：3381 | Loss: 0.17257845401763916\n",
      "Batch：3382 | Loss: 0.15752431750297546\n",
      "Batch：3383 | Loss: 0.177511066198349\n",
      "Batch：3384 | Loss: 0.1712467074394226\n",
      "Batch：3385 | Loss: 0.18606416881084442\n",
      "Batch：3386 | Loss: 0.16690030694007874\n",
      "Batch：3387 | Loss: 0.18508674204349518\n",
      "Batch：3388 | Loss: 0.17395615577697754\n",
      "Batch：3389 | Loss: 0.18175266683101654\n",
      "Batch：3390 | Loss: 0.17686021327972412\n",
      "Batch：3391 | Loss: 0.18289269506931305\n",
      "Batch：3392 | Loss: 0.18634752929210663\n",
      "Batch：3393 | Loss: 0.16985443234443665\n",
      "Batch：3394 | Loss: 0.18279819190502167\n",
      "Batch：3395 | Loss: 0.18257081508636475\n",
      "Batch：3396 | Loss: 0.1761043220758438\n",
      "Batch：3397 | Loss: 0.18427099287509918\n",
      "Batch：3398 | Loss: 0.20551221072673798\n",
      "Batch：3399 | Loss: 0.17731457948684692\n",
      "Batch：3400 | Loss: 0.18735705316066742\n",
      "Batch：3401 | Loss: 0.1940830796957016\n",
      "Batch：3402 | Loss: 0.1758592575788498\n",
      "Batch：3403 | Loss: 0.1668006032705307\n",
      "Batch：3404 | Loss: 0.1781076192855835\n",
      "Batch：3405 | Loss: 0.18284551799297333\n",
      "Batch：3406 | Loss: 0.17833179235458374\n",
      "Batch：3407 | Loss: 0.17242611944675446\n",
      "Batch：3408 | Loss: 0.18175329267978668\n",
      "Batch：3409 | Loss: 0.1656908392906189\n",
      "Batch：3410 | Loss: 0.18343009054660797\n",
      "Batch：3411 | Loss: 0.16774794459342957\n",
      "Batch：3412 | Loss: 0.17580051720142365\n",
      "Batch：3413 | Loss: 0.18333832919597626\n",
      "Batch：3414 | Loss: 0.17083026468753815\n",
      "Batch：3415 | Loss: 0.19011616706848145\n",
      "Batch：3416 | Loss: 0.17302748560905457\n",
      "Batch：3417 | Loss: 0.1764928549528122\n",
      "Batch：3418 | Loss: 0.17931106686592102\n",
      "Batch：3419 | Loss: 0.17415161430835724\n",
      "Batch：3420 | Loss: 0.17162728309631348\n",
      "Batch：3421 | Loss: 0.17961782217025757\n",
      "Batch：3422 | Loss: 0.18237662315368652\n",
      "Batch：3423 | Loss: 0.16528408229351044\n",
      "Batch：3424 | Loss: 0.18196740746498108\n",
      "Batch：3425 | Loss: 0.1759999841451645\n",
      "Batch：3426 | Loss: 0.17859800159931183\n",
      "Batch：3427 | Loss: 0.1762126088142395\n",
      "Batch：3428 | Loss: 0.17397621273994446\n",
      "Batch：3429 | Loss: 0.16878940165042877\n",
      "Batch：3430 | Loss: 0.1681455820798874\n",
      "Batch：3431 | Loss: 0.18376240134239197\n",
      "Batch：3432 | Loss: 0.16290704905986786\n",
      "Batch：3433 | Loss: 0.18133006989955902\n",
      "Batch：3434 | Loss: 0.18939204514026642\n",
      "Batch：3435 | Loss: 0.17798374593257904\n",
      "Batch：3436 | Loss: 0.18373075127601624\n",
      "Batch：3437 | Loss: 0.1817263811826706\n",
      "Batch：3438 | Loss: 0.19174285233020782\n",
      "Batch：3439 | Loss: 0.1722375601530075\n",
      "Batch：3440 | Loss: 0.180239737033844\n",
      "Batch：3441 | Loss: 0.18721647560596466\n",
      "Batch：3442 | Loss: 0.1812184900045395\n",
      "Batch：3443 | Loss: 0.17491990327835083\n",
      "Batch：3444 | Loss: 0.16541317105293274\n",
      "Batch：3445 | Loss: 0.17696785926818848\n",
      "Batch：3446 | Loss: 0.17365458607673645\n",
      "Batch：3447 | Loss: 0.19121380150318146\n",
      "Batch：3448 | Loss: 0.1862558126449585\n",
      "Batch：3449 | Loss: 0.1625649780035019\n",
      "Batch：3450 | Loss: 0.1803552657365799\n",
      "Batch：3451 | Loss: 0.1796233355998993\n",
      "Batch：3452 | Loss: 0.1756596863269806\n",
      "Batch：3453 | Loss: 0.1753268986940384\n",
      "Batch：3454 | Loss: 0.1746550053358078\n",
      "Batch：3455 | Loss: 0.18800088763237\n",
      "Batch：3456 | Loss: 0.17680442333221436\n",
      "Batch：3457 | Loss: 0.19268591701984406\n",
      "Batch：3458 | Loss: 0.18512608110904694\n",
      "Batch：3459 | Loss: 0.1774739772081375\n",
      "Batch：3460 | Loss: 0.15972669422626495\n",
      "Batch：3461 | Loss: 0.19044402241706848\n",
      "Batch：3462 | Loss: 0.1682625114917755\n",
      "Batch：3463 | Loss: 0.17983028292655945\n",
      "Batch：3464 | Loss: 0.18690648674964905\n",
      "Batch：3465 | Loss: 0.16929428279399872\n",
      "Batch：3466 | Loss: 0.17495420575141907\n",
      "Batch：3467 | Loss: 0.18227988481521606\n",
      "Batch：3468 | Loss: 0.181504026055336\n",
      "Batch：3469 | Loss: 0.18178676068782806\n",
      "Batch：3470 | Loss: 0.17012499272823334\n",
      "Batch：3471 | Loss: 0.16050733625888824\n",
      "Batch：3472 | Loss: 0.1839391440153122\n",
      "Batch：3473 | Loss: 0.17788389325141907\n",
      "Batch：3474 | Loss: 0.17132893204689026\n",
      "Batch：3475 | Loss: 0.17325198650360107\n",
      "Batch：3476 | Loss: 0.1592009961605072\n",
      "Batch：3477 | Loss: 0.16329370439052582\n",
      "Batch：3478 | Loss: 0.18525542318820953\n",
      "Batch：3479 | Loss: 0.18273374438285828\n",
      "Batch：3480 | Loss: 0.17611666023731232\n",
      "Batch：3481 | Loss: 0.1623726785182953\n",
      "Batch：3482 | Loss: 0.17535792291164398\n",
      "Batch：3483 | Loss: 0.18057717382907867\n",
      "Batch：3484 | Loss: 0.1821848750114441\n",
      "Batch：3485 | Loss: 0.1836242526769638\n",
      "Batch：3486 | Loss: 0.1854458451271057\n",
      "Batch：3487 | Loss: 0.1612457036972046\n",
      "Batch：3488 | Loss: 0.19698023796081543\n",
      "Batch：3489 | Loss: 0.1656671166419983\n",
      "Batch：3490 | Loss: 0.17674396932125092\n",
      "Batch：3491 | Loss: 0.16388969123363495\n",
      "Batch：3492 | Loss: 0.17766731977462769\n",
      "Batch：3493 | Loss: 0.19104796648025513\n",
      "Batch：3494 | Loss: 0.171224445104599\n",
      "Batch：3495 | Loss: 0.17407220602035522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：3496 | Loss: 0.15911830961704254\n",
      "Batch：3497 | Loss: 0.19429361820220947\n",
      "Batch：3498 | Loss: 0.17848996818065643\n",
      "Batch：3499 | Loss: 0.16379857063293457\n",
      "Batch：3500 | Loss: 0.18050087988376617\n",
      "Batch：3501 | Loss: 0.1747894287109375\n",
      "Batch：3502 | Loss: 0.18019689619541168\n",
      "Batch：3503 | Loss: 0.15796726942062378\n",
      "Batch：3504 | Loss: 0.17105183005332947\n",
      "Batch：3505 | Loss: 0.16953091323375702\n",
      "Batch：3506 | Loss: 0.1830141544342041\n",
      "Batch：3507 | Loss: 0.171036034822464\n",
      "Batch：3508 | Loss: 0.18031728267669678\n",
      "Batch：3509 | Loss: 0.17112115025520325\n",
      "Batch：3510 | Loss: 0.16068826615810394\n",
      "Batch：3511 | Loss: 0.18814469873905182\n",
      "Batch：3512 | Loss: 0.17493745684623718\n",
      "Batch：3513 | Loss: 0.1682191789150238\n",
      "Batch：3514 | Loss: 0.15830077230930328\n",
      "Batch：3515 | Loss: 0.18321241438388824\n",
      "Batch：3516 | Loss: 0.1676732450723648\n",
      "Batch：3517 | Loss: 0.16075517237186432\n",
      "Batch：3518 | Loss: 0.17142325639724731\n",
      "Batch：3519 | Loss: 0.16060467064380646\n",
      "Batch：3520 | Loss: 0.17506848275661469\n",
      "Batch：3521 | Loss: 0.17757967114448547\n",
      "Batch：3522 | Loss: 0.17037083208560944\n",
      "Batch：3523 | Loss: 0.1770600974559784\n",
      "Batch：3524 | Loss: 0.17669372260570526\n",
      "Batch：3525 | Loss: 0.17483261227607727\n",
      "Batch：3526 | Loss: 0.17684197425842285\n",
      "Batch：3527 | Loss: 0.17558512091636658\n",
      "Batch：3528 | Loss: 0.179022416472435\n",
      "Batch：3529 | Loss: 0.1698809117078781\n",
      "Batch：3530 | Loss: 0.1644354909658432\n",
      "Batch：3531 | Loss: 0.17628923058509827\n",
      "Batch：3532 | Loss: 0.1772889345884323\n",
      "Batch：3533 | Loss: 0.1684686690568924\n",
      "Batch：3534 | Loss: 0.18041881918907166\n",
      "Batch：3535 | Loss: 0.16687394678592682\n",
      "Batch：3536 | Loss: 0.1665021926164627\n",
      "Batch：3537 | Loss: 0.16884399950504303\n",
      "Batch：3538 | Loss: 0.16055572032928467\n",
      "Batch：3539 | Loss: 0.17219823598861694\n",
      "Batch：3540 | Loss: 0.1754516363143921\n",
      "Batch：3541 | Loss: 0.16531719267368317\n",
      "Batch：3542 | Loss: 0.16970333456993103\n",
      "Batch：3543 | Loss: 0.19415032863616943\n",
      "Batch：3544 | Loss: 0.15974397957324982\n",
      "Batch：3545 | Loss: 0.17540746927261353\n",
      "Batch：3546 | Loss: 0.18533910810947418\n",
      "Batch：3547 | Loss: 0.18450427055358887\n",
      "Batch：3548 | Loss: 0.174484983086586\n",
      "Batch：3549 | Loss: 0.155536949634552\n",
      "Batch：3550 | Loss: 0.16958917677402496\n",
      "Batch：3551 | Loss: 0.17284142971038818\n",
      "Batch：3552 | Loss: 0.17019741237163544\n",
      "Batch：3553 | Loss: 0.17857661843299866\n",
      "Batch：3554 | Loss: 0.16297617554664612\n",
      "Batch：3555 | Loss: 0.17008164525032043\n",
      "Batch：3556 | Loss: 0.16211913526058197\n",
      "Batch：3557 | Loss: 0.16075436770915985\n",
      "Batch：3558 | Loss: 0.1736680120229721\n",
      "Batch：3559 | Loss: 0.17865033447742462\n",
      "Batch：3560 | Loss: 0.15419459342956543\n",
      "Batch：3561 | Loss: 0.17200671136379242\n",
      "Batch：3562 | Loss: 0.1732758730649948\n",
      "Batch：3563 | Loss: 0.1734452098608017\n",
      "Batch：3564 | Loss: 0.17666809260845184\n",
      "Batch：3565 | Loss: 0.1724357306957245\n",
      "Batch：3566 | Loss: 0.1606033444404602\n",
      "Batch：3567 | Loss: 0.1569366306066513\n",
      "Batch：3568 | Loss: 0.1818946748971939\n",
      "Batch：3569 | Loss: 0.17407181859016418\n",
      "Batch：3570 | Loss: 0.17666341364383698\n",
      "Batch：3571 | Loss: 0.1841288059949875\n",
      "Batch：3572 | Loss: 0.1645328551530838\n",
      "Batch：3573 | Loss: 0.15898142755031586\n",
      "Batch：3574 | Loss: 0.17061883211135864\n",
      "Batch：3575 | Loss: 0.17914503812789917\n",
      "Batch：3576 | Loss: 0.16622862219810486\n",
      "Batch：3577 | Loss: 0.17867518961429596\n",
      "Batch：3578 | Loss: 0.16151294112205505\n",
      "Batch：3579 | Loss: 0.1691354215145111\n",
      "Batch：3580 | Loss: 0.16351181268692017\n",
      "Batch：3581 | Loss: 0.17840449512004852\n",
      "Batch：3582 | Loss: 0.16883857548236847\n",
      "Batch：3583 | Loss: 0.1605200320482254\n",
      "Batch：3584 | Loss: 0.17513833940029144\n",
      "Batch：3585 | Loss: 0.17963655292987823\n",
      "Batch：3586 | Loss: 0.16972467303276062\n",
      "Batch：3587 | Loss: 0.1638277918100357\n",
      "Batch：3588 | Loss: 0.17009001970291138\n",
      "Batch：3589 | Loss: 0.14784283936023712\n",
      "Batch：3590 | Loss: 0.17898917198181152\n",
      "Batch：3591 | Loss: 0.16104473173618317\n",
      "Batch：3592 | Loss: 0.17393644154071808\n",
      "Batch：3593 | Loss: 0.16651253402233124\n",
      "Batch：3594 | Loss: 0.16060857474803925\n",
      "Batch：3595 | Loss: 0.1810334473848343\n",
      "Batch：3596 | Loss: 0.17441947758197784\n",
      "Batch：3597 | Loss: 0.18216601014137268\n",
      "Batch：3598 | Loss: 0.1733010858297348\n",
      "Batch：3599 | Loss: 0.16047796607017517\n",
      "Batch：3600 | Loss: 0.17009755969047546\n",
      "Batch：3601 | Loss: 0.16927197575569153\n",
      "Batch：3602 | Loss: 0.15822431445121765\n",
      "Batch：3603 | Loss: 0.16459743678569794\n",
      "Batch：3604 | Loss: 0.1774352788925171\n",
      "Batch：3605 | Loss: 0.1784542202949524\n",
      "Batch：3606 | Loss: 0.1585351973772049\n",
      "Batch：3607 | Loss: 0.15863944590091705\n",
      "Batch：3608 | Loss: 0.18019598722457886\n",
      "Batch：3609 | Loss: 0.17007625102996826\n",
      "Batch：3610 | Loss: 0.17756952345371246\n",
      "Batch：3611 | Loss: 0.17069412767887115\n",
      "Batch：3612 | Loss: 0.17249402403831482\n",
      "Batch：3613 | Loss: 0.17878881096839905\n",
      "Batch：3614 | Loss: 0.1749391108751297\n",
      "Batch：3615 | Loss: 0.17069154977798462\n",
      "Batch：3616 | Loss: 0.18039554357528687\n",
      "Batch：3617 | Loss: 0.16080138087272644\n",
      "Batch：3618 | Loss: 0.17554080486297607\n",
      "Batch：3619 | Loss: 0.17058774828910828\n",
      "Batch：3620 | Loss: 0.17244714498519897\n",
      "Batch：3621 | Loss: 0.15209557116031647\n",
      "Batch：3622 | Loss: 0.1676511913537979\n",
      "Batch：3623 | Loss: 0.1711772382259369\n",
      "Batch：3624 | Loss: 0.1720869541168213\n",
      "Batch：3625 | Loss: 0.1724674105644226\n",
      "Batch：3626 | Loss: 0.1548030823469162\n",
      "Batch：3627 | Loss: 0.1688322126865387\n",
      "Batch：3628 | Loss: 0.16907013952732086\n",
      "Batch：3629 | Loss: 0.17578966915607452\n",
      "Batch：3630 | Loss: 0.17504101991653442\n",
      "Batch：3631 | Loss: 0.17241692543029785\n",
      "Batch：3632 | Loss: 0.16827642917633057\n",
      "Batch：3633 | Loss: 0.16406729817390442\n",
      "Batch：3634 | Loss: 0.17491276562213898\n",
      "Batch：3635 | Loss: 0.17895832657814026\n",
      "Batch：3636 | Loss: 0.16845837235450745\n",
      "Batch：3637 | Loss: 0.1656845510005951\n",
      "Batch：3638 | Loss: 0.16885437071323395\n",
      "Batch：3639 | Loss: 0.1521628051996231\n",
      "Batch：3640 | Loss: 0.1697661578655243\n",
      "Batch：3641 | Loss: 0.1651391088962555\n",
      "Batch：3642 | Loss: 0.16435348987579346\n",
      "Batch：3643 | Loss: 0.16532234847545624\n",
      "Batch：3644 | Loss: 0.17720083892345428\n",
      "Batch：3645 | Loss: 0.17013025283813477\n",
      "Batch：3646 | Loss: 0.15763862431049347\n",
      "Batch：3647 | Loss: 0.1778990924358368\n",
      "Batch：3648 | Loss: 0.16153894364833832\n",
      "Batch：3649 | Loss: 0.16268441081047058\n",
      "Batch：3650 | Loss: 0.17409124970436096\n",
      "Batch：3651 | Loss: 0.179576575756073\n",
      "Batch：3652 | Loss: 0.16801588237285614\n",
      "Batch：3653 | Loss: 0.1808452159166336\n",
      "Batch：3654 | Loss: 0.16888649761676788\n",
      "Batch：3655 | Loss: 0.17269690334796906\n",
      "Batch：3656 | Loss: 0.16195188462734222\n",
      "Batch：3657 | Loss: 0.16098594665527344\n",
      "Batch：3658 | Loss: 0.1719757318496704\n",
      "Batch：3659 | Loss: 0.17525476217269897\n",
      "Batch：3660 | Loss: 0.1621333658695221\n",
      "Batch：3661 | Loss: 0.18059185147285461\n",
      "Batch：3662 | Loss: 0.16553716361522675\n",
      "Batch：3663 | Loss: 0.16271911561489105\n",
      "Batch：3664 | Loss: 0.18319982290267944\n",
      "Batch：3665 | Loss: 0.18806982040405273\n",
      "Batch：3666 | Loss: 0.17509599030017853\n",
      "Batch：3667 | Loss: 0.16800251603126526\n",
      "Batch：3668 | Loss: 0.1823940873146057\n",
      "Batch：3669 | Loss: 0.17132647335529327\n",
      "Batch：3670 | Loss: 0.16626015305519104\n",
      "Batch：3671 | Loss: 0.17639917135238647\n",
      "Batch：3672 | Loss: 0.16762733459472656\n",
      "Batch：3673 | Loss: 0.16886433959007263\n",
      "Batch：3674 | Loss: 0.1719847321510315\n",
      "Batch：3675 | Loss: 0.16201499104499817\n",
      "Batch：3676 | Loss: 0.17057465016841888\n",
      "Batch：3677 | Loss: 0.16643579304218292\n",
      "Batch：3678 | Loss: 0.16059571504592896\n",
      "Batch：3679 | Loss: 0.15671014785766602\n",
      "Batch：3680 | Loss: 0.1735154539346695\n",
      "Batch：3681 | Loss: 0.1726800948381424\n",
      "Batch：3682 | Loss: 0.16478757560253143\n",
      "Batch：3683 | Loss: 0.15382283926010132\n",
      "Batch：3684 | Loss: 0.17477841675281525\n",
      "Batch：3685 | Loss: 0.16662855446338654\n",
      "Batch：3686 | Loss: 0.15656159818172455\n",
      "Batch：3687 | Loss: 0.16711317002773285\n",
      "Batch：3688 | Loss: 0.17775537073612213\n",
      "Batch：3689 | Loss: 0.16359932720661163\n",
      "Batch：3690 | Loss: 0.17099706828594208\n",
      "Batch：3691 | Loss: 0.17608357965946198\n",
      "Batch：3692 | Loss: 0.1804327368736267\n",
      "Batch：3693 | Loss: 0.18277889490127563\n",
      "Batch：3694 | Loss: 0.15566736459732056\n",
      "Batch：3695 | Loss: 0.15659013390541077\n",
      "Batch：3696 | Loss: 0.1597357988357544\n",
      "Batch：3697 | Loss: 0.16475751996040344\n",
      "Batch：3698 | Loss: 0.16664867103099823\n",
      "Batch：3699 | Loss: 0.166387677192688\n",
      "Batch：3700 | Loss: 0.16957418620586395\n",
      "Batch：3701 | Loss: 0.18150699138641357\n",
      "Batch：3702 | Loss: 0.16620464622974396\n",
      "Batch：3703 | Loss: 0.16334104537963867\n",
      "Batch：3704 | Loss: 0.1868647187948227\n",
      "Batch：3705 | Loss: 0.1720571517944336\n",
      "Batch：3706 | Loss: 0.16833707690238953\n",
      "Batch：3707 | Loss: 0.1587841808795929\n",
      "Batch：3708 | Loss: 0.1776358038187027\n",
      "Batch：3709 | Loss: 0.16268610954284668\n",
      "Batch：3710 | Loss: 0.16627687215805054\n",
      "Batch：3711 | Loss: 0.16349714994430542\n",
      "Batch：3712 | Loss: 0.165145605802536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：3713 | Loss: 0.16045664250850677\n",
      "Batch：3714 | Loss: 0.1516542285680771\n",
      "Batch：3715 | Loss: 0.16214539110660553\n",
      "Batch：3716 | Loss: 0.17845527827739716\n",
      "Batch：3717 | Loss: 0.1679142713546753\n",
      "Batch：3718 | Loss: 0.16706955432891846\n",
      "Batch：3719 | Loss: 0.17880557477474213\n",
      "Batch：3720 | Loss: 0.15151190757751465\n",
      "Batch：3721 | Loss: 0.1604415625333786\n",
      "Batch：3722 | Loss: 0.17462284862995148\n",
      "Batch：3723 | Loss: 0.17739471793174744\n",
      "Batch：3724 | Loss: 0.1620926409959793\n",
      "Batch：3725 | Loss: 0.14412499964237213\n",
      "Batch：3726 | Loss: 0.1738056242465973\n",
      "Batch：3727 | Loss: 0.16968652606010437\n",
      "Batch：3728 | Loss: 0.1586579829454422\n",
      "Batch：3729 | Loss: 0.17182515561580658\n",
      "Batch：3730 | Loss: 0.17530706524848938\n",
      "Batch：3731 | Loss: 0.17638292908668518\n",
      "Batch：3732 | Loss: 0.1561693698167801\n",
      "Batch：3733 | Loss: 0.16546450555324554\n",
      "Batch：3734 | Loss: 0.16659250855445862\n",
      "Batch：3735 | Loss: 0.16955481469631195\n",
      "Batch：3736 | Loss: 0.16362683475017548\n",
      "Batch：3737 | Loss: 0.1591120809316635\n",
      "Batch：3738 | Loss: 0.16921499371528625\n",
      "Batch：3739 | Loss: 0.17414529621601105\n",
      "Batch：3740 | Loss: 0.1720724105834961\n",
      "Batch：3741 | Loss: 0.16302527487277985\n",
      "Batch：3742 | Loss: 0.1711997240781784\n",
      "Batch：3743 | Loss: 0.17078916728496552\n",
      "Batch：3744 | Loss: 0.15624447166919708\n",
      "Batch：3745 | Loss: 0.1764337569475174\n",
      "Batch：3746 | Loss: 0.1735876500606537\n",
      "Batch：3747 | Loss: 0.1472589671611786\n",
      "Batch：3748 | Loss: 0.1795467883348465\n",
      "Batch：3749 | Loss: 0.17668941617012024\n",
      "Batch：3750 | Loss: 0.1676015853881836\n",
      "Batch：3751 | Loss: 0.15497198700904846\n",
      "Batch：3752 | Loss: 0.1825113445520401\n",
      "Batch：3753 | Loss: 0.16397258639335632\n",
      "Batch：3754 | Loss: 0.15271039307117462\n",
      "Batch：3755 | Loss: 0.16897353529930115\n",
      "Batch：3756 | Loss: 0.178126722574234\n",
      "Batch：3757 | Loss: 0.1573888063430786\n",
      "Batch：3758 | Loss: 0.16516482830047607\n",
      "Batch：3759 | Loss: 0.16647733747959137\n",
      "Batch：3760 | Loss: 0.14952388405799866\n",
      "Batch：3761 | Loss: 0.17759361863136292\n",
      "Batch：3762 | Loss: 0.1616213470697403\n",
      "Batch：3763 | Loss: 0.17495866119861603\n",
      "Batch：3764 | Loss: 0.16090917587280273\n",
      "Batch：3765 | Loss: 0.17532840371131897\n",
      "Batch：3766 | Loss: 0.1629897803068161\n",
      "Batch：3767 | Loss: 0.16445821523666382\n",
      "Batch：3768 | Loss: 0.17051464319229126\n",
      "Batch：3769 | Loss: 0.1701166331768036\n",
      "Batch：3770 | Loss: 0.158673495054245\n",
      "Batch：3771 | Loss: 0.15857328474521637\n",
      "Batch：3772 | Loss: 0.15574781596660614\n",
      "Batch：3773 | Loss: 0.16624094545841217\n",
      "Batch：3774 | Loss: 0.16506431996822357\n",
      "Batch：3775 | Loss: 0.16888439655303955\n",
      "Batch：3776 | Loss: 0.17082291841506958\n",
      "Batch：3777 | Loss: 0.1620248556137085\n",
      "Batch：3778 | Loss: 0.15254250168800354\n",
      "Batch：3779 | Loss: 0.17479020357131958\n",
      "Batch：3780 | Loss: 0.1530522108078003\n",
      "Batch：3781 | Loss: 0.16112537682056427\n",
      "Batch：3782 | Loss: 0.1622728407382965\n",
      "Batch：3783 | Loss: 0.1625274270772934\n",
      "Batch：3784 | Loss: 0.15059304237365723\n",
      "Batch：3785 | Loss: 0.15697255730628967\n",
      "Batch：3786 | Loss: 0.155185267329216\n",
      "Batch：3787 | Loss: 0.16491132974624634\n",
      "Batch：3788 | Loss: 0.1668168157339096\n",
      "Batch：3789 | Loss: 0.1679805964231491\n",
      "Batch：3790 | Loss: 0.15804089605808258\n",
      "Batch：3791 | Loss: 0.15279754996299744\n",
      "Batch：3792 | Loss: 0.15351788699626923\n",
      "Batch：3793 | Loss: 0.16763313114643097\n",
      "Batch：3794 | Loss: 0.17001380026340485\n",
      "Batch：3795 | Loss: 0.16860075294971466\n",
      "Batch：3796 | Loss: 0.1737198680639267\n",
      "Batch：3797 | Loss: 0.1575075387954712\n",
      "Batch：3798 | Loss: 0.1667335331439972\n",
      "Batch：3799 | Loss: 0.15595629811286926\n",
      "Batch：3800 | Loss: 0.16180890798568726\n",
      "Batch：3801 | Loss: 0.15480071306228638\n",
      "Batch：3802 | Loss: 0.17587341368198395\n",
      "Batch：3803 | Loss: 0.15759047865867615\n",
      "Batch：3804 | Loss: 0.1555977165699005\n",
      "Batch：3805 | Loss: 0.16561762988567352\n",
      "Batch：3806 | Loss: 0.16124306619167328\n",
      "Batch：3807 | Loss: 0.16149619221687317\n",
      "Batch：3808 | Loss: 0.16154180467128754\n",
      "Batch：3809 | Loss: 0.16826127469539642\n",
      "Batch：3810 | Loss: 0.16853812336921692\n",
      "Batch：3811 | Loss: 0.17469437420368195\n",
      "Batch：3812 | Loss: 0.14196468889713287\n",
      "Batch：3813 | Loss: 0.16990014910697937\n",
      "Batch：3814 | Loss: 0.1688711792230606\n",
      "Batch：3815 | Loss: 0.15729722380638123\n",
      "Batch：3816 | Loss: 0.16635026037693024\n",
      "Batch：3817 | Loss: 0.15447328984737396\n",
      "Batch：3818 | Loss: 0.1653534173965454\n",
      "Batch：3819 | Loss: 0.15379533171653748\n",
      "Batch：3820 | Loss: 0.15648406744003296\n",
      "Batch：3821 | Loss: 0.15165971219539642\n",
      "Batch：3822 | Loss: 0.1613660305738449\n",
      "Batch：3823 | Loss: 0.17485156655311584\n",
      "Batch：3824 | Loss: 0.17312011122703552\n",
      "Batch：3825 | Loss: 0.15889573097229004\n",
      "Batch：3826 | Loss: 0.1706579327583313\n",
      "Batch：3827 | Loss: 0.16351525485515594\n",
      "Batch：3828 | Loss: 0.16304953396320343\n",
      "Batch：3829 | Loss: 0.1870535910129547\n",
      "Batch：3830 | Loss: 0.16019779443740845\n",
      "Batch：3831 | Loss: 0.15447403490543365\n",
      "Batch：3832 | Loss: 0.1778004914522171\n",
      "Batch：3833 | Loss: 0.14845474064350128\n",
      "Batch：3834 | Loss: 0.15370866656303406\n",
      "Batch：3835 | Loss: 0.1651911437511444\n",
      "Batch：3836 | Loss: 0.1480351686477661\n",
      "Batch：3837 | Loss: 0.17214135825634003\n",
      "Batch：3838 | Loss: 0.15741464495658875\n",
      "Batch：3839 | Loss: 0.16842341423034668\n",
      "Batch：3840 | Loss: 0.1595645695924759\n",
      "Batch：3841 | Loss: 0.1593761295080185\n",
      "Batch：3842 | Loss: 0.16247251629829407\n",
      "Batch：3843 | Loss: 0.15621721744537354\n",
      "Batch：3844 | Loss: 0.15770737826824188\n",
      "Batch：3845 | Loss: 0.16133278608322144\n",
      "Batch：3846 | Loss: 0.1609674096107483\n",
      "Batch：3847 | Loss: 0.15800032019615173\n",
      "Batch：3848 | Loss: 0.15348859131336212\n",
      "Batch：3849 | Loss: 0.16008995473384857\n",
      "Batch：3850 | Loss: 0.16592109203338623\n",
      "Batch：3851 | Loss: 0.15759918093681335\n",
      "Batch：3852 | Loss: 0.14576363563537598\n",
      "Batch：3853 | Loss: 0.15876729786396027\n",
      "Batch：3854 | Loss: 0.16901075839996338\n",
      "Batch：3855 | Loss: 0.1628875583410263\n",
      "Batch：3856 | Loss: 0.16990512609481812\n",
      "Batch：3857 | Loss: 0.1713632196187973\n",
      "Batch：3858 | Loss: 0.15824192762374878\n",
      "Batch：3859 | Loss: 0.1642988622188568\n",
      "Batch：3860 | Loss: 0.1600370854139328\n",
      "Batch：3861 | Loss: 0.16296976804733276\n",
      "Batch：3862 | Loss: 0.15683913230895996\n",
      "Batch：3863 | Loss: 0.15686911344528198\n",
      "Batch：3864 | Loss: 0.1738525927066803\n",
      "Batch：3865 | Loss: 0.1724444180727005\n",
      "Batch：3866 | Loss: 0.15805627405643463\n",
      "Batch：3867 | Loss: 0.14493517577648163\n",
      "Batch：3868 | Loss: 0.1545417606830597\n",
      "Batch：3869 | Loss: 0.15528109669685364\n",
      "Batch：3870 | Loss: 0.16791439056396484\n",
      "Batch：3871 | Loss: 0.1513119637966156\n",
      "Batch：3872 | Loss: 0.16437508165836334\n",
      "Batch：3873 | Loss: 0.14247898757457733\n",
      "Batch：3874 | Loss: 0.17004767060279846\n",
      "Batch：3875 | Loss: 0.16647747159004211\n",
      "Batch：3876 | Loss: 0.15061983466148376\n",
      "Batch：3877 | Loss: 0.15831536054611206\n",
      "Batch：3878 | Loss: 0.17533119022846222\n",
      "Batch：3879 | Loss: 0.16693037748336792\n",
      "Batch：3880 | Loss: 0.1710648387670517\n",
      "Batch：3881 | Loss: 0.17411106824874878\n",
      "Batch：3882 | Loss: 0.15668664872646332\n",
      "Batch：3883 | Loss: 0.1738131046295166\n",
      "Batch：3884 | Loss: 0.16922232508659363\n",
      "Batch：3885 | Loss: 0.16195516288280487\n",
      "Batch：3886 | Loss: 0.1842798888683319\n",
      "Batch：3887 | Loss: 0.15915027260780334\n",
      "Batch：3888 | Loss: 0.16979651153087616\n",
      "Batch：3889 | Loss: 0.15054774284362793\n",
      "Batch：3890 | Loss: 0.153146892786026\n",
      "Batch：3891 | Loss: 0.14468471705913544\n",
      "Batch：3892 | Loss: 0.15746816992759705\n",
      "Batch：3893 | Loss: 0.1597677618265152\n",
      "Batch：3894 | Loss: 0.17008347809314728\n",
      "Batch：3895 | Loss: 0.16939277946949005\n",
      "Batch：3896 | Loss: 0.16009066998958588\n",
      "Batch：3897 | Loss: 0.16295044124126434\n",
      "Batch：3898 | Loss: 0.1592720001935959\n",
      "Batch：3899 | Loss: 0.14998993277549744\n",
      "Batch：3900 | Loss: 0.15539707243442535\n",
      "Batch：3901 | Loss: 0.15772294998168945\n",
      "Batch：3902 | Loss: 0.1400376856327057\n",
      "Batch：3903 | Loss: 0.15989823639392853\n",
      "Batch：3904 | Loss: 0.16468016803264618\n",
      "Batch：3905 | Loss: 0.1487538069486618\n",
      "Batch：3906 | Loss: 0.16869491338729858\n",
      "Batch：3907 | Loss: 0.16280540823936462\n",
      "Batch：3908 | Loss: 0.17096024751663208\n",
      "Batch：3909 | Loss: 0.16118492186069489\n",
      "Batch：3910 | Loss: 0.16879414021968842\n",
      "Batch：3911 | Loss: 0.1546182483434677\n",
      "Batch：3912 | Loss: 0.17077045142650604\n",
      "Batch：3913 | Loss: 0.1624547243118286\n",
      "Batch：3914 | Loss: 0.16227097809314728\n",
      "Batch：3915 | Loss: 0.1645611822605133\n",
      "Batch：3916 | Loss: 0.15754342079162598\n",
      "Batch：3917 | Loss: 0.16401192545890808\n",
      "Batch：3918 | Loss: 0.16321144998073578\n",
      "Batch：3919 | Loss: 0.14613361656665802\n",
      "Batch：3920 | Loss: 0.16223196685314178\n",
      "Batch：3921 | Loss: 0.14456979930400848\n",
      "Batch：3922 | Loss: 0.16872471570968628\n",
      "Batch：3923 | Loss: 0.1727980375289917\n",
      "Batch：3924 | Loss: 0.16178853809833527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：3925 | Loss: 0.16978470981121063\n",
      "Batch：3926 | Loss: 0.15123814344406128\n",
      "Batch：3927 | Loss: 0.1734260469675064\n",
      "Batch：3928 | Loss: 0.16136811673641205\n",
      "Batch：3929 | Loss: 0.1637355387210846\n",
      "Batch：3930 | Loss: 0.1516094207763672\n",
      "Batch：3931 | Loss: 0.15283659100532532\n",
      "Batch：3932 | Loss: 0.15546537935733795\n",
      "Batch：3933 | Loss: 0.14848382771015167\n",
      "Batch：3934 | Loss: 0.16612744331359863\n",
      "Batch：3935 | Loss: 0.15755996108055115\n",
      "Batch：3936 | Loss: 0.15637661516666412\n",
      "Batch：3937 | Loss: 0.1676204800605774\n",
      "Batch：3938 | Loss: 0.14185760915279388\n",
      "Batch：3939 | Loss: 0.15885575115680695\n",
      "Batch：3940 | Loss: 0.15893466770648956\n",
      "Batch：3941 | Loss: 0.14748139679431915\n",
      "Batch：3942 | Loss: 0.17037512362003326\n",
      "Batch：3943 | Loss: 0.14882458746433258\n",
      "Batch：3944 | Loss: 0.1486005187034607\n",
      "Batch：3945 | Loss: 0.15699166059494019\n",
      "Batch：3946 | Loss: 0.16792206466197968\n",
      "Batch：3947 | Loss: 0.15414021909236908\n",
      "Batch：3948 | Loss: 0.1549557000398636\n",
      "Batch：3949 | Loss: 0.15673063695430756\n",
      "Batch：3950 | Loss: 0.15484696626663208\n",
      "Batch：3951 | Loss: 0.1520332396030426\n",
      "Batch：3952 | Loss: 0.15842613577842712\n",
      "Batch：3953 | Loss: 0.14918282628059387\n",
      "Batch：3954 | Loss: 0.15501271188259125\n",
      "Batch：3955 | Loss: 0.1574631631374359\n",
      "Batch：3956 | Loss: 0.16434597969055176\n",
      "Batch：3957 | Loss: 0.15450888872146606\n",
      "Batch：3958 | Loss: 0.14982233941555023\n",
      "Batch：3959 | Loss: 0.15318742394447327\n",
      "Batch：3960 | Loss: 0.14840881526470184\n",
      "Batch：3961 | Loss: 0.16257326304912567\n",
      "Batch：3962 | Loss: 0.15440306067466736\n",
      "Batch：3963 | Loss: 0.14856065809726715\n",
      "Batch：3964 | Loss: 0.15304087102413177\n",
      "Batch：3965 | Loss: 0.15920326113700867\n",
      "Batch：3966 | Loss: 0.16593292355537415\n",
      "Batch：3967 | Loss: 0.16553136706352234\n",
      "Batch：3968 | Loss: 0.17464983463287354\n",
      "Batch：3969 | Loss: 0.15632909536361694\n",
      "Batch：3970 | Loss: 0.16183267533779144\n",
      "Batch：3971 | Loss: 0.15992772579193115\n",
      "Batch：3972 | Loss: 0.1618076115846634\n",
      "Batch：3973 | Loss: 0.1512506604194641\n",
      "Batch：3974 | Loss: 0.16238190233707428\n",
      "Batch：3975 | Loss: 0.15757150948047638\n",
      "Batch：3976 | Loss: 0.13719089329242706\n",
      "Batch：3977 | Loss: 0.16366274654865265\n",
      "Batch：3978 | Loss: 0.1547696739435196\n",
      "Batch：3979 | Loss: 0.17361541092395782\n",
      "Batch：3980 | Loss: 0.14893685281276703\n",
      "Batch：3981 | Loss: 0.14523980021476746\n",
      "Batch：3982 | Loss: 0.1630612313747406\n",
      "Batch：3983 | Loss: 0.1539427936077118\n",
      "Batch：3984 | Loss: 0.15896780788898468\n",
      "Batch：3985 | Loss: 0.16611813008785248\n",
      "Batch：3986 | Loss: 0.156624436378479\n",
      "Batch：3987 | Loss: 0.1413818895816803\n",
      "Batch：3988 | Loss: 0.15567469596862793\n",
      "Batch：3989 | Loss: 0.1546000987291336\n",
      "Batch：3990 | Loss: 0.15924811363220215\n",
      "Batch：3991 | Loss: 0.14724092185497284\n",
      "Batch：3992 | Loss: 0.1694810837507248\n",
      "Batch：3993 | Loss: 0.15851984918117523\n",
      "Batch：3994 | Loss: 0.15468114614486694\n",
      "Batch：3995 | Loss: 0.1662721186876297\n",
      "Batch：3996 | Loss: 0.14738371968269348\n",
      "Batch：3997 | Loss: 0.1528700590133667\n",
      "Batch：3998 | Loss: 0.15693430602550507\n",
      "Batch：3999 | Loss: 0.16889791190624237\n",
      "Batch：4000 | Loss: 0.16115246713161469\n",
      "Batch：4001 | Loss: 0.14409536123275757\n",
      "Batch：4002 | Loss: 0.16263937950134277\n",
      "Batch：4003 | Loss: 0.1454026699066162\n",
      "Batch：4004 | Loss: 0.16682051122188568\n",
      "Batch：4005 | Loss: 0.1635744422674179\n",
      "Batch：4006 | Loss: 0.1511443853378296\n",
      "Batch：4007 | Loss: 0.1602102667093277\n",
      "Batch：4008 | Loss: 0.15680089592933655\n",
      "Batch：4009 | Loss: 0.16564123332500458\n",
      "Batch：4010 | Loss: 0.16543160378932953\n",
      "Batch：4011 | Loss: 0.15190619230270386\n",
      "Batch：4012 | Loss: 0.14968810975551605\n",
      "Batch：4013 | Loss: 0.14687758684158325\n",
      "Batch：4014 | Loss: 0.1502775400876999\n",
      "Batch：4015 | Loss: 0.15792369842529297\n",
      "Batch：4016 | Loss: 0.1679125726222992\n",
      "Batch：4017 | Loss: 0.15330734848976135\n",
      "Batch：4018 | Loss: 0.15636467933654785\n",
      "Batch：4019 | Loss: 0.14785398542881012\n",
      "Batch：4020 | Loss: 0.15493355691432953\n",
      "Batch：4021 | Loss: 0.15429630875587463\n",
      "Batch：4022 | Loss: 0.1620466560125351\n",
      "Batch：4023 | Loss: 0.16595271229743958\n",
      "Batch：4024 | Loss: 0.16462020576000214\n",
      "Batch：4025 | Loss: 0.1484595686197281\n",
      "Batch：4026 | Loss: 0.1533535271883011\n",
      "Batch：4027 | Loss: 0.14900343120098114\n",
      "Batch：4028 | Loss: 0.15611056983470917\n",
      "Batch：4029 | Loss: 0.16507725417613983\n",
      "Batch：4030 | Loss: 0.15063902735710144\n",
      "Batch：4031 | Loss: 0.14630746841430664\n",
      "Batch：4032 | Loss: 0.1539558470249176\n",
      "Batch：4033 | Loss: 0.15191757678985596\n",
      "Batch：4034 | Loss: 0.14793579280376434\n",
      "Batch：4035 | Loss: 0.1594439446926117\n",
      "Batch：4036 | Loss: 0.14022207260131836\n",
      "Batch：4037 | Loss: 0.15750502049922943\n",
      "Batch：4038 | Loss: 0.15588808059692383\n",
      "Batch：4039 | Loss: 0.15817604959011078\n",
      "Batch：4040 | Loss: 0.1596234142780304\n",
      "Batch：4041 | Loss: 0.15214501321315765\n",
      "Batch：4042 | Loss: 0.16070540249347687\n",
      "Batch：4043 | Loss: 0.14419957995414734\n",
      "Batch：4044 | Loss: 0.16049115359783173\n",
      "Batch：4045 | Loss: 0.16558443009853363\n",
      "Batch：4046 | Loss: 0.1682683825492859\n",
      "Batch：4047 | Loss: 0.1548343300819397\n",
      "Batch：4048 | Loss: 0.14544767141342163\n",
      "Batch：4049 | Loss: 0.14844518899917603\n",
      "Batch：4050 | Loss: 0.15722350776195526\n",
      "Batch：4051 | Loss: 0.16967558860778809\n",
      "Batch：4052 | Loss: 0.1522674709558487\n",
      "Batch：4053 | Loss: 0.14881084859371185\n",
      "Batch：4054 | Loss: 0.1485014110803604\n",
      "Batch：4055 | Loss: 0.1473812609910965\n",
      "Batch：4056 | Loss: 0.14336393773555756\n",
      "Batch：4057 | Loss: 0.15177947282791138\n",
      "Batch：4058 | Loss: 0.15687969326972961\n",
      "Batch：4059 | Loss: 0.13889475166797638\n",
      "Batch：4060 | Loss: 0.17650219798088074\n",
      "Batch：4061 | Loss: 0.15244771540164948\n",
      "Batch：4062 | Loss: 0.1469639539718628\n",
      "Batch：4063 | Loss: 0.14378444850444794\n",
      "Batch：4064 | Loss: 0.15033957362174988\n",
      "Batch：4065 | Loss: 0.15666264295578003\n",
      "Batch：4066 | Loss: 0.1556617170572281\n",
      "Batch：4067 | Loss: 0.1333545744419098\n",
      "Batch：4068 | Loss: 0.155891552567482\n",
      "Batch：4069 | Loss: 0.1465233415365219\n",
      "Batch：4070 | Loss: 0.15173804759979248\n",
      "Batch：4071 | Loss: 0.15263505280017853\n",
      "Batch：4072 | Loss: 0.1606113612651825\n",
      "Batch：4073 | Loss: 0.14665769040584564\n",
      "Batch：4074 | Loss: 0.1451733410358429\n",
      "Batch：4075 | Loss: 0.153090700507164\n",
      "Batch：4076 | Loss: 0.16255973279476166\n",
      "Batch：4077 | Loss: 0.15470926463603973\n",
      "Batch：4078 | Loss: 0.14673897624015808\n",
      "Batch：4079 | Loss: 0.15958178043365479\n",
      "Batch：4080 | Loss: 0.15276029706001282\n",
      "Batch：4081 | Loss: 0.14411933720111847\n",
      "Batch：4082 | Loss: 0.1463354080915451\n",
      "Batch：4083 | Loss: 0.13996222615242004\n",
      "Batch：4084 | Loss: 0.15181711316108704\n",
      "Batch：4085 | Loss: 0.15701505541801453\n",
      "Batch：4086 | Loss: 0.15595324337482452\n",
      "Batch：4087 | Loss: 0.16072385013103485\n",
      "Batch：4088 | Loss: 0.13184447586536407\n",
      "Batch：4089 | Loss: 0.15373508632183075\n",
      "Batch：4090 | Loss: 0.14574837684631348\n",
      "Batch：4091 | Loss: 0.158108189702034\n",
      "Batch：4092 | Loss: 0.15091757476329803\n",
      "Batch：4093 | Loss: 0.15752831101417542\n",
      "Batch：4094 | Loss: 0.15657548606395721\n",
      "Batch：4095 | Loss: 0.14651118218898773\n",
      "Batch：4096 | Loss: 0.1494649201631546\n",
      "Batch：4097 | Loss: 0.15833568572998047\n",
      "Batch：4098 | Loss: 0.15752337872982025\n",
      "Batch：4099 | Loss: 0.1626175343990326\n",
      "Batch：4100 | Loss: 0.13771401345729828\n",
      "Batch：4101 | Loss: 0.16806137561798096\n",
      "Batch：4102 | Loss: 0.14198294281959534\n",
      "Batch：4103 | Loss: 0.15435460209846497\n",
      "Batch：4104 | Loss: 0.1596427857875824\n",
      "Batch：4105 | Loss: 0.1462719440460205\n",
      "Batch：4106 | Loss: 0.16026076674461365\n",
      "Batch：4107 | Loss: 0.15914081037044525\n",
      "Batch：4108 | Loss: 0.14613939821720123\n",
      "Batch：4109 | Loss: 0.1430780291557312\n",
      "Batch：4110 | Loss: 0.1418754607439041\n",
      "Batch：4111 | Loss: 0.1522473394870758\n",
      "Batch：4112 | Loss: 0.15616881847381592\n",
      "Batch：4113 | Loss: 0.16842424869537354\n",
      "Batch：4114 | Loss: 0.13883325457572937\n",
      "Batch：4115 | Loss: 0.1601758748292923\n",
      "Batch：4116 | Loss: 0.15532778203487396\n",
      "Batch：4117 | Loss: 0.16072309017181396\n",
      "Batch：4118 | Loss: 0.14948472380638123\n",
      "Batch：4119 | Loss: 0.15225203335285187\n",
      "Batch：4120 | Loss: 0.14660924673080444\n",
      "Batch：4121 | Loss: 0.1442696750164032\n",
      "Batch：4122 | Loss: 0.14216378331184387\n",
      "Batch：4123 | Loss: 0.15440070629119873\n",
      "Batch：4124 | Loss: 0.1524626910686493\n",
      "Batch：4125 | Loss: 0.14789441227912903\n",
      "Batch：4126 | Loss: 0.1503426730632782\n",
      "Batch：4127 | Loss: 0.14263367652893066\n",
      "Batch：4128 | Loss: 0.1380913108587265\n",
      "Batch：4129 | Loss: 0.1525334268808365\n",
      "Batch：4130 | Loss: 0.14418886601924896\n",
      "Batch：4131 | Loss: 0.15747101604938507\n",
      "Batch：4132 | Loss: 0.15767459571361542\n",
      "Batch：4133 | Loss: 0.14437995851039886\n",
      "Batch：4134 | Loss: 0.15159288048744202\n",
      "Batch：4135 | Loss: 0.14972913265228271\n",
      "Batch：4136 | Loss: 0.1494860202074051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：4137 | Loss: 0.15582069754600525\n",
      "Batch：4138 | Loss: 0.14595532417297363\n",
      "Batch：4139 | Loss: 0.16986586153507233\n",
      "Batch：4140 | Loss: 0.1477368026971817\n",
      "Batch：4141 | Loss: 0.15272603929042816\n",
      "Batch：4142 | Loss: 0.15108227729797363\n",
      "Batch：4143 | Loss: 0.15765975415706635\n",
      "Batch：4144 | Loss: 0.14814184606075287\n",
      "Batch：4145 | Loss: 0.159845769405365\n",
      "Batch：4146 | Loss: 0.15044918656349182\n",
      "Batch：4147 | Loss: 0.1399889439344406\n",
      "Batch：4148 | Loss: 0.13964968919754028\n",
      "Batch：4149 | Loss: 0.16091053187847137\n",
      "Batch：4150 | Loss: 0.17123118042945862\n",
      "Batch：4151 | Loss: 0.15190792083740234\n",
      "Batch：4152 | Loss: 0.14235098659992218\n",
      "Batch：4153 | Loss: 0.14767298102378845\n",
      "Batch：4154 | Loss: 0.15654417872428894\n",
      "Batch：4155 | Loss: 0.1546250730752945\n",
      "Batch：4156 | Loss: 0.1323775351047516\n",
      "Batch：4157 | Loss: 0.15585266053676605\n",
      "Batch：4158 | Loss: 0.14392919838428497\n",
      "Batch：4159 | Loss: 0.15632221102714539\n",
      "Batch：4160 | Loss: 0.16468459367752075\n",
      "Batch：4161 | Loss: 0.14793837070465088\n",
      "Batch：4162 | Loss: 0.14840129017829895\n",
      "Batch：4163 | Loss: 0.1578231006860733\n",
      "Batch：4164 | Loss: 0.16517893970012665\n",
      "Batch：4165 | Loss: 0.14247561991214752\n",
      "Batch：4166 | Loss: 0.15741486847400665\n",
      "Batch：4167 | Loss: 0.15747372806072235\n",
      "Batch：4168 | Loss: 0.15825976431369781\n",
      "Batch：4169 | Loss: 0.16610488295555115\n",
      "Batch：4170 | Loss: 0.15020915865898132\n",
      "Batch：4171 | Loss: 0.1391085833311081\n",
      "Batch：4172 | Loss: 0.14557932317256927\n",
      "Batch：4173 | Loss: 0.14984598755836487\n",
      "Batch：4174 | Loss: 0.15140360593795776\n",
      "Batch：4175 | Loss: 0.15256495773792267\n",
      "Batch：4176 | Loss: 0.14450715482234955\n",
      "Batch：4177 | Loss: 0.1454140841960907\n",
      "Batch：4178 | Loss: 0.16135290265083313\n",
      "Batch：4179 | Loss: 0.1531534492969513\n",
      "Batch：4180 | Loss: 0.1524224877357483\n",
      "Batch：4181 | Loss: 0.14189058542251587\n",
      "Batch：4182 | Loss: 0.1357797086238861\n",
      "Batch：4183 | Loss: 0.16396096348762512\n",
      "Batch：4184 | Loss: 0.14402803778648376\n",
      "Batch：4185 | Loss: 0.15082649886608124\n",
      "Batch：4186 | Loss: 0.13955816626548767\n",
      "Batch：4187 | Loss: 0.15202417969703674\n",
      "Batch：4188 | Loss: 0.13848945498466492\n",
      "Batch：4189 | Loss: 0.1461866945028305\n",
      "Batch：4190 | Loss: 0.15647141635417938\n",
      "Batch：4191 | Loss: 0.15332041680812836\n",
      "Batch：4192 | Loss: 0.15200655162334442\n",
      "Batch：4193 | Loss: 0.1543911099433899\n",
      "Batch：4194 | Loss: 0.15881456434726715\n",
      "Batch：4195 | Loss: 0.16094961762428284\n",
      "Batch：4196 | Loss: 0.14834900200366974\n",
      "Batch：4197 | Loss: 0.13593505322933197\n",
      "Batch：4198 | Loss: 0.15367722511291504\n",
      "Batch：4199 | Loss: 0.15329429507255554\n",
      "Batch：4200 | Loss: 0.14137689769268036\n",
      "Batch：4201 | Loss: 0.1401030719280243\n",
      "Batch：4202 | Loss: 0.14411556720733643\n",
      "Batch：4203 | Loss: 0.16029541194438934\n",
      "Batch：4204 | Loss: 0.14445710182189941\n",
      "Batch：4205 | Loss: 0.147507905960083\n",
      "Batch：4206 | Loss: 0.1538577526807785\n",
      "Batch：4207 | Loss: 0.1545906811952591\n",
      "Batch：4208 | Loss: 0.1408068686723709\n",
      "Batch：4209 | Loss: 0.16162297129631042\n",
      "Batch：4210 | Loss: 0.14192511141300201\n",
      "Batch：4211 | Loss: 0.1404082179069519\n",
      "Batch：4212 | Loss: 0.1414184272289276\n",
      "Batch：4213 | Loss: 0.13843755424022675\n",
      "Batch：4214 | Loss: 0.16170518100261688\n",
      "Batch：4215 | Loss: 0.16692855954170227\n",
      "Batch：4216 | Loss: 0.1533379703760147\n",
      "Batch：4217 | Loss: 0.14733560383319855\n",
      "Batch：4218 | Loss: 0.1414795070886612\n",
      "Batch：4219 | Loss: 0.14408068358898163\n",
      "Batch：4220 | Loss: 0.14832037687301636\n",
      "Batch：4221 | Loss: 0.13921324908733368\n",
      "Batch：4222 | Loss: 0.13993506133556366\n",
      "Batch：4223 | Loss: 0.14758743345737457\n",
      "Batch：4224 | Loss: 0.15549035370349884\n",
      "Batch：4225 | Loss: 0.1716976761817932\n",
      "Batch：4226 | Loss: 0.14744217693805695\n",
      "Batch：4227 | Loss: 0.1518820971250534\n",
      "Batch：4228 | Loss: 0.1394791603088379\n",
      "Batch：4229 | Loss: 0.1468098908662796\n",
      "Batch：4230 | Loss: 0.15530994534492493\n",
      "Batch：4231 | Loss: 0.1572074443101883\n",
      "Batch：4232 | Loss: 0.14640825986862183\n",
      "Batch：4233 | Loss: 0.13485227525234222\n",
      "Batch：4234 | Loss: 0.15091371536254883\n",
      "Batch：4235 | Loss: 0.1569584161043167\n",
      "Batch：4236 | Loss: 0.15940801799297333\n",
      "Batch：4237 | Loss: 0.14617902040481567\n",
      "Batch：4238 | Loss: 0.15151870250701904\n",
      "Batch：4239 | Loss: 0.1541244238615036\n",
      "Batch：4240 | Loss: 0.13855847716331482\n",
      "Batch：4241 | Loss: 0.16325867176055908\n",
      "Batch：4242 | Loss: 0.1541377305984497\n",
      "Batch：4243 | Loss: 0.1582082062959671\n",
      "Batch：4244 | Loss: 0.14345790445804596\n",
      "Batch：4245 | Loss: 0.15092895925045013\n",
      "Batch：4246 | Loss: 0.1524854153394699\n",
      "Batch：4247 | Loss: 0.14051948487758636\n",
      "Batch：4248 | Loss: 0.15781986713409424\n",
      "Batch：4249 | Loss: 0.1573764830827713\n",
      "Batch：4250 | Loss: 0.15301603078842163\n",
      "Batch：4251 | Loss: 0.14491057395935059\n",
      "Batch：4252 | Loss: 0.14027640223503113\n",
      "Batch：4253 | Loss: 0.14849387109279633\n",
      "Batch：4254 | Loss: 0.15189938247203827\n",
      "Batch：4255 | Loss: 0.12037670612335205\n",
      "Batch：4256 | Loss: 0.1538156270980835\n",
      "Batch：4257 | Loss: 0.1537674367427826\n",
      "Batch：4258 | Loss: 0.15948650240898132\n",
      "Batch：4259 | Loss: 0.13839077949523926\n",
      "Batch：4260 | Loss: 0.1540953814983368\n",
      "Batch：4261 | Loss: 0.14811624586582184\n",
      "Batch：4262 | Loss: 0.1461842656135559\n",
      "Batch：4263 | Loss: 0.15403562784194946\n",
      "Batch：4264 | Loss: 0.15431950986385345\n",
      "Batch：4265 | Loss: 0.14872103929519653\n",
      "Batch：4266 | Loss: 0.15164919197559357\n",
      "Batch：4267 | Loss: 0.14934752881526947\n",
      "Batch：4268 | Loss: 0.1441953331232071\n",
      "Batch：4269 | Loss: 0.151300847530365\n",
      "Batch：4270 | Loss: 0.15474262833595276\n",
      "Batch：4271 | Loss: 0.14826491475105286\n",
      "Batch：4272 | Loss: 0.169941246509552\n",
      "Batch：4273 | Loss: 0.14959083497524261\n",
      "Batch：4274 | Loss: 0.13923345506191254\n",
      "Batch：4275 | Loss: 0.14790114760398865\n",
      "Batch：4276 | Loss: 0.1516813039779663\n",
      "Batch：4277 | Loss: 0.15545445680618286\n",
      "Batch：4278 | Loss: 0.1555211991071701\n",
      "Batch：4279 | Loss: 0.14212298393249512\n",
      "Batch：4280 | Loss: 0.1566668003797531\n",
      "Batch：4281 | Loss: 0.14152537286281586\n",
      "Batch：4282 | Loss: 0.13032953441143036\n",
      "Batch：4283 | Loss: 0.1536131650209427\n",
      "Batch：4284 | Loss: 0.16022391617298126\n",
      "Batch：4285 | Loss: 0.16222046315670013\n",
      "Batch：4286 | Loss: 0.1406022310256958\n",
      "Batch：4287 | Loss: 0.14563366770744324\n",
      "Batch：4288 | Loss: 0.1528579741716385\n",
      "Batch：4289 | Loss: 0.146706685423851\n",
      "Batch：4290 | Loss: 0.1488272100687027\n",
      "Batch：4291 | Loss: 0.138877272605896\n",
      "Batch：4292 | Loss: 0.13468411564826965\n",
      "Batch：4293 | Loss: 0.1476629227399826\n",
      "Batch：4294 | Loss: 0.15423786640167236\n",
      "Batch：4295 | Loss: 0.14023390412330627\n",
      "Batch：4296 | Loss: 0.15082034468650818\n",
      "Batch：4297 | Loss: 0.158397376537323\n",
      "Batch：4298 | Loss: 0.15837836265563965\n",
      "Batch：4299 | Loss: 0.13227596879005432\n",
      "Batch：4300 | Loss: 0.1509438455104828\n",
      "Batch：4301 | Loss: 0.14543184638023376\n",
      "Batch：4302 | Loss: 0.15755636990070343\n",
      "Batch：4303 | Loss: 0.15517644584178925\n",
      "Batch：4304 | Loss: 0.15925854444503784\n",
      "Batch：4305 | Loss: 0.15381641685962677\n",
      "Batch：4306 | Loss: 0.15344248712062836\n",
      "Batch：4307 | Loss: 0.13786180317401886\n",
      "Batch：4308 | Loss: 0.15195193886756897\n",
      "Batch：4309 | Loss: 0.1471114307641983\n",
      "Batch：4310 | Loss: 0.1350409984588623\n",
      "Batch：4311 | Loss: 0.139360249042511\n",
      "Batch：4312 | Loss: 0.15027207136154175\n",
      "Batch：4313 | Loss: 0.14509616792201996\n",
      "Batch：4314 | Loss: 0.15878526866436005\n",
      "Batch：4315 | Loss: 0.15069490671157837\n",
      "Batch：4316 | Loss: 0.154778391122818\n",
      "Batch：4317 | Loss: 0.1453462690114975\n",
      "Batch：4318 | Loss: 0.15070639550685883\n",
      "Batch：4319 | Loss: 0.15053804218769073\n",
      "Batch：4320 | Loss: 0.15381170809268951\n",
      "Batch：4321 | Loss: 0.13931265473365784\n",
      "Batch：4322 | Loss: 0.15250228345394135\n",
      "Batch：4323 | Loss: 0.14074282348155975\n",
      "Batch：4324 | Loss: 0.14132758975028992\n",
      "Batch：4325 | Loss: 0.14079901576042175\n",
      "Batch：4326 | Loss: 0.147212952375412\n",
      "Batch：4327 | Loss: 0.15498647093772888\n",
      "Batch：4328 | Loss: 0.14000967144966125\n",
      "Batch：4329 | Loss: 0.14062300324440002\n",
      "Batch：4330 | Loss: 0.1630663424730301\n",
      "Batch：4331 | Loss: 0.14453352987766266\n",
      "Batch：4332 | Loss: 0.15120317041873932\n",
      "Batch：4333 | Loss: 0.13402925431728363\n",
      "Batch：4334 | Loss: 0.14481276273727417\n",
      "Batch：4335 | Loss: 0.14649595320224762\n",
      "Batch：4336 | Loss: 0.14353741705417633\n",
      "Batch：4337 | Loss: 0.1371377557516098\n",
      "Batch：4338 | Loss: 0.13046428561210632\n",
      "Batch：4339 | Loss: 0.1359414905309677\n",
      "Batch：4340 | Loss: 0.14077089726924896\n",
      "Batch：4341 | Loss: 0.1367649883031845\n",
      "Batch：4342 | Loss: 0.14855100214481354\n",
      "Batch：4343 | Loss: 0.1511884480714798\n",
      "Batch：4344 | Loss: 0.1355152726173401\n",
      "Batch：4345 | Loss: 0.1500733643770218\n",
      "Batch：4346 | Loss: 0.15604902803897858\n",
      "Batch：4347 | Loss: 0.1479295790195465\n",
      "Batch：4348 | Loss: 0.16267944872379303\n",
      "Batch：4349 | Loss: 0.15538622438907623\n",
      "Batch：4350 | Loss: 0.15029504895210266\n",
      "Batch：4351 | Loss: 0.1533220410346985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：4352 | Loss: 0.13952820003032684\n",
      "Batch：4353 | Loss: 0.1429683417081833\n",
      "Batch：4354 | Loss: 0.14777107536792755\n",
      "Batch：4355 | Loss: 0.13891099393367767\n",
      "Batch：4356 | Loss: 0.13506633043289185\n",
      "Batch：4357 | Loss: 0.14693647623062134\n",
      "Batch：4358 | Loss: 0.15362493693828583\n",
      "Batch：4359 | Loss: 0.14744146168231964\n",
      "Batch：4360 | Loss: 0.1452312469482422\n",
      "Batch：4361 | Loss: 0.14645415544509888\n",
      "Batch：4362 | Loss: 0.14032228291034698\n",
      "Batch：4363 | Loss: 0.14100319147109985\n",
      "Batch：4364 | Loss: 0.1312291920185089\n",
      "Batch：4365 | Loss: 0.13735409080982208\n",
      "Batch：4366 | Loss: 0.1516539454460144\n",
      "Batch：4367 | Loss: 0.15530924499034882\n",
      "Batch：4368 | Loss: 0.15079396963119507\n",
      "Batch：4369 | Loss: 0.13342717289924622\n",
      "Batch：4370 | Loss: 0.15006516873836517\n",
      "Batch：4371 | Loss: 0.13670866191387177\n",
      "Batch：4372 | Loss: 0.16003471612930298\n",
      "Batch：4373 | Loss: 0.1397130936384201\n",
      "Batch：4374 | Loss: 0.15339817106723785\n",
      "Batch：4375 | Loss: 0.15405075252056122\n",
      "Batch：4376 | Loss: 0.14407211542129517\n",
      "Batch：4377 | Loss: 0.1350647509098053\n",
      "Batch：4378 | Loss: 0.1436232328414917\n",
      "Batch：4379 | Loss: 0.15423272550106049\n",
      "Batch：4380 | Loss: 0.1425943225622177\n",
      "Batch：4381 | Loss: 0.1333860456943512\n",
      "Batch：4382 | Loss: 0.13751402497291565\n",
      "Batch：4383 | Loss: 0.14414186775684357\n",
      "Batch：4384 | Loss: 0.13337846100330353\n",
      "Batch：4385 | Loss: 0.14179235696792603\n",
      "Batch：4386 | Loss: 0.13937459886074066\n",
      "Batch：4387 | Loss: 0.14938409626483917\n",
      "Batch：4388 | Loss: 0.1391674131155014\n",
      "Batch：4389 | Loss: 0.13322821259498596\n",
      "Batch：4390 | Loss: 0.153691828250885\n",
      "Batch：4391 | Loss: 0.13247966766357422\n",
      "Batch：4392 | Loss: 0.14406003057956696\n",
      "Batch：4393 | Loss: 0.15193600952625275\n",
      "Batch：4394 | Loss: 0.14768099784851074\n",
      "Batch：4395 | Loss: 0.14200733602046967\n",
      "Batch：4396 | Loss: 0.154514342546463\n",
      "Batch：4397 | Loss: 0.1484655886888504\n",
      "Batch：4398 | Loss: 0.15469969809055328\n",
      "Batch：4399 | Loss: 0.1347767859697342\n",
      "Batch：4400 | Loss: 0.1445857584476471\n",
      "Batch：4401 | Loss: 0.14563721418380737\n",
      "Batch：4402 | Loss: 0.15138638019561768\n",
      "Batch：4403 | Loss: 0.16177362203598022\n",
      "Batch：4404 | Loss: 0.15887445211410522\n",
      "Batch：4405 | Loss: 0.13357628881931305\n",
      "Batch：4406 | Loss: 0.15955354273319244\n",
      "Batch：4407 | Loss: 0.14879196882247925\n",
      "Batch：4408 | Loss: 0.14461445808410645\n",
      "Batch：4409 | Loss: 0.14607462286949158\n",
      "Batch：4410 | Loss: 0.1461525857448578\n",
      "Batch：4411 | Loss: 0.16659925878047943\n",
      "Batch：4412 | Loss: 0.14442498981952667\n",
      "Batch：4413 | Loss: 0.14458014070987701\n",
      "Batch：4414 | Loss: 0.1410032957792282\n",
      "Batch：4415 | Loss: 0.13582389056682587\n",
      "Batch：4416 | Loss: 0.13204066455364227\n",
      "Batch：4417 | Loss: 0.14296454191207886\n",
      "Batch：4418 | Loss: 0.1372324377298355\n",
      "Batch：4419 | Loss: 0.1355409324169159\n",
      "Batch：4420 | Loss: 0.13207823038101196\n",
      "Batch：4421 | Loss: 0.14758354425430298\n",
      "Batch：4422 | Loss: 0.13819950819015503\n",
      "Batch：4423 | Loss: 0.15017393231391907\n",
      "Batch：4424 | Loss: 0.14774900674819946\n",
      "Batch：4425 | Loss: 0.14394716918468475\n",
      "Batch：4426 | Loss: 0.14170072972774506\n",
      "Batch：4427 | Loss: 0.15077538788318634\n",
      "Batch：4428 | Loss: 0.1393091380596161\n",
      "Batch：4429 | Loss: 0.1523268073797226\n",
      "Batch：4430 | Loss: 0.14064745604991913\n",
      "Batch：4431 | Loss: 0.13429886102676392\n",
      "Batch：4432 | Loss: 0.14453013241291046\n",
      "Batch：4433 | Loss: 0.14739996194839478\n",
      "Batch：4434 | Loss: 0.14220963418483734\n",
      "Batch：4435 | Loss: 0.1407935917377472\n",
      "Batch：4436 | Loss: 0.15477554500102997\n",
      "Batch：4437 | Loss: 0.12390242516994476\n",
      "Batch：4438 | Loss: 0.1534402221441269\n",
      "Batch：4439 | Loss: 0.12113156914710999\n",
      "Batch：4440 | Loss: 0.13211983442306519\n",
      "Batch：4441 | Loss: 0.14310306310653687\n",
      "Batch：4442 | Loss: 0.1443282663822174\n",
      "Batch：4443 | Loss: 0.14774370193481445\n",
      "Batch：4444 | Loss: 0.1452251374721527\n",
      "Batch：4445 | Loss: 0.13918565213680267\n",
      "Batch：4446 | Loss: 0.1433769166469574\n",
      "Batch：4447 | Loss: 0.1427871435880661\n",
      "Batch：4448 | Loss: 0.12892748415470123\n",
      "Batch：4449 | Loss: 0.13391834497451782\n",
      "Batch：4450 | Loss: 0.14929227530956268\n",
      "Batch：4451 | Loss: 0.1434151977300644\n",
      "Batch：4452 | Loss: 0.14491727948188782\n",
      "Batch：4453 | Loss: 0.15020021796226501\n",
      "Batch：4454 | Loss: 0.14252422749996185\n",
      "Batch：4455 | Loss: 0.13718421757221222\n",
      "Batch：4456 | Loss: 0.14687511324882507\n",
      "Batch：4457 | Loss: 0.15611237287521362\n",
      "Batch：4458 | Loss: 0.15139959752559662\n",
      "Batch：4459 | Loss: 0.14801594614982605\n",
      "Batch：4460 | Loss: 0.14102999866008759\n",
      "Batch：4461 | Loss: 0.12801212072372437\n",
      "Batch：4462 | Loss: 0.14825543761253357\n",
      "Batch：4463 | Loss: 0.14944659173488617\n",
      "Batch：4464 | Loss: 0.15238748490810394\n",
      "Batch：4465 | Loss: 0.1453654021024704\n",
      "Batch：4466 | Loss: 0.130802184343338\n",
      "Batch：4467 | Loss: 0.13737739622592926\n",
      "Batch：4468 | Loss: 0.15306216478347778\n",
      "Batch：4469 | Loss: 0.1483526974916458\n",
      "Batch：4470 | Loss: 0.12657751142978668\n",
      "Batch：4471 | Loss: 0.1546226441860199\n",
      "Batch：4472 | Loss: 0.15100117027759552\n",
      "Batch：4473 | Loss: 0.13746437430381775\n",
      "Batch：4474 | Loss: 0.13997255265712738\n",
      "Batch：4475 | Loss: 0.14353886246681213\n",
      "Batch：4476 | Loss: 0.13704729080200195\n",
      "Batch：4477 | Loss: 0.13718412816524506\n",
      "Batch：4478 | Loss: 0.1483776569366455\n",
      "Batch：4479 | Loss: 0.15307602286338806\n",
      "Batch：4480 | Loss: 0.13587811589241028\n",
      "Batch：4481 | Loss: 0.15080705285072327\n",
      "Batch：4482 | Loss: 0.1445203572511673\n",
      "Batch：4483 | Loss: 0.1361030638217926\n",
      "Batch：4484 | Loss: 0.13400766253471375\n",
      "Batch：4485 | Loss: 0.12725500762462616\n",
      "Batch：4486 | Loss: 0.1279253363609314\n",
      "Batch：4487 | Loss: 0.13088905811309814\n",
      "Batch：4488 | Loss: 0.13053609430789948\n",
      "Batch：4489 | Loss: 0.13221979141235352\n",
      "Batch：4490 | Loss: 0.14027857780456543\n",
      "Batch：4491 | Loss: 0.14414316415786743\n",
      "Batch：4492 | Loss: 0.13196732103824615\n",
      "Batch：4493 | Loss: 0.1505969613790512\n",
      "Batch：4494 | Loss: 0.13952785730361938\n",
      "Batch：4495 | Loss: 0.13376137614250183\n",
      "Batch：4496 | Loss: 0.1325768679380417\n",
      "Batch：4497 | Loss: 0.14570674300193787\n",
      "Batch：4498 | Loss: 0.1367568075656891\n",
      "Batch：4499 | Loss: 0.13978612422943115\n",
      "Batch：4500 | Loss: 0.15084929764270782\n",
      "Batch：4501 | Loss: 0.1369878053665161\n",
      "Batch：4502 | Loss: 0.13664652407169342\n",
      "Batch：4503 | Loss: 0.1334964781999588\n",
      "Batch：4504 | Loss: 0.13682250678539276\n",
      "Batch：4505 | Loss: 0.14255903661251068\n",
      "Batch：4506 | Loss: 0.1319294422864914\n",
      "Batch：4507 | Loss: 0.14240111410617828\n",
      "Batch：4508 | Loss: 0.14890162646770477\n",
      "Batch：4509 | Loss: 0.1419125199317932\n",
      "Batch：4510 | Loss: 0.15493038296699524\n",
      "Batch：4511 | Loss: 0.13607542216777802\n",
      "Batch：4512 | Loss: 0.14736348390579224\n",
      "Batch：4513 | Loss: 0.12777692079544067\n",
      "Batch：4514 | Loss: 0.14896923303604126\n",
      "Batch：4515 | Loss: 0.1350187212228775\n",
      "Batch：4516 | Loss: 0.14477476477622986\n",
      "Batch：4517 | Loss: 0.12733346223831177\n",
      "Batch：4518 | Loss: 0.1485971212387085\n",
      "Batch：4519 | Loss: 0.14052756130695343\n",
      "Batch：4520 | Loss: 0.14445160329341888\n",
      "Batch：4521 | Loss: 0.13085629045963287\n",
      "Batch：4522 | Loss: 0.13906405866146088\n",
      "Batch：4523 | Loss: 0.14264503121376038\n",
      "Batch：4524 | Loss: 0.1455778330564499\n",
      "Batch：4525 | Loss: 0.14114202558994293\n",
      "Batch：4526 | Loss: 0.149258553981781\n",
      "Batch：4527 | Loss: 0.15357781946659088\n",
      "Batch：4528 | Loss: 0.1323370784521103\n",
      "Batch：4529 | Loss: 0.13377492129802704\n",
      "Batch：4530 | Loss: 0.1390613317489624\n",
      "Batch：4531 | Loss: 0.1394469141960144\n",
      "Batch：4532 | Loss: 0.13336603343486786\n",
      "Batch：4533 | Loss: 0.14394918084144592\n",
      "Batch：4534 | Loss: 0.1318974792957306\n",
      "Batch：4535 | Loss: 0.14502432942390442\n",
      "Batch：4536 | Loss: 0.14372394979000092\n",
      "Batch：4537 | Loss: 0.13205428421497345\n",
      "Batch：4538 | Loss: 0.14966000616550446\n",
      "Batch：4539 | Loss: 0.15127445757389069\n",
      "Batch：4540 | Loss: 0.14884237945079803\n",
      "Batch：4541 | Loss: 0.1377851814031601\n",
      "Batch：4542 | Loss: 0.14664389193058014\n",
      "Batch：4543 | Loss: 0.14584942162036896\n",
      "Batch：4544 | Loss: 0.12469588220119476\n",
      "Batch：4545 | Loss: 0.1358529031276703\n",
      "Batch：4546 | Loss: 0.12961675226688385\n",
      "Batch：4547 | Loss: 0.12097199261188507\n",
      "Batch：4548 | Loss: 0.11892238259315491\n",
      "Batch：4549 | Loss: 0.13228094577789307\n",
      "Batch：4550 | Loss: 0.1469980925321579\n",
      "Batch：4551 | Loss: 0.14057417213916779\n",
      "Batch：4552 | Loss: 0.1452181190252304\n",
      "Batch：4553 | Loss: 0.15462081134319305\n",
      "Batch：4554 | Loss: 0.13662445545196533\n",
      "Batch：4555 | Loss: 0.13740786910057068\n",
      "Batch：4556 | Loss: 0.14128701388835907\n",
      "Batch：4557 | Loss: 0.14856253564357758\n",
      "Batch：4558 | Loss: 0.1437174528837204\n",
      "Batch：4559 | Loss: 0.14393268525600433\n",
      "Batch：4560 | Loss: 0.13905386626720428\n",
      "Batch：4561 | Loss: 0.13632680475711823\n",
      "Batch：4562 | Loss: 0.12848080694675446\n",
      "Batch：4563 | Loss: 0.14452190697193146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：4564 | Loss: 0.14067350327968597\n",
      "Batch：4565 | Loss: 0.14016903936862946\n",
      "Batch：4566 | Loss: 0.11668390035629272\n",
      "Batch：4567 | Loss: 0.137383833527565\n",
      "Batch：4568 | Loss: 0.14670923352241516\n",
      "Batch：4569 | Loss: 0.15699496865272522\n",
      "Batch：4570 | Loss: 0.13602794706821442\n",
      "Batch：4571 | Loss: 0.13292153179645538\n",
      "Batch：4572 | Loss: 0.14048850536346436\n",
      "Batch：4573 | Loss: 0.12960276007652283\n",
      "Batch：4574 | Loss: 0.1508486121892929\n",
      "Batch：4575 | Loss: 0.15604491531848907\n",
      "Batch：4576 | Loss: 0.1348375827074051\n",
      "Batch：4577 | Loss: 0.14327581226825714\n",
      "Batch：4578 | Loss: 0.14982649683952332\n",
      "Batch：4579 | Loss: 0.13740232586860657\n",
      "Batch：4580 | Loss: 0.15188951790332794\n",
      "Batch：4581 | Loss: 0.14989593625068665\n",
      "Batch：4582 | Loss: 0.1344854086637497\n",
      "Batch：4583 | Loss: 0.15107867121696472\n",
      "Batch：4584 | Loss: 0.14741404354572296\n",
      "Batch：4585 | Loss: 0.13636620342731476\n",
      "Batch：4586 | Loss: 0.1505374014377594\n",
      "Batch：4587 | Loss: 0.1353476196527481\n",
      "Batch：4588 | Loss: 0.14261116087436676\n",
      "Batch：4589 | Loss: 0.1374693661928177\n",
      "Batch：4590 | Loss: 0.14873559772968292\n",
      "Batch：4591 | Loss: 0.14068621397018433\n",
      "Batch：4592 | Loss: 0.12371493130922318\n",
      "Batch：4593 | Loss: 0.13018153607845306\n",
      "Batch：4594 | Loss: 0.14255918562412262\n",
      "Batch：4595 | Loss: 0.13977080583572388\n",
      "Batch：4596 | Loss: 0.11494707316160202\n",
      "Batch：4597 | Loss: 0.1597844809293747\n",
      "Batch：4598 | Loss: 0.1395416408777237\n",
      "Batch：4599 | Loss: 0.15612870454788208\n",
      "Batch：4600 | Loss: 0.14949055016040802\n",
      "Batch：4601 | Loss: 0.1385130137205124\n",
      "Batch：4602 | Loss: 0.14573459327220917\n",
      "Batch：4603 | Loss: 0.14422182738780975\n",
      "Batch：4604 | Loss: 0.12491249293088913\n",
      "Batch：4605 | Loss: 0.13176962733268738\n",
      "Batch：4606 | Loss: 0.12691082060337067\n",
      "Batch：4607 | Loss: 0.13289611041545868\n",
      "Batch：4608 | Loss: 0.133488729596138\n",
      "Batch：4609 | Loss: 0.15755340456962585\n",
      "Batch：4610 | Loss: 0.1331646591424942\n",
      "Batch：4611 | Loss: 0.1500195562839508\n",
      "Batch：4612 | Loss: 0.14215348660945892\n",
      "Batch：4613 | Loss: 0.14339770376682281\n",
      "Batch：4614 | Loss: 0.13125361502170563\n",
      "Batch：4615 | Loss: 0.11602935940027237\n",
      "Batch：4616 | Loss: 0.14529018104076385\n",
      "Batch：4617 | Loss: 0.1338708996772766\n",
      "Batch：4618 | Loss: 0.13917754590511322\n",
      "Batch：4619 | Loss: 0.13634343445301056\n",
      "Batch：4620 | Loss: 0.14886587858200073\n",
      "Batch：4621 | Loss: 0.14512096345424652\n",
      "Batch：4622 | Loss: 0.1366506665945053\n",
      "Batch：4623 | Loss: 0.1540786325931549\n",
      "Batch：4624 | Loss: 0.14049258828163147\n",
      "Batch：4625 | Loss: 0.13327810168266296\n",
      "Batch：4626 | Loss: 0.13092321157455444\n",
      "Batch：4627 | Loss: 0.14993397891521454\n",
      "Batch：4628 | Loss: 0.14332358539104462\n",
      "Batch：4629 | Loss: 0.1420535296201706\n",
      "Batch：4630 | Loss: 0.12809062004089355\n",
      "Batch：4631 | Loss: 0.1532335877418518\n",
      "Batch：4632 | Loss: 0.14571718871593475\n",
      "Batch：4633 | Loss: 0.14774073660373688\n",
      "Batch：4634 | Loss: 0.12815457582473755\n",
      "Batch：4635 | Loss: 0.13630224764347076\n",
      "Batch：4636 | Loss: 0.13415858149528503\n",
      "Batch：4637 | Loss: 0.13370314240455627\n",
      "Batch：4638 | Loss: 0.1413387805223465\n",
      "Batch：4639 | Loss: 0.12801112234592438\n",
      "Batch：4640 | Loss: 0.14226293563842773\n",
      "Batch：4641 | Loss: 0.13239654898643494\n",
      "Batch：4642 | Loss: 0.13223575055599213\n",
      "Batch：4643 | Loss: 0.14205202460289001\n",
      "Batch：4644 | Loss: 0.14747574925422668\n",
      "Batch：4645 | Loss: 0.13643142580986023\n",
      "Batch：4646 | Loss: 0.14536474645137787\n",
      "Batch：4647 | Loss: 0.1455652415752411\n",
      "Batch：4648 | Loss: 0.13824063539505005\n",
      "Batch：4649 | Loss: 0.14737418293952942\n",
      "Batch：4650 | Loss: 0.1350155621767044\n",
      "Batch：4651 | Loss: 0.1363876312971115\n",
      "Batch：4652 | Loss: 0.1556776762008667\n",
      "Batch：4653 | Loss: 0.12928028404712677\n",
      "Batch：4654 | Loss: 0.14078666269779205\n",
      "Batch：4655 | Loss: 0.13773296773433685\n",
      "Batch：4656 | Loss: 0.1346222460269928\n",
      "Batch：4657 | Loss: 0.15095190703868866\n",
      "Batch：4658 | Loss: 0.1351320743560791\n",
      "Batch：4659 | Loss: 0.12663978338241577\n",
      "Batch：4660 | Loss: 0.12597240507602692\n",
      "Batch：4661 | Loss: 0.1279626190662384\n",
      "Batch：4662 | Loss: 0.14256127178668976\n",
      "Batch：4663 | Loss: 0.13670188188552856\n",
      "Batch：4664 | Loss: 0.13774526119232178\n",
      "Batch：4665 | Loss: 0.13425111770629883\n",
      "Batch：4666 | Loss: 0.15602001547813416\n",
      "Batch：4667 | Loss: 0.13622799515724182\n",
      "Batch：4668 | Loss: 0.13794146478176117\n",
      "Batch：4669 | Loss: 0.14015741646289825\n",
      "Batch：4670 | Loss: 0.13948053121566772\n",
      "Batch：4671 | Loss: 0.13255447149276733\n",
      "Batch：4672 | Loss: 0.14046697318553925\n",
      "Batch：4673 | Loss: 0.13241221010684967\n",
      "Batch：4674 | Loss: 0.14088751375675201\n",
      "Batch：4675 | Loss: 0.12740550935268402\n",
      "Batch：4676 | Loss: 0.15337716042995453\n",
      "Batch：4677 | Loss: 0.1272978037595749\n",
      "Batch：4678 | Loss: 0.1346912980079651\n",
      "Batch：4679 | Loss: 0.13227342069149017\n",
      "Batch：4680 | Loss: 0.1356152892112732\n",
      "Batch：4681 | Loss: 0.13025370240211487\n",
      "Batch：4682 | Loss: 0.14279456436634064\n",
      "Batch：4683 | Loss: 0.1318882554769516\n",
      "Batch：4684 | Loss: 0.15142321586608887\n",
      "Batch：4685 | Loss: 0.13732999563217163\n",
      "Batch：4686 | Loss: 0.1415081024169922\n",
      "Batch：4687 | Loss: 0.15533804893493652\n",
      "Batch：4688 | Loss: 0.13151895999908447\n",
      "Batch：4689 | Loss: 0.13847751915454865\n",
      "Batch：4690 | Loss: 0.1333119422197342\n",
      "Batch：4691 | Loss: 0.12410397082567215\n",
      "Batch：4692 | Loss: 0.136327862739563\n",
      "Batch：4693 | Loss: 0.14115746319293976\n",
      "Batch：4694 | Loss: 0.13585904240608215\n",
      "Batch：4695 | Loss: 0.13504157960414886\n",
      "Batch：4696 | Loss: 0.14661802351474762\n",
      "Batch：4697 | Loss: 0.12650901079177856\n",
      "Batch：4698 | Loss: 0.13083794713020325\n",
      "Batch：4699 | Loss: 0.14008647203445435\n",
      "Batch：4700 | Loss: 0.12602075934410095\n",
      "Batch：4701 | Loss: 0.1429823487997055\n",
      "Batch：4702 | Loss: 0.13724660873413086\n",
      "Batch：4703 | Loss: 0.1397080272436142\n",
      "Batch：4704 | Loss: 0.1346546858549118\n",
      "Batch：4705 | Loss: 0.126113161444664\n",
      "Batch：4706 | Loss: 0.12370714545249939\n",
      "Batch：4707 | Loss: 0.13245107233524323\n",
      "Batch：4708 | Loss: 0.12746921181678772\n",
      "Batch：4709 | Loss: 0.15675821900367737\n",
      "Batch：4710 | Loss: 0.1256335973739624\n",
      "Batch：4711 | Loss: 0.13048554956912994\n",
      "Batch：4712 | Loss: 0.12876319885253906\n",
      "Batch：4713 | Loss: 0.14789441227912903\n",
      "Batch：4714 | Loss: 0.14119872450828552\n",
      "Batch：4715 | Loss: 0.14924326539039612\n",
      "Batch：4716 | Loss: 0.13860628008842468\n",
      "Batch：4717 | Loss: 0.14223843812942505\n",
      "Batch：4718 | Loss: 0.13077257573604584\n",
      "Batch：4719 | Loss: 0.12755540013313293\n",
      "Batch：4720 | Loss: 0.1508835405111313\n",
      "Batch：4721 | Loss: 0.14012441039085388\n",
      "Batch：4722 | Loss: 0.1352260857820511\n",
      "Batch：4723 | Loss: 0.13245023787021637\n",
      "Batch：4724 | Loss: 0.14131692051887512\n",
      "Batch：4725 | Loss: 0.1434958577156067\n",
      "Batch：4726 | Loss: 0.1264285296201706\n",
      "Batch：4727 | Loss: 0.14057277143001556\n",
      "Batch：4728 | Loss: 0.13110807538032532\n",
      "Batch：4729 | Loss: 0.12156148999929428\n",
      "Batch：4730 | Loss: 0.1325751543045044\n",
      "Batch：4731 | Loss: 0.1530260443687439\n",
      "Batch：4732 | Loss: 0.13687372207641602\n",
      "Batch：4733 | Loss: 0.1362171620130539\n",
      "Batch：4734 | Loss: 0.12718695402145386\n",
      "Batch：4735 | Loss: 0.13306370377540588\n",
      "Batch：4736 | Loss: 0.14479778707027435\n",
      "Batch：4737 | Loss: 0.14197425544261932\n",
      "Batch：4738 | Loss: 0.1533857136964798\n",
      "Batch：4739 | Loss: 0.12806834280490875\n",
      "Batch：4740 | Loss: 0.14306269586086273\n",
      "Batch：4741 | Loss: 0.15281565487384796\n",
      "Batch：4742 | Loss: 0.13215160369873047\n",
      "Batch：4743 | Loss: 0.14051763713359833\n",
      "Batch：4744 | Loss: 0.12253637611865997\n",
      "Batch：4745 | Loss: 0.1282995343208313\n",
      "Batch：4746 | Loss: 0.1338377594947815\n",
      "Batch：4747 | Loss: 0.13040325045585632\n",
      "Batch：4748 | Loss: 0.1368815153837204\n",
      "Batch：4749 | Loss: 0.13627083599567413\n",
      "Batch：4750 | Loss: 0.1308920979499817\n",
      "Batch：4751 | Loss: 0.13906121253967285\n",
      "Batch：4752 | Loss: 0.13662591576576233\n",
      "Batch：4753 | Loss: 0.11517257243394852\n",
      "Batch：4754 | Loss: 0.14661051332950592\n",
      "Batch：4755 | Loss: 0.1270938515663147\n",
      "Batch：4756 | Loss: 0.14148828387260437\n",
      "Batch：4757 | Loss: 0.13881324231624603\n",
      "Batch：4758 | Loss: 0.1214362159371376\n",
      "Batch：4759 | Loss: 0.12938348948955536\n",
      "Batch：4760 | Loss: 0.12765012681484222\n",
      "Batch：4761 | Loss: 0.13951340317726135\n",
      "Batch：4762 | Loss: 0.13159671425819397\n",
      "Batch：4763 | Loss: 0.1341557800769806\n",
      "Batch：4764 | Loss: 0.13136988878250122\n",
      "Batch：4765 | Loss: 0.13886092603206635\n",
      "Batch：4766 | Loss: 0.13801582157611847\n",
      "Batch：4767 | Loss: 0.12466902285814285\n",
      "Batch：4768 | Loss: 0.14397019147872925\n",
      "Batch：4769 | Loss: 0.1447961926460266\n",
      "Batch：4770 | Loss: 0.13055101037025452\n",
      "Batch：4771 | Loss: 0.13800117373466492\n",
      "Batch：4772 | Loss: 0.1335325539112091\n",
      "Batch：4773 | Loss: 0.13333866000175476\n",
      "Batch：4774 | Loss: 0.12667535245418549\n",
      "Batch：4775 | Loss: 0.1356525421142578\n",
      "Batch：4776 | Loss: 0.12927596271038055\n",
      "Batch：4777 | Loss: 0.1319892406463623\n",
      "Batch：4778 | Loss: 0.14569038152694702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：4779 | Loss: 0.13869288563728333\n",
      "Batch：4780 | Loss: 0.14083118736743927\n",
      "Batch：4781 | Loss: 0.14236034452915192\n",
      "Batch：4782 | Loss: 0.1430378258228302\n",
      "Batch：4783 | Loss: 0.1286156326532364\n",
      "Batch：4784 | Loss: 0.12204229831695557\n",
      "Batch：4785 | Loss: 0.12495043128728867\n",
      "Batch：4786 | Loss: 0.13269510865211487\n",
      "Batch：4787 | Loss: 0.12637859582901\n",
      "Batch：4788 | Loss: 0.12715181708335876\n",
      "Batch：4789 | Loss: 0.128975972533226\n",
      "Batch：4790 | Loss: 0.14446325600147247\n",
      "Batch：4791 | Loss: 0.13057859241962433\n",
      "Batch：4792 | Loss: 0.1336335986852646\n",
      "Batch：4793 | Loss: 0.13514959812164307\n",
      "Batch：4794 | Loss: 0.1367219239473343\n",
      "Batch：4795 | Loss: 0.1491195112466812\n",
      "Batch：4796 | Loss: 0.13287469744682312\n",
      "Batch：4797 | Loss: 0.12145910412073135\n",
      "Batch：4798 | Loss: 0.13316069543361664\n",
      "Batch：4799 | Loss: 0.14278140664100647\n",
      "Batch：4800 | Loss: 0.14464852213859558\n",
      "Batch：4801 | Loss: 0.13863952457904816\n",
      "Batch：4802 | Loss: 0.1347922384738922\n",
      "Batch：4803 | Loss: 0.12837211787700653\n",
      "Batch：4804 | Loss: 0.14101454615592957\n",
      "Batch：4805 | Loss: 0.12693364918231964\n",
      "Batch：4806 | Loss: 0.12576395273208618\n",
      "Batch：4807 | Loss: 0.13365328311920166\n",
      "Batch：4808 | Loss: 0.12207666039466858\n",
      "Batch：4809 | Loss: 0.12704190611839294\n",
      "Batch：4810 | Loss: 0.13865944743156433\n",
      "Batch：4811 | Loss: 0.13670550286769867\n",
      "Batch：4812 | Loss: 0.14203445613384247\n",
      "Batch：4813 | Loss: 0.12293338775634766\n",
      "Batch：4814 | Loss: 0.12941648066043854\n",
      "Batch：4815 | Loss: 0.13270270824432373\n",
      "Batch：4816 | Loss: 0.14840006828308105\n",
      "Batch：4817 | Loss: 0.13383735716342926\n",
      "Batch：4818 | Loss: 0.13239510357379913\n",
      "Batch：4819 | Loss: 0.12975510954856873\n",
      "Batch：4820 | Loss: 0.14109556376934052\n",
      "Batch：4821 | Loss: 0.1297624260187149\n",
      "Batch：4822 | Loss: 0.13223972916603088\n",
      "Batch：4823 | Loss: 0.13559240102767944\n",
      "Batch：4824 | Loss: 0.13952510058879852\n",
      "Batch：4825 | Loss: 0.12051314115524292\n",
      "Batch：4826 | Loss: 0.14512081444263458\n",
      "Batch：4827 | Loss: 0.12894532084465027\n",
      "Batch：4828 | Loss: 0.12889574468135834\n",
      "Batch：4829 | Loss: 0.13562753796577454\n",
      "Batch：4830 | Loss: 0.12540724873542786\n",
      "Batch：4831 | Loss: 0.14083042740821838\n",
      "Batch：4832 | Loss: 0.13274690508842468\n",
      "Batch：4833 | Loss: 0.13706961274147034\n",
      "Batch：4834 | Loss: 0.133301243185997\n",
      "Batch：4835 | Loss: 0.13910037279129028\n",
      "Batch：4836 | Loss: 0.12167651951313019\n",
      "Batch：4837 | Loss: 0.12836819887161255\n",
      "Batch：4838 | Loss: 0.133351668715477\n",
      "Batch：4839 | Loss: 0.13187672197818756\n",
      "Batch：4840 | Loss: 0.12759292125701904\n",
      "Batch：4841 | Loss: 0.13704243302345276\n",
      "Batch：4842 | Loss: 0.13111013174057007\n",
      "Batch：4843 | Loss: 0.13333512842655182\n",
      "Batch：4844 | Loss: 0.13209086656570435\n",
      "Batch：4845 | Loss: 0.1313358098268509\n",
      "Batch：4846 | Loss: 0.15371492505073547\n",
      "Batch：4847 | Loss: 0.14459332823753357\n",
      "Batch：4848 | Loss: 0.12621629238128662\n",
      "Batch：4849 | Loss: 0.13101257383823395\n",
      "Batch：4850 | Loss: 0.12948574125766754\n",
      "Batch：4851 | Loss: 0.126159206032753\n",
      "Batch：4852 | Loss: 0.1289498507976532\n",
      "Batch：4853 | Loss: 0.1501391977071762\n",
      "Batch：4854 | Loss: 0.12143994122743607\n",
      "Batch：4855 | Loss: 0.12964095175266266\n",
      "Batch：4856 | Loss: 0.13230939209461212\n",
      "Batch：4857 | Loss: 0.1242140680551529\n",
      "Batch：4858 | Loss: 0.12982486188411713\n",
      "Batch：4859 | Loss: 0.14388541877269745\n",
      "Batch：4860 | Loss: 0.12052549421787262\n",
      "Batch：4861 | Loss: 0.13520124554634094\n",
      "Batch：4862 | Loss: 0.1392515003681183\n",
      "Batch：4863 | Loss: 0.14022411406040192\n",
      "Batch：4864 | Loss: 0.14282916486263275\n",
      "Batch：4865 | Loss: 0.14000307023525238\n",
      "Batch：4866 | Loss: 0.1427198201417923\n",
      "Batch：4867 | Loss: 0.1421986073255539\n",
      "Batch：4868 | Loss: 0.12365347146987915\n",
      "Batch：4869 | Loss: 0.12433799356222153\n",
      "Batch：4870 | Loss: 0.14264611899852753\n",
      "Batch：4871 | Loss: 0.13825733959674835\n",
      "Batch：4872 | Loss: 0.14100757241249084\n",
      "Batch：4873 | Loss: 0.1288738250732422\n",
      "Batch：4874 | Loss: 0.1258196383714676\n",
      "Batch：4875 | Loss: 0.13792075216770172\n",
      "Batch：4876 | Loss: 0.14117838442325592\n",
      "Batch：4877 | Loss: 0.12841947376728058\n",
      "Batch：4878 | Loss: 0.12940172851085663\n",
      "Batch：4879 | Loss: 0.13285815715789795\n",
      "Batch：4880 | Loss: 0.13110394775867462\n",
      "Batch：4881 | Loss: 0.1347619593143463\n",
      "Batch：4882 | Loss: 0.13330312073230743\n",
      "Batch：4883 | Loss: 0.14206556975841522\n",
      "Batch：4884 | Loss: 0.11476342380046844\n",
      "Batch：4885 | Loss: 0.12108340114355087\n",
      "Batch：4886 | Loss: 0.12686772644519806\n",
      "Batch：4887 | Loss: 0.13976609706878662\n",
      "Batch：4888 | Loss: 0.13768433034420013\n",
      "Batch：4889 | Loss: 0.1291942149400711\n",
      "Batch：4890 | Loss: 0.12555430829524994\n",
      "Batch：4891 | Loss: 0.12517507374286652\n",
      "Batch：4892 | Loss: 0.13155482709407806\n",
      "Batch：4893 | Loss: 0.146348774433136\n",
      "Batch：4894 | Loss: 0.13138549029827118\n",
      "Batch：4895 | Loss: 0.14085322618484497\n",
      "Batch：4896 | Loss: 0.1264929324388504\n",
      "Batch：4897 | Loss: 0.132381871342659\n",
      "Batch：4898 | Loss: 0.1308756172657013\n",
      "Batch：4899 | Loss: 0.1281099170446396\n",
      "Batch：4900 | Loss: 0.12753620743751526\n",
      "Batch：4901 | Loss: 0.1396251618862152\n",
      "Batch：4902 | Loss: 0.1405085176229477\n",
      "Batch：4903 | Loss: 0.12706434726715088\n",
      "Batch：4904 | Loss: 0.12308753281831741\n",
      "Batch：4905 | Loss: 0.12735731899738312\n",
      "Batch：4906 | Loss: 0.12040837109088898\n",
      "Batch：4907 | Loss: 0.14021191000938416\n",
      "Batch：4908 | Loss: 0.1342090219259262\n",
      "Batch：4909 | Loss: 0.1257379949092865\n",
      "Batch：4910 | Loss: 0.13394220173358917\n",
      "Batch：4911 | Loss: 0.1313590258359909\n",
      "Batch：4912 | Loss: 0.13083787262439728\n",
      "Batch：4913 | Loss: 0.11457981169223785\n",
      "Batch：4914 | Loss: 0.11853600293397903\n",
      "Batch：4915 | Loss: 0.13311994075775146\n",
      "Batch：4916 | Loss: 0.11323244124650955\n",
      "Batch：4917 | Loss: 0.13213224709033966\n",
      "Batch：4918 | Loss: 0.12865698337554932\n",
      "Batch：4919 | Loss: 0.1261870115995407\n",
      "Batch：4920 | Loss: 0.12086787819862366\n",
      "Batch：4921 | Loss: 0.12587937712669373\n",
      "Batch：4922 | Loss: 0.1337575912475586\n",
      "Batch：4923 | Loss: 0.12872068583965302\n",
      "Batch：4924 | Loss: 0.13137288391590118\n",
      "Batch：4925 | Loss: 0.13897618651390076\n",
      "Batch：4926 | Loss: 0.1217455044388771\n",
      "Batch：4927 | Loss: 0.12211848050355911\n",
      "Batch：4928 | Loss: 0.12285389751195908\n",
      "Batch：4929 | Loss: 0.14616551995277405\n",
      "Batch：4930 | Loss: 0.11903148144483566\n",
      "Batch：4931 | Loss: 0.12653188407421112\n",
      "Batch：4932 | Loss: 0.1337238997220993\n",
      "Batch：4933 | Loss: 0.12745462357997894\n",
      "Batch：4934 | Loss: 0.13429071009159088\n",
      "Batch：4935 | Loss: 0.12795114517211914\n",
      "Batch：4936 | Loss: 0.1256769597530365\n",
      "Batch：4937 | Loss: 0.12901417911052704\n",
      "Batch：4938 | Loss: 0.13603636622428894\n",
      "Batch：4939 | Loss: 0.12703338265419006\n",
      "Batch：4940 | Loss: 0.14274637401103973\n",
      "Batch：4941 | Loss: 0.12832362949848175\n",
      "Batch：4942 | Loss: 0.1292334794998169\n",
      "Batch：4943 | Loss: 0.12695929408073425\n",
      "Batch：4944 | Loss: 0.13439792394638062\n",
      "Batch：4945 | Loss: 0.1222282275557518\n",
      "Batch：4946 | Loss: 0.13743513822555542\n",
      "Batch：4947 | Loss: 0.13644567131996155\n",
      "Batch：4948 | Loss: 0.12900064885616302\n",
      "Batch：4949 | Loss: 0.12847866117954254\n",
      "Batch：4950 | Loss: 0.13613411784172058\n",
      "Batch：4951 | Loss: 0.13090574741363525\n",
      "Batch：4952 | Loss: 0.13072222471237183\n",
      "Batch：4953 | Loss: 0.1442759484052658\n",
      "Batch：4954 | Loss: 0.12810638546943665\n",
      "Batch：4955 | Loss: 0.1411590725183487\n",
      "Batch：4956 | Loss: 0.13044582307338715\n",
      "Batch：4957 | Loss: 0.143325537443161\n",
      "Batch：4958 | Loss: 0.13861191272735596\n",
      "Batch：4959 | Loss: 0.13820019364356995\n",
      "Batch：4960 | Loss: 0.13202716410160065\n",
      "Batch：4961 | Loss: 0.13950270414352417\n",
      "Batch：4962 | Loss: 0.13387614488601685\n",
      "Batch：4963 | Loss: 0.13044194877147675\n",
      "Batch：4964 | Loss: 0.1336858719587326\n",
      "Batch：4965 | Loss: 0.12875519692897797\n",
      "Batch：4966 | Loss: 0.14705409109592438\n",
      "Batch：4967 | Loss: 0.11701963096857071\n",
      "Batch：4968 | Loss: 0.11077023297548294\n",
      "Batch：4969 | Loss: 0.12053102254867554\n",
      "Batch：4970 | Loss: 0.13566061854362488\n",
      "Batch：4971 | Loss: 0.13756628334522247\n",
      "Batch：4972 | Loss: 0.12871921062469482\n",
      "Batch：4973 | Loss: 0.12972602248191833\n",
      "Batch：4974 | Loss: 0.11975466459989548\n",
      "Batch：4975 | Loss: 0.12858304381370544\n",
      "Batch：4976 | Loss: 0.11421006172895432\n",
      "Batch：4977 | Loss: 0.13749586045742035\n",
      "Batch：4978 | Loss: 0.1310170441865921\n",
      "Batch：4979 | Loss: 0.1244809553027153\n",
      "Batch：4980 | Loss: 0.12651164829730988\n",
      "Batch：4981 | Loss: 0.12288437783718109\n",
      "Batch：4982 | Loss: 0.1107926145195961\n",
      "Batch：4983 | Loss: 0.14187784492969513\n",
      "Batch：4984 | Loss: 0.13598257303237915\n",
      "Batch：4985 | Loss: 0.1265738159418106\n",
      "Batch：4986 | Loss: 0.1138170138001442\n",
      "Batch：4987 | Loss: 0.12850093841552734\n",
      "Batch：4988 | Loss: 0.11908179521560669\n",
      "Batch：4989 | Loss: 0.13488085567951202\n",
      "Batch：4990 | Loss: 0.12880128622055054\n",
      "Batch：4991 | Loss: 0.12042032927274704\n",
      "Batch：4992 | Loss: 0.12906751036643982\n",
      "Batch：4993 | Loss: 0.13458983600139618\n",
      "Batch：4994 | Loss: 0.10914778709411621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：4995 | Loss: 0.1290060132741928\n",
      "Batch：4996 | Loss: 0.14075839519500732\n",
      "Batch：4997 | Loss: 0.12945076823234558\n",
      "Batch：4998 | Loss: 0.13156062364578247\n",
      "Batch：4999 | Loss: 0.1249542310833931\n",
      "Batch：5000 | Loss: 0.13456711173057556\n",
      "Batch：5001 | Loss: 0.11771449446678162\n",
      "Batch：5002 | Loss: 0.11965979635715485\n",
      "Batch：5003 | Loss: 0.11993853747844696\n",
      "Batch：5004 | Loss: 0.12436236441135406\n",
      "Batch：5005 | Loss: 0.11791215091943741\n",
      "Batch：5006 | Loss: 0.14120706915855408\n",
      "Batch：5007 | Loss: 0.1390659511089325\n",
      "Batch：5008 | Loss: 0.12420066446065903\n",
      "Batch：5009 | Loss: 0.13836562633514404\n",
      "Batch：5010 | Loss: 0.12235014885663986\n",
      "Batch：5011 | Loss: 0.11837538331747055\n",
      "Batch：5012 | Loss: 0.12034250050783157\n",
      "Batch：5013 | Loss: 0.12027458846569061\n",
      "Batch：5014 | Loss: 0.1341768205165863\n",
      "Batch：5015 | Loss: 0.13035644590854645\n",
      "Batch：5016 | Loss: 0.13196472823619843\n",
      "Batch：5017 | Loss: 0.12309539318084717\n",
      "Batch：5018 | Loss: 0.11885888874530792\n",
      "Batch：5019 | Loss: 0.13899962604045868\n",
      "Batch：5020 | Loss: 0.1216435506939888\n",
      "Batch：5021 | Loss: 0.12588243186473846\n",
      "Batch：5022 | Loss: 0.12813647091388702\n",
      "Batch：5023 | Loss: 0.1311333328485489\n",
      "Batch：5024 | Loss: 0.12044545263051987\n",
      "Batch：5025 | Loss: 0.13553816080093384\n",
      "Batch：5026 | Loss: 0.11452612280845642\n",
      "Batch：5027 | Loss: 0.13636083900928497\n",
      "Batch：5028 | Loss: 0.13359957933425903\n",
      "Batch：5029 | Loss: 0.1178961992263794\n",
      "Batch：5030 | Loss: 0.12532834708690643\n",
      "Batch：5031 | Loss: 0.1305888444185257\n",
      "Batch：5032 | Loss: 0.13383010029792786\n",
      "Batch：5033 | Loss: 0.13129912316799164\n",
      "Batch：5034 | Loss: 0.13101525604724884\n",
      "Batch：5035 | Loss: 0.139450341463089\n",
      "Batch：5036 | Loss: 0.1363680362701416\n",
      "Batch：5037 | Loss: 0.1291198581457138\n",
      "Batch：5038 | Loss: 0.13941971957683563\n",
      "Batch：5039 | Loss: 0.1299004703760147\n",
      "Batch：5040 | Loss: 0.1327776312828064\n",
      "Batch：5041 | Loss: 0.12215304374694824\n",
      "Batch：5042 | Loss: 0.13045041263103485\n",
      "Batch：5043 | Loss: 0.12564854323863983\n",
      "Batch：5044 | Loss: 0.13165777921676636\n",
      "Batch：5045 | Loss: 0.1400703340768814\n",
      "Batch：5046 | Loss: 0.1265939176082611\n",
      "Batch：5047 | Loss: 0.13730545341968536\n",
      "Batch：5048 | Loss: 0.13475152850151062\n",
      "Batch：5049 | Loss: 0.12353736907243729\n",
      "Batch：5050 | Loss: 0.13549938797950745\n",
      "Batch：5051 | Loss: 0.1313859075307846\n",
      "Batch：5052 | Loss: 0.13031283020973206\n",
      "Batch：5053 | Loss: 0.12980656325817108\n",
      "Batch：5054 | Loss: 0.12975606322288513\n",
      "Batch：5055 | Loss: 0.1404545158147812\n",
      "Batch：5056 | Loss: 0.12173192948102951\n",
      "Batch：5057 | Loss: 0.1184195727109909\n",
      "Batch：5058 | Loss: 0.12305231392383575\n",
      "Batch：5059 | Loss: 0.14212755858898163\n",
      "Batch：5060 | Loss: 0.1182718575000763\n",
      "Batch：5061 | Loss: 0.12648950517177582\n",
      "Batch：5062 | Loss: 0.13615882396697998\n",
      "Batch：5063 | Loss: 0.13427738845348358\n",
      "Batch：5064 | Loss: 0.10554693639278412\n",
      "Batch：5065 | Loss: 0.12216749787330627\n",
      "Batch：5066 | Loss: 0.11994560807943344\n",
      "Batch：5067 | Loss: 0.11099599301815033\n",
      "Batch：5068 | Loss: 0.135340616106987\n",
      "Batch：5069 | Loss: 0.14060771465301514\n",
      "Batch：5070 | Loss: 0.12281070649623871\n",
      "Batch：5071 | Loss: 0.1237240806221962\n",
      "Batch：5072 | Loss: 0.13974720239639282\n",
      "Batch：5073 | Loss: 0.11884381622076035\n",
      "Batch：5074 | Loss: 0.12454347312450409\n",
      "Batch：5075 | Loss: 0.12835034728050232\n",
      "Batch：5076 | Loss: 0.13920046389102936\n",
      "Batch：5077 | Loss: 0.12975573539733887\n",
      "Batch：5078 | Loss: 0.12917417287826538\n",
      "Batch：5079 | Loss: 0.13266149163246155\n",
      "Batch：5080 | Loss: 0.127685084939003\n",
      "Batch：5081 | Loss: 0.1293487697839737\n",
      "Batch：5082 | Loss: 0.12574702501296997\n",
      "Batch：5083 | Loss: 0.1119069829583168\n",
      "Batch：5084 | Loss: 0.13063453137874603\n",
      "Batch：5085 | Loss: 0.12830926477909088\n",
      "Batch：5086 | Loss: 0.11686354130506516\n",
      "Batch：5087 | Loss: 0.12428398430347443\n",
      "Batch：5088 | Loss: 0.1422489583492279\n",
      "Batch：5089 | Loss: 0.12814655900001526\n",
      "Batch：5090 | Loss: 0.13338516652584076\n",
      "Batch：5091 | Loss: 0.13991592824459076\n",
      "Batch：5092 | Loss: 0.13410437107086182\n",
      "Batch：5093 | Loss: 0.12292062491178513\n",
      "Batch：5094 | Loss: 0.12253183871507645\n",
      "Batch：5095 | Loss: 0.13374285399913788\n",
      "Batch：5096 | Loss: 0.13139985501766205\n",
      "Batch：5097 | Loss: 0.13021144270896912\n",
      "Batch：5098 | Loss: 0.13614585995674133\n",
      "Batch：5099 | Loss: 0.12455281615257263\n",
      "Batch：5100 | Loss: 0.1321856677532196\n",
      "Batch：5101 | Loss: 0.12925605475902557\n",
      "Batch：5102 | Loss: 0.11898826062679291\n",
      "Batch：5103 | Loss: 0.11783764511346817\n",
      "Batch：5104 | Loss: 0.13778111338615417\n",
      "Batch：5105 | Loss: 0.1117827519774437\n",
      "Batch：5106 | Loss: 0.12377052009105682\n",
      "Batch：5107 | Loss: 0.12134486436843872\n",
      "Batch：5108 | Loss: 0.11595647782087326\n",
      "Batch：5109 | Loss: 0.13226692378520966\n",
      "Batch：5110 | Loss: 0.12799330055713654\n",
      "Batch：5111 | Loss: 0.12701921164989471\n",
      "Batch：5112 | Loss: 0.13119617104530334\n",
      "Batch：5113 | Loss: 0.11446604132652283\n",
      "Batch：5114 | Loss: 0.12770976126194\n",
      "Batch：5115 | Loss: 0.12648488581180573\n",
      "Batch：5116 | Loss: 0.12680064141750336\n",
      "Batch：5117 | Loss: 0.13209231197834015\n",
      "Batch：5118 | Loss: 0.13583123683929443\n",
      "Batch：5119 | Loss: 0.11823813617229462\n",
      "Batch：5120 | Loss: 0.1324032098054886\n",
      "Batch：5121 | Loss: 0.12920741736888885\n",
      "Batch：5122 | Loss: 0.12996502220630646\n",
      "Batch：5123 | Loss: 0.1258474439382553\n",
      "Batch：5124 | Loss: 0.1386454850435257\n",
      "Batch：5125 | Loss: 0.12532275915145874\n",
      "Batch：5126 | Loss: 0.12381680309772491\n",
      "Batch：5127 | Loss: 0.12878456711769104\n",
      "Batch：5128 | Loss: 0.13835635781288147\n",
      "Batch：5129 | Loss: 0.13388793170452118\n",
      "Batch：5130 | Loss: 0.1253070831298828\n",
      "Batch：5131 | Loss: 0.1367853432893753\n",
      "Batch：5132 | Loss: 0.12736360728740692\n",
      "Batch：5133 | Loss: 0.13493262231349945\n",
      "Batch：5134 | Loss: 0.1371179223060608\n",
      "Batch：5135 | Loss: 0.12644656002521515\n",
      "Batch：5136 | Loss: 0.1209399625658989\n",
      "Batch：5137 | Loss: 0.1136905699968338\n",
      "Batch：5138 | Loss: 0.12227795273065567\n",
      "Batch：5139 | Loss: 0.1301591992378235\n",
      "Batch：5140 | Loss: 0.1148996651172638\n",
      "Batch：5141 | Loss: 0.12721598148345947\n",
      "Batch：5142 | Loss: 0.14622238278388977\n",
      "Batch：5143 | Loss: 0.13062424957752228\n",
      "Batch：5144 | Loss: 0.13051076233386993\n",
      "Batch：5145 | Loss: 0.1166386678814888\n",
      "Batch：5146 | Loss: 0.1315653920173645\n",
      "Batch：5147 | Loss: 0.12372320145368576\n",
      "Batch：5148 | Loss: 0.11982295662164688\n",
      "Batch：5149 | Loss: 0.12683580815792084\n",
      "Batch：5150 | Loss: 0.1335826814174652\n",
      "Batch：5151 | Loss: 0.1236022561788559\n",
      "Batch：5152 | Loss: 0.12208353728055954\n",
      "Batch：5153 | Loss: 0.1374610960483551\n",
      "Batch：5154 | Loss: 0.12456551194190979\n",
      "Batch：5155 | Loss: 0.1219874769449234\n",
      "Batch：5156 | Loss: 0.13671278953552246\n",
      "Batch：5157 | Loss: 0.13668130338191986\n",
      "Batch：5158 | Loss: 0.12770554423332214\n",
      "Batch：5159 | Loss: 0.12341916561126709\n",
      "Batch：5160 | Loss: 0.12813445925712585\n",
      "Batch：5161 | Loss: 0.12548121809959412\n",
      "Batch：5162 | Loss: 0.115635447204113\n",
      "Batch：5163 | Loss: 0.12067936360836029\n",
      "Batch：5164 | Loss: 0.11281508207321167\n",
      "Batch：5165 | Loss: 0.1278134286403656\n",
      "Batch：5166 | Loss: 0.11508241295814514\n",
      "Batch：5167 | Loss: 0.12760397791862488\n",
      "Batch：5168 | Loss: 0.1288880854845047\n",
      "Batch：5169 | Loss: 0.12330018728971481\n",
      "Batch：5170 | Loss: 0.11711432784795761\n",
      "Batch：5171 | Loss: 0.11372911185026169\n",
      "Batch：5172 | Loss: 0.1245059221982956\n",
      "Batch：5173 | Loss: 0.11835561692714691\n",
      "Batch：5174 | Loss: 0.12829641997814178\n",
      "Batch：5175 | Loss: 0.12202298641204834\n",
      "Batch：5176 | Loss: 0.12575027346611023\n",
      "Batch：5177 | Loss: 0.1411290019750595\n",
      "Batch：5178 | Loss: 0.11893505603075027\n",
      "Batch：5179 | Loss: 0.1221248060464859\n",
      "Batch：5180 | Loss: 0.12997747957706451\n",
      "Batch：5181 | Loss: 0.12284313142299652\n",
      "Batch：5182 | Loss: 0.12861177325248718\n",
      "Batch：5183 | Loss: 0.13039791584014893\n",
      "Batch：5184 | Loss: 0.13486072421073914\n",
      "Batch：5185 | Loss: 0.12272625416517258\n",
      "Batch：5186 | Loss: 0.11942704021930695\n",
      "Batch：5187 | Loss: 0.1169268786907196\n",
      "Batch：5188 | Loss: 0.11872809380292892\n",
      "Batch：5189 | Loss: 0.12511643767356873\n",
      "Batch：5190 | Loss: 0.139182448387146\n",
      "Batch：5191 | Loss: 0.1334809809923172\n",
      "Batch：5192 | Loss: 0.12626881897449493\n",
      "Batch：5193 | Loss: 0.13647888600826263\n",
      "Batch：5194 | Loss: 0.12883815169334412\n",
      "Batch：5195 | Loss: 0.14205265045166016\n",
      "Batch：5196 | Loss: 0.12181330472230911\n",
      "Batch：5197 | Loss: 0.1259137988090515\n",
      "Batch：5198 | Loss: 0.12602698802947998\n",
      "Batch：5199 | Loss: 0.12067730724811554\n",
      "Batch：5200 | Loss: 0.12589387595653534\n",
      "Batch：5201 | Loss: 0.13028599321842194\n",
      "Batch：5202 | Loss: 0.12342291325330734\n",
      "Batch：5203 | Loss: 0.129543736577034\n",
      "Batch：5204 | Loss: 0.1178591176867485\n",
      "Batch：5205 | Loss: 0.1205916628241539\n",
      "Batch：5206 | Loss: 0.11728493869304657\n",
      "Batch：5207 | Loss: 0.12371311336755753\n",
      "Batch：5208 | Loss: 0.1280864179134369\n",
      "Batch：5209 | Loss: 0.12153605371713638\n",
      "Batch：5210 | Loss: 0.13739563524723053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：5211 | Loss: 0.13166645169258118\n",
      "Batch：5212 | Loss: 0.13953012228012085\n",
      "Batch：5213 | Loss: 0.122176393866539\n",
      "Batch：5214 | Loss: 0.12847092747688293\n",
      "Batch：5215 | Loss: 0.12806202471256256\n",
      "Batch：5216 | Loss: 0.1285519152879715\n",
      "Batch：5217 | Loss: 0.1111944392323494\n",
      "Batch：5218 | Loss: 0.12686988711357117\n",
      "Batch：5219 | Loss: 0.13924281299114227\n",
      "Batch：5220 | Loss: 0.12368274480104446\n",
      "Batch：5221 | Loss: 0.11978207528591156\n",
      "Batch：5222 | Loss: 0.1392820030450821\n",
      "Batch：5223 | Loss: 0.12501314282417297\n",
      "Batch：5224 | Loss: 0.12667915225028992\n",
      "Batch：5225 | Loss: 0.1223282441496849\n",
      "Batch：5226 | Loss: 0.12267584353685379\n",
      "Batch：5227 | Loss: 0.13322730362415314\n",
      "Batch：5228 | Loss: 0.12063919007778168\n",
      "Batch：5229 | Loss: 0.12520456314086914\n",
      "Batch：5230 | Loss: 0.11512269079685211\n",
      "Batch：5231 | Loss: 0.12801802158355713\n",
      "Batch：5232 | Loss: 0.12688331305980682\n",
      "Batch：5233 | Loss: 0.13120296597480774\n",
      "Batch：5234 | Loss: 0.10478956997394562\n",
      "Batch：5235 | Loss: 0.1263047605752945\n",
      "Batch：5236 | Loss: 0.1337299346923828\n",
      "Batch：5237 | Loss: 0.12912611663341522\n",
      "Batch：5238 | Loss: 0.12740761041641235\n",
      "Batch：5239 | Loss: 0.11687587201595306\n",
      "Batch：5240 | Loss: 0.12620244920253754\n",
      "Batch：5241 | Loss: 0.1059231385588646\n",
      "Batch：5242 | Loss: 0.1370026022195816\n",
      "Batch：5243 | Loss: 0.1328335702419281\n",
      "Batch：5244 | Loss: 0.12717537581920624\n",
      "Batch：5245 | Loss: 0.12389624118804932\n",
      "Batch：5246 | Loss: 0.11937546730041504\n",
      "Batch：5247 | Loss: 0.12772159278392792\n",
      "Batch：5248 | Loss: 0.12306196987628937\n",
      "Batch：5249 | Loss: 0.12904128432273865\n",
      "Batch：5250 | Loss: 0.10573844611644745\n",
      "Batch：5251 | Loss: 0.12827670574188232\n",
      "Batch：5252 | Loss: 0.11882679909467697\n",
      "Batch：5253 | Loss: 0.11908520013093948\n",
      "Batch：5254 | Loss: 0.1220114529132843\n",
      "Batch：5255 | Loss: 0.1215662956237793\n",
      "Batch：5256 | Loss: 0.12379330396652222\n",
      "Batch：5257 | Loss: 0.12177948653697968\n",
      "Batch：5258 | Loss: 0.1093175858259201\n",
      "Batch：5259 | Loss: 0.1189943253993988\n",
      "Batch：5260 | Loss: 0.1202620342373848\n",
      "Batch：5261 | Loss: 0.11952637881040573\n",
      "Batch：5262 | Loss: 0.12770463526248932\n",
      "Batch：5263 | Loss: 0.12033310532569885\n",
      "Batch：5264 | Loss: 0.1121620163321495\n",
      "Batch：5265 | Loss: 0.11847645789384842\n",
      "Batch：5266 | Loss: 0.13688001036643982\n",
      "Batch：5267 | Loss: 0.1409199982881546\n",
      "Batch：5268 | Loss: 0.1353556364774704\n",
      "Batch：5269 | Loss: 0.14260874688625336\n",
      "Batch：5270 | Loss: 0.1287880688905716\n",
      "Batch：5271 | Loss: 0.13708876073360443\n",
      "Batch：5272 | Loss: 0.12602144479751587\n",
      "Batch：5273 | Loss: 0.10406877845525742\n",
      "Batch：5274 | Loss: 0.1317019909620285\n",
      "Batch：5275 | Loss: 0.11472214758396149\n",
      "Batch：5276 | Loss: 0.12950435280799866\n",
      "Batch：5277 | Loss: 0.11991291493177414\n",
      "Batch：5278 | Loss: 0.11553958803415298\n",
      "Batch：5279 | Loss: 0.1295289695262909\n",
      "Batch：5280 | Loss: 0.12997686862945557\n",
      "Batch：5281 | Loss: 0.12861070036888123\n",
      "Batch：5282 | Loss: 0.1258002668619156\n",
      "Batch：5283 | Loss: 0.10253060609102249\n",
      "Batch：5284 | Loss: 0.1115955114364624\n",
      "Batch：5285 | Loss: 0.1321483999490738\n",
      "Batch：5286 | Loss: 0.1264643371105194\n",
      "Batch：5287 | Loss: 0.11607155203819275\n",
      "Batch：5288 | Loss: 0.12320786714553833\n",
      "Batch：5289 | Loss: 0.12991221249103546\n",
      "Batch：5290 | Loss: 0.11248622834682465\n",
      "Batch：5291 | Loss: 0.12936381995677948\n",
      "Batch：5292 | Loss: 0.12240026891231537\n",
      "Batch：5293 | Loss: 0.12671716511249542\n",
      "Batch：5294 | Loss: 0.13592121005058289\n",
      "Batch：5295 | Loss: 0.11920032650232315\n",
      "Batch：5296 | Loss: 0.12207484990358353\n",
      "Batch：5297 | Loss: 0.12167731672525406\n",
      "Batch：5298 | Loss: 0.12066436558961868\n",
      "Batch：5299 | Loss: 0.12488411366939545\n",
      "Batch：5300 | Loss: 0.12253507226705551\n",
      "Batch：5301 | Loss: 0.13135679066181183\n",
      "Batch：5302 | Loss: 0.1227688193321228\n",
      "Batch：5303 | Loss: 0.12743721902370453\n",
      "Batch：5304 | Loss: 0.10982435941696167\n",
      "Batch：5305 | Loss: 0.12588448822498322\n",
      "Batch：5306 | Loss: 0.12904101610183716\n",
      "Batch：5307 | Loss: 0.13150924444198608\n",
      "Batch：5308 | Loss: 0.1250562071800232\n",
      "Batch：5309 | Loss: 0.13186362385749817\n",
      "Batch：5310 | Loss: 0.11398240178823471\n",
      "Batch：5311 | Loss: 0.12136019021272659\n",
      "Batch：5312 | Loss: 0.12536849081516266\n",
      "Batch：5313 | Loss: 0.11812733858823776\n",
      "Batch：5314 | Loss: 0.128818541765213\n",
      "Batch：5315 | Loss: 0.13517464697360992\n",
      "Batch：5316 | Loss: 0.11539888381958008\n",
      "Batch：5317 | Loss: 0.11150640994310379\n",
      "Batch：5318 | Loss: 0.11254150420427322\n",
      "Batch：5319 | Loss: 0.13624435663223267\n",
      "Batch：5320 | Loss: 0.12634940445423126\n",
      "Batch：5321 | Loss: 0.12315183132886887\n",
      "Batch：5322 | Loss: 0.12450259178876877\n",
      "Batch：5323 | Loss: 0.1198355108499527\n",
      "Batch：5324 | Loss: 0.12284163385629654\n",
      "Batch：5325 | Loss: 0.1094127967953682\n",
      "Batch：5326 | Loss: 0.12588971853256226\n",
      "Batch：5327 | Loss: 0.12394421547651291\n",
      "Batch：5328 | Loss: 0.1251031756401062\n",
      "Batch：5329 | Loss: 0.12808680534362793\n",
      "Batch：5330 | Loss: 0.13234843313694\n",
      "Batch：5331 | Loss: 0.1258380115032196\n",
      "Batch：5332 | Loss: 0.11916858702898026\n",
      "Batch：5333 | Loss: 0.12536725401878357\n",
      "Batch：5334 | Loss: 0.11513489484786987\n",
      "Batch：5335 | Loss: 0.11535201221704483\n",
      "Batch：5336 | Loss: 0.12593717873096466\n",
      "Batch：5337 | Loss: 0.11953910440206528\n",
      "Batch：5338 | Loss: 0.12387233227491379\n",
      "Batch：5339 | Loss: 0.118611641228199\n",
      "Batch：5340 | Loss: 0.12244289368391037\n",
      "Batch：5341 | Loss: 0.11107645183801651\n",
      "Batch：5342 | Loss: 0.11856062710285187\n",
      "Batch：5343 | Loss: 0.11821649968624115\n",
      "Batch：5344 | Loss: 0.11830238997936249\n",
      "Batch：5345 | Loss: 0.12009861320257187\n",
      "Batch：5346 | Loss: 0.1206013485789299\n",
      "Batch：5347 | Loss: 0.1309615522623062\n",
      "Batch：5348 | Loss: 0.1185842975974083\n",
      "Batch：5349 | Loss: 0.11648673564195633\n",
      "Batch：5350 | Loss: 0.11659098416566849\n",
      "Batch：5351 | Loss: 0.12095227092504501\n",
      "Batch：5352 | Loss: 0.13531187176704407\n",
      "Batch：5353 | Loss: 0.11270729452371597\n",
      "Batch：5354 | Loss: 0.11297255009412766\n",
      "Batch：5355 | Loss: 0.1250963807106018\n",
      "Batch：5356 | Loss: 0.12010443210601807\n",
      "Batch：5357 | Loss: 0.11708862334489822\n",
      "Batch：5358 | Loss: 0.1332547962665558\n",
      "Batch：5359 | Loss: 0.1281944215297699\n",
      "Batch：5360 | Loss: 0.11925674974918365\n",
      "Batch：5361 | Loss: 0.13438670337200165\n",
      "Batch：5362 | Loss: 0.11543530225753784\n",
      "Batch：5363 | Loss: 0.1251550018787384\n",
      "Batch：5364 | Loss: 0.1268334686756134\n",
      "Batch：5365 | Loss: 0.12693297863006592\n",
      "Batch：5366 | Loss: 0.1282232701778412\n",
      "Batch：5367 | Loss: 0.11607054620981216\n",
      "Batch：5368 | Loss: 0.12638694047927856\n",
      "Batch：5369 | Loss: 0.11899730563163757\n",
      "Batch：5370 | Loss: 0.12307967990636826\n",
      "Batch：5371 | Loss: 0.11981313675642014\n",
      "Batch：5372 | Loss: 0.11045851558446884\n",
      "Batch：5373 | Loss: 0.11881306022405624\n",
      "Batch：5374 | Loss: 0.1106930747628212\n",
      "Batch：5375 | Loss: 0.1317640095949173\n",
      "Batch：5376 | Loss: 0.12141479551792145\n",
      "Batch：5377 | Loss: 0.13145224750041962\n",
      "Batch：5378 | Loss: 0.12227985262870789\n",
      "Batch：5379 | Loss: 0.1200375184416771\n",
      "Batch：5380 | Loss: 0.12472521513700485\n",
      "Batch：5381 | Loss: 0.11106112599372864\n",
      "Batch：5382 | Loss: 0.11873258650302887\n",
      "Batch：5383 | Loss: 0.11759235709905624\n",
      "Batch：5384 | Loss: 0.129083514213562\n",
      "Batch：5385 | Loss: 0.11724191904067993\n",
      "Batch：5386 | Loss: 0.13175800442695618\n",
      "Batch：5387 | Loss: 0.13258109986782074\n",
      "Batch：5388 | Loss: 0.12343499809503555\n",
      "Batch：5389 | Loss: 0.11528745293617249\n",
      "Batch：5390 | Loss: 0.1234796866774559\n",
      "Batch：5391 | Loss: 0.1280777007341385\n",
      "Batch：5392 | Loss: 0.11031217128038406\n",
      "Batch：5393 | Loss: 0.12733159959316254\n",
      "Batch：5394 | Loss: 0.1281503289937973\n",
      "Batch：5395 | Loss: 0.11462707072496414\n",
      "Batch：5396 | Loss: 0.11696387827396393\n",
      "Batch：5397 | Loss: 0.10957776755094528\n",
      "Batch：5398 | Loss: 0.119424968957901\n",
      "Batch：5399 | Loss: 0.13118036091327667\n",
      "Batch：5400 | Loss: 0.1252441555261612\n",
      "Batch：5401 | Loss: 0.12550756335258484\n",
      "Batch：5402 | Loss: 0.132144957780838\n",
      "Batch：5403 | Loss: 0.12060312926769257\n",
      "Batch：5404 | Loss: 0.12068343162536621\n",
      "Batch：5405 | Loss: 0.12058041989803314\n",
      "Batch：5406 | Loss: 0.12277796119451523\n",
      "Batch：5407 | Loss: 0.12277060747146606\n",
      "Batch：5408 | Loss: 0.1218680590391159\n",
      "Batch：5409 | Loss: 0.10923606902360916\n",
      "Batch：5410 | Loss: 0.13258202373981476\n",
      "Batch：5411 | Loss: 0.12502793967723846\n",
      "Batch：5412 | Loss: 0.12746670842170715\n",
      "Batch：5413 | Loss: 0.12554268538951874\n",
      "Batch：5414 | Loss: 0.1208147332072258\n",
      "Batch：5415 | Loss: 0.11987177282571793\n",
      "Batch：5416 | Loss: 0.11161384731531143\n",
      "Batch：5417 | Loss: 0.12717483937740326\n",
      "Batch：5418 | Loss: 0.1163356602191925\n",
      "Batch：5419 | Loss: 0.1296011507511139\n",
      "Batch：5420 | Loss: 0.12220372259616852\n",
      "Batch：5421 | Loss: 0.1279509961605072\n",
      "Batch：5422 | Loss: 0.12217866629362106\n",
      "Batch：5423 | Loss: 0.12480828911066055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：5424 | Loss: 0.11901377886533737\n",
      "Batch：5425 | Loss: 0.13862615823745728\n",
      "Batch：5426 | Loss: 0.11899714171886444\n",
      "Batch：5427 | Loss: 0.11495036631822586\n",
      "Batch：5428 | Loss: 0.1188078224658966\n",
      "Batch：5429 | Loss: 0.13542243838310242\n",
      "Batch：5430 | Loss: 0.1089579164981842\n",
      "Batch：5431 | Loss: 0.1211388111114502\n",
      "Batch：5432 | Loss: 0.12291467934846878\n",
      "Batch：5433 | Loss: 0.12897737324237823\n",
      "Batch：5434 | Loss: 0.1329316645860672\n",
      "Batch：5435 | Loss: 0.12864427268505096\n",
      "Batch：5436 | Loss: 0.11031191051006317\n",
      "Batch：5437 | Loss: 0.10804790258407593\n",
      "Batch：5438 | Loss: 0.11716421693563461\n",
      "Batch：5439 | Loss: 0.13312987983226776\n",
      "Batch：5440 | Loss: 0.13862837851047516\n",
      "Batch：5441 | Loss: 0.12517841160297394\n",
      "Batch：5442 | Loss: 0.11100409924983978\n",
      "Batch：5443 | Loss: 0.12285040318965912\n",
      "Batch：5444 | Loss: 0.11656632274389267\n",
      "Batch：5445 | Loss: 0.12752172350883484\n",
      "Batch：5446 | Loss: 0.1186680719256401\n",
      "Batch：5447 | Loss: 0.1171109676361084\n",
      "Batch：5448 | Loss: 0.1273333877325058\n",
      "Batch：5449 | Loss: 0.12284665554761887\n",
      "Batch：5450 | Loss: 0.10082315653562546\n",
      "Batch：5451 | Loss: 0.11790240556001663\n",
      "Batch：5452 | Loss: 0.11299735307693481\n",
      "Batch：5453 | Loss: 0.10031817853450775\n",
      "Batch：5454 | Loss: 0.12972337007522583\n",
      "Batch：5455 | Loss: 0.12024984508752823\n",
      "Batch：5456 | Loss: 0.11309407651424408\n",
      "Batch：5457 | Loss: 0.12023860216140747\n",
      "Batch：5458 | Loss: 0.11208919435739517\n",
      "Batch：5459 | Loss: 0.1245390996336937\n",
      "Batch：5460 | Loss: 0.12277824431657791\n",
      "Batch：5461 | Loss: 0.11895023286342621\n",
      "Batch：5462 | Loss: 0.12701115012168884\n",
      "Batch：5463 | Loss: 0.131462961435318\n",
      "Batch：5464 | Loss: 0.12253415584564209\n",
      "Batch：5465 | Loss: 0.12480835616588593\n",
      "Batch：5466 | Loss: 0.1156017854809761\n",
      "Batch：5467 | Loss: 0.1421796679496765\n",
      "Batch：5468 | Loss: 0.1183738261461258\n",
      "Batch：5469 | Loss: 0.1133258044719696\n",
      "Batch：5470 | Loss: 0.11098213493824005\n",
      "Batch：5471 | Loss: 0.11622403562068939\n",
      "Batch：5472 | Loss: 0.12629003822803497\n",
      "Batch：5473 | Loss: 0.128636434674263\n",
      "Batch：5474 | Loss: 0.10527573525905609\n",
      "Batch：5475 | Loss: 0.11146785318851471\n",
      "Batch：5476 | Loss: 0.12496252357959747\n",
      "Batch：5477 | Loss: 0.12574975192546844\n",
      "Batch：5478 | Loss: 0.12249716371297836\n",
      "Batch：5479 | Loss: 0.11749796569347382\n",
      "Batch：5480 | Loss: 0.14297379553318024\n",
      "Batch：5481 | Loss: 0.12840582430362701\n",
      "Batch：5482 | Loss: 0.11655907332897186\n",
      "Batch：5483 | Loss: 0.11273543536663055\n",
      "Batch：5484 | Loss: 0.1190425232052803\n",
      "Batch：5485 | Loss: 0.1082109734416008\n",
      "Batch：5486 | Loss: 0.11405336111783981\n",
      "Batch：5487 | Loss: 0.12293098121881485\n",
      "Batch：5488 | Loss: 0.11221040785312653\n",
      "Batch：5489 | Loss: 0.13409018516540527\n",
      "Batch：5490 | Loss: 0.11160974949598312\n",
      "Batch：5491 | Loss: 0.1249808818101883\n",
      "Batch：5492 | Loss: 0.11099031567573547\n",
      "Batch：5493 | Loss: 0.11482405662536621\n",
      "Batch：5494 | Loss: 0.10857566446065903\n",
      "Batch：5495 | Loss: 0.10422136634588242\n",
      "Batch：5496 | Loss: 0.11052295565605164\n",
      "Batch：5497 | Loss: 0.11438470333814621\n",
      "Batch：5498 | Loss: 0.12146656960248947\n",
      "Batch：5499 | Loss: 0.10767919570207596\n",
      "Batch：5500 | Loss: 0.1080852523446083\n",
      "Batch：5501 | Loss: 0.11563466489315033\n",
      "Batch：5502 | Loss: 0.12443523854017258\n",
      "Batch：5503 | Loss: 0.12482810020446777\n",
      "Batch：5504 | Loss: 0.11277607828378677\n",
      "Batch：5505 | Loss: 0.10704828798770905\n",
      "Batch：5506 | Loss: 0.11333315074443817\n",
      "Batch：5507 | Loss: 0.13129207491874695\n",
      "Batch：5508 | Loss: 0.1133250743150711\n",
      "Batch：5509 | Loss: 0.09899961203336716\n",
      "Batch：5510 | Loss: 0.11757663637399673\n",
      "Batch：5511 | Loss: 0.12163551896810532\n",
      "Batch：5512 | Loss: 0.10863278806209564\n",
      "Batch：5513 | Loss: 0.1274327039718628\n",
      "Batch：5514 | Loss: 0.11873900890350342\n",
      "Batch：5515 | Loss: 0.12519319355487823\n",
      "Batch：5516 | Loss: 0.12186187505722046\n",
      "Batch：5517 | Loss: 0.11843426525592804\n",
      "Batch：5518 | Loss: 0.11834247410297394\n",
      "Batch：5519 | Loss: 0.12121425569057465\n",
      "Batch：5520 | Loss: 0.12793847918510437\n",
      "Batch：5521 | Loss: 0.12978726625442505\n",
      "Batch：5522 | Loss: 0.1254972517490387\n",
      "Batch：5523 | Loss: 0.11044624447822571\n",
      "Batch：5524 | Loss: 0.11065938323736191\n",
      "Batch：5525 | Loss: 0.11203596740961075\n",
      "Batch：5526 | Loss: 0.10823092609643936\n",
      "Batch：5527 | Loss: 0.12195122987031937\n",
      "Batch：5528 | Loss: 0.12589068710803986\n",
      "Batch：5529 | Loss: 0.11315447837114334\n",
      "Batch：5530 | Loss: 0.12749314308166504\n",
      "Batch：5531 | Loss: 0.1316153109073639\n",
      "Batch：5532 | Loss: 0.11967175453901291\n",
      "Batch：5533 | Loss: 0.12169595062732697\n",
      "Batch：5534 | Loss: 0.13094152510166168\n",
      "Batch：5535 | Loss: 0.1159227266907692\n",
      "Batch：5536 | Loss: 0.1220192015171051\n",
      "Batch：5537 | Loss: 0.12348958104848862\n",
      "Batch：5538 | Loss: 0.12031184881925583\n",
      "Batch：5539 | Loss: 0.10256163775920868\n",
      "Batch：5540 | Loss: 0.10159997642040253\n",
      "Batch：5541 | Loss: 0.1115969642996788\n",
      "Batch：5542 | Loss: 0.12051932513713837\n",
      "Batch：5543 | Loss: 0.12702250480651855\n",
      "Batch：5544 | Loss: 0.11953780055046082\n",
      "Batch：5545 | Loss: 0.11203457415103912\n",
      "Batch：5546 | Loss: 0.11171137541532516\n",
      "Batch：5547 | Loss: 0.12035077810287476\n",
      "Batch：5548 | Loss: 0.11934968084096909\n",
      "Batch：5549 | Loss: 0.11788606643676758\n",
      "Batch：5550 | Loss: 0.12493648380041122\n",
      "Batch：5551 | Loss: 0.1114816814661026\n",
      "Batch：5552 | Loss: 0.11350531131029129\n",
      "Batch：5553 | Loss: 0.12405817210674286\n",
      "Batch：5554 | Loss: 0.12202673405408859\n",
      "Batch：5555 | Loss: 0.11151371151208878\n",
      "Batch：5556 | Loss: 0.12417513132095337\n",
      "Batch：5557 | Loss: 0.1194603443145752\n",
      "Batch：5558 | Loss: 0.12042075395584106\n",
      "Batch：5559 | Loss: 0.12637688219547272\n",
      "Batch：5560 | Loss: 0.1238599643111229\n",
      "Batch：5561 | Loss: 0.10841745883226395\n",
      "Batch：5562 | Loss: 0.11714310944080353\n",
      "Batch：5563 | Loss: 0.10967490822076797\n",
      "Batch：5564 | Loss: 0.11890342086553574\n",
      "Batch：5565 | Loss: 0.11503975093364716\n",
      "Batch：5566 | Loss: 0.13529959321022034\n",
      "Batch：5567 | Loss: 0.12443080544471741\n",
      "Batch：5568 | Loss: 0.11144991219043732\n",
      "Batch：5569 | Loss: 0.12249844521284103\n",
      "Batch：5570 | Loss: 0.11318589001893997\n",
      "Batch：5571 | Loss: 0.10759527236223221\n",
      "Batch：5572 | Loss: 0.11144904792308807\n",
      "Batch：5573 | Loss: 0.12101000547409058\n",
      "Batch：5574 | Loss: 0.11065064370632172\n",
      "Batch：5575 | Loss: 0.12421154975891113\n",
      "Batch：5576 | Loss: 0.12712743878364563\n",
      "Batch：5577 | Loss: 0.12348432093858719\n",
      "Batch：5578 | Loss: 0.118324413895607\n",
      "Batch：5579 | Loss: 0.12093119323253632\n",
      "Batch：5580 | Loss: 0.12300676107406616\n",
      "Batch：5581 | Loss: 0.12895452976226807\n",
      "Batch：5582 | Loss: 0.11771437525749207\n",
      "Batch：5583 | Loss: 0.13111145794391632\n",
      "Batch：5584 | Loss: 0.11607630550861359\n",
      "Batch：5585 | Loss: 0.11542591452598572\n",
      "Batch：5586 | Loss: 0.10865490883588791\n",
      "Batch：5587 | Loss: 0.11681528389453888\n",
      "Batch：5588 | Loss: 0.11314355581998825\n",
      "Batch：5589 | Loss: 0.12282785773277283\n",
      "Batch：5590 | Loss: 0.11669173836708069\n",
      "Batch：5591 | Loss: 0.12300360202789307\n",
      "Batch：5592 | Loss: 0.12499142438173294\n",
      "Batch：5593 | Loss: 0.1202029287815094\n",
      "Batch：5594 | Loss: 0.11408142000436783\n",
      "Batch：5595 | Loss: 0.12566883862018585\n",
      "Batch：5596 | Loss: 0.1189175471663475\n",
      "Batch：5597 | Loss: 0.11387849599123001\n",
      "Batch：5598 | Loss: 0.10820605605840683\n",
      "Batch：5599 | Loss: 0.12414389103651047\n",
      "Batch：5600 | Loss: 0.10737442970275879\n",
      "Batch：5601 | Loss: 0.11309812217950821\n",
      "Batch：5602 | Loss: 0.12945778667926788\n",
      "Batch：5603 | Loss: 0.11188898235559464\n",
      "Batch：5604 | Loss: 0.12011340260505676\n",
      "Batch：5605 | Loss: 0.1277882307767868\n",
      "Batch：5606 | Loss: 0.12371664494276047\n",
      "Batch：5607 | Loss: 0.11967005580663681\n",
      "Batch：5608 | Loss: 0.12246213853359222\n",
      "Batch：5609 | Loss: 0.11271148920059204\n",
      "Batch：5610 | Loss: 0.11077950894832611\n",
      "Batch：5611 | Loss: 0.11049451678991318\n",
      "Batch：5612 | Loss: 0.11543378233909607\n",
      "Batch：5613 | Loss: 0.11806422472000122\n",
      "Batch：5614 | Loss: 0.11218933761119843\n",
      "Batch：5615 | Loss: 0.11902982741594315\n",
      "Batch：5616 | Loss: 0.1225702315568924\n",
      "Batch：5617 | Loss: 0.11605139076709747\n",
      "Batch：5618 | Loss: 0.11576709896326065\n",
      "Batch：5619 | Loss: 0.10690703243017197\n",
      "Batch：5620 | Loss: 0.11765208095312119\n",
      "Batch：5621 | Loss: 0.11934693157672882\n",
      "Batch：5622 | Loss: 0.10100321471691132\n",
      "Batch：5623 | Loss: 0.10533960908651352\n",
      "Batch：5624 | Loss: 0.12165459990501404\n",
      "Batch：5625 | Loss: 0.12076142430305481\n",
      "Batch：5626 | Loss: 0.12493258714675903\n",
      "Batch：5627 | Loss: 0.1097889170050621\n",
      "Batch：5628 | Loss: 0.12966099381446838\n",
      "Batch：5629 | Loss: 0.10778148472309113\n",
      "Batch：5630 | Loss: 0.1308860033750534\n",
      "Batch：5631 | Loss: 0.11059829592704773\n",
      "Batch：5632 | Loss: 0.1103552058339119\n",
      "Batch：5633 | Loss: 0.11812686920166016\n",
      "Batch：5634 | Loss: 0.11079560965299606\n",
      "Batch：5635 | Loss: 0.12243727594614029\n",
      "Batch：5636 | Loss: 0.11606614291667938\n",
      "Batch：5637 | Loss: 0.11079960316419601\n",
      "Batch：5638 | Loss: 0.11113032698631287\n",
      "Batch：5639 | Loss: 0.11702626198530197\n",
      "Batch：5640 | Loss: 0.12348829954862595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：5641 | Loss: 0.12391816824674606\n",
      "Batch：5642 | Loss: 0.12979598343372345\n",
      "Batch：5643 | Loss: 0.1202913373708725\n",
      "Batch：5644 | Loss: 0.11795097589492798\n",
      "Batch：5645 | Loss: 0.11589193344116211\n",
      "Batch：5646 | Loss: 0.12016595155000687\n",
      "Batch：5647 | Loss: 0.11579082906246185\n",
      "Batch：5648 | Loss: 0.1133115142583847\n",
      "Batch：5649 | Loss: 0.11672741919755936\n",
      "Batch：5650 | Loss: 0.11123529076576233\n",
      "Batch：5651 | Loss: 0.11382274329662323\n",
      "Batch：5652 | Loss: 0.12682770192623138\n",
      "Batch：5653 | Loss: 0.11309657990932465\n",
      "Batch：5654 | Loss: 0.11995801329612732\n",
      "Batch：5655 | Loss: 0.09671728312969208\n",
      "Batch：5656 | Loss: 0.11145512014627457\n",
      "Batch：5657 | Loss: 0.11566416174173355\n",
      "Batch：5658 | Loss: 0.13077889382839203\n",
      "Batch：5659 | Loss: 0.1115100309252739\n",
      "Batch：5660 | Loss: 0.11118912696838379\n",
      "Batch：5661 | Loss: 0.13293932378292084\n",
      "Batch：5662 | Loss: 0.1124688982963562\n",
      "Batch：5663 | Loss: 0.1207769364118576\n",
      "Batch：5664 | Loss: 0.10916442424058914\n",
      "Batch：5665 | Loss: 0.12076845020055771\n",
      "Batch：5666 | Loss: 0.119021937251091\n",
      "Batch：5667 | Loss: 0.1277308613061905\n",
      "Batch：5668 | Loss: 0.1211666688323021\n",
      "Batch：5669 | Loss: 0.10710275918245316\n",
      "Batch：5670 | Loss: 0.11610294133424759\n",
      "Batch：5671 | Loss: 0.1186518743634224\n",
      "Batch：5672 | Loss: 0.10995397716760635\n",
      "Batch：5673 | Loss: 0.12270022183656693\n",
      "Batch：5674 | Loss: 0.12030129134654999\n",
      "Batch：5675 | Loss: 0.11053434014320374\n",
      "Batch：5676 | Loss: 0.1122027263045311\n",
      "Batch：5677 | Loss: 0.1181260347366333\n",
      "Batch：5678 | Loss: 0.1000002920627594\n",
      "Batch：5679 | Loss: 0.11383281648159027\n",
      "Batch：5680 | Loss: 0.12665699422359467\n",
      "Batch：5681 | Loss: 0.11065498739480972\n",
      "Batch：5682 | Loss: 0.11847667396068573\n",
      "Batch：5683 | Loss: 0.11690922826528549\n",
      "Batch：5684 | Loss: 0.10797970741987228\n",
      "Batch：5685 | Loss: 0.11397220939397812\n",
      "Batch：5686 | Loss: 0.11068166047334671\n",
      "Batch：5687 | Loss: 0.11138929426670074\n",
      "Batch：5688 | Loss: 0.12183042615652084\n",
      "Batch：5689 | Loss: 0.1136293113231659\n",
      "Batch：5690 | Loss: 0.11726875603199005\n",
      "Batch：5691 | Loss: 0.11536258459091187\n",
      "Batch：5692 | Loss: 0.1166519969701767\n",
      "Batch：5693 | Loss: 0.1134181022644043\n",
      "Batch：5694 | Loss: 0.12223555147647858\n",
      "Batch：5695 | Loss: 0.10461097210645676\n",
      "Batch：5696 | Loss: 0.11967045068740845\n",
      "Batch：5697 | Loss: 0.12117762118577957\n",
      "Batch：5698 | Loss: 0.11789119988679886\n",
      "Batch：5699 | Loss: 0.10686905682086945\n",
      "Batch：5700 | Loss: 0.11356988549232483\n",
      "Batch：5701 | Loss: 0.11276175826787949\n",
      "Batch：5702 | Loss: 0.11810702085494995\n",
      "Batch：5703 | Loss: 0.10999610275030136\n",
      "Batch：5704 | Loss: 0.10908189415931702\n",
      "Batch：5705 | Loss: 0.10681620240211487\n",
      "Batch：5706 | Loss: 0.11964130401611328\n",
      "Batch：5707 | Loss: 0.10814221203327179\n",
      "Batch：5708 | Loss: 0.12445371598005295\n",
      "Batch：5709 | Loss: 0.11468985676765442\n",
      "Batch：5710 | Loss: 0.10840620845556259\n",
      "Batch：5711 | Loss: 0.11245933175086975\n",
      "Batch：5712 | Loss: 0.11832654476165771\n",
      "Batch：5713 | Loss: 0.12017744034528732\n",
      "Batch：5714 | Loss: 0.11594559252262115\n",
      "Batch：5715 | Loss: 0.111862912774086\n",
      "Batch：5716 | Loss: 0.10059304535388947\n",
      "Batch：5717 | Loss: 0.10685055702924728\n",
      "Batch：5718 | Loss: 0.11834795773029327\n",
      "Batch：5719 | Loss: 0.11644714325666428\n",
      "Batch：5720 | Loss: 0.108503557741642\n",
      "Batch：5721 | Loss: 0.11114732921123505\n",
      "Batch：5722 | Loss: 0.12682625651359558\n",
      "Batch：5723 | Loss: 0.12845276296138763\n",
      "Batch：5724 | Loss: 0.1118173897266388\n",
      "Batch：5725 | Loss: 0.11099468171596527\n",
      "Batch：5726 | Loss: 0.11429843306541443\n",
      "Batch：5727 | Loss: 0.09399642050266266\n",
      "Batch：5728 | Loss: 0.134770929813385\n",
      "Batch：5729 | Loss: 0.11163195967674255\n",
      "Batch：5730 | Loss: 0.12350717186927795\n",
      "Batch：5731 | Loss: 0.1207350417971611\n",
      "Batch：5732 | Loss: 0.11999882012605667\n",
      "Batch：5733 | Loss: 0.10733548551797867\n",
      "Batch：5734 | Loss: 0.11967677623033524\n",
      "Batch：5735 | Loss: 0.11887090653181076\n",
      "Batch：5736 | Loss: 0.12102267146110535\n",
      "Batch：5737 | Loss: 0.11579520255327225\n",
      "Batch：5738 | Loss: 0.1086912527680397\n",
      "Batch：5739 | Loss: 0.12360164523124695\n",
      "Batch：5740 | Loss: 0.12286867946386337\n",
      "Batch：5741 | Loss: 0.11191664636135101\n",
      "Batch：5742 | Loss: 0.11307303607463837\n",
      "Batch：5743 | Loss: 0.11065996438264847\n",
      "Batch：5744 | Loss: 0.11649531126022339\n",
      "Batch：5745 | Loss: 0.10702673345804214\n",
      "Batch：5746 | Loss: 0.12878915667533875\n",
      "Batch：5747 | Loss: 0.1144496276974678\n",
      "Batch：5748 | Loss: 0.11926385015249252\n",
      "Batch：5749 | Loss: 0.10581064969301224\n",
      "Batch：5750 | Loss: 0.11503259837627411\n",
      "Batch：5751 | Loss: 0.1422746330499649\n",
      "Batch：5752 | Loss: 0.12038500607013702\n",
      "Batch：5753 | Loss: 0.10773519426584244\n",
      "Batch：5754 | Loss: 0.09974499046802521\n",
      "Batch：5755 | Loss: 0.10868922621011734\n",
      "Batch：5756 | Loss: 0.1243738904595375\n",
      "Batch：5757 | Loss: 0.12533558905124664\n",
      "Batch：5758 | Loss: 0.1210239827632904\n",
      "Batch：5759 | Loss: 0.11013855040073395\n",
      "Batch：5760 | Loss: 0.11358829587697983\n",
      "Batch：5761 | Loss: 0.10670511424541473\n",
      "Batch：5762 | Loss: 0.10776600241661072\n",
      "Batch：5763 | Loss: 0.11342653632164001\n",
      "Batch：5764 | Loss: 0.12308319658041\n",
      "Batch：5765 | Loss: 0.11422184109687805\n",
      "Batch：5766 | Loss: 0.11693651229143143\n",
      "Batch：5767 | Loss: 0.10980653762817383\n",
      "Batch：5768 | Loss: 0.10256140679121017\n",
      "Batch：5769 | Loss: 0.11676112562417984\n",
      "Batch：5770 | Loss: 0.11369635164737701\n",
      "Batch：5771 | Loss: 0.13015097379684448\n",
      "Batch：5772 | Loss: 0.12824277579784393\n",
      "Batch：5773 | Loss: 0.11892206966876984\n",
      "Batch：5774 | Loss: 0.10272447764873505\n",
      "Batch：5775 | Loss: 0.1131279468536377\n",
      "Batch：5776 | Loss: 0.11121221631765366\n",
      "Batch：5777 | Loss: 0.10878823697566986\n",
      "Batch：5778 | Loss: 0.10670778155326843\n",
      "Batch：5779 | Loss: 0.10223262757062912\n",
      "Batch：5780 | Loss: 0.12298177182674408\n",
      "Batch：5781 | Loss: 0.11998748779296875\n",
      "Batch：5782 | Loss: 0.10093449801206589\n",
      "Batch：5783 | Loss: 0.11163242161273956\n",
      "Batch：5784 | Loss: 0.11959204822778702\n",
      "Batch：5785 | Loss: 0.1093701496720314\n",
      "Batch：5786 | Loss: 0.11037392169237137\n",
      "Batch：5787 | Loss: 0.13055363297462463\n",
      "Batch：5788 | Loss: 0.11789634078741074\n",
      "Batch：5789 | Loss: 0.11554025858640671\n",
      "Batch：5790 | Loss: 0.12059559673070908\n",
      "Batch：5791 | Loss: 0.11944182962179184\n",
      "Batch：5792 | Loss: 0.1181115135550499\n",
      "Batch：5793 | Loss: 0.11108017712831497\n",
      "Batch：5794 | Loss: 0.12543421983718872\n",
      "Batch：5795 | Loss: 0.13375236093997955\n",
      "Batch：5796 | Loss: 0.10129109770059586\n",
      "Batch：5797 | Loss: 0.12117289006710052\n",
      "Batch：5798 | Loss: 0.1199261024594307\n",
      "Batch：5799 | Loss: 0.12477491796016693\n",
      "Batch：5800 | Loss: 0.11066148430109024\n",
      "Batch：5801 | Loss: 0.11806999891996384\n",
      "Batch：5802 | Loss: 0.12417718023061752\n",
      "Batch：5803 | Loss: 0.11682471632957458\n",
      "Batch：5804 | Loss: 0.1125561073422432\n",
      "Batch：5805 | Loss: 0.10256671160459518\n",
      "Batch：5806 | Loss: 0.11231599748134613\n",
      "Batch：5807 | Loss: 0.12691853940486908\n",
      "Batch：5808 | Loss: 0.12297261506319046\n",
      "Batch：5809 | Loss: 0.11348877102136612\n",
      "Batch：5810 | Loss: 0.12501747906208038\n",
      "Batch：5811 | Loss: 0.11583282053470612\n",
      "Batch：5812 | Loss: 0.11659454554319382\n",
      "Batch：5813 | Loss: 0.1121010035276413\n",
      "Batch：5814 | Loss: 0.12580999732017517\n",
      "Batch：5815 | Loss: 0.11692584306001663\n",
      "Batch：5816 | Loss: 0.1043599545955658\n",
      "Batch：5817 | Loss: 0.11672484874725342\n",
      "Batch：5818 | Loss: 0.11120320856571198\n",
      "Batch：5819 | Loss: 0.12443121522665024\n",
      "Batch：5820 | Loss: 0.10174159705638885\n",
      "Batch：5821 | Loss: 0.10742079466581345\n",
      "Batch：5822 | Loss: 0.11466885358095169\n",
      "Batch：5823 | Loss: 0.1135113537311554\n",
      "Batch：5824 | Loss: 0.123745858669281\n",
      "Batch：5825 | Loss: 0.12106219679117203\n",
      "Batch：5826 | Loss: 0.113139808177948\n",
      "Batch：5827 | Loss: 0.12015879899263382\n",
      "Batch：5828 | Loss: 0.11891575902700424\n",
      "Batch：5829 | Loss: 0.11503584682941437\n",
      "Batch：5830 | Loss: 0.12408217042684555\n",
      "Batch：5831 | Loss: 0.10993926972150803\n",
      "Batch：5832 | Loss: 0.12569761276245117\n",
      "Batch：5833 | Loss: 0.09609152376651764\n",
      "Batch：5834 | Loss: 0.11850301176309586\n",
      "Batch：5835 | Loss: 0.0968538224697113\n",
      "Batch：5836 | Loss: 0.1171034500002861\n",
      "Batch：5837 | Loss: 0.10917617380619049\n",
      "Batch：5838 | Loss: 0.11467480659484863\n",
      "Batch：5839 | Loss: 0.11123335361480713\n",
      "Batch：5840 | Loss: 0.10769172012805939\n",
      "Batch：5841 | Loss: 0.10775351524353027\n",
      "Batch：5842 | Loss: 0.10924404114484787\n",
      "Batch：5843 | Loss: 0.10207358747720718\n",
      "Batch：5844 | Loss: 0.13474483788013458\n",
      "Batch：5845 | Loss: 0.10931646823883057\n",
      "Batch：5846 | Loss: 0.10405083000659943\n",
      "Batch：5847 | Loss: 0.10888100415468216\n",
      "Batch：5848 | Loss: 0.11511660367250443\n",
      "Batch：5849 | Loss: 0.10525626689195633\n",
      "Batch：5850 | Loss: 0.09965688735246658\n",
      "Batch：5851 | Loss: 0.09352804720401764\n",
      "Batch：5852 | Loss: 0.10872900485992432\n",
      "Batch：5853 | Loss: 0.10870595276355743\n",
      "Batch：5854 | Loss: 0.12465142458677292\n",
      "Batch：5855 | Loss: 0.1157328188419342\n",
      "Batch：5856 | Loss: 0.11848382651805878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：5857 | Loss: 0.12142008543014526\n",
      "Batch：5858 | Loss: 0.10309857875108719\n",
      "Batch：5859 | Loss: 0.11024503409862518\n",
      "Batch：5860 | Loss: 0.10830448567867279\n",
      "Batch：5861 | Loss: 0.11312849819660187\n",
      "Batch：5862 | Loss: 0.12117692828178406\n",
      "Batch：5863 | Loss: 0.12231627106666565\n",
      "Batch：5864 | Loss: 0.11060353368520737\n",
      "Batch：5865 | Loss: 0.11125175654888153\n",
      "Batch：5866 | Loss: 0.1007986068725586\n",
      "Batch：5867 | Loss: 0.11180463433265686\n",
      "Batch：5868 | Loss: 0.10121539235115051\n",
      "Batch：5869 | Loss: 0.12155161052942276\n",
      "Batch：5870 | Loss: 0.11552014201879501\n",
      "Batch：5871 | Loss: 0.11403218656778336\n",
      "Batch：5872 | Loss: 0.12734729051589966\n",
      "Batch：5873 | Loss: 0.10431011766195297\n",
      "Batch：5874 | Loss: 0.10480107367038727\n",
      "Batch：5875 | Loss: 0.11094499379396439\n",
      "Batch：5876 | Loss: 0.11669069528579712\n",
      "Batch：5877 | Loss: 0.11372298002243042\n",
      "Batch：5878 | Loss: 0.12215637415647507\n",
      "Batch：5879 | Loss: 0.10803695768117905\n",
      "Batch：5880 | Loss: 0.12321210652589798\n",
      "Batch：5881 | Loss: 0.10807765275239944\n",
      "Batch：5882 | Loss: 0.11150898784399033\n",
      "Batch：5883 | Loss: 0.1152181401848793\n",
      "Batch：5884 | Loss: 0.11192464083433151\n",
      "Batch：5885 | Loss: 0.10239508748054504\n",
      "Batch：5886 | Loss: 0.11928904056549072\n",
      "Batch：5887 | Loss: 0.11511720716953278\n",
      "Batch：5888 | Loss: 0.09991106390953064\n",
      "Batch：5889 | Loss: 0.11573608219623566\n",
      "Batch：5890 | Loss: 0.1154954582452774\n",
      "Batch：5891 | Loss: 0.11388523131608963\n",
      "Batch：5892 | Loss: 0.11218137294054031\n",
      "Batch：5893 | Loss: 0.1126733049750328\n",
      "Batch：5894 | Loss: 0.11391466856002808\n",
      "Batch：5895 | Loss: 0.11799522489309311\n",
      "Batch：5896 | Loss: 0.12044762820005417\n",
      "Batch：5897 | Loss: 0.10866516828536987\n",
      "Batch：5898 | Loss: 0.10135478526353836\n",
      "Batch：5899 | Loss: 0.11834198236465454\n",
      "Batch：5900 | Loss: 0.11043605208396912\n",
      "Batch：5901 | Loss: 0.09849301725625992\n",
      "Batch：5902 | Loss: 0.09346670657396317\n",
      "Batch：5903 | Loss: 0.10959655791521072\n",
      "Batch：5904 | Loss: 0.10417618602514267\n",
      "Batch：5905 | Loss: 0.11555051803588867\n",
      "Batch：5906 | Loss: 0.11398842185735703\n",
      "Batch：5907 | Loss: 0.09918812662363052\n",
      "Batch：5908 | Loss: 0.14100585877895355\n",
      "Batch：5909 | Loss: 0.11870967596769333\n",
      "Batch：5910 | Loss: 0.10414919257164001\n",
      "Batch：5911 | Loss: 0.11201493442058563\n",
      "Batch：5912 | Loss: 0.12446577847003937\n",
      "Batch：5913 | Loss: 0.10992682725191116\n",
      "Batch：5914 | Loss: 0.11428333073854446\n",
      "Batch：5915 | Loss: 0.10819832235574722\n",
      "Batch：5916 | Loss: 0.10703226923942566\n",
      "Batch：5917 | Loss: 0.11029896885156631\n",
      "Batch：5918 | Loss: 0.11410721391439438\n",
      "Batch：5919 | Loss: 0.10546591877937317\n",
      "Batch：5920 | Loss: 0.10762475430965424\n",
      "Batch：5921 | Loss: 0.10884574055671692\n",
      "Batch：5922 | Loss: 0.10723874717950821\n",
      "Batch：5923 | Loss: 0.12107217311859131\n",
      "Batch：5924 | Loss: 0.12002361565828323\n",
      "Batch：5925 | Loss: 0.10074097663164139\n",
      "Batch：5926 | Loss: 0.11873085051774979\n",
      "Batch：5927 | Loss: 0.12320876866579056\n",
      "Batch：5928 | Loss: 0.10886888206005096\n",
      "Batch：5929 | Loss: 0.10405701398849487\n",
      "Batch：5930 | Loss: 0.12813495099544525\n",
      "Batch：5931 | Loss: 0.12113834172487259\n",
      "Batch：5932 | Loss: 0.11315187811851501\n",
      "Batch：5933 | Loss: 0.11110274493694305\n",
      "Batch：5934 | Loss: 0.11584138870239258\n",
      "Batch：5935 | Loss: 0.11014331132173538\n",
      "Batch：5936 | Loss: 0.11848307400941849\n",
      "Batch：5937 | Loss: 0.09867926687002182\n",
      "Batch：5938 | Loss: 0.11521705240011215\n",
      "Batch：5939 | Loss: 0.10604450106620789\n",
      "Batch：5940 | Loss: 0.11802628636360168\n",
      "Batch：5941 | Loss: 0.1010330468416214\n",
      "Batch：5942 | Loss: 0.10406307876110077\n",
      "Batch：5943 | Loss: 0.11122407019138336\n",
      "Batch：5944 | Loss: 0.12616823613643646\n",
      "Batch：5945 | Loss: 0.10890940576791763\n",
      "Batch：5946 | Loss: 0.09708894789218903\n",
      "Batch：5947 | Loss: 0.11072980612516403\n",
      "Batch：5948 | Loss: 0.09626536071300507\n",
      "Batch：5949 | Loss: 0.10230572521686554\n",
      "Batch：5950 | Loss: 0.1144418939948082\n",
      "Batch：5951 | Loss: 0.10473990440368652\n",
      "Batch：5952 | Loss: 0.11592581123113632\n",
      "Batch：5953 | Loss: 0.10692059993743896\n",
      "Batch：5954 | Loss: 0.11520471423864365\n",
      "Batch：5955 | Loss: 0.12278982251882553\n",
      "Batch：5956 | Loss: 0.12348366528749466\n",
      "Batch：5957 | Loss: 0.10729518532752991\n",
      "Batch：5958 | Loss: 0.10760766267776489\n",
      "Batch：5959 | Loss: 0.09949786216020584\n",
      "Batch：5960 | Loss: 0.12204709649085999\n",
      "Batch：5961 | Loss: 0.10458701103925705\n",
      "Batch：5962 | Loss: 0.11404471844434738\n",
      "Batch：5963 | Loss: 0.1193663701415062\n",
      "Batch：5964 | Loss: 0.12197764217853546\n",
      "Batch：5965 | Loss: 0.11015964299440384\n",
      "Batch：5966 | Loss: 0.11004384607076645\n",
      "Batch：5967 | Loss: 0.10836391150951385\n",
      "Batch：5968 | Loss: 0.10742947459220886\n",
      "Batch：5969 | Loss: 0.1038336381316185\n",
      "Batch：5970 | Loss: 0.11352664977312088\n",
      "Batch：5971 | Loss: 0.1188315749168396\n",
      "Batch：5972 | Loss: 0.09874826669692993\n",
      "Batch：5973 | Loss: 0.11155401170253754\n",
      "Batch：5974 | Loss: 0.12539678812026978\n",
      "Batch：5975 | Loss: 0.09815654158592224\n",
      "Batch：5976 | Loss: 0.1092526838183403\n",
      "Batch：5977 | Loss: 0.11667057126760483\n",
      "Batch：5978 | Loss: 0.12099051475524902\n",
      "Batch：5979 | Loss: 0.09596773236989975\n",
      "Batch：5980 | Loss: 0.12307614833116531\n",
      "Batch：5981 | Loss: 0.10969860851764679\n",
      "Batch：5982 | Loss: 0.10476431250572205\n",
      "Batch：5983 | Loss: 0.10610730201005936\n",
      "Batch：5984 | Loss: 0.10445159673690796\n",
      "Batch：5985 | Loss: 0.11808960884809494\n",
      "Batch：5986 | Loss: 0.11916743963956833\n",
      "Batch：5987 | Loss: 0.11676175147294998\n",
      "Batch：5988 | Loss: 0.10402439534664154\n",
      "Batch：5989 | Loss: 0.12172743678092957\n",
      "Batch：5990 | Loss: 0.11302103847265244\n",
      "Batch：5991 | Loss: 0.11355207860469818\n",
      "Batch：5992 | Loss: 0.10292597115039825\n",
      "Batch：5993 | Loss: 0.1147676557302475\n",
      "Batch：5994 | Loss: 0.11059198528528214\n",
      "Batch：5995 | Loss: 0.10720375180244446\n",
      "Batch：5996 | Loss: 0.12423113733530045\n",
      "Batch：5997 | Loss: 0.10026222467422485\n",
      "Batch：5998 | Loss: 0.11522315442562103\n",
      "Batch：5999 | Loss: 0.12159224599599838\n",
      "Batch：6000 | Loss: 0.11394158750772476\n",
      "Batch：6001 | Loss: 0.11177375912666321\n",
      "Batch：6002 | Loss: 0.10304225236177444\n",
      "Batch：6003 | Loss: 0.108248271048069\n",
      "Batch：6004 | Loss: 0.10955104231834412\n",
      "Batch：6005 | Loss: 0.1091989129781723\n",
      "Batch：6006 | Loss: 0.12328403443098068\n",
      "Batch：6007 | Loss: 0.11660302430391312\n",
      "Batch：6008 | Loss: 0.11115403473377228\n",
      "Batch：6009 | Loss: 0.11520341038703918\n",
      "Batch：6010 | Loss: 0.12604014575481415\n",
      "Batch：6011 | Loss: 0.10643517971038818\n",
      "Batch：6012 | Loss: 0.12190957367420197\n",
      "Batch：6013 | Loss: 0.10396325588226318\n",
      "Batch：6014 | Loss: 0.12453676015138626\n",
      "Batch：6015 | Loss: 0.10377762466669083\n",
      "Batch：6016 | Loss: 0.12272471189498901\n",
      "Batch：6017 | Loss: 0.11584974825382233\n",
      "Batch：6018 | Loss: 0.11145028471946716\n",
      "Batch：6019 | Loss: 0.11117196828126907\n",
      "Batch：6020 | Loss: 0.11925335228443146\n",
      "Batch：6021 | Loss: 0.11599016934633255\n",
      "Batch：6022 | Loss: 0.11218805611133575\n",
      "Batch：6023 | Loss: 0.10707899183034897\n",
      "Batch：6024 | Loss: 0.11104350537061691\n",
      "Batch：6025 | Loss: 0.11683697253465652\n",
      "Batch：6026 | Loss: 0.11660638451576233\n",
      "Batch：6027 | Loss: 0.09411019086837769\n",
      "Batch：6028 | Loss: 0.10377753525972366\n",
      "Batch：6029 | Loss: 0.11223778128623962\n",
      "Batch：6030 | Loss: 0.09508074074983597\n",
      "Batch：6031 | Loss: 0.10443446785211563\n",
      "Batch：6032 | Loss: 0.09925243258476257\n",
      "Batch：6033 | Loss: 0.09718144685029984\n",
      "Batch：6034 | Loss: 0.09800271689891815\n",
      "Batch：6035 | Loss: 0.10550012439489365\n",
      "Batch：6036 | Loss: 0.10367631912231445\n",
      "Batch：6037 | Loss: 0.11180797219276428\n",
      "Batch：6038 | Loss: 0.10967139899730682\n",
      "Batch：6039 | Loss: 0.11652026325464249\n",
      "Batch：6040 | Loss: 0.10319080203771591\n",
      "Batch：6041 | Loss: 0.10522951930761337\n",
      "Batch：6042 | Loss: 0.1144772320985794\n",
      "Batch：6043 | Loss: 0.10782832652330399\n",
      "Batch：6044 | Loss: 0.09739944338798523\n",
      "Batch：6045 | Loss: 0.10680560022592545\n",
      "Batch：6046 | Loss: 0.11127728223800659\n",
      "Batch：6047 | Loss: 0.10835418850183487\n",
      "Batch：6048 | Loss: 0.1106690838932991\n",
      "Batch：6049 | Loss: 0.12165158987045288\n",
      "Batch：6050 | Loss: 0.10762369632720947\n",
      "Batch：6051 | Loss: 0.10446861386299133\n",
      "Batch：6052 | Loss: 0.1003950983285904\n",
      "Batch：6053 | Loss: 0.11153971403837204\n",
      "Batch：6054 | Loss: 0.0927375853061676\n",
      "Batch：6055 | Loss: 0.12139575928449631\n",
      "Batch：6056 | Loss: 0.11468303948640823\n",
      "Batch：6057 | Loss: 0.10026942938566208\n",
      "Batch：6058 | Loss: 0.10893141478300095\n",
      "Batch：6059 | Loss: 0.11790981143712997\n",
      "Batch：6060 | Loss: 0.09969209879636765\n",
      "Batch：6061 | Loss: 0.105937659740448\n",
      "Batch：6062 | Loss: 0.10523341596126556\n",
      "Batch：6063 | Loss: 0.11337694525718689\n",
      "Batch：6064 | Loss: 0.10508614778518677\n",
      "Batch：6065 | Loss: 0.10915851593017578\n",
      "Batch：6066 | Loss: 0.11840080469846725\n",
      "Batch：6067 | Loss: 0.10950720310211182\n",
      "Batch：6068 | Loss: 0.10275378078222275\n",
      "Batch：6069 | Loss: 0.10382258147001266\n",
      "Batch：6070 | Loss: 0.11224768310785294\n",
      "Batch：6071 | Loss: 0.10060673952102661\n",
      "Batch：6072 | Loss: 0.11090303212404251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：6073 | Loss: 0.12460979074239731\n",
      "Batch：6074 | Loss: 0.11474918574094772\n",
      "Batch：6075 | Loss: 0.09771498292684555\n",
      "Batch：6076 | Loss: 0.11629548668861389\n",
      "Batch：6077 | Loss: 0.11019521951675415\n",
      "Batch：6078 | Loss: 0.11642453819513321\n",
      "Batch：6079 | Loss: 0.10814011842012405\n",
      "Batch：6080 | Loss: 0.12139347195625305\n",
      "Batch：6081 | Loss: 0.10620242357254028\n",
      "Batch：6082 | Loss: 0.09874105453491211\n",
      "Batch：6083 | Loss: 0.10929200798273087\n",
      "Batch：6084 | Loss: 0.11428739130496979\n",
      "Batch：6085 | Loss: 0.11363919079303741\n",
      "Batch：6086 | Loss: 0.1056344285607338\n",
      "Batch：6087 | Loss: 0.1156320571899414\n",
      "Batch：6088 | Loss: 0.11782185733318329\n",
      "Batch：6089 | Loss: 0.1090172752737999\n",
      "Batch：6090 | Loss: 0.11008266359567642\n",
      "Batch：6091 | Loss: 0.10872924327850342\n",
      "Batch：6092 | Loss: 0.12613095343112946\n",
      "Batch：6093 | Loss: 0.10483389347791672\n",
      "Batch：6094 | Loss: 0.10339310765266418\n",
      "Batch：6095 | Loss: 0.10636407136917114\n",
      "Batch：6096 | Loss: 0.09123505651950836\n",
      "Batch：6097 | Loss: 0.10095296055078506\n",
      "Batch：6098 | Loss: 0.11475023627281189\n",
      "Batch：6099 | Loss: 0.09864242374897003\n",
      "Batch：6100 | Loss: 0.10880844295024872\n",
      "Batch：6101 | Loss: 0.11782892048358917\n",
      "Batch：6102 | Loss: 0.11554035544395447\n",
      "Batch：6103 | Loss: 0.10697190463542938\n",
      "Batch：6104 | Loss: 0.10366109013557434\n",
      "Batch：6105 | Loss: 0.11869712173938751\n",
      "Batch：6106 | Loss: 0.10308843106031418\n",
      "Batch：6107 | Loss: 0.10494203865528107\n",
      "Batch：6108 | Loss: 0.12648679316043854\n",
      "Batch：6109 | Loss: 0.11370999366044998\n",
      "Batch：6110 | Loss: 0.10687896609306335\n",
      "Batch：6111 | Loss: 0.1085103377699852\n",
      "Batch：6112 | Loss: 0.09875085204839706\n",
      "Batch：6113 | Loss: 0.11258513480424881\n",
      "Batch：6114 | Loss: 0.10843976587057114\n",
      "Batch：6115 | Loss: 0.10218127071857452\n",
      "Batch：6116 | Loss: 0.10362188518047333\n",
      "Batch：6117 | Loss: 0.10494177043437958\n",
      "Batch：6118 | Loss: 0.11226090043783188\n",
      "Batch：6119 | Loss: 0.11462146788835526\n",
      "Batch：6120 | Loss: 0.09453552216291428\n",
      "Batch：6121 | Loss: 0.10273470729589462\n",
      "Batch：6122 | Loss: 0.11406394094228745\n",
      "Batch：6123 | Loss: 0.11400482058525085\n",
      "Batch：6124 | Loss: 0.10826326161623001\n",
      "Batch：6125 | Loss: 0.09925520420074463\n",
      "Batch：6126 | Loss: 0.11080110818147659\n",
      "Batch：6127 | Loss: 0.10580502450466156\n",
      "Batch：6128 | Loss: 0.11286729574203491\n",
      "Batch：6129 | Loss: 0.1180332824587822\n",
      "Batch：6130 | Loss: 0.09592410922050476\n",
      "Batch：6131 | Loss: 0.11203822493553162\n",
      "Batch：6132 | Loss: 0.1099625825881958\n",
      "Batch：6133 | Loss: 0.12077609449625015\n",
      "Batch：6134 | Loss: 0.11088834702968597\n",
      "Batch：6135 | Loss: 0.10711555927991867\n",
      "Batch：6136 | Loss: 0.11748850345611572\n",
      "Batch：6137 | Loss: 0.10980197042226791\n",
      "Batch：6138 | Loss: 0.11483718454837799\n",
      "Batch：6139 | Loss: 0.11009406298398972\n",
      "Batch：6140 | Loss: 0.11593335121870041\n",
      "Batch：6141 | Loss: 0.10675489902496338\n",
      "Batch：6142 | Loss: 0.1089368388056755\n",
      "Batch：6143 | Loss: 0.09646447747945786\n",
      "Batch：6144 | Loss: 0.10613905638456345\n",
      "Batch：6145 | Loss: 0.10863011330366135\n",
      "Batch：6146 | Loss: 0.10174831002950668\n",
      "Batch：6147 | Loss: 0.10929591953754425\n",
      "Batch：6148 | Loss: 0.10921012610197067\n",
      "Batch：6149 | Loss: 0.09965498000383377\n",
      "Batch：6150 | Loss: 0.11893854290246964\n",
      "Batch：6151 | Loss: 0.1133248507976532\n",
      "Batch：6152 | Loss: 0.10706022381782532\n",
      "Batch：6153 | Loss: 0.09836370497941971\n",
      "Batch：6154 | Loss: 0.12162099033594131\n",
      "Batch：6155 | Loss: 0.11670957505702972\n",
      "Batch：6156 | Loss: 0.1163119301199913\n",
      "Batch：6157 | Loss: 0.11016092449426651\n",
      "Batch：6158 | Loss: 0.12106508016586304\n",
      "Batch：6159 | Loss: 0.10069472342729568\n",
      "Batch：6160 | Loss: 0.11662237346172333\n",
      "Batch：6161 | Loss: 0.09819918870925903\n",
      "Batch：6162 | Loss: 0.10780370980501175\n",
      "Batch：6163 | Loss: 0.10490535199642181\n",
      "Batch：6164 | Loss: 0.1049879640340805\n",
      "Batch：6165 | Loss: 0.1264168620109558\n",
      "Batch：6166 | Loss: 0.11675895005464554\n",
      "Batch：6167 | Loss: 0.10862583667039871\n",
      "Batch：6168 | Loss: 0.09981018304824829\n",
      "Batch：6169 | Loss: 0.10493896156549454\n",
      "Batch：6170 | Loss: 0.09759190678596497\n",
      "Batch：6171 | Loss: 0.11951974034309387\n",
      "Batch：6172 | Loss: 0.10240321606397629\n",
      "Batch：6173 | Loss: 0.11051484942436218\n",
      "Batch：6174 | Loss: 0.12352332472801208\n",
      "Batch：6175 | Loss: 0.11561269313097\n",
      "Batch：6176 | Loss: 0.09368643909692764\n",
      "Batch：6177 | Loss: 0.11834375560283661\n",
      "Batch：6178 | Loss: 0.09609216451644897\n",
      "Batch：6179 | Loss: 0.10511615127325058\n",
      "Batch：6180 | Loss: 0.11088551580905914\n",
      "Batch：6181 | Loss: 0.12339556962251663\n",
      "Batch：6182 | Loss: 0.09855645895004272\n",
      "Batch：6183 | Loss: 0.10841377824544907\n",
      "Batch：6184 | Loss: 0.11572330445051193\n",
      "Batch：6185 | Loss: 0.11607476323843002\n",
      "Batch：6186 | Loss: 0.1086975708603859\n",
      "Batch：6187 | Loss: 0.1095491498708725\n",
      "Batch：6188 | Loss: 0.10636734962463379\n",
      "Batch：6189 | Loss: 0.1102306917309761\n",
      "Batch：6190 | Loss: 0.10070390999317169\n",
      "Batch：6191 | Loss: 0.1086294949054718\n",
      "Batch：6192 | Loss: 0.09597711265087128\n",
      "Batch：6193 | Loss: 0.11578214168548584\n",
      "Batch：6194 | Loss: 0.09818296134471893\n",
      "Batch：6195 | Loss: 0.1122380942106247\n",
      "Batch：6196 | Loss: 0.09808489680290222\n",
      "Batch：6197 | Loss: 0.10181237757205963\n",
      "Batch：6198 | Loss: 0.11054994910955429\n",
      "Batch：6199 | Loss: 0.10410807281732559\n",
      "Batch：6200 | Loss: 0.10719995200634003\n",
      "Batch：6201 | Loss: 0.10708282142877579\n",
      "Batch：6202 | Loss: 0.09145734459161758\n",
      "Batch：6203 | Loss: 0.1099572628736496\n",
      "Batch：6204 | Loss: 0.10899540036916733\n",
      "Batch：6205 | Loss: 0.1082722544670105\n",
      "Batch：6206 | Loss: 0.10928824543952942\n",
      "Batch：6207 | Loss: 0.11274179071187973\n",
      "Batch：6208 | Loss: 0.11561165004968643\n",
      "Batch：6209 | Loss: 0.1044129803776741\n",
      "Batch：6210 | Loss: 0.10731687396764755\n",
      "Batch：6211 | Loss: 0.09649065881967545\n",
      "Batch：6212 | Loss: 0.10995712876319885\n",
      "Batch：6213 | Loss: 0.10512781888246536\n",
      "Batch：6214 | Loss: 0.1000724509358406\n",
      "Batch：6215 | Loss: 0.1071685180068016\n",
      "Batch：6216 | Loss: 0.10016635805368423\n",
      "Batch：6217 | Loss: 0.10132130980491638\n",
      "Batch：6218 | Loss: 0.10993851721286774\n",
      "Batch：6219 | Loss: 0.1054193377494812\n",
      "Batch：6220 | Loss: 0.10065118968486786\n",
      "Batch：6221 | Loss: 0.10785166174173355\n",
      "Batch：6222 | Loss: 0.09571630507707596\n",
      "Batch：6223 | Loss: 0.09812472760677338\n",
      "Batch：6224 | Loss: 0.11115565150976181\n",
      "Batch：6225 | Loss: 0.09563251584768295\n",
      "Batch：6226 | Loss: 0.09962521493434906\n",
      "Batch：6227 | Loss: 0.10997721552848816\n",
      "Batch：6228 | Loss: 0.09794847667217255\n",
      "Batch：6229 | Loss: 0.11463244259357452\n",
      "Batch：6230 | Loss: 0.1087535098195076\n",
      "Batch：6231 | Loss: 0.11532529443502426\n",
      "Batch：6232 | Loss: 0.09607599675655365\n",
      "Batch：6233 | Loss: 0.11317950487136841\n",
      "Batch：6234 | Loss: 0.09827793389558792\n",
      "Batch：6235 | Loss: 0.10082172602415085\n",
      "Batch：6236 | Loss: 0.12251975387334824\n",
      "Batch：6237 | Loss: 0.09732671827077866\n",
      "Batch：6238 | Loss: 0.0983053594827652\n",
      "Batch：6239 | Loss: 0.1024811714887619\n",
      "Batch：6240 | Loss: 0.10577329248189926\n",
      "Batch：6241 | Loss: 0.09960608929395676\n",
      "Batch：6242 | Loss: 0.11503340303897858\n",
      "Batch：6243 | Loss: 0.09896477311849594\n",
      "Batch：6244 | Loss: 0.10517554730176926\n",
      "Batch：6245 | Loss: 0.10851100832223892\n",
      "Batch：6246 | Loss: 0.10691457241773605\n",
      "Batch：6247 | Loss: 0.11806789040565491\n",
      "Batch：6248 | Loss: 0.10909560322761536\n",
      "Batch：6249 | Loss: 0.10267364233732224\n",
      "Batch：6250 | Loss: 0.10986817628145218\n",
      "Batch：6251 | Loss: 0.0980934202671051\n",
      "Batch：6252 | Loss: 0.10177050530910492\n",
      "Batch：6253 | Loss: 0.11581937223672867\n",
      "Batch：6254 | Loss: 0.10032979398965836\n",
      "Batch：6255 | Loss: 0.09809084236621857\n",
      "Batch：6256 | Loss: 0.11357053369283676\n",
      "Batch：6257 | Loss: 0.11427482217550278\n",
      "Batch：6258 | Loss: 0.10547268390655518\n",
      "Batch：6259 | Loss: 0.09606705605983734\n",
      "Batch：6260 | Loss: 0.10659671574831009\n",
      "Batch：6261 | Loss: 0.11493135243654251\n",
      "Batch：6262 | Loss: 0.10783178359270096\n",
      "Batch：6263 | Loss: 0.10446616262197495\n",
      "Batch：6264 | Loss: 0.1019274964928627\n",
      "Batch：6265 | Loss: 0.10824950784444809\n",
      "Batch：6266 | Loss: 0.1027611792087555\n",
      "Batch：6267 | Loss: 0.10919967293739319\n",
      "Batch：6268 | Loss: 0.10219624638557434\n",
      "Batch：6269 | Loss: 0.09762507677078247\n",
      "Batch：6270 | Loss: 0.09955298900604248\n",
      "Batch：6271 | Loss: 0.10285847634077072\n",
      "Batch：6272 | Loss: 0.11185313016176224\n",
      "Batch：6273 | Loss: 0.10947326570749283\n",
      "Batch：6274 | Loss: 0.11738073825836182\n",
      "Batch：6275 | Loss: 0.08903500437736511\n",
      "Batch：6276 | Loss: 0.1155870333313942\n",
      "Batch：6277 | Loss: 0.09992317855358124\n",
      "Batch：6278 | Loss: 0.11100557446479797\n",
      "Batch：6279 | Loss: 0.08494648337364197\n",
      "Batch：6280 | Loss: 0.11151031404733658\n",
      "Batch：6281 | Loss: 0.11429212242364883\n",
      "Batch：6282 | Loss: 0.10585664957761765\n",
      "Batch：6283 | Loss: 0.11385509371757507\n",
      "Batch：6284 | Loss: 0.10255560278892517\n",
      "Batch：6285 | Loss: 0.1101309210062027\n",
      "Batch：6286 | Loss: 0.10199437290430069\n",
      "Batch：6287 | Loss: 0.11455655843019485\n",
      "Batch：6288 | Loss: 0.11554215103387833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：6289 | Loss: 0.12159779667854309\n",
      "Batch：6290 | Loss: 0.09896029531955719\n",
      "Batch：6291 | Loss: 0.10773031413555145\n",
      "Batch：6292 | Loss: 0.1129988580942154\n",
      "Batch：6293 | Loss: 0.11016058921813965\n",
      "Batch：6294 | Loss: 0.11342014372348785\n",
      "Batch：6295 | Loss: 0.09945440292358398\n",
      "Batch：6296 | Loss: 0.0961504727602005\n",
      "Batch：6297 | Loss: 0.11144162714481354\n",
      "Batch：6298 | Loss: 0.10087001323699951\n",
      "Batch：6299 | Loss: 0.11049281805753708\n",
      "Batch：6300 | Loss: 0.11038728803396225\n",
      "Batch：6301 | Loss: 0.11315375566482544\n",
      "Batch：6302 | Loss: 0.09124471247196198\n",
      "Batch：6303 | Loss: 0.10258007049560547\n",
      "Batch：6304 | Loss: 0.10131415724754333\n",
      "Batch：6305 | Loss: 0.10147901624441147\n",
      "Batch：6306 | Loss: 0.10205624997615814\n",
      "Batch：6307 | Loss: 0.11088693141937256\n",
      "Batch：6308 | Loss: 0.09692889451980591\n",
      "Batch：6309 | Loss: 0.10376854985952377\n",
      "Batch：6310 | Loss: 0.10448680818080902\n",
      "Batch：6311 | Loss: 0.10434792190790176\n",
      "Batch：6312 | Loss: 0.09760351479053497\n",
      "Batch：6313 | Loss: 0.10116473585367203\n",
      "Batch：6314 | Loss: 0.11234994232654572\n",
      "Batch：6315 | Loss: 0.11266382038593292\n",
      "Batch：6316 | Loss: 0.09671472012996674\n",
      "Batch：6317 | Loss: 0.11835819482803345\n",
      "Batch：6318 | Loss: 0.10188741981983185\n",
      "Batch：6319 | Loss: 0.10638929158449173\n",
      "Batch：6320 | Loss: 0.10936792939901352\n",
      "Batch：6321 | Loss: 0.11313287168741226\n",
      "Batch：6322 | Loss: 0.10854499042034149\n",
      "Batch：6323 | Loss: 0.10019317269325256\n",
      "Batch：6324 | Loss: 0.1101645901799202\n",
      "Batch：6325 | Loss: 0.1067374125123024\n",
      "Batch：6326 | Loss: 0.09076426178216934\n",
      "Batch：6327 | Loss: 0.10583435744047165\n",
      "Batch：6328 | Loss: 0.1166667491197586\n",
      "Batch：6329 | Loss: 0.10191614925861359\n",
      "Batch：6330 | Loss: 0.09911967068910599\n",
      "Batch：6331 | Loss: 0.10617087036371231\n",
      "Batch：6332 | Loss: 0.11171449720859528\n",
      "Batch：6333 | Loss: 0.09546254575252533\n",
      "Batch：6334 | Loss: 0.0980779379606247\n",
      "Batch：6335 | Loss: 0.10721924901008606\n",
      "Batch：6336 | Loss: 0.11591080576181412\n",
      "Batch：6337 | Loss: 0.09634630382061005\n",
      "Batch：6338 | Loss: 0.11374110728502274\n",
      "Batch：6339 | Loss: 0.09752663224935532\n",
      "Batch：6340 | Loss: 0.1042337417602539\n",
      "Batch：6341 | Loss: 0.09980762749910355\n",
      "Batch：6342 | Loss: 0.10056126117706299\n",
      "Batch：6343 | Loss: 0.1071435809135437\n",
      "Batch：6344 | Loss: 0.09832368791103363\n",
      "Batch：6345 | Loss: 0.11152437329292297\n",
      "Batch：6346 | Loss: 0.08985292166471481\n",
      "Batch：6347 | Loss: 0.11008244007825851\n",
      "Batch：6348 | Loss: 0.12015876173973083\n",
      "Batch：6349 | Loss: 0.10338540375232697\n",
      "Batch：6350 | Loss: 0.11899454891681671\n",
      "Batch：6351 | Loss: 0.11532436311244965\n",
      "Batch：6352 | Loss: 0.10669449716806412\n",
      "Batch：6353 | Loss: 0.097069650888443\n",
      "Batch：6354 | Loss: 0.11187785863876343\n",
      "Batch：6355 | Loss: 0.10488352179527283\n",
      "Batch：6356 | Loss: 0.1019257977604866\n",
      "Batch：6357 | Loss: 0.10637557506561279\n",
      "Batch：6358 | Loss: 0.10319098085165024\n",
      "Batch：6359 | Loss: 0.10684675723314285\n",
      "Batch：6360 | Loss: 0.11468943953514099\n",
      "Batch：6361 | Loss: 0.10810881108045578\n",
      "Batch：6362 | Loss: 0.10083947330713272\n",
      "Batch：6363 | Loss: 0.10211803019046783\n",
      "Batch：6364 | Loss: 0.10370920598506927\n",
      "Batch：6365 | Loss: 0.10315269976854324\n",
      "Batch：6366 | Loss: 0.1129138395190239\n",
      "Batch：6367 | Loss: 0.09413737058639526\n",
      "Batch：6368 | Loss: 0.10158087313175201\n",
      "Batch：6369 | Loss: 0.1041913628578186\n",
      "Batch：6370 | Loss: 0.10748440772294998\n",
      "Batch：6371 | Loss: 0.11243820935487747\n",
      "Batch：6372 | Loss: 0.10911121219396591\n",
      "Batch：6373 | Loss: 0.09667691588401794\n",
      "Batch：6374 | Loss: 0.09595337510108948\n",
      "Batch：6375 | Loss: 0.10530369728803635\n",
      "Batch：6376 | Loss: 0.11366871744394302\n",
      "Batch：6377 | Loss: 0.1018020510673523\n",
      "Batch：6378 | Loss: 0.10000649839639664\n",
      "Batch：6379 | Loss: 0.1112050786614418\n",
      "Batch：6380 | Loss: 0.1118878498673439\n",
      "Batch：6381 | Loss: 0.09673494100570679\n",
      "Batch：6382 | Loss: 0.09720448404550552\n",
      "Batch：6383 | Loss: 0.10171854496002197\n",
      "Batch：6384 | Loss: 0.10536497086286545\n",
      "Batch：6385 | Loss: 0.09962945431470871\n",
      "Batch：6386 | Loss: 0.10719264298677444\n",
      "Batch：6387 | Loss: 0.10382576286792755\n",
      "Batch：6388 | Loss: 0.09694162011146545\n",
      "Batch：6389 | Loss: 0.11010058224201202\n",
      "Batch：6390 | Loss: 0.1056608036160469\n",
      "Batch：6391 | Loss: 0.10113531351089478\n",
      "Batch：6392 | Loss: 0.10311848670244217\n",
      "Batch：6393 | Loss: 0.10328253358602524\n",
      "Batch：6394 | Loss: 0.09698661416769028\n",
      "Batch：6395 | Loss: 0.09313354641199112\n",
      "Batch：6396 | Loss: 0.0914262905716896\n",
      "Batch：6397 | Loss: 0.11381015926599503\n",
      "Batch：6398 | Loss: 0.10469868034124374\n",
      "Batch：6399 | Loss: 0.12411294132471085\n",
      "Batch：6400 | Loss: 0.11695089936256409\n",
      "Batch：6401 | Loss: 0.10864458978176117\n",
      "Batch：6402 | Loss: 0.11129886656999588\n",
      "Batch：6403 | Loss: 0.10355525463819504\n",
      "Batch：6404 | Loss: 0.11089228838682175\n",
      "Batch：6405 | Loss: 0.1079842820763588\n",
      "Batch：6406 | Loss: 0.11316853761672974\n",
      "Batch：6407 | Loss: 0.0988098531961441\n",
      "Batch：6408 | Loss: 0.10784553736448288\n",
      "Batch：6409 | Loss: 0.10449685901403427\n",
      "Batch：6410 | Loss: 0.10321024805307388\n",
      "Batch：6411 | Loss: 0.10749083012342453\n",
      "Batch：6412 | Loss: 0.11140157282352448\n",
      "Batch：6413 | Loss: 0.10870666056871414\n",
      "Batch：6414 | Loss: 0.1052018329501152\n",
      "Batch：6415 | Loss: 0.10222475230693817\n",
      "Batch：6416 | Loss: 0.09950360655784607\n",
      "Batch：6417 | Loss: 0.10190307348966599\n",
      "Batch：6418 | Loss: 0.10526400804519653\n",
      "Batch：6419 | Loss: 0.1027485653758049\n",
      "Batch：6420 | Loss: 0.09169591963291168\n",
      "Batch：6421 | Loss: 0.10138415545225143\n",
      "Batch：6422 | Loss: 0.09649772197008133\n",
      "Batch：6423 | Loss: 0.10131015628576279\n",
      "Batch：6424 | Loss: 0.11031347513198853\n",
      "Batch：6425 | Loss: 0.10502280294895172\n",
      "Batch：6426 | Loss: 0.10436830669641495\n",
      "Batch：6427 | Loss: 0.11141882091760635\n",
      "Batch：6428 | Loss: 0.10581288486719131\n",
      "Batch：6429 | Loss: 0.09139703214168549\n",
      "Batch：6430 | Loss: 0.0929807499051094\n",
      "Batch：6431 | Loss: 0.12039867788553238\n",
      "Batch：6432 | Loss: 0.103473000228405\n",
      "Batch：6433 | Loss: 0.09388002753257751\n",
      "Batch：6434 | Loss: 0.11975223571062088\n",
      "Batch：6435 | Loss: 0.11443009227514267\n",
      "Batch：6436 | Loss: 0.10094750672578812\n",
      "Batch：6437 | Loss: 0.11212331056594849\n",
      "Batch：6438 | Loss: 0.10335011780261993\n",
      "Batch：6439 | Loss: 0.11254987120628357\n",
      "Batch：6440 | Loss: 0.09832116961479187\n",
      "Batch：6441 | Loss: 0.11378516256809235\n",
      "Batch：6442 | Loss: 0.09472096711397171\n",
      "Batch：6443 | Loss: 0.0890800803899765\n",
      "Batch：6444 | Loss: 0.10448537021875381\n",
      "Batch：6445 | Loss: 0.09758127480745316\n",
      "Batch：6446 | Loss: 0.10382041335105896\n",
      "Batch：6447 | Loss: 0.09679758548736572\n",
      "Batch：6448 | Loss: 0.10151712596416473\n",
      "Batch：6449 | Loss: 0.10176969319581985\n",
      "Batch：6450 | Loss: 0.10203362256288528\n",
      "Batch：6451 | Loss: 0.09877970069646835\n",
      "Batch：6452 | Loss: 0.10781481862068176\n",
      "Batch：6453 | Loss: 0.10238274931907654\n",
      "Batch：6454 | Loss: 0.09887503832578659\n",
      "Batch：6455 | Loss: 0.1051328107714653\n",
      "Batch：6456 | Loss: 0.09596189111471176\n",
      "Batch：6457 | Loss: 0.10016677528619766\n",
      "Batch：6458 | Loss: 0.09481300413608551\n",
      "Batch：6459 | Loss: 0.10452615469694138\n",
      "Batch：6460 | Loss: 0.10437750071287155\n",
      "Batch：6461 | Loss: 0.11196407675743103\n",
      "Batch：6462 | Loss: 0.09511574357748032\n",
      "Batch：6463 | Loss: 0.10854556411504745\n",
      "Batch：6464 | Loss: 0.09772399812936783\n",
      "Batch：6465 | Loss: 0.10581686347723007\n",
      "Batch：6466 | Loss: 0.1012578010559082\n",
      "Batch：6467 | Loss: 0.10302186757326126\n",
      "Batch：6468 | Loss: 0.11608617007732391\n",
      "Batch：6469 | Loss: 0.09890449792146683\n",
      "Batch：6470 | Loss: 0.10838146507740021\n",
      "Batch：6471 | Loss: 0.10294325649738312\n",
      "Batch：6472 | Loss: 0.10361509770154953\n",
      "Batch：6473 | Loss: 0.10630578547716141\n",
      "Batch：6474 | Loss: 0.09656583517789841\n",
      "Batch：6475 | Loss: 0.09716544300317764\n",
      "Batch：6476 | Loss: 0.10962426662445068\n",
      "Batch：6477 | Loss: 0.09441892057657242\n",
      "Batch：6478 | Loss: 0.09708704799413681\n",
      "Batch：6479 | Loss: 0.09784907847642899\n",
      "Batch：6480 | Loss: 0.11226808279752731\n",
      "Batch：6481 | Loss: 0.10240419209003448\n",
      "Batch：6482 | Loss: 0.1122470498085022\n",
      "Batch：6483 | Loss: 0.10566766560077667\n",
      "Batch：6484 | Loss: 0.10752400755882263\n",
      "Batch：6485 | Loss: 0.10686451941728592\n",
      "Batch：6486 | Loss: 0.10499835014343262\n",
      "Batch：6487 | Loss: 0.10432937741279602\n",
      "Batch：6488 | Loss: 0.09368021786212921\n",
      "Batch：6489 | Loss: 0.10250116139650345\n",
      "Batch：6490 | Loss: 0.10850619524717331\n",
      "Batch：6491 | Loss: 0.10915423184633255\n",
      "Batch：6492 | Loss: 0.09995446354150772\n",
      "Batch：6493 | Loss: 0.09881505370140076\n",
      "Batch：6494 | Loss: 0.11468376219272614\n",
      "Batch：6495 | Loss: 0.11670897156000137\n",
      "Batch：6496 | Loss: 0.09819190204143524\n",
      "Batch：6497 | Loss: 0.10436095297336578\n",
      "Batch：6498 | Loss: 0.09013032168149948\n",
      "Batch：6499 | Loss: 0.10693641006946564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：6500 | Loss: 0.08935225009918213\n",
      "Batch：6501 | Loss: 0.09880778193473816\n",
      "Batch：6502 | Loss: 0.10079798102378845\n",
      "Batch：6503 | Loss: 0.0950511023402214\n",
      "Batch：6504 | Loss: 0.10127631574869156\n",
      "Batch：6505 | Loss: 0.09740722179412842\n",
      "Batch：6506 | Loss: 0.09725888818502426\n",
      "Batch：6507 | Loss: 0.11569738388061523\n",
      "Batch：6508 | Loss: 0.10388077795505524\n",
      "Batch：6509 | Loss: 0.10393151640892029\n",
      "Batch：6510 | Loss: 0.1092906966805458\n",
      "Batch：6511 | Loss: 0.1091950461268425\n",
      "Batch：6512 | Loss: 0.0964144691824913\n",
      "Batch：6513 | Loss: 0.10242340713739395\n",
      "Batch：6514 | Loss: 0.10557623207569122\n",
      "Batch：6515 | Loss: 0.09793945401906967\n",
      "Batch：6516 | Loss: 0.10394234210252762\n",
      "Batch：6517 | Loss: 0.10486087948083878\n",
      "Batch：6518 | Loss: 0.09559335559606552\n",
      "Batch：6519 | Loss: 0.10468250513076782\n",
      "Batch：6520 | Loss: 0.09840065240859985\n",
      "Batch：6521 | Loss: 0.10306552797555923\n",
      "Batch：6522 | Loss: 0.10134529322385788\n",
      "Batch：6523 | Loss: 0.11078540235757828\n",
      "Batch：6524 | Loss: 0.10411291569471359\n",
      "Batch：6525 | Loss: 0.1173960492014885\n",
      "Batch：6526 | Loss: 0.10426455736160278\n",
      "Batch：6527 | Loss: 0.09973227977752686\n",
      "Batch：6528 | Loss: 0.0952986627817154\n",
      "Batch：6529 | Loss: 0.10084987431764603\n",
      "Batch：6530 | Loss: 0.10994720458984375\n",
      "Batch：6531 | Loss: 0.10067785531282425\n",
      "Batch：6532 | Loss: 0.1083950623869896\n",
      "Batch：6533 | Loss: 0.09751732647418976\n",
      "Batch：6534 | Loss: 0.09858404099941254\n",
      "Batch：6535 | Loss: 0.10402937978506088\n",
      "Batch：6536 | Loss: 0.10666288435459137\n",
      "Batch：6537 | Loss: 0.1017346903681755\n",
      "Batch：6538 | Loss: 0.10051383078098297\n",
      "Batch：6539 | Loss: 0.09951898455619812\n",
      "Batch：6540 | Loss: 0.10690650343894958\n",
      "Batch：6541 | Loss: 0.09792138636112213\n",
      "Batch：6542 | Loss: 0.08965129405260086\n",
      "Batch：6543 | Loss: 0.10941001027822495\n",
      "Batch：6544 | Loss: 0.10649247467517853\n",
      "Batch：6545 | Loss: 0.10728916525840759\n",
      "Batch：6546 | Loss: 0.1052248552441597\n",
      "Batch：6547 | Loss: 0.10765120387077332\n",
      "Batch：6548 | Loss: 0.10802751779556274\n",
      "Batch：6549 | Loss: 0.1014493778347969\n",
      "Batch：6550 | Loss: 0.11094297468662262\n",
      "Batch：6551 | Loss: 0.10059309750795364\n",
      "Batch：6552 | Loss: 0.1063612550497055\n",
      "Batch：6553 | Loss: 0.12068333476781845\n",
      "Batch：6554 | Loss: 0.10466686636209488\n",
      "Batch：6555 | Loss: 0.10743560642004013\n",
      "Batch：6556 | Loss: 0.09387405961751938\n",
      "Batch：6557 | Loss: 0.0916348248720169\n",
      "Batch：6558 | Loss: 0.09972598403692245\n",
      "Batch：6559 | Loss: 0.10195045918226242\n",
      "Batch：6560 | Loss: 0.11089438945055008\n",
      "Batch：6561 | Loss: 0.10568468272686005\n",
      "Batch：6562 | Loss: 0.1049637719988823\n",
      "Batch：6563 | Loss: 0.09304133802652359\n",
      "Batch：6564 | Loss: 0.11080333590507507\n",
      "Batch：6565 | Loss: 0.09834283590316772\n",
      "Batch：6566 | Loss: 0.1080435961484909\n",
      "Batch：6567 | Loss: 0.10574847459793091\n",
      "Batch：6568 | Loss: 0.0934021919965744\n",
      "Batch：6569 | Loss: 0.10018184036016464\n",
      "Batch：6570 | Loss: 0.11120245605707169\n",
      "Batch：6571 | Loss: 0.10743904858827591\n",
      "Batch：6572 | Loss: 0.1008945107460022\n",
      "Batch：6573 | Loss: 0.11735109984874725\n",
      "Batch：6574 | Loss: 0.11589141935110092\n",
      "Batch：6575 | Loss: 0.10973509401082993\n",
      "Batch：6576 | Loss: 0.10585252940654755\n",
      "Batch：6577 | Loss: 0.101731076836586\n",
      "Batch：6578 | Loss: 0.11407112330198288\n",
      "Batch：6579 | Loss: 0.10095864534378052\n",
      "Batch：6580 | Loss: 0.10197237879037857\n",
      "Batch：6581 | Loss: 0.09780074656009674\n",
      "Batch：6582 | Loss: 0.09706129133701324\n",
      "Batch：6583 | Loss: 0.1056651771068573\n",
      "Batch：6584 | Loss: 0.10090416669845581\n",
      "Batch：6585 | Loss: 0.10553271323442459\n",
      "Batch：6586 | Loss: 0.10834631323814392\n",
      "Batch：6587 | Loss: 0.1001187339425087\n",
      "Batch：6588 | Loss: 0.09744808077812195\n",
      "Batch：6589 | Loss: 0.11973998695611954\n",
      "Batch：6590 | Loss: 0.08458240330219269\n",
      "Batch：6591 | Loss: 0.10936189442873001\n",
      "Batch：6592 | Loss: 0.09682966023683548\n",
      "Batch：6593 | Loss: 0.0897618979215622\n",
      "Batch：6594 | Loss: 0.09301312267780304\n",
      "Batch：6595 | Loss: 0.09850585460662842\n",
      "Batch：6596 | Loss: 0.11074287444353104\n",
      "Batch：6597 | Loss: 0.10723396390676498\n",
      "Batch：6598 | Loss: 0.10239628702402115\n",
      "Batch：6599 | Loss: 0.09914945065975189\n",
      "Batch：6600 | Loss: 0.1013442799448967\n",
      "Batch：6601 | Loss: 0.11144677549600601\n",
      "Batch：6602 | Loss: 0.11534082889556885\n",
      "Batch：6603 | Loss: 0.10889151692390442\n",
      "Batch：6604 | Loss: 0.10969040542840958\n",
      "Batch：6605 | Loss: 0.1094733253121376\n",
      "Batch：6606 | Loss: 0.1009562760591507\n",
      "Batch：6607 | Loss: 0.10036630928516388\n",
      "Batch：6608 | Loss: 0.10216672718524933\n",
      "Batch：6609 | Loss: 0.09986387938261032\n",
      "Batch：6610 | Loss: 0.1088903620839119\n",
      "Batch：6611 | Loss: 0.09611492604017258\n",
      "Batch：6612 | Loss: 0.10590175539255142\n",
      "Batch：6613 | Loss: 0.09486948698759079\n",
      "Batch：6614 | Loss: 0.10429054498672485\n",
      "Batch：6615 | Loss: 0.10919150710105896\n",
      "Batch：6616 | Loss: 0.09778297692537308\n",
      "Batch：6617 | Loss: 0.09797440469264984\n",
      "Batch：6618 | Loss: 0.10498473048210144\n",
      "Batch：6619 | Loss: 0.09809543937444687\n",
      "Batch：6620 | Loss: 0.1056794747710228\n",
      "Batch：6621 | Loss: 0.10916940122842789\n",
      "Batch：6622 | Loss: 0.08861622959375381\n",
      "Batch：6623 | Loss: 0.09060454368591309\n",
      "Batch：6624 | Loss: 0.10260472446680069\n",
      "Batch：6625 | Loss: 0.10461629182100296\n",
      "Batch：6626 | Loss: 0.1091071143746376\n",
      "Batch：6627 | Loss: 0.09937825053930283\n",
      "Batch：6628 | Loss: 0.1042819619178772\n",
      "Batch：6629 | Loss: 0.10526935011148453\n",
      "Batch：6630 | Loss: 0.1047278419137001\n",
      "Batch：6631 | Loss: 0.09157002717256546\n",
      "Batch：6632 | Loss: 0.11432556807994843\n",
      "Batch：6633 | Loss: 0.09543424099683762\n",
      "Batch：6634 | Loss: 0.09484028071165085\n",
      "Batch：6635 | Loss: 0.09082399308681488\n",
      "Batch：6636 | Loss: 0.10654042661190033\n",
      "Batch：6637 | Loss: 0.11075205355882645\n",
      "Batch：6638 | Loss: 0.09379871189594269\n",
      "Batch：6639 | Loss: 0.10534801334142685\n",
      "Batch：6640 | Loss: 0.10208718478679657\n",
      "Batch：6641 | Loss: 0.10199695825576782\n",
      "Batch：6642 | Loss: 0.1099415197968483\n",
      "Batch：6643 | Loss: 0.10117025673389435\n",
      "Batch：6644 | Loss: 0.09398718178272247\n",
      "Batch：6645 | Loss: 0.10689845681190491\n",
      "Batch：6646 | Loss: 0.09611230343580246\n",
      "Batch：6647 | Loss: 0.09515071660280228\n",
      "Batch：6648 | Loss: 0.0972505509853363\n",
      "Batch：6649 | Loss: 0.09789339452981949\n",
      "Batch：6650 | Loss: 0.1026335135102272\n",
      "Batch：6651 | Loss: 0.09043890237808228\n",
      "Batch：6652 | Loss: 0.10247562825679779\n",
      "Batch：6653 | Loss: 0.10564812272787094\n",
      "Batch：6654 | Loss: 0.10277044773101807\n",
      "Batch：6655 | Loss: 0.12140931934118271\n",
      "Batch：6656 | Loss: 0.09788341075181961\n",
      "Batch：6657 | Loss: 0.10998865962028503\n",
      "Batch：6658 | Loss: 0.10288307815790176\n",
      "Batch：6659 | Loss: 0.08951053768396378\n",
      "Batch：6660 | Loss: 0.09561698138713837\n",
      "Batch：6661 | Loss: 0.10573063045740128\n",
      "Batch：6662 | Loss: 0.08937356621026993\n",
      "Batch：6663 | Loss: 0.10298259556293488\n",
      "Batch：6664 | Loss: 0.09771373122930527\n",
      "Batch：6665 | Loss: 0.11129815876483917\n",
      "Batch：6666 | Loss: 0.10589827597141266\n",
      "Batch：6667 | Loss: 0.09725341945886612\n",
      "Batch：6668 | Loss: 0.08260518312454224\n",
      "Batch：6669 | Loss: 0.09163493663072586\n",
      "Batch：6670 | Loss: 0.0962148904800415\n",
      "Batch：6671 | Loss: 0.10337144881486893\n",
      "Batch：6672 | Loss: 0.09668116271495819\n",
      "Batch：6673 | Loss: 0.09533972293138504\n",
      "Batch：6674 | Loss: 0.1073877215385437\n",
      "Batch：6675 | Loss: 0.10422065109014511\n",
      "Batch：6676 | Loss: 0.09472449868917465\n",
      "Batch：6677 | Loss: 0.09866705536842346\n",
      "Batch：6678 | Loss: 0.10591483116149902\n",
      "Batch：6679 | Loss: 0.10273490101099014\n",
      "Batch：6680 | Loss: 0.10408493131399155\n",
      "Batch：6681 | Loss: 0.09208624064922333\n",
      "Batch：6682 | Loss: 0.11116944998502731\n",
      "Batch：6683 | Loss: 0.09397484362125397\n",
      "Batch：6684 | Loss: 0.10395994037389755\n",
      "Batch：6685 | Loss: 0.09399186074733734\n",
      "Batch：6686 | Loss: 0.10239188373088837\n",
      "Batch：6687 | Loss: 0.10035085678100586\n",
      "Batch：6688 | Loss: 0.10143230855464935\n",
      "Batch：6689 | Loss: 0.10392781347036362\n",
      "Batch：6690 | Loss: 0.09515386819839478\n",
      "Batch：6691 | Loss: 0.09937696903944016\n",
      "Batch：6692 | Loss: 0.10161326080560684\n",
      "Batch：6693 | Loss: 0.1098145917057991\n",
      "Batch：6694 | Loss: 0.1115172728896141\n",
      "Batch：6695 | Loss: 0.11019232124090195\n",
      "Batch：6696 | Loss: 0.10740138590335846\n",
      "Batch：6697 | Loss: 0.1025475263595581\n",
      "Batch：6698 | Loss: 0.10390820354223251\n",
      "Batch：6699 | Loss: 0.1006937325000763\n",
      "Batch：6700 | Loss: 0.10725601762533188\n",
      "Batch：6701 | Loss: 0.11520639806985855\n",
      "Batch：6702 | Loss: 0.09914471209049225\n",
      "Batch：6703 | Loss: 0.1035013422369957\n",
      "Batch：6704 | Loss: 0.09279710054397583\n",
      "Batch：6705 | Loss: 0.09993089735507965\n",
      "Batch：6706 | Loss: 0.09436573833227158\n",
      "Batch：6707 | Loss: 0.10210377722978592\n",
      "Batch：6708 | Loss: 0.10237907618284225\n",
      "Batch：6709 | Loss: 0.09162900596857071\n",
      "Batch：6710 | Loss: 0.10008566081523895\n",
      "Batch：6711 | Loss: 0.09691298007965088\n",
      "Batch：6712 | Loss: 0.10377766937017441\n",
      "Batch：6713 | Loss: 0.10580698400735855\n",
      "Batch：6714 | Loss: 0.1082444116473198\n",
      "Batch：6715 | Loss: 0.09664365649223328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：6716 | Loss: 0.10257332026958466\n",
      "Batch：6717 | Loss: 0.09520379453897476\n",
      "Batch：6718 | Loss: 0.09754660725593567\n",
      "Batch：6719 | Loss: 0.093549944460392\n",
      "Batch：6720 | Loss: 0.10161123424768448\n",
      "Batch：6721 | Loss: 0.10438075661659241\n",
      "Batch：6722 | Loss: 0.11303624510765076\n",
      "Batch：6723 | Loss: 0.10072330385446548\n",
      "Batch：6724 | Loss: 0.09725451469421387\n",
      "Batch：6725 | Loss: 0.10652760416269302\n",
      "Batch：6726 | Loss: 0.1014006957411766\n",
      "Batch：6727 | Loss: 0.09093597531318665\n",
      "Batch：6728 | Loss: 0.10832114517688751\n",
      "Batch：6729 | Loss: 0.09930609166622162\n",
      "Batch：6730 | Loss: 0.11520974338054657\n",
      "Batch：6731 | Loss: 0.10201562196016312\n",
      "Batch：6732 | Loss: 0.09051097184419632\n",
      "Batch：6733 | Loss: 0.09192712604999542\n",
      "Batch：6734 | Loss: 0.10107238590717316\n",
      "Batch：6735 | Loss: 0.10278726369142532\n",
      "Batch：6736 | Loss: 0.10062702000141144\n",
      "Batch：6737 | Loss: 0.11329305171966553\n",
      "Batch：6738 | Loss: 0.10262978821992874\n",
      "Batch：6739 | Loss: 0.08486716449260712\n",
      "Batch：6740 | Loss: 0.10109157860279083\n",
      "Batch：6741 | Loss: 0.09394735842943192\n",
      "Batch：6742 | Loss: 0.11038626730442047\n",
      "Batch：6743 | Loss: 0.0997786819934845\n",
      "Batch：6744 | Loss: 0.09633444994688034\n",
      "Batch：6745 | Loss: 0.1126677617430687\n",
      "Batch：6746 | Loss: 0.12234804034233093\n",
      "Batch：6747 | Loss: 0.10528531670570374\n",
      "Batch：6748 | Loss: 0.10716166347265244\n",
      "Batch：6749 | Loss: 0.09759161621332169\n",
      "Batch：6750 | Loss: 0.0967387780547142\n",
      "Batch：6751 | Loss: 0.08853831142187119\n",
      "Batch：6752 | Loss: 0.10080714523792267\n",
      "Batch：6753 | Loss: 0.08861663937568665\n",
      "Batch：6754 | Loss: 0.10357479006052017\n",
      "Batch：6755 | Loss: 0.10164996981620789\n",
      "Batch：6756 | Loss: 0.10357688367366791\n",
      "Batch：6757 | Loss: 0.10054542124271393\n",
      "Batch：6758 | Loss: 0.09108459204435349\n",
      "Batch：6759 | Loss: 0.1030995100736618\n",
      "Batch：6760 | Loss: 0.09173032641410828\n",
      "Batch：6761 | Loss: 0.09299793094396591\n",
      "Batch：6762 | Loss: 0.08396641165018082\n",
      "Batch：6763 | Loss: 0.10425827652215958\n",
      "Batch：6764 | Loss: 0.0966666042804718\n",
      "Batch：6765 | Loss: 0.0880117416381836\n",
      "Batch：6766 | Loss: 0.09453638643026352\n",
      "Batch：6767 | Loss: 0.0870390310883522\n",
      "Batch：6768 | Loss: 0.0937914028763771\n",
      "Batch：6769 | Loss: 0.10787329077720642\n",
      "Batch：6770 | Loss: 0.08702017366886139\n",
      "Batch：6771 | Loss: 0.10913562029600143\n",
      "Batch：6772 | Loss: 0.10914740711450577\n",
      "Batch：6773 | Loss: 0.10215960443019867\n",
      "Batch：6774 | Loss: 0.0987246185541153\n",
      "Batch：6775 | Loss: 0.10110044479370117\n",
      "Batch：6776 | Loss: 0.09553534537553787\n",
      "Batch：6777 | Loss: 0.09848640114068985\n",
      "Batch：6778 | Loss: 0.10263623297214508\n",
      "Batch：6779 | Loss: 0.08998163789510727\n",
      "Batch：6780 | Loss: 0.0990767627954483\n",
      "Batch：6781 | Loss: 0.09524570405483246\n",
      "Batch：6782 | Loss: 0.09350302070379257\n",
      "Batch：6783 | Loss: 0.0875663012266159\n",
      "Batch：6784 | Loss: 0.11006231606006622\n",
      "Batch：6785 | Loss: 0.10120091587305069\n",
      "Batch：6786 | Loss: 0.11249211430549622\n",
      "Batch：6787 | Loss: 0.0941082313656807\n",
      "Batch：6788 | Loss: 0.09972628951072693\n",
      "Batch：6789 | Loss: 0.10161002725362778\n",
      "Batch：6790 | Loss: 0.09658592939376831\n",
      "Batch：6791 | Loss: 0.09457356482744217\n",
      "Batch：6792 | Loss: 0.10078556090593338\n",
      "Batch：6793 | Loss: 0.09040189534425735\n",
      "Batch：6794 | Loss: 0.09647105634212494\n",
      "Batch：6795 | Loss: 0.0949261337518692\n",
      "Batch：6796 | Loss: 0.0902528464794159\n",
      "Batch：6797 | Loss: 0.11455680429935455\n",
      "Batch：6798 | Loss: 0.10354592651128769\n",
      "Batch：6799 | Loss: 0.09787318855524063\n",
      "Batch：6800 | Loss: 0.10752742737531662\n",
      "Batch：6801 | Loss: 0.08835741877555847\n",
      "Batch：6802 | Loss: 0.09407112747430801\n",
      "Batch：6803 | Loss: 0.0996091291308403\n",
      "Batch：6804 | Loss: 0.09510291367769241\n",
      "Batch：6805 | Loss: 0.11074700951576233\n",
      "Batch：6806 | Loss: 0.11441806703805923\n",
      "Batch：6807 | Loss: 0.0910286009311676\n",
      "Batch：6808 | Loss: 0.09661094099283218\n",
      "Batch：6809 | Loss: 0.11312279850244522\n",
      "Batch：6810 | Loss: 0.09726011008024216\n",
      "Batch：6811 | Loss: 0.09191591292619705\n",
      "Batch：6812 | Loss: 0.0947573333978653\n",
      "Batch：6813 | Loss: 0.1015949472784996\n",
      "Batch：6814 | Loss: 0.08759936690330505\n",
      "Batch：6815 | Loss: 0.10199332237243652\n",
      "Batch：6816 | Loss: 0.10097648948431015\n",
      "Batch：6817 | Loss: 0.10072061419487\n",
      "Batch：6818 | Loss: 0.10771697014570236\n",
      "Batch：6819 | Loss: 0.09240143746137619\n",
      "Batch：6820 | Loss: 0.08739341795444489\n",
      "Batch：6821 | Loss: 0.09948799759149551\n",
      "Batch：6822 | Loss: 0.10101877897977829\n",
      "Batch：6823 | Loss: 0.10821464657783508\n",
      "Batch：6824 | Loss: 0.10019681602716446\n",
      "Batch：6825 | Loss: 0.09307193756103516\n",
      "Batch：6826 | Loss: 0.09946327656507492\n",
      "Batch：6827 | Loss: 0.11066261678934097\n",
      "Batch：6828 | Loss: 0.09876315295696259\n",
      "Batch：6829 | Loss: 0.09877286851406097\n",
      "Batch：6830 | Loss: 0.09431632608175278\n",
      "Batch：6831 | Loss: 0.11227262020111084\n",
      "Batch：6832 | Loss: 0.094118632376194\n",
      "Batch：6833 | Loss: 0.10120765119791031\n",
      "Batch：6834 | Loss: 0.1075393334031105\n",
      "Batch：6835 | Loss: 0.10299979895353317\n",
      "Batch：6836 | Loss: 0.10051608085632324\n",
      "Batch：6837 | Loss: 0.09975297749042511\n",
      "Batch：6838 | Loss: 0.09520013630390167\n",
      "Batch：6839 | Loss: 0.10032639652490616\n",
      "Batch：6840 | Loss: 0.10939685255289078\n",
      "Batch：6841 | Loss: 0.09695109724998474\n",
      "Batch：6842 | Loss: 0.101780965924263\n",
      "Batch：6843 | Loss: 0.10821570456027985\n",
      "Batch：6844 | Loss: 0.09538643062114716\n",
      "Batch：6845 | Loss: 0.09375328570604324\n",
      "Batch：6846 | Loss: 0.09550657123327255\n",
      "Batch：6847 | Loss: 0.09478411823511124\n",
      "Batch：6848 | Loss: 0.10350385308265686\n",
      "Batch：6849 | Loss: 0.09955599159002304\n",
      "Batch：6850 | Loss: 0.10972965508699417\n",
      "Batch：6851 | Loss: 0.09348153322935104\n",
      "Batch：6852 | Loss: 0.09983375668525696\n",
      "Batch：6853 | Loss: 0.09605681151151657\n",
      "Batch：6854 | Loss: 0.09470837563276291\n",
      "Batch：6855 | Loss: 0.09623167663812637\n",
      "Batch：6856 | Loss: 0.10179923474788666\n",
      "Batch：6857 | Loss: 0.1007591113448143\n",
      "Batch：6858 | Loss: 0.10342928022146225\n",
      "Batch：6859 | Loss: 0.11074697971343994\n",
      "Batch：6860 | Loss: 0.08766583353281021\n",
      "Batch：6861 | Loss: 0.10452217608690262\n",
      "Batch：6862 | Loss: 0.10103342682123184\n",
      "Batch：6863 | Loss: 0.0960308387875557\n",
      "Batch：6864 | Loss: 0.09953460842370987\n",
      "Batch：6865 | Loss: 0.10589614510536194\n",
      "Batch：6866 | Loss: 0.10651920735836029\n",
      "Batch：6867 | Loss: 0.10132072120904922\n",
      "Batch：6868 | Loss: 0.10273858904838562\n",
      "Batch：6869 | Loss: 0.09054426848888397\n",
      "Batch：6870 | Loss: 0.10399268567562103\n",
      "Batch：6871 | Loss: 0.10230696201324463\n",
      "Batch：6872 | Loss: 0.09640009701251984\n",
      "Batch：6873 | Loss: 0.09196628630161285\n",
      "Batch：6874 | Loss: 0.09409767389297485\n",
      "Batch：6875 | Loss: 0.105507493019104\n",
      "Batch：6876 | Loss: 0.1039557158946991\n",
      "Batch：6877 | Loss: 0.09450200945138931\n",
      "Batch：6878 | Loss: 0.09308690577745438\n",
      "Batch：6879 | Loss: 0.09270567446947098\n",
      "Batch：6880 | Loss: 0.10351192206144333\n",
      "Batch：6881 | Loss: 0.0985836610198021\n",
      "Batch：6882 | Loss: 0.09826719015836716\n",
      "Batch：6883 | Loss: 0.11412976682186127\n",
      "Batch：6884 | Loss: 0.09077490121126175\n",
      "Batch：6885 | Loss: 0.0948675125837326\n",
      "Batch：6886 | Loss: 0.0953882560133934\n",
      "Batch：6887 | Loss: 0.0936308205127716\n",
      "Batch：6888 | Loss: 0.09730791300535202\n",
      "Batch：6889 | Loss: 0.09425538778305054\n",
      "Batch：6890 | Loss: 0.1082170158624649\n",
      "Batch：6891 | Loss: 0.11350636929273605\n",
      "Batch：6892 | Loss: 0.0912124440073967\n",
      "Batch：6893 | Loss: 0.09837594628334045\n",
      "Batch：6894 | Loss: 0.09382690489292145\n",
      "Batch：6895 | Loss: 0.10599391907453537\n",
      "Batch：6896 | Loss: 0.09489896893501282\n",
      "Batch：6897 | Loss: 0.10861144214868546\n",
      "Batch：6898 | Loss: 0.08345774561166763\n",
      "Batch：6899 | Loss: 0.09417075663805008\n",
      "Batch：6900 | Loss: 0.09646760672330856\n",
      "Batch：6901 | Loss: 0.10573402792215347\n",
      "Batch：6902 | Loss: 0.11541374772787094\n",
      "Batch：6903 | Loss: 0.09841342270374298\n",
      "Batch：6904 | Loss: 0.09478247165679932\n",
      "Batch：6905 | Loss: 0.10362563282251358\n",
      "Batch：6906 | Loss: 0.10371142625808716\n",
      "Batch：6907 | Loss: 0.1034349650144577\n",
      "Batch：6908 | Loss: 0.1009511724114418\n",
      "Batch：6909 | Loss: 0.10052952170372009\n",
      "Batch：6910 | Loss: 0.09406164288520813\n",
      "Batch：6911 | Loss: 0.10383030027151108\n",
      "Batch：6912 | Loss: 0.08861692249774933\n",
      "Batch：6913 | Loss: 0.09649702161550522\n",
      "Batch：6914 | Loss: 0.1151406317949295\n",
      "Batch：6915 | Loss: 0.1022142544388771\n",
      "Batch：6916 | Loss: 0.102013498544693\n",
      "Batch：6917 | Loss: 0.11319287121295929\n",
      "Batch：6918 | Loss: 0.10050671547651291\n",
      "Batch：6919 | Loss: 0.09566216915845871\n",
      "Batch：6920 | Loss: 0.09231970459222794\n",
      "Batch：6921 | Loss: 0.10138572007417679\n",
      "Batch：6922 | Loss: 0.10609708726406097\n",
      "Batch：6923 | Loss: 0.09282451122999191\n",
      "Batch：6924 | Loss: 0.09866449236869812\n",
      "Batch：6925 | Loss: 0.1130627915263176\n",
      "Batch：6926 | Loss: 0.09984446316957474\n",
      "Batch：6927 | Loss: 0.09631559252738953\n",
      "Batch：6928 | Loss: 0.09341487288475037\n",
      "Batch：6929 | Loss: 0.08756822347640991\n",
      "Batch：6930 | Loss: 0.0972207635641098\n",
      "Batch：6931 | Loss: 0.0879644900560379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：6932 | Loss: 0.10865466296672821\n",
      "Batch：6933 | Loss: 0.10706708580255508\n",
      "Batch：6934 | Loss: 0.09380234032869339\n",
      "Batch：6935 | Loss: 0.09299557656049728\n",
      "Batch：6936 | Loss: 0.10824190825223923\n",
      "Batch：6937 | Loss: 0.10257264226675034\n",
      "Batch：6938 | Loss: 0.09058066457509995\n",
      "Batch：6939 | Loss: 0.09863349050283432\n",
      "Batch：6940 | Loss: 0.09428846091032028\n",
      "Batch：6941 | Loss: 0.09797588735818863\n",
      "Batch：6942 | Loss: 0.10545725375413895\n",
      "Batch：6943 | Loss: 0.09301329404115677\n",
      "Batch：6944 | Loss: 0.10420235246419907\n",
      "Batch：6945 | Loss: 0.10750476270914078\n",
      "Batch：6946 | Loss: 0.10446612536907196\n",
      "Batch：6947 | Loss: 0.11069688946008682\n",
      "Batch：6948 | Loss: 0.09448321163654327\n",
      "Batch：6949 | Loss: 0.09787750989198685\n",
      "Batch：6950 | Loss: 0.09078581631183624\n",
      "Batch：6951 | Loss: 0.09842631220817566\n",
      "Batch：6952 | Loss: 0.09452167898416519\n",
      "Batch：6953 | Loss: 0.0862765684723854\n",
      "Batch：6954 | Loss: 0.08648860454559326\n",
      "Batch：6955 | Loss: 0.09645918756723404\n",
      "Batch：6956 | Loss: 0.09446053206920624\n",
      "Batch：6957 | Loss: 0.08726997673511505\n",
      "Batch：6958 | Loss: 0.09625201672315598\n",
      "Batch：6959 | Loss: 0.09401550889015198\n",
      "Batch：6960 | Loss: 0.0999385342001915\n",
      "Batch：6961 | Loss: 0.10509728640317917\n",
      "Batch：6962 | Loss: 0.09863409399986267\n",
      "Batch：6963 | Loss: 0.09529848396778107\n",
      "Batch：6964 | Loss: 0.10473410785198212\n",
      "Batch：6965 | Loss: 0.09181085973978043\n",
      "Batch：6966 | Loss: 0.1004369705915451\n",
      "Batch：6967 | Loss: 0.10122641921043396\n",
      "Batch：6968 | Loss: 0.1052696704864502\n",
      "Batch：6969 | Loss: 0.1090158075094223\n",
      "Batch：6970 | Loss: 0.0933695137500763\n",
      "Batch：6971 | Loss: 0.0952976793050766\n",
      "Batch：6972 | Loss: 0.09788569062948227\n",
      "Batch：6973 | Loss: 0.10862882435321808\n",
      "Batch：6974 | Loss: 0.09146196395158768\n",
      "Batch：6975 | Loss: 0.09855031222105026\n",
      "Batch：6976 | Loss: 0.10033982247114182\n",
      "Batch：6977 | Loss: 0.10227515548467636\n",
      "Batch：6978 | Loss: 0.0878484696149826\n",
      "Batch：6979 | Loss: 0.09028491377830505\n",
      "Batch：6980 | Loss: 0.10379304736852646\n",
      "Batch：6981 | Loss: 0.09599619358778\n",
      "Batch：6982 | Loss: 0.0988449901342392\n",
      "Batch：6983 | Loss: 0.09532216936349869\n",
      "Batch：6984 | Loss: 0.11291426420211792\n",
      "Batch：6985 | Loss: 0.08673209697008133\n",
      "Batch：6986 | Loss: 0.08474606275558472\n",
      "Batch：6987 | Loss: 0.09811419248580933\n",
      "Batch：6988 | Loss: 0.08961958438158035\n",
      "Batch：6989 | Loss: 0.09879565238952637\n",
      "Batch：6990 | Loss: 0.10485996305942535\n",
      "Batch：6991 | Loss: 0.09209815412759781\n",
      "Batch：6992 | Loss: 0.10526036471128464\n",
      "Batch：6993 | Loss: 0.10026473551988602\n",
      "Batch：6994 | Loss: 0.09547154605388641\n",
      "Batch：6995 | Loss: 0.10222035646438599\n",
      "Batch：6996 | Loss: 0.104261614382267\n",
      "Batch：6997 | Loss: 0.09478458762168884\n",
      "Batch：6998 | Loss: 0.10214594751596451\n",
      "Batch：6999 | Loss: 0.08908665180206299\n",
      "Batch：7000 | Loss: 0.09521856904029846\n",
      "Batch：7001 | Loss: 0.09116160124540329\n",
      "Batch：7002 | Loss: 0.09184671193361282\n",
      "Batch：7003 | Loss: 0.1019621342420578\n",
      "Batch：7004 | Loss: 0.09365641325712204\n",
      "Batch：7005 | Loss: 0.11426720768213272\n",
      "Batch：7006 | Loss: 0.09903430193662643\n",
      "Batch：7007 | Loss: 0.09662601351737976\n",
      "Batch：7008 | Loss: 0.10364700853824615\n",
      "Batch：7009 | Loss: 0.11550024151802063\n",
      "Batch：7010 | Loss: 0.1086333617568016\n",
      "Batch：7011 | Loss: 0.10379935801029205\n",
      "Batch：7012 | Loss: 0.10106004029512405\n",
      "Batch：7013 | Loss: 0.09099081158638\n",
      "Batch：7014 | Loss: 0.09483073651790619\n",
      "Batch：7015 | Loss: 0.09341367334127426\n",
      "Batch：7016 | Loss: 0.10533522069454193\n",
      "Batch：7017 | Loss: 0.09004559367895126\n",
      "Batch：7018 | Loss: 0.10628601908683777\n",
      "Batch：7019 | Loss: 0.09296528995037079\n",
      "Batch：7020 | Loss: 0.09337304532527924\n",
      "Batch：7021 | Loss: 0.10459653288125992\n",
      "Batch：7022 | Loss: 0.09347547590732574\n",
      "Batch：7023 | Loss: 0.09304040670394897\n",
      "Batch：7024 | Loss: 0.10135219991207123\n",
      "Batch：7025 | Loss: 0.09989935159683228\n",
      "Batch：7026 | Loss: 0.09287746250629425\n",
      "Batch：7027 | Loss: 0.10316938906908035\n",
      "Batch：7028 | Loss: 0.09769966453313828\n",
      "Batch：7029 | Loss: 0.10262685269117355\n",
      "Batch：7030 | Loss: 0.0981978103518486\n",
      "Batch：7031 | Loss: 0.09720554202795029\n",
      "Batch：7032 | Loss: 0.09617482125759125\n",
      "Batch：7033 | Loss: 0.10672193020582199\n",
      "Batch：7034 | Loss: 0.10057874768972397\n",
      "Batch：7035 | Loss: 0.08017191290855408\n",
      "Batch：7036 | Loss: 0.10110733658075333\n",
      "Batch：7037 | Loss: 0.09884896874427795\n",
      "Batch：7038 | Loss: 0.09281734377145767\n",
      "Batch：7039 | Loss: 0.08583931624889374\n",
      "Batch：7040 | Loss: 0.11051905900239944\n",
      "Batch：7041 | Loss: 0.09656418859958649\n",
      "Batch：7042 | Loss: 0.0969628095626831\n",
      "Batch：7043 | Loss: 0.09578827023506165\n",
      "Batch：7044 | Loss: 0.10178026556968689\n",
      "Batch：7045 | Loss: 0.10531970113515854\n",
      "Batch：7046 | Loss: 0.0954054445028305\n",
      "Batch：7047 | Loss: 0.09536246955394745\n",
      "Batch：7048 | Loss: 0.09916450828313828\n",
      "Batch：7049 | Loss: 0.1084970012307167\n",
      "Batch：7050 | Loss: 0.10569725185632706\n",
      "Batch：7051 | Loss: 0.10885698348283768\n",
      "Batch：7052 | Loss: 0.09228448569774628\n",
      "Batch：7053 | Loss: 0.08405546098947525\n",
      "Batch：7054 | Loss: 0.09301076084375381\n",
      "Batch：7055 | Loss: 0.09136229008436203\n",
      "Batch：7056 | Loss: 0.09337008744478226\n",
      "Batch：7057 | Loss: 0.07881790399551392\n",
      "Batch：7058 | Loss: 0.10544783622026443\n",
      "Batch：7059 | Loss: 0.09957221150398254\n",
      "Batch：7060 | Loss: 0.09205219149589539\n",
      "Batch：7061 | Loss: 0.09897196292877197\n",
      "Batch：7062 | Loss: 0.1000734269618988\n",
      "Batch：7063 | Loss: 0.1036144569516182\n",
      "Batch：7064 | Loss: 0.10996990650892258\n",
      "Batch：7065 | Loss: 0.0916365310549736\n",
      "Batch：7066 | Loss: 0.09197040647268295\n",
      "Batch：7067 | Loss: 0.09611915051937103\n",
      "Batch：7068 | Loss: 0.10308261960744858\n",
      "Batch：7069 | Loss: 0.10390118509531021\n",
      "Batch：7070 | Loss: 0.10563135892152786\n",
      "Batch：7071 | Loss: 0.10064780712127686\n",
      "Batch：7072 | Loss: 0.10180605202913284\n",
      "Batch：7073 | Loss: 0.0996762290596962\n",
      "Batch：7074 | Loss: 0.09263372421264648\n",
      "Batch：7075 | Loss: 0.09049008041620255\n",
      "Batch：7076 | Loss: 0.09404370188713074\n",
      "Batch：7077 | Loss: 0.09866926819086075\n",
      "Batch：7078 | Loss: 0.11402294784784317\n",
      "Batch：7079 | Loss: 0.09119931608438492\n",
      "Batch：7080 | Loss: 0.0868331715464592\n",
      "Batch：7081 | Loss: 0.10046304017305374\n",
      "Batch：7082 | Loss: 0.1110931783914566\n",
      "Batch：7083 | Loss: 0.10800743848085403\n",
      "Batch：7084 | Loss: 0.10582273453474045\n",
      "Batch：7085 | Loss: 0.10495519638061523\n",
      "Batch：7086 | Loss: 0.10299067199230194\n",
      "Batch：7087 | Loss: 0.10840874165296555\n",
      "Batch：7088 | Loss: 0.09832005947828293\n",
      "Batch：7089 | Loss: 0.10508992522954941\n",
      "Batch：7090 | Loss: 0.08581197261810303\n",
      "Batch：7091 | Loss: 0.09522102028131485\n",
      "Batch：7092 | Loss: 0.08503470569849014\n",
      "Batch：7093 | Loss: 0.09713392704725266\n",
      "Batch：7094 | Loss: 0.09654141217470169\n",
      "Batch：7095 | Loss: 0.10923505574464798\n",
      "Batch：7096 | Loss: 0.09342032670974731\n",
      "Batch：7097 | Loss: 0.08369122445583344\n",
      "Batch：7098 | Loss: 0.10486169159412384\n",
      "Batch：7099 | Loss: 0.09591910988092422\n",
      "Batch：7100 | Loss: 0.0933678150177002\n",
      "Batch：7101 | Loss: 0.094364233314991\n",
      "Batch：7102 | Loss: 0.09421265870332718\n",
      "Batch：7103 | Loss: 0.0861518457531929\n",
      "Batch：7104 | Loss: 0.10699649900197983\n",
      "Batch：7105 | Loss: 0.10209774971008301\n",
      "Batch：7106 | Loss: 0.09605954587459564\n",
      "Batch：7107 | Loss: 0.10087036341428757\n",
      "Batch：7108 | Loss: 0.08689883351325989\n",
      "Batch：7109 | Loss: 0.09732769429683685\n",
      "Batch：7110 | Loss: 0.10018743574619293\n",
      "Batch：7111 | Loss: 0.08570212870836258\n",
      "Batch：7112 | Loss: 0.10616854578256607\n",
      "Batch：7113 | Loss: 0.08948347717523575\n",
      "Batch：7114 | Loss: 0.09109915792942047\n",
      "Batch：7115 | Loss: 0.09714410454034805\n",
      "Batch：7116 | Loss: 0.09487200528383255\n",
      "Batch：7117 | Loss: 0.10025028139352798\n",
      "Batch：7118 | Loss: 0.08722615242004395\n",
      "Batch：7119 | Loss: 0.10039571672677994\n",
      "Batch：7120 | Loss: 0.101389080286026\n",
      "Batch：7121 | Loss: 0.0962052196264267\n",
      "Batch：7122 | Loss: 0.09929873794317245\n",
      "Batch：7123 | Loss: 0.10400368273258209\n",
      "Batch：7124 | Loss: 0.09339115023612976\n",
      "Batch：7125 | Loss: 0.10867683589458466\n",
      "Batch：7126 | Loss: 0.08650686591863632\n",
      "Batch：7127 | Loss: 0.0997844859957695\n",
      "Batch：7128 | Loss: 0.09580603986978531\n",
      "Batch：7129 | Loss: 0.10130513459444046\n",
      "Batch：7130 | Loss: 0.09754353761672974\n",
      "Batch：7131 | Loss: 0.09648311138153076\n",
      "Batch：7132 | Loss: 0.09779123961925507\n",
      "Batch：7133 | Loss: 0.10907068103551865\n",
      "Batch：7134 | Loss: 0.10014484822750092\n",
      "Batch：7135 | Loss: 0.09190171957015991\n",
      "Batch：7136 | Loss: 0.10047322511672974\n",
      "Batch：7137 | Loss: 0.09373649209737778\n",
      "Batch：7138 | Loss: 0.08371255546808243\n",
      "Batch：7139 | Loss: 0.0986940935254097\n",
      "Batch：7140 | Loss: 0.09433117508888245\n",
      "Batch：7141 | Loss: 0.10421004891395569\n",
      "Batch：7142 | Loss: 0.09000489115715027\n",
      "Batch：7143 | Loss: 0.09030784666538239\n",
      "Batch：7144 | Loss: 0.10351226478815079\n",
      "Batch：7145 | Loss: 0.0817762166261673\n",
      "Batch：7146 | Loss: 0.0926952213048935\n",
      "Batch：7147 | Loss: 0.09418760240077972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：7148 | Loss: 0.08019547909498215\n",
      "Batch：7149 | Loss: 0.08985770493745804\n",
      "Batch：7150 | Loss: 0.09416463226079941\n",
      "Batch：7151 | Loss: 0.10528603941202164\n",
      "Batch：7152 | Loss: 0.10745816677808762\n",
      "Batch：7153 | Loss: 0.10677913576364517\n",
      "Batch：7154 | Loss: 0.10942818969488144\n",
      "Batch：7155 | Loss: 0.10990878939628601\n",
      "Batch：7156 | Loss: 0.08794297277927399\n",
      "Batch：7157 | Loss: 0.10312911123037338\n",
      "Batch：7158 | Loss: 0.09890254586935043\n",
      "Batch：7159 | Loss: 0.09681501239538193\n",
      "Batch：7160 | Loss: 0.09211558848619461\n",
      "Batch：7161 | Loss: 0.08888942003250122\n",
      "Batch：7162 | Loss: 0.09554959833621979\n",
      "Batch：7163 | Loss: 0.1166466698050499\n",
      "Batch：7164 | Loss: 0.1121574118733406\n",
      "Batch：7165 | Loss: 0.08620806783437729\n",
      "Batch：7166 | Loss: 0.097127765417099\n",
      "Batch：7167 | Loss: 0.10681049525737762\n",
      "Batch：7168 | Loss: 0.08986401557922363\n",
      "Batch：7169 | Loss: 0.08964257687330246\n",
      "Batch：7170 | Loss: 0.09257619082927704\n",
      "Batch：7171 | Loss: 0.10255540907382965\n",
      "Batch：7172 | Loss: 0.08741212636232376\n",
      "Batch：7173 | Loss: 0.09731394052505493\n",
      "Batch：7174 | Loss: 0.10228128731250763\n",
      "Batch：7175 | Loss: 0.09247218817472458\n",
      "Batch：7176 | Loss: 0.08957347273826599\n",
      "Batch：7177 | Loss: 0.09714753925800323\n",
      "Batch：7178 | Loss: 0.11043044179677963\n",
      "Batch：7179 | Loss: 0.10569153726100922\n",
      "Batch：7180 | Loss: 0.0890362560749054\n",
      "Batch：7181 | Loss: 0.09732946753501892\n",
      "Batch：7182 | Loss: 0.09403538703918457\n",
      "Batch：7183 | Loss: 0.09331398457288742\n",
      "Batch：7184 | Loss: 0.10258862376213074\n",
      "Batch：7185 | Loss: 0.08851765841245651\n",
      "Batch：7186 | Loss: 0.09640166908502579\n",
      "Batch：7187 | Loss: 0.0950612872838974\n",
      "Batch：7188 | Loss: 0.09584683924913406\n",
      "Batch：7189 | Loss: 0.08782029151916504\n",
      "Batch：7190 | Loss: 0.09845536947250366\n",
      "Batch：7191 | Loss: 0.09564276039600372\n",
      "Batch：7192 | Loss: 0.10027626156806946\n",
      "Batch：7193 | Loss: 0.09351976215839386\n",
      "Batch：7194 | Loss: 0.09137066453695297\n",
      "Batch：7195 | Loss: 0.08980420976877213\n",
      "Batch：7196 | Loss: 0.10380053520202637\n",
      "Batch：7197 | Loss: 0.10445450991392136\n",
      "Batch：7198 | Loss: 0.09611302614212036\n",
      "Batch：7199 | Loss: 0.12023446708917618\n",
      "Batch：7200 | Loss: 0.08937159925699234\n",
      "Batch：7201 | Loss: 0.09239456802606583\n",
      "Batch：7202 | Loss: 0.10017342865467072\n",
      "Batch：7203 | Loss: 0.10260739922523499\n",
      "Batch：7204 | Loss: 0.09870868921279907\n",
      "Batch：7205 | Loss: 0.08998648822307587\n",
      "Batch：7206 | Loss: 0.08205430209636688\n",
      "Batch：7207 | Loss: 0.09349334985017776\n",
      "Batch：7208 | Loss: 0.09328313916921616\n",
      "Batch：7209 | Loss: 0.09175586700439453\n",
      "Batch：7210 | Loss: 0.08279167115688324\n",
      "Batch：7211 | Loss: 0.09359811246395111\n",
      "Batch：7212 | Loss: 0.09942331910133362\n",
      "Batch：7213 | Loss: 0.09756851941347122\n",
      "Batch：7214 | Loss: 0.09660813212394714\n",
      "Batch：7215 | Loss: 0.08986318111419678\n",
      "Batch：7216 | Loss: 0.08983083814382553\n",
      "Batch：7217 | Loss: 0.09732474386692047\n",
      "Batch：7218 | Loss: 0.09098086506128311\n",
      "Batch：7219 | Loss: 0.10042691230773926\n",
      "Batch：7220 | Loss: 0.10024011880159378\n",
      "Batch：7221 | Loss: 0.09526397287845612\n",
      "Batch：7222 | Loss: 0.10293830186128616\n",
      "Batch：7223 | Loss: 0.09883006662130356\n",
      "Batch：7224 | Loss: 0.1073039248585701\n",
      "Batch：7225 | Loss: 0.08720823377370834\n",
      "Batch：7226 | Loss: 0.09855729341506958\n",
      "Batch：7227 | Loss: 0.09575723856687546\n",
      "Batch：7228 | Loss: 0.09687520563602448\n",
      "Batch：7229 | Loss: 0.09422165155410767\n",
      "Batch：7230 | Loss: 0.09050719439983368\n",
      "Batch：7231 | Loss: 0.1030026227235794\n",
      "Batch：7232 | Loss: 0.0875721201300621\n",
      "Batch：7233 | Loss: 0.10739259421825409\n",
      "Batch：7234 | Loss: 0.08550697565078735\n",
      "Batch：7235 | Loss: 0.08959861099720001\n",
      "Batch：7236 | Loss: 0.09116112440824509\n",
      "Batch：7237 | Loss: 0.09086517244577408\n",
      "Batch：7238 | Loss: 0.0972350463271141\n",
      "Batch：7239 | Loss: 0.0828530490398407\n",
      "Batch：7240 | Loss: 0.09381832927465439\n",
      "Batch：7241 | Loss: 0.09210491925477982\n",
      "Batch：7242 | Loss: 0.09877866506576538\n",
      "Batch：7243 | Loss: 0.08963409066200256\n",
      "Batch：7244 | Loss: 0.09997063875198364\n",
      "Batch：7245 | Loss: 0.09780163317918777\n",
      "Batch：7246 | Loss: 0.0834684818983078\n",
      "Batch：7247 | Loss: 0.09260788559913635\n",
      "Batch：7248 | Loss: 0.0850737988948822\n",
      "Batch：7249 | Loss: 0.09919247031211853\n",
      "Batch：7250 | Loss: 0.08995839208364487\n",
      "Batch：7251 | Loss: 0.09238355606794357\n",
      "Batch：7252 | Loss: 0.11055104434490204\n",
      "Batch：7253 | Loss: 0.0909651443362236\n",
      "Batch：7254 | Loss: 0.10305675864219666\n",
      "Batch：7255 | Loss: 0.08991969376802444\n",
      "Batch：7256 | Loss: 0.09582767635583878\n",
      "Batch：7257 | Loss: 0.09227336198091507\n",
      "Batch：7258 | Loss: 0.08832378685474396\n",
      "Batch：7259 | Loss: 0.0915348082780838\n",
      "Batch：7260 | Loss: 0.09445814043283463\n",
      "Batch：7261 | Loss: 0.08984413743019104\n",
      "Batch：7262 | Loss: 0.10201677680015564\n",
      "Batch：7263 | Loss: 0.0921441838145256\n",
      "Batch：7264 | Loss: 0.09114113450050354\n",
      "Batch：7265 | Loss: 0.10139545798301697\n",
      "Batch：7266 | Loss: 0.09297135472297668\n",
      "Batch：7267 | Loss: 0.0987483486533165\n",
      "Batch：7268 | Loss: 0.08512337505817413\n",
      "Batch：7269 | Loss: 0.09435722976922989\n",
      "Batch：7270 | Loss: 0.09508516639471054\n",
      "Batch：7271 | Loss: 0.08902760595083237\n",
      "Batch：7272 | Loss: 0.09562352299690247\n",
      "Batch：7273 | Loss: 0.09995696693658829\n",
      "Batch：7274 | Loss: 0.09711854159832001\n",
      "Batch：7275 | Loss: 0.08905342221260071\n",
      "Batch：7276 | Loss: 0.0915398821234703\n",
      "Batch：7277 | Loss: 0.09413950145244598\n",
      "Batch：7278 | Loss: 0.0948229730129242\n",
      "Batch：7279 | Loss: 0.09093235433101654\n",
      "Batch：7280 | Loss: 0.10350365936756134\n",
      "Batch：7281 | Loss: 0.10029660910367966\n",
      "Batch：7282 | Loss: 0.1060817539691925\n",
      "Batch：7283 | Loss: 0.09566245228052139\n",
      "Batch：7284 | Loss: 0.10167651623487473\n",
      "Batch：7285 | Loss: 0.08388759940862656\n",
      "Batch：7286 | Loss: 0.08656298369169235\n",
      "Batch：7287 | Loss: 0.09225459396839142\n",
      "Batch：7288 | Loss: 0.09548135101795197\n",
      "Batch：7289 | Loss: 0.09370546042919159\n",
      "Batch：7290 | Loss: 0.07902586460113525\n",
      "Batch：7291 | Loss: 0.08735281974077225\n",
      "Batch：7292 | Loss: 0.09923520684242249\n",
      "Batch：7293 | Loss: 0.09920704364776611\n",
      "Batch：7294 | Loss: 0.09015337377786636\n",
      "Batch：7295 | Loss: 0.09300099313259125\n",
      "Batch：7296 | Loss: 0.08906683325767517\n",
      "Batch：7297 | Loss: 0.09429074823856354\n",
      "Batch：7298 | Loss: 0.09601456671953201\n",
      "Batch：7299 | Loss: 0.0905839204788208\n",
      "Batch：7300 | Loss: 0.09595673531293869\n",
      "Batch：7301 | Loss: 0.09972265362739563\n",
      "Batch：7302 | Loss: 0.0913035050034523\n",
      "Batch：7303 | Loss: 0.09763731062412262\n",
      "Batch：7304 | Loss: 0.07414859533309937\n",
      "Batch：7305 | Loss: 0.10425626486539841\n",
      "Batch：7306 | Loss: 0.10091754049062729\n",
      "Batch：7307 | Loss: 0.09475540369749069\n",
      "Batch：7308 | Loss: 0.08727969974279404\n",
      "Batch：7309 | Loss: 0.10804000496864319\n",
      "Batch：7310 | Loss: 0.09476570785045624\n",
      "Batch：7311 | Loss: 0.08808105438947678\n",
      "Batch：7312 | Loss: 0.09943678975105286\n",
      "Batch：7313 | Loss: 0.09438358247280121\n",
      "Batch：7314 | Loss: 0.09794659167528152\n",
      "Batch：7315 | Loss: 0.08092065155506134\n",
      "Batch：7316 | Loss: 0.09025518596172333\n",
      "Batch：7317 | Loss: 0.07840441167354584\n",
      "Batch：7318 | Loss: 0.08046620339155197\n",
      "Batch：7319 | Loss: 0.09434523433446884\n",
      "Batch：7320 | Loss: 0.08479780703783035\n",
      "Batch：7321 | Loss: 0.09095413982868195\n",
      "Batch：7322 | Loss: 0.08593359589576721\n",
      "Batch：7323 | Loss: 0.09771113842725754\n",
      "Batch：7324 | Loss: 0.08608318865299225\n",
      "Batch：7325 | Loss: 0.11008044332265854\n",
      "Batch：7326 | Loss: 0.09233686327934265\n",
      "Batch：7327 | Loss: 0.10481429100036621\n",
      "Batch：7328 | Loss: 0.09296586364507675\n",
      "Batch：7329 | Loss: 0.08448835462331772\n",
      "Batch：7330 | Loss: 0.09752140939235687\n",
      "Batch：7331 | Loss: 0.08618985116481781\n",
      "Batch：7332 | Loss: 0.09640499949455261\n",
      "Batch：7333 | Loss: 0.09821225702762604\n",
      "Batch：7334 | Loss: 0.09665587544441223\n",
      "Batch：7335 | Loss: 0.07298213988542557\n",
      "Batch：7336 | Loss: 0.10322336852550507\n",
      "Batch：7337 | Loss: 0.09368360042572021\n",
      "Batch：7338 | Loss: 0.09919087588787079\n",
      "Batch：7339 | Loss: 0.0854979008436203\n",
      "Batch：7340 | Loss: 0.100181944668293\n",
      "Batch：7341 | Loss: 0.10494038462638855\n",
      "Batch：7342 | Loss: 0.08373669534921646\n",
      "Batch：7343 | Loss: 0.0954667329788208\n",
      "Batch：7344 | Loss: 0.09105585515499115\n",
      "Batch：7345 | Loss: 0.09531880915164948\n",
      "Batch：7346 | Loss: 0.10276976227760315\n",
      "Batch：7347 | Loss: 0.09364375472068787\n",
      "Batch：7348 | Loss: 0.10080279409885406\n",
      "Batch：7349 | Loss: 0.10138848423957825\n",
      "Batch：7350 | Loss: 0.07878178358078003\n",
      "Batch：7351 | Loss: 0.08649680763483047\n",
      "Batch：7352 | Loss: 0.09259983152151108\n",
      "Batch：7353 | Loss: 0.10066583007574081\n",
      "Batch：7354 | Loss: 0.10833648592233658\n",
      "Batch：7355 | Loss: 0.10893648117780685\n",
      "Batch：7356 | Loss: 0.08999834954738617\n",
      "Batch：7357 | Loss: 0.09475159645080566\n",
      "Batch：7358 | Loss: 0.0970706194639206\n",
      "Batch：7359 | Loss: 0.08605177700519562\n",
      "Batch：7360 | Loss: 0.09035668522119522\n",
      "Batch：7361 | Loss: 0.09745856374502182\n",
      "Batch：7362 | Loss: 0.09290172904729843\n",
      "Batch：7363 | Loss: 0.09193674474954605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：7364 | Loss: 0.1014009565114975\n",
      "Batch：7365 | Loss: 0.09784682095050812\n",
      "Batch：7366 | Loss: 0.09388629347085953\n",
      "Batch：7367 | Loss: 0.07733938843011856\n",
      "Batch：7368 | Loss: 0.09301741421222687\n",
      "Batch：7369 | Loss: 0.09030881524085999\n",
      "Batch：7370 | Loss: 0.09550438076257706\n",
      "Batch：7371 | Loss: 0.0900011658668518\n",
      "Batch：7372 | Loss: 0.08955887705087662\n",
      "Batch：7373 | Loss: 0.0937812477350235\n",
      "Batch：7374 | Loss: 0.08661529421806335\n",
      "Batch：7375 | Loss: 0.08422254770994186\n",
      "Batch：7376 | Loss: 0.08366239070892334\n",
      "Batch：7377 | Loss: 0.09125524759292603\n",
      "Batch：7378 | Loss: 0.09460029751062393\n",
      "Batch：7379 | Loss: 0.08986784517765045\n",
      "Batch：7380 | Loss: 0.0991465374827385\n",
      "Batch：7381 | Loss: 0.09355529397726059\n",
      "Batch：7382 | Loss: 0.0871850997209549\n",
      "Batch：7383 | Loss: 0.08515370637178421\n",
      "Batch：7384 | Loss: 0.09609904140233994\n",
      "Batch：7385 | Loss: 0.07927201688289642\n",
      "Batch：7386 | Loss: 0.08746059238910675\n",
      "Batch：7387 | Loss: 0.09780379384756088\n",
      "Batch：7388 | Loss: 0.09766235202550888\n",
      "Batch：7389 | Loss: 0.09477460384368896\n",
      "Batch：7390 | Loss: 0.09668771177530289\n",
      "Batch：7391 | Loss: 0.09595242887735367\n",
      "Batch：7392 | Loss: 0.10410478711128235\n",
      "Batch：7393 | Loss: 0.08187668025493622\n",
      "Batch：7394 | Loss: 0.09718570858240128\n",
      "Batch：7395 | Loss: 0.08549273759126663\n",
      "Batch：7396 | Loss: 0.10824509710073471\n",
      "Batch：7397 | Loss: 0.09235741943120956\n",
      "Batch：7398 | Loss: 0.09826766699552536\n",
      "Batch：7399 | Loss: 0.10823335498571396\n",
      "Batch：7400 | Loss: 0.08238782733678818\n",
      "Batch：7401 | Loss: 0.11034119874238968\n",
      "Batch：7402 | Loss: 0.09311317652463913\n",
      "Batch：7403 | Loss: 0.08843677490949631\n",
      "Batch：7404 | Loss: 0.08910054713487625\n",
      "Batch：7405 | Loss: 0.08278201520442963\n",
      "Batch：7406 | Loss: 0.09213480353355408\n",
      "Batch：7407 | Loss: 0.08984710276126862\n",
      "Batch：7408 | Loss: 0.09977941960096359\n",
      "Batch：7409 | Loss: 0.08501390367746353\n",
      "Batch：7410 | Loss: 0.09377502650022507\n",
      "Batch：7411 | Loss: 0.09021338075399399\n",
      "Batch：7412 | Loss: 0.08594604581594467\n",
      "Batch：7413 | Loss: 0.10169050842523575\n",
      "Batch：7414 | Loss: 0.09403129667043686\n",
      "Batch：7415 | Loss: 0.07993396371603012\n",
      "Batch：7416 | Loss: 0.09511277079582214\n",
      "Batch：7417 | Loss: 0.08610471338033676\n",
      "Batch：7418 | Loss: 0.08547743409872055\n",
      "Batch：7419 | Loss: 0.10001768916845322\n",
      "Batch：7420 | Loss: 0.08446747064590454\n",
      "Batch：7421 | Loss: 0.08916900306940079\n",
      "Batch：7422 | Loss: 0.0859469398856163\n",
      "Batch：7423 | Loss: 0.09922625869512558\n",
      "Batch：7424 | Loss: 0.0964171513915062\n",
      "Batch：7425 | Loss: 0.08420808613300323\n",
      "Batch：7426 | Loss: 0.08212593197822571\n",
      "Batch：7427 | Loss: 0.08420669287443161\n",
      "Batch：7428 | Loss: 0.09510538727045059\n",
      "Batch：7429 | Loss: 0.08401884883642197\n",
      "Batch：7430 | Loss: 0.08104360103607178\n",
      "Batch：7431 | Loss: 0.09571576118469238\n",
      "Batch：7432 | Loss: 0.09065484255552292\n",
      "Batch：7433 | Loss: 0.09264758229255676\n",
      "Batch：7434 | Loss: 0.10205401480197906\n",
      "Batch：7435 | Loss: 0.09177644550800323\n",
      "Batch：7436 | Loss: 0.09248034656047821\n",
      "Batch：7437 | Loss: 0.11157282441854477\n",
      "Batch：7438 | Loss: 0.08969300985336304\n",
      "Batch：7439 | Loss: 0.08415655791759491\n",
      "Batch：7440 | Loss: 0.09900089353322983\n",
      "Batch：7441 | Loss: 0.09448930621147156\n",
      "Batch：7442 | Loss: 0.0972195416688919\n",
      "Batch：7443 | Loss: 0.09989021718502045\n",
      "Batch：7444 | Loss: 0.09020839631557465\n",
      "Batch：7445 | Loss: 0.09186849743127823\n",
      "Batch：7446 | Loss: 0.08777054399251938\n",
      "Batch：7447 | Loss: 0.09186161309480667\n",
      "Batch：7448 | Loss: 0.09389709681272507\n",
      "Batch：7449 | Loss: 0.09182047098875046\n",
      "Batch：7450 | Loss: 0.0883919894695282\n",
      "Batch：7451 | Loss: 0.10679259896278381\n",
      "Batch：7452 | Loss: 0.08411496877670288\n",
      "Batch：7453 | Loss: 0.0833345353603363\n",
      "Batch：7454 | Loss: 0.09950612485408783\n",
      "Batch：7455 | Loss: 0.10223276913166046\n",
      "Batch：7456 | Loss: 0.09418362379074097\n",
      "Batch：7457 | Loss: 0.10252924263477325\n",
      "Batch：7458 | Loss: 0.0753154531121254\n",
      "Batch：7459 | Loss: 0.10067358613014221\n",
      "Batch：7460 | Loss: 0.09562978893518448\n",
      "Batch：7461 | Loss: 0.08919265866279602\n",
      "Batch：7462 | Loss: 0.08649458736181259\n",
      "Batch：7463 | Loss: 0.09622381627559662\n",
      "Batch：7464 | Loss: 0.08736816048622131\n",
      "Batch：7465 | Loss: 0.09657841175794601\n",
      "Batch：7466 | Loss: 0.09099157899618149\n",
      "Batch：7467 | Loss: 0.10215876251459122\n",
      "Batch：7468 | Loss: 0.09452357888221741\n",
      "Batch：7469 | Loss: 0.08205288648605347\n",
      "Batch：7470 | Loss: 0.09535115212202072\n",
      "Batch：7471 | Loss: 0.09079534560441971\n",
      "Batch：7472 | Loss: 0.10172335058450699\n",
      "Batch：7473 | Loss: 0.09601401537656784\n",
      "Batch：7474 | Loss: 0.10683252662420273\n",
      "Batch：7475 | Loss: 0.08642257750034332\n",
      "Batch：7476 | Loss: 0.09061412513256073\n",
      "Batch：7477 | Loss: 0.08520175516605377\n",
      "Batch：7478 | Loss: 0.09824865311384201\n",
      "Batch：7479 | Loss: 0.0886915847659111\n",
      "Batch：7480 | Loss: 0.08872105926275253\n",
      "Batch：7481 | Loss: 0.07767609506845474\n",
      "Batch：7482 | Loss: 0.09733150899410248\n",
      "Batch：7483 | Loss: 0.09699910134077072\n",
      "Batch：7484 | Loss: 0.09307926148176193\n",
      "Batch：7485 | Loss: 0.08881394565105438\n",
      "Batch：7486 | Loss: 0.09905804693698883\n",
      "Batch：7487 | Loss: 0.09384522587060928\n",
      "Batch：7488 | Loss: 0.09662570804357529\n",
      "Batch：7489 | Loss: 0.09037017822265625\n",
      "Batch：7490 | Loss: 0.1064172014594078\n",
      "Batch：7491 | Loss: 0.09243236482143402\n",
      "Batch：7492 | Loss: 0.10510674864053726\n",
      "Batch：7493 | Loss: 0.10668566823005676\n",
      "Batch：7494 | Loss: 0.09208575636148453\n",
      "Batch：7495 | Loss: 0.10113395005464554\n",
      "Batch：7496 | Loss: 0.10033782571554184\n",
      "Batch：7497 | Loss: 0.09503696858882904\n",
      "Batch：7498 | Loss: 0.09624194353818893\n",
      "Batch：7499 | Loss: 0.10485971719026566\n",
      "Batch：7500 | Loss: 0.09509661793708801\n",
      "Batch：7501 | Loss: 0.10182446241378784\n",
      "Batch：7502 | Loss: 0.10160212963819504\n",
      "Batch：7503 | Loss: 0.08864666521549225\n",
      "Batch：7504 | Loss: 0.09706678986549377\n",
      "Batch：7505 | Loss: 0.09736266732215881\n",
      "Batch：7506 | Loss: 0.104227215051651\n",
      "Batch：7507 | Loss: 0.09349313378334045\n",
      "Batch：7508 | Loss: 0.08799829334020615\n",
      "Batch：7509 | Loss: 0.08557267487049103\n",
      "Batch：7510 | Loss: 0.09331408888101578\n",
      "Batch：7511 | Loss: 0.10309403389692307\n",
      "Batch：7512 | Loss: 0.09887029975652695\n",
      "Batch：7513 | Loss: 0.092899851500988\n",
      "Batch：7514 | Loss: 0.09373554587364197\n",
      "Batch：7515 | Loss: 0.1018853560090065\n",
      "Batch：7516 | Loss: 0.0826282650232315\n",
      "Batch：7517 | Loss: 0.09497986733913422\n",
      "Batch：7518 | Loss: 0.0791451632976532\n",
      "Batch：7519 | Loss: 0.09905215352773666\n",
      "Batch：7520 | Loss: 0.0911804661154747\n",
      "Batch：7521 | Loss: 0.10044670850038528\n",
      "Batch：7522 | Loss: 0.0873493105173111\n",
      "Batch：7523 | Loss: 0.08105221390724182\n",
      "Batch：7524 | Loss: 0.09374840557575226\n",
      "Batch：7525 | Loss: 0.08694728463888168\n",
      "Batch：7526 | Loss: 0.07526171952486038\n",
      "Batch：7527 | Loss: 0.09223871678113937\n",
      "Batch：7528 | Loss: 0.10331328958272934\n",
      "Batch：7529 | Loss: 0.10182195901870728\n",
      "Batch：7530 | Loss: 0.0818922147154808\n",
      "Batch：7531 | Loss: 0.09077029675245285\n",
      "Batch：7532 | Loss: 0.08731113374233246\n",
      "Batch：7533 | Loss: 0.09470844268798828\n",
      "Batch：7534 | Loss: 0.09071037918329239\n",
      "Batch：7535 | Loss: 0.09727180749177933\n",
      "Batch：7536 | Loss: 0.08402148634195328\n",
      "Batch：7537 | Loss: 0.08645232766866684\n",
      "Batch：7538 | Loss: 0.10015042871236801\n",
      "Batch：7539 | Loss: 0.09707217663526535\n",
      "Batch：7540 | Loss: 0.10578747093677521\n",
      "Batch：7541 | Loss: 0.08815275877714157\n",
      "Batch：7542 | Loss: 0.07761561870574951\n",
      "Batch：7543 | Loss: 0.09266932308673859\n",
      "Batch：7544 | Loss: 0.07805784791707993\n",
      "Batch：7545 | Loss: 0.0889655128121376\n",
      "Batch：7546 | Loss: 0.0799395740032196\n",
      "Batch：7547 | Loss: 0.0961686223745346\n",
      "Batch：7548 | Loss: 0.08094529062509537\n",
      "Batch：7549 | Loss: 0.08835765719413757\n",
      "Batch：7550 | Loss: 0.08579068630933762\n",
      "Batch：7551 | Loss: 0.09954951703548431\n",
      "Batch：7552 | Loss: 0.09604541212320328\n",
      "Batch：7553 | Loss: 0.09470957517623901\n",
      "Batch：7554 | Loss: 0.0905185118317604\n",
      "Batch：7555 | Loss: 0.08878211677074432\n",
      "Batch：7556 | Loss: 0.10275886207818985\n",
      "Batch：7557 | Loss: 0.09031941741704941\n",
      "Batch：7558 | Loss: 0.09070487320423126\n",
      "Batch：7559 | Loss: 0.10011018812656403\n",
      "Batch：7560 | Loss: 0.09838433563709259\n",
      "Batch：7561 | Loss: 0.09620662033557892\n",
      "Batch：7562 | Loss: 0.09969666600227356\n",
      "Batch：7563 | Loss: 0.10465828329324722\n",
      "Batch：7564 | Loss: 0.08797547221183777\n",
      "Batch：7565 | Loss: 0.0964355319738388\n",
      "Batch：7566 | Loss: 0.07960759103298187\n",
      "Batch：7567 | Loss: 0.0963989868760109\n",
      "Batch：7568 | Loss: 0.09272794425487518\n",
      "Batch：7569 | Loss: 0.09931335598230362\n",
      "Batch：7570 | Loss: 0.0931922197341919\n",
      "Batch：7571 | Loss: 0.09324551373720169\n",
      "Batch：7572 | Loss: 0.09220606088638306\n",
      "Batch：7573 | Loss: 0.08692138642072678\n",
      "Batch：7574 | Loss: 0.0936104953289032\n",
      "Batch：7575 | Loss: 0.09688496589660645\n",
      "Batch：7576 | Loss: 0.0953914001584053\n",
      "Batch：7577 | Loss: 0.08526111394166946\n",
      "Batch：7578 | Loss: 0.09652648121118546\n",
      "Batch：7579 | Loss: 0.08203819394111633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：7580 | Loss: 0.07945149391889572\n",
      "Batch：7581 | Loss: 0.09850548952817917\n",
      "Batch：7582 | Loss: 0.09916715323925018\n",
      "Batch：7583 | Loss: 0.0819258987903595\n",
      "Batch：7584 | Loss: 0.0968497022986412\n",
      "Batch：7585 | Loss: 0.08355406671762466\n",
      "Batch：7586 | Loss: 0.08731058984994888\n",
      "Batch：7587 | Loss: 0.08638598769903183\n",
      "Batch：7588 | Loss: 0.08193323761224747\n",
      "Batch：7589 | Loss: 0.08348479121923447\n",
      "Batch：7590 | Loss: 0.09268408268690109\n",
      "Batch：7591 | Loss: 0.09503588825464249\n",
      "Batch：7592 | Loss: 0.09468720108270645\n",
      "Batch：7593 | Loss: 0.10598354041576385\n",
      "Batch：7594 | Loss: 0.08583489805459976\n",
      "Batch：7595 | Loss: 0.09286356717348099\n",
      "Batch：7596 | Loss: 0.09333609789609909\n",
      "Batch：7597 | Loss: 0.08271282911300659\n",
      "Batch：7598 | Loss: 0.08931280672550201\n",
      "Batch：7599 | Loss: 0.0907038152217865\n",
      "Batch：7600 | Loss: 0.09981054812669754\n",
      "Batch：7601 | Loss: 0.09486313909292221\n",
      "Batch：7602 | Loss: 0.08807773888111115\n",
      "Batch：7603 | Loss: 0.09334831684827805\n",
      "Batch：7604 | Loss: 0.09764169901609421\n",
      "Batch：7605 | Loss: 0.09073032438755035\n",
      "Batch：7606 | Loss: 0.09931158274412155\n",
      "Batch：7607 | Loss: 0.08278995007276535\n",
      "Batch：7608 | Loss: 0.08203292638063431\n",
      "Batch：7609 | Loss: 0.08924231678247452\n",
      "Batch：7610 | Loss: 0.08789706230163574\n",
      "Batch：7611 | Loss: 0.10553468763828278\n",
      "Batch：7612 | Loss: 0.08463861793279648\n",
      "Batch：7613 | Loss: 0.09827890247106552\n",
      "Batch：7614 | Loss: 0.07723316550254822\n",
      "Batch：7615 | Loss: 0.11322809755802155\n",
      "Batch：7616 | Loss: 0.09587296098470688\n",
      "Batch：7617 | Loss: 0.08790787309408188\n",
      "Batch：7618 | Loss: 0.10307668894529343\n",
      "Batch：7619 | Loss: 0.08740516752004623\n",
      "Batch：7620 | Loss: 0.09015148133039474\n",
      "Batch：7621 | Loss: 0.08991111069917679\n",
      "Batch：7622 | Loss: 0.08776064217090607\n",
      "Batch：7623 | Loss: 0.08933646231889725\n",
      "Batch：7624 | Loss: 0.09437283873558044\n",
      "Batch：7625 | Loss: 0.08880592882633209\n",
      "Batch：7626 | Loss: 0.08753437548875809\n",
      "Batch：7627 | Loss: 0.09195613861083984\n",
      "Batch：7628 | Loss: 0.08149795234203339\n",
      "Batch：7629 | Loss: 0.09704320132732391\n",
      "Batch：7630 | Loss: 0.07844921201467514\n",
      "Batch：7631 | Loss: 0.09326278418302536\n",
      "Batch：7632 | Loss: 0.09039690345525742\n",
      "Batch：7633 | Loss: 0.09204903244972229\n",
      "Batch：7634 | Loss: 0.09495499730110168\n",
      "Batch：7635 | Loss: 0.09121164679527283\n",
      "Batch：7636 | Loss: 0.0829060897231102\n",
      "Batch：7637 | Loss: 0.08374308049678802\n",
      "Batch：7638 | Loss: 0.0990186333656311\n",
      "Batch：7639 | Loss: 0.10075993090867996\n",
      "Batch：7640 | Loss: 0.08560734987258911\n",
      "Batch：7641 | Loss: 0.10219290852546692\n",
      "Batch：7642 | Loss: 0.09786850959062576\n",
      "Batch：7643 | Loss: 0.09249251335859299\n",
      "Batch：7644 | Loss: 0.07787825167179108\n",
      "Batch：7645 | Loss: 0.08927915245294571\n",
      "Batch：7646 | Loss: 0.09011229127645493\n",
      "Batch：7647 | Loss: 0.08745346963405609\n",
      "Batch：7648 | Loss: 0.09442033618688583\n",
      "Batch：7649 | Loss: 0.08843415975570679\n",
      "Batch：7650 | Loss: 0.08413448929786682\n",
      "Batch：7651 | Loss: 0.10147006064653397\n",
      "Batch：7652 | Loss: 0.09110744297504425\n",
      "Batch：7653 | Loss: 0.08680834621191025\n",
      "Batch：7654 | Loss: 0.09336778521537781\n",
      "Batch：7655 | Loss: 0.08163949847221375\n",
      "Batch：7656 | Loss: 0.09252128005027771\n",
      "Batch：7657 | Loss: 0.08240832388401031\n",
      "Batch：7658 | Loss: 0.08343441784381866\n",
      "Batch：7659 | Loss: 0.09108638763427734\n",
      "Batch：7660 | Loss: 0.09608042240142822\n",
      "Batch：7661 | Loss: 0.08257322013378143\n",
      "Batch：7662 | Loss: 0.07067084312438965\n",
      "Batch：7663 | Loss: 0.09085367619991302\n",
      "Batch：7664 | Loss: 0.09590563178062439\n",
      "Batch：7665 | Loss: 0.07566101104021072\n",
      "Batch：7666 | Loss: 0.09818040579557419\n",
      "Batch：7667 | Loss: 0.09041351079940796\n",
      "Batch：7668 | Loss: 0.08784165233373642\n",
      "Batch：7669 | Loss: 0.07967021316289902\n",
      "Batch：7670 | Loss: 0.08697723597288132\n",
      "Batch：7671 | Loss: 0.07772345095872879\n",
      "Batch：7672 | Loss: 0.086728535592556\n",
      "Batch：7673 | Loss: 0.08415587246417999\n",
      "Batch：7674 | Loss: 0.09932981431484222\n",
      "Batch：7675 | Loss: 0.09515445679426193\n",
      "Batch：7676 | Loss: 0.09229540824890137\n",
      "Batch：7677 | Loss: 0.09683846682310104\n",
      "Batch：7678 | Loss: 0.08205059170722961\n",
      "Batch：7679 | Loss: 0.09042345732450485\n",
      "Batch：7680 | Loss: 0.08911419659852982\n",
      "Batch：7681 | Loss: 0.09460010379552841\n",
      "Batch：7682 | Loss: 0.0919046550989151\n",
      "Batch：7683 | Loss: 0.09912293404340744\n",
      "Batch：7684 | Loss: 0.10350359231233597\n",
      "Batch：7685 | Loss: 0.08057878166437149\n",
      "Batch：7686 | Loss: 0.078831247985363\n",
      "Batch：7687 | Loss: 0.08998492360115051\n",
      "Batch：7688 | Loss: 0.08898067474365234\n",
      "Batch：7689 | Loss: 0.09129501134157181\n",
      "Batch：7690 | Loss: 0.09626784920692444\n",
      "Batch：7691 | Loss: 0.08580593019723892\n",
      "Batch：7692 | Loss: 0.10499394685029984\n",
      "Batch：7693 | Loss: 0.08460862934589386\n",
      "Batch：7694 | Loss: 0.09977677464485168\n",
      "Batch：7695 | Loss: 0.07377859205007553\n",
      "Batch：7696 | Loss: 0.07525721937417984\n",
      "Batch：7697 | Loss: 0.0955241248011589\n",
      "Batch：7698 | Loss: 0.09082053601741791\n",
      "Batch：7699 | Loss: 0.08979736268520355\n",
      "Batch：7700 | Loss: 0.09157883375883102\n",
      "Batch：7701 | Loss: 0.08485902845859528\n",
      "Batch：7702 | Loss: 0.09049400687217712\n",
      "Batch：7703 | Loss: 0.08626075834035873\n",
      "Batch：7704 | Loss: 0.09148713946342468\n",
      "Batch：7705 | Loss: 0.09348907321691513\n",
      "Batch：7706 | Loss: 0.09120345860719681\n",
      "Batch：7707 | Loss: 0.10651162266731262\n",
      "Batch：7708 | Loss: 0.08667587488889694\n",
      "Batch：7709 | Loss: 0.09175241738557816\n",
      "Batch：7710 | Loss: 0.07915862649679184\n",
      "Batch：7711 | Loss: 0.09037742018699646\n",
      "Batch：7712 | Loss: 0.08074843138456345\n",
      "Batch：7713 | Loss: 0.09622914344072342\n",
      "Batch：7714 | Loss: 0.0895066112279892\n",
      "Batch：7715 | Loss: 0.09497270733118057\n",
      "Batch：7716 | Loss: 0.10077943652868271\n",
      "Batch：7717 | Loss: 0.10457981377840042\n",
      "Batch：7718 | Loss: 0.07895335555076599\n",
      "Batch：7719 | Loss: 0.09207306802272797\n",
      "Batch：7720 | Loss: 0.09615400433540344\n",
      "Batch：7721 | Loss: 0.08150836825370789\n",
      "Batch：7722 | Loss: 0.09442155063152313\n",
      "Batch：7723 | Loss: 0.09913880378007889\n",
      "Batch：7724 | Loss: 0.08723333477973938\n",
      "Batch：7725 | Loss: 0.08946996182203293\n",
      "Batch：7726 | Loss: 0.09481661021709442\n",
      "Batch：7727 | Loss: 0.09143359214067459\n",
      "Batch：7728 | Loss: 0.09582304954528809\n",
      "Batch：7729 | Loss: 0.076917365193367\n",
      "Batch：7730 | Loss: 0.08264283835887909\n",
      "Batch：7731 | Loss: 0.08924704790115356\n",
      "Batch：7732 | Loss: 0.10574813932180405\n",
      "Batch：7733 | Loss: 0.09556740522384644\n",
      "Batch：7734 | Loss: 0.07767336815595627\n",
      "Batch：7735 | Loss: 0.09587258100509644\n",
      "Batch：7736 | Loss: 0.09718072414398193\n",
      "Batch：7737 | Loss: 0.08962678909301758\n",
      "Batch：7738 | Loss: 0.09302917122840881\n",
      "Batch：7739 | Loss: 0.08755657821893692\n",
      "Batch：7740 | Loss: 0.0923687145113945\n",
      "Batch：7741 | Loss: 0.09006931632757187\n",
      "Batch：7742 | Loss: 0.0823969841003418\n",
      "Batch：7743 | Loss: 0.08338849991559982\n",
      "Batch：7744 | Loss: 0.08613645285367966\n",
      "Batch：7745 | Loss: 0.09473966062068939\n",
      "Batch：7746 | Loss: 0.08036518096923828\n",
      "Batch：7747 | Loss: 0.08445313572883606\n",
      "Batch：7748 | Loss: 0.0852738693356514\n",
      "Batch：7749 | Loss: 0.08679942786693573\n",
      "Batch：7750 | Loss: 0.07733286172151566\n",
      "Batch：7751 | Loss: 0.10082710534334183\n",
      "Batch：7752 | Loss: 0.09271905571222305\n",
      "Batch：7753 | Loss: 0.07924890518188477\n",
      "Batch：7754 | Loss: 0.08946353197097778\n",
      "Batch：7755 | Loss: 0.07195443660020828\n",
      "Batch：7756 | Loss: 0.09266725927591324\n",
      "Batch：7757 | Loss: 0.09439518302679062\n",
      "Batch：7758 | Loss: 0.09699108451604843\n",
      "Batch：7759 | Loss: 0.10017489641904831\n",
      "Batch：7760 | Loss: 0.09269171953201294\n",
      "Batch：7761 | Loss: 0.09772109985351562\n",
      "Batch：7762 | Loss: 0.0958784967660904\n",
      "Batch：7763 | Loss: 0.07670655101537704\n",
      "Batch：7764 | Loss: 0.08697258681058884\n",
      "Batch：7765 | Loss: 0.07719135284423828\n",
      "Batch：7766 | Loss: 0.09062755107879639\n",
      "Batch：7767 | Loss: 0.10859151929616928\n",
      "Batch：7768 | Loss: 0.09790470451116562\n",
      "Batch：7769 | Loss: 0.08164560794830322\n",
      "Batch：7770 | Loss: 0.08659463375806808\n",
      "Batch：7771 | Loss: 0.08419527858495712\n",
      "Batch：7772 | Loss: 0.08543576300144196\n",
      "Batch：7773 | Loss: 0.08117780834436417\n",
      "Batch：7774 | Loss: 0.0957249328494072\n",
      "Batch：7775 | Loss: 0.08515098690986633\n",
      "Batch：7776 | Loss: 0.09284975379705429\n",
      "Batch：7777 | Loss: 0.08605620265007019\n",
      "Batch：7778 | Loss: 0.09861277043819427\n",
      "Batch：7779 | Loss: 0.08499498665332794\n",
      "Batch：7780 | Loss: 0.08823870867490768\n",
      "Batch：7781 | Loss: 0.09475132077932358\n",
      "Batch：7782 | Loss: 0.09836392849683762\n",
      "Batch：7783 | Loss: 0.07804951071739197\n",
      "Batch：7784 | Loss: 0.09167741984128952\n",
      "Batch：7785 | Loss: 0.09587674587965012\n",
      "Batch：7786 | Loss: 0.0964464321732521\n",
      "Batch：7787 | Loss: 0.08124291896820068\n",
      "Batch：7788 | Loss: 0.08309555053710938\n",
      "Batch：7789 | Loss: 0.09933638572692871\n",
      "Batch：7790 | Loss: 0.07425235211849213\n",
      "Batch：7791 | Loss: 0.0897364690899849\n",
      "Batch：7792 | Loss: 0.09877024590969086\n",
      "Batch：7793 | Loss: 0.09491421282291412\n",
      "Batch：7794 | Loss: 0.08945200592279434\n",
      "Batch：7795 | Loss: 0.08746663480997086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：7796 | Loss: 0.0953354686498642\n",
      "Batch：7797 | Loss: 0.0875445157289505\n",
      "Batch：7798 | Loss: 0.08749858289957047\n",
      "Batch：7799 | Loss: 0.1072099581360817\n",
      "Batch：7800 | Loss: 0.091766856610775\n",
      "Batch：7801 | Loss: 0.09750595688819885\n",
      "Batch：7802 | Loss: 0.08382827788591385\n",
      "Batch：7803 | Loss: 0.09379631280899048\n",
      "Batch：7804 | Loss: 0.09817571938037872\n",
      "Batch：7805 | Loss: 0.09464587271213531\n",
      "Batch：7806 | Loss: 0.1049363911151886\n",
      "Batch：7807 | Loss: 0.09196621924638748\n",
      "Batch：7808 | Loss: 0.09654705971479416\n",
      "Batch：7809 | Loss: 0.07733536511659622\n",
      "Batch：7810 | Loss: 0.09013684093952179\n",
      "Batch：7811 | Loss: 0.08352265506982803\n",
      "Batch：7812 | Loss: 0.08112774789333344\n",
      "Batch：7813 | Loss: 0.08400614559650421\n",
      "Batch：7814 | Loss: 0.09568241238594055\n",
      "Batch：7815 | Loss: 0.07850971072912216\n",
      "Batch：7816 | Loss: 0.08184730261564255\n",
      "Batch：7817 | Loss: 0.08015729486942291\n",
      "Batch：7818 | Loss: 0.08261337131261826\n",
      "Batch：7819 | Loss: 0.08300840109586716\n",
      "Batch：7820 | Loss: 0.09046736359596252\n",
      "Batch：7821 | Loss: 0.09315140545368195\n",
      "Batch：7822 | Loss: 0.09513824433088303\n",
      "Batch：7823 | Loss: 0.10237062722444534\n",
      "Batch：7824 | Loss: 0.09167768061161041\n",
      "Batch：7825 | Loss: 0.08577530086040497\n",
      "Batch：7826 | Loss: 0.08318762481212616\n",
      "Batch：7827 | Loss: 0.10051820427179337\n",
      "Batch：7828 | Loss: 0.08812323957681656\n",
      "Batch：7829 | Loss: 0.09840384125709534\n",
      "Batch：7830 | Loss: 0.09085990488529205\n",
      "Batch：7831 | Loss: 0.09603144973516464\n",
      "Batch：7832 | Loss: 0.08630767464637756\n",
      "Batch：7833 | Loss: 0.0744624137878418\n",
      "Batch：7834 | Loss: 0.09839443117380142\n",
      "Batch：7835 | Loss: 0.08696039021015167\n",
      "Batch：7836 | Loss: 0.07926659286022186\n",
      "Batch：7837 | Loss: 0.08721253275871277\n",
      "Batch：7838 | Loss: 0.08139130473136902\n",
      "Batch：7839 | Loss: 0.09499827027320862\n",
      "Batch：7840 | Loss: 0.0879550650715828\n",
      "Batch：7841 | Loss: 0.09004426747560501\n",
      "Batch：7842 | Loss: 0.08336439728736877\n",
      "Batch：7843 | Loss: 0.08095492422580719\n",
      "Batch：7844 | Loss: 0.10355334728956223\n",
      "Batch：7845 | Loss: 0.08571916818618774\n",
      "Batch：7846 | Loss: 0.0970284715294838\n",
      "Batch：7847 | Loss: 0.08923200517892838\n",
      "Batch：7848 | Loss: 0.09562132507562637\n",
      "Batch：7849 | Loss: 0.08097133785486221\n",
      "Batch：7850 | Loss: 0.08372174203395844\n",
      "Batch：7851 | Loss: 0.08577397465705872\n",
      "Batch：7852 | Loss: 0.08197644352912903\n",
      "Batch：7853 | Loss: 0.07976619154214859\n",
      "Batch：7854 | Loss: 0.0932805985212326\n",
      "Batch：7855 | Loss: 0.07882067561149597\n",
      "Batch：7856 | Loss: 0.08673369139432907\n",
      "Batch：7857 | Loss: 0.08833173662424088\n",
      "Batch：7858 | Loss: 0.08129144459962845\n",
      "Batch：7859 | Loss: 0.0968523770570755\n",
      "Batch：7860 | Loss: 0.09394952654838562\n",
      "Batch：7861 | Loss: 0.09317684173583984\n",
      "Batch：7862 | Loss: 0.10534834861755371\n",
      "Batch：7863 | Loss: 0.07791085541248322\n",
      "Batch：7864 | Loss: 0.09128281474113464\n",
      "Batch：7865 | Loss: 0.0924564003944397\n",
      "Batch：7866 | Loss: 0.0940595492720604\n",
      "Batch：7867 | Loss: 0.09208636730909348\n",
      "Batch：7868 | Loss: 0.09229512512683868\n",
      "Batch：7869 | Loss: 0.09382819384336472\n",
      "Batch：7870 | Loss: 0.09337827563285828\n",
      "Batch：7871 | Loss: 0.08466899394989014\n",
      "Batch：7872 | Loss: 0.07982612401247025\n",
      "Batch：7873 | Loss: 0.08842365443706512\n",
      "Batch：7874 | Loss: 0.10548141598701477\n",
      "Batch：7875 | Loss: 0.08348535746335983\n",
      "Batch：7876 | Loss: 0.0826314315199852\n",
      "Batch：7877 | Loss: 0.08561200648546219\n",
      "Batch：7878 | Loss: 0.08562784641981125\n",
      "Batch：7879 | Loss: 0.09881208837032318\n",
      "Batch：7880 | Loss: 0.08347755670547485\n",
      "Batch：7881 | Loss: 0.0816873237490654\n",
      "Batch：7882 | Loss: 0.08636201918125153\n",
      "Batch：7883 | Loss: 0.0911274179816246\n",
      "Batch：7884 | Loss: 0.08449237793684006\n",
      "Batch：7885 | Loss: 0.09216941893100739\n",
      "Batch：7886 | Loss: 0.08696360141038895\n",
      "Batch：7887 | Loss: 0.09093210846185684\n",
      "Batch：7888 | Loss: 0.07874412089586258\n",
      "Batch：7889 | Loss: 0.08367267996072769\n",
      "Batch：7890 | Loss: 0.09253508597612381\n",
      "Batch：7891 | Loss: 0.08273454755544662\n",
      "Batch：7892 | Loss: 0.0855802372097969\n",
      "Batch：7893 | Loss: 0.09369108825922012\n",
      "Batch：7894 | Loss: 0.08203686028718948\n",
      "Batch：7895 | Loss: 0.09471188485622406\n",
      "Batch：7896 | Loss: 0.09544648975133896\n",
      "Batch：7897 | Loss: 0.07464803010225296\n",
      "Batch：7898 | Loss: 0.09068380296230316\n",
      "Batch：7899 | Loss: 0.07960285246372223\n",
      "Batch：7900 | Loss: 0.0909532979130745\n",
      "Batch：7901 | Loss: 0.08772572875022888\n",
      "Batch：7902 | Loss: 0.08594752848148346\n",
      "Batch：7903 | Loss: 0.08851601928472519\n",
      "Batch：7904 | Loss: 0.08207130432128906\n",
      "Batch：7905 | Loss: 0.09338531643152237\n",
      "Batch：7906 | Loss: 0.09057462215423584\n",
      "Batch：7907 | Loss: 0.08826684206724167\n",
      "Batch：7908 | Loss: 0.08301106840372086\n",
      "Batch：7909 | Loss: 0.08636307716369629\n",
      "Batch：7910 | Loss: 0.09582193940877914\n",
      "Batch：7911 | Loss: 0.09238584339618683\n",
      "Batch：7912 | Loss: 0.09397237002849579\n",
      "Batch：7913 | Loss: 0.08897007256746292\n",
      "Batch：7914 | Loss: 0.09014839679002762\n",
      "Batch：7915 | Loss: 0.09428366273641586\n",
      "Batch：7916 | Loss: 0.09085951745510101\n",
      "Batch：7917 | Loss: 0.09879881888628006\n",
      "Batch：7918 | Loss: 0.08745300024747849\n",
      "Batch：7919 | Loss: 0.10361436754465103\n",
      "Batch：7920 | Loss: 0.08301321417093277\n",
      "Batch：7921 | Loss: 0.09156748652458191\n",
      "Batch：7922 | Loss: 0.0860411673784256\n",
      "Batch：7923 | Loss: 0.1001695916056633\n",
      "Batch：7924 | Loss: 0.09811502695083618\n",
      "Batch：7925 | Loss: 0.08518442511558533\n",
      "Batch：7926 | Loss: 0.0975634977221489\n",
      "Batch：7927 | Loss: 0.07882927358150482\n",
      "Batch：7928 | Loss: 0.08769364655017853\n",
      "Batch：7929 | Loss: 0.09971101582050323\n",
      "Batch：7930 | Loss: 0.07869178056716919\n",
      "Batch：7931 | Loss: 0.0817146822810173\n",
      "Batch：7932 | Loss: 0.0943213701248169\n",
      "Batch：7933 | Loss: 0.08574822545051575\n",
      "Batch：7934 | Loss: 0.0916614755988121\n",
      "Batch：7935 | Loss: 0.08218654245138168\n",
      "Batch：7936 | Loss: 0.09039381891489029\n",
      "Batch：7937 | Loss: 0.09991566091775894\n",
      "Batch：7938 | Loss: 0.07835868000984192\n",
      "Batch：7939 | Loss: 0.10057984292507172\n",
      "Batch：7940 | Loss: 0.09039092808961868\n",
      "Batch：7941 | Loss: 0.09937681257724762\n",
      "Batch：7942 | Loss: 0.0923004150390625\n",
      "Batch：7943 | Loss: 0.09332532435655594\n",
      "Batch：7944 | Loss: 0.08357051759958267\n",
      "Batch：7945 | Loss: 0.09224417805671692\n",
      "Batch：7946 | Loss: 0.08628436177968979\n",
      "Batch：7947 | Loss: 0.09289166331291199\n",
      "Batch：7948 | Loss: 0.08490699529647827\n",
      "Batch：7949 | Loss: 0.09999953955411911\n",
      "Batch：7950 | Loss: 0.09879345446825027\n",
      "Batch：7951 | Loss: 0.08961521089076996\n",
      "Batch：7952 | Loss: 0.09396267682313919\n",
      "Batch：7953 | Loss: 0.08553262054920197\n",
      "Batch：7954 | Loss: 0.0885985717177391\n",
      "Batch：7955 | Loss: 0.08030377328395844\n",
      "Batch：7956 | Loss: 0.1020260602235794\n",
      "Batch：7957 | Loss: 0.08649305999279022\n",
      "Batch：7958 | Loss: 0.08892880380153656\n",
      "Batch：7959 | Loss: 0.08336646854877472\n",
      "Batch：7960 | Loss: 0.07301848381757736\n",
      "Batch：7961 | Loss: 0.09207812696695328\n",
      "Batch：7962 | Loss: 0.08904923498630524\n",
      "Batch：7963 | Loss: 0.08062995225191116\n",
      "Batch：7964 | Loss: 0.09409059584140778\n",
      "Batch：7965 | Loss: 0.08019670844078064\n",
      "Batch：7966 | Loss: 0.08014650642871857\n",
      "Batch：7967 | Loss: 0.0856681615114212\n",
      "Batch：7968 | Loss: 0.08914157748222351\n",
      "Batch：7969 | Loss: 0.08793722093105316\n",
      "Batch：7970 | Loss: 0.07585682719945908\n",
      "Batch：7971 | Loss: 0.08193454891443253\n",
      "Batch：7972 | Loss: 0.08889199048280716\n",
      "Batch：7973 | Loss: 0.09285709261894226\n",
      "Batch：7974 | Loss: 0.08816266059875488\n",
      "Batch：7975 | Loss: 0.08855906128883362\n",
      "Batch：7976 | Loss: 0.08750515431165695\n",
      "Batch：7977 | Loss: 0.08771117776632309\n",
      "Batch：7978 | Loss: 0.08708669245243073\n",
      "Batch：7979 | Loss: 0.08750738203525543\n",
      "Batch：7980 | Loss: 0.09485500305891037\n",
      "Batch：7981 | Loss: 0.09177061170339584\n",
      "Batch：7982 | Loss: 0.08386920392513275\n",
      "Batch：7983 | Loss: 0.09450408816337585\n",
      "Batch：7984 | Loss: 0.08234111964702606\n",
      "Batch：7985 | Loss: 0.06632757186889648\n",
      "Batch：7986 | Loss: 0.08841190487146378\n",
      "Batch：7987 | Loss: 0.09164320677518845\n",
      "Batch：7988 | Loss: 0.0915592834353447\n",
      "Batch：7989 | Loss: 0.0784468799829483\n",
      "Batch：7990 | Loss: 0.0781196653842926\n",
      "Batch：7991 | Loss: 0.08575960248708725\n",
      "Batch：7992 | Loss: 0.09874355047941208\n",
      "Batch：7993 | Loss: 0.09848510473966599\n",
      "Batch：7994 | Loss: 0.08995062857866287\n",
      "Batch：7995 | Loss: 0.08383604139089584\n",
      "Batch：7996 | Loss: 0.08671467006206512\n",
      "Batch：7997 | Loss: 0.07508780807256699\n",
      "Batch：7998 | Loss: 0.08488388359546661\n",
      "Batch：7999 | Loss: 0.0925147607922554\n",
      "Batch：8000 | Loss: 0.08364798873662949\n",
      "Batch：8001 | Loss: 0.07643576711416245\n",
      "Batch：8002 | Loss: 0.09457904100418091\n",
      "Batch：8003 | Loss: 0.08969857543706894\n",
      "Batch：8004 | Loss: 0.08520068228244781\n",
      "Batch：8005 | Loss: 0.08707767724990845\n",
      "Batch：8006 | Loss: 0.09008808434009552\n",
      "Batch：8007 | Loss: 0.07667718827724457\n",
      "Batch：8008 | Loss: 0.08184562623500824\n",
      "Batch：8009 | Loss: 0.09610838443040848\n",
      "Batch：8010 | Loss: 0.09714552760124207\n",
      "Batch：8011 | Loss: 0.07980778068304062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：8012 | Loss: 0.08211755007505417\n",
      "Batch：8013 | Loss: 0.09301061928272247\n",
      "Batch：8014 | Loss: 0.1056087538599968\n",
      "Batch：8015 | Loss: 0.09053952246904373\n",
      "Batch：8016 | Loss: 0.08077579736709595\n",
      "Batch：8017 | Loss: 0.08985421806573868\n",
      "Batch：8018 | Loss: 0.07946457713842392\n",
      "Batch：8019 | Loss: 0.08616451174020767\n",
      "Batch：8020 | Loss: 0.07418861240148544\n",
      "Batch：8021 | Loss: 0.07794070243835449\n",
      "Batch：8022 | Loss: 0.09558869153261185\n",
      "Batch：8023 | Loss: 0.088884137570858\n",
      "Batch：8024 | Loss: 0.07914747297763824\n",
      "Batch：8025 | Loss: 0.07665040343999863\n",
      "Batch：8026 | Loss: 0.08685356378555298\n",
      "Batch：8027 | Loss: 0.08813855797052383\n",
      "Batch：8028 | Loss: 0.07488704472780228\n",
      "Batch：8029 | Loss: 0.08562762290239334\n",
      "Batch：8030 | Loss: 0.0794198289513588\n",
      "Batch：8031 | Loss: 0.08829053491353989\n",
      "Batch：8032 | Loss: 0.08122114092111588\n",
      "Batch：8033 | Loss: 0.08790655434131622\n",
      "Batch：8034 | Loss: 0.0857783630490303\n",
      "Batch：8035 | Loss: 0.09572047740221024\n",
      "Batch：8036 | Loss: 0.08548233658075333\n",
      "Batch：8037 | Loss: 0.09088120609521866\n",
      "Batch：8038 | Loss: 0.09230414032936096\n",
      "Batch：8039 | Loss: 0.096327044069767\n",
      "Batch：8040 | Loss: 0.0892530083656311\n",
      "Batch：8041 | Loss: 0.09003548324108124\n",
      "Batch：8042 | Loss: 0.08792669326066971\n",
      "Batch：8043 | Loss: 0.09199170023202896\n",
      "Batch：8044 | Loss: 0.0894455537199974\n",
      "Batch：8045 | Loss: 0.08377718925476074\n",
      "Batch：8046 | Loss: 0.08564402163028717\n",
      "Batch：8047 | Loss: 0.0734577476978302\n",
      "Batch：8048 | Loss: 0.08909677714109421\n",
      "Batch：8049 | Loss: 0.08110742270946503\n",
      "Batch：8050 | Loss: 0.10293208062648773\n",
      "Batch：8051 | Loss: 0.0868975818157196\n",
      "Batch：8052 | Loss: 0.08212395012378693\n",
      "Batch：8053 | Loss: 0.09740155190229416\n",
      "Batch：8054 | Loss: 0.08793774247169495\n",
      "Batch：8055 | Loss: 0.07565665990114212\n",
      "Batch：8056 | Loss: 0.0867130309343338\n",
      "Batch：8057 | Loss: 0.07723341137170792\n",
      "Batch：8058 | Loss: 0.08786331862211227\n",
      "Batch：8059 | Loss: 0.0800514668226242\n",
      "Batch：8060 | Loss: 0.08748912811279297\n",
      "Batch：8061 | Loss: 0.09152518957853317\n",
      "Batch：8062 | Loss: 0.08692541718482971\n",
      "Batch：8063 | Loss: 0.09010813385248184\n",
      "Batch：8064 | Loss: 0.10703851282596588\n",
      "Batch：8065 | Loss: 0.08525672554969788\n",
      "Batch：8066 | Loss: 0.0971674993634224\n",
      "Batch：8067 | Loss: 0.09100203216075897\n",
      "Batch：8068 | Loss: 0.08740382641553879\n",
      "Batch：8069 | Loss: 0.09607014805078506\n",
      "Batch：8070 | Loss: 0.08285506814718246\n",
      "Batch：8071 | Loss: 0.1074451357126236\n",
      "Batch：8072 | Loss: 0.09153294563293457\n",
      "Batch：8073 | Loss: 0.07245906442403793\n",
      "Batch：8074 | Loss: 0.07902684807777405\n",
      "Batch：8075 | Loss: 0.09610024094581604\n",
      "Batch：8076 | Loss: 0.08808077126741409\n",
      "Batch：8077 | Loss: 0.10188443958759308\n",
      "Batch：8078 | Loss: 0.08669080585241318\n",
      "Batch：8079 | Loss: 0.07948944717645645\n",
      "Batch：8080 | Loss: 0.08506377786397934\n",
      "Batch：8081 | Loss: 0.077947698533535\n",
      "Batch：8082 | Loss: 0.0759303867816925\n",
      "Batch：8083 | Loss: 0.09130225330591202\n",
      "Batch：8084 | Loss: 0.08824175596237183\n",
      "Batch：8085 | Loss: 0.09564635902643204\n",
      "Batch：8086 | Loss: 0.10144196450710297\n",
      "Batch：8087 | Loss: 0.08673649281263351\n",
      "Batch：8088 | Loss: 0.08983363956212997\n",
      "Batch：8089 | Loss: 0.0800708532333374\n",
      "Batch：8090 | Loss: 0.08327069878578186\n",
      "Batch：8091 | Loss: 0.09531176835298538\n",
      "Batch：8092 | Loss: 0.07460320740938187\n",
      "Batch：8093 | Loss: 0.08732004463672638\n",
      "Batch：8094 | Loss: 0.08892984688282013\n",
      "Batch：8095 | Loss: 0.08347850292921066\n",
      "Batch：8096 | Loss: 0.08221255987882614\n",
      "Batch：8097 | Loss: 0.08818291872739792\n",
      "Batch：8098 | Loss: 0.09320312738418579\n",
      "Batch：8099 | Loss: 0.0934472531080246\n",
      "Batch：8100 | Loss: 0.08031677454710007\n",
      "Batch：8101 | Loss: 0.07704730331897736\n",
      "Batch：8102 | Loss: 0.08017424494028091\n",
      "Batch：8103 | Loss: 0.0905337929725647\n",
      "Batch：8104 | Loss: 0.09390488266944885\n",
      "Batch：8105 | Loss: 0.0959540382027626\n",
      "Batch：8106 | Loss: 0.07963450253009796\n",
      "Batch：8107 | Loss: 0.08937688916921616\n",
      "Batch：8108 | Loss: 0.0871095359325409\n",
      "Batch：8109 | Loss: 0.08189697563648224\n",
      "Batch：8110 | Loss: 0.08902158588171005\n",
      "Batch：8111 | Loss: 0.07492046058177948\n",
      "Batch：8112 | Loss: 0.08644785732030869\n",
      "Batch：8113 | Loss: 0.07766077667474747\n",
      "Batch：8114 | Loss: 0.07057536393404007\n",
      "Batch：8115 | Loss: 0.09451719373464584\n",
      "Batch：8116 | Loss: 0.08831962943077087\n",
      "Batch：8117 | Loss: 0.08840112388134003\n",
      "Batch：8118 | Loss: 0.10144282877445221\n",
      "Batch：8119 | Loss: 0.08374904841184616\n",
      "Batch：8120 | Loss: 0.08498937636613846\n",
      "Batch：8121 | Loss: 0.09686338156461716\n",
      "Batch：8122 | Loss: 0.085458904504776\n",
      "Batch：8123 | Loss: 0.08378920704126358\n",
      "Batch：8124 | Loss: 0.07618415355682373\n",
      "Batch：8125 | Loss: 0.08927302807569504\n",
      "Batch：8126 | Loss: 0.08020921796560287\n",
      "Batch：8127 | Loss: 0.09193029999732971\n",
      "Batch：8128 | Loss: 0.08535778522491455\n",
      "Batch：8129 | Loss: 0.08148714900016785\n",
      "Batch：8130 | Loss: 0.07843568921089172\n",
      "Batch：8131 | Loss: 0.08293063193559647\n",
      "Batch：8132 | Loss: 0.0918264165520668\n",
      "Batch：8133 | Loss: 0.08460535854101181\n",
      "Batch：8134 | Loss: 0.07667769491672516\n",
      "Batch：8135 | Loss: 0.08401525020599365\n",
      "Batch：8136 | Loss: 0.0745687335729599\n",
      "Batch：8137 | Loss: 0.0872296616435051\n",
      "Batch：8138 | Loss: 0.07588721811771393\n",
      "Batch：8139 | Loss: 0.0913398340344429\n",
      "Batch：8140 | Loss: 0.09017755091190338\n",
      "Batch：8141 | Loss: 0.0874054953455925\n",
      "Batch：8142 | Loss: 0.09764566272497177\n",
      "Batch：8143 | Loss: 0.08151066303253174\n",
      "Batch：8144 | Loss: 0.08288523554801941\n",
      "Batch：8145 | Loss: 0.08264066278934479\n",
      "Batch：8146 | Loss: 0.08498872816562653\n",
      "Batch：8147 | Loss: 0.09191499650478363\n",
      "Batch：8148 | Loss: 0.06636541336774826\n",
      "Batch：8149 | Loss: 0.07844175398349762\n",
      "Batch：8150 | Loss: 0.08442329615354538\n",
      "Batch：8151 | Loss: 0.08148873597383499\n",
      "Batch：8152 | Loss: 0.09128159284591675\n",
      "Batch：8153 | Loss: 0.077854223549366\n",
      "Batch：8154 | Loss: 0.08869218081235886\n",
      "Batch：8155 | Loss: 0.09938376396894455\n",
      "Batch：8156 | Loss: 0.0944160521030426\n",
      "Batch：8157 | Loss: 0.08858568966388702\n",
      "Batch：8158 | Loss: 0.08914465457201004\n",
      "Batch：8159 | Loss: 0.08525900542736053\n",
      "Batch：8160 | Loss: 0.08914443105459213\n",
      "Batch：8161 | Loss: 0.07984922081232071\n",
      "Batch：8162 | Loss: 0.08404324948787689\n",
      "Batch：8163 | Loss: 0.07707186043262482\n",
      "Batch：8164 | Loss: 0.09653820842504501\n",
      "Batch：8165 | Loss: 0.0814349427819252\n",
      "Batch：8166 | Loss: 0.08713305741548538\n",
      "Batch：8167 | Loss: 0.09311966598033905\n",
      "Batch：8168 | Loss: 0.0783476009964943\n",
      "Batch：8169 | Loss: 0.07976190745830536\n",
      "Batch：8170 | Loss: 0.09954672306776047\n",
      "Batch：8171 | Loss: 0.08467520773410797\n",
      "Batch：8172 | Loss: 0.08887719362974167\n",
      "Batch：8173 | Loss: 0.0861990675330162\n",
      "Batch：8174 | Loss: 0.07210364937782288\n",
      "Batch：8175 | Loss: 0.08534110337495804\n",
      "Batch：8176 | Loss: 0.07839258015155792\n",
      "Batch：8177 | Loss: 0.09457603096961975\n",
      "Batch：8178 | Loss: 0.09296698868274689\n",
      "Batch：8179 | Loss: 0.0786176472902298\n",
      "Batch：8180 | Loss: 0.08374884724617004\n",
      "Batch：8181 | Loss: 0.07378526777029037\n",
      "Batch：8182 | Loss: 0.08448721468448639\n",
      "Batch：8183 | Loss: 0.09045803546905518\n",
      "Batch：8184 | Loss: 0.0824396014213562\n",
      "Batch：8185 | Loss: 0.07940123230218887\n",
      "Batch：8186 | Loss: 0.08177554607391357\n",
      "Batch：8187 | Loss: 0.08234043419361115\n",
      "Batch：8188 | Loss: 0.09051289409399033\n",
      "Batch：8189 | Loss: 0.09246762096881866\n",
      "Batch：8190 | Loss: 0.08141990751028061\n",
      "Batch：8191 | Loss: 0.08931288868188858\n",
      "Batch：8192 | Loss: 0.09244494885206223\n",
      "Batch：8193 | Loss: 0.08959771692752838\n",
      "Batch：8194 | Loss: 0.0981827974319458\n",
      "Batch：8195 | Loss: 0.09551014751195908\n",
      "Batch：8196 | Loss: 0.08068842440843582\n",
      "Batch：8197 | Loss: 0.08752527087926865\n",
      "Batch：8198 | Loss: 0.09157224744558334\n",
      "Batch：8199 | Loss: 0.07807270437479019\n",
      "Batch：8200 | Loss: 0.07763621211051941\n",
      "Batch：8201 | Loss: 0.0920214131474495\n",
      "Batch：8202 | Loss: 0.09049835056066513\n",
      "Batch：8203 | Loss: 0.08564692735671997\n",
      "Batch：8204 | Loss: 0.08414001017808914\n",
      "Batch：8205 | Loss: 0.09149763733148575\n",
      "Batch：8206 | Loss: 0.07910534739494324\n",
      "Batch：8207 | Loss: 0.09297651797533035\n",
      "Batch：8208 | Loss: 0.07845388352870941\n",
      "Batch：8209 | Loss: 0.07945389300584793\n",
      "Batch：8210 | Loss: 0.08438103646039963\n",
      "Batch：8211 | Loss: 0.08409026265144348\n",
      "Batch：8212 | Loss: 0.08807350695133209\n",
      "Batch：8213 | Loss: 0.07143288105726242\n",
      "Batch：8214 | Loss: 0.07675003260374069\n",
      "Batch：8215 | Loss: 0.09403057396411896\n",
      "Batch：8216 | Loss: 0.09075307101011276\n",
      "Batch：8217 | Loss: 0.07448618859052658\n",
      "Batch：8218 | Loss: 0.07645417004823685\n",
      "Batch：8219 | Loss: 0.07713112980127335\n",
      "Batch：8220 | Loss: 0.09460489451885223\n",
      "Batch：8221 | Loss: 0.09001562744379044\n",
      "Batch：8222 | Loss: 0.07826688885688782\n",
      "Batch：8223 | Loss: 0.0849532037973404\n",
      "Batch：8224 | Loss: 0.08159834891557693\n",
      "Batch：8225 | Loss: 0.08274558186531067\n",
      "Batch：8226 | Loss: 0.07811687141656876\n",
      "Batch：8227 | Loss: 0.0829300507903099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：8228 | Loss: 0.09777504205703735\n",
      "Batch：8229 | Loss: 0.09671337902545929\n",
      "Batch：8230 | Loss: 0.08877979218959808\n",
      "Batch：8231 | Loss: 0.08670546114444733\n",
      "Batch：8232 | Loss: 0.08110691606998444\n",
      "Batch：8233 | Loss: 0.0915934145450592\n",
      "Batch：8234 | Loss: 0.07510007172822952\n",
      "Batch：8235 | Loss: 0.08808845281600952\n",
      "Batch：8236 | Loss: 0.09000580757856369\n",
      "Batch：8237 | Loss: 0.08376075327396393\n",
      "Batch：8238 | Loss: 0.08670073002576828\n",
      "Batch：8239 | Loss: 0.08187904953956604\n",
      "Batch：8240 | Loss: 0.09577800333499908\n",
      "Batch：8241 | Loss: 0.08814236521720886\n",
      "Batch：8242 | Loss: 0.07934451848268509\n",
      "Batch：8243 | Loss: 0.07766541093587875\n",
      "Batch：8244 | Loss: 0.09326303750276566\n",
      "Batch：8245 | Loss: 0.09822411835193634\n",
      "Batch：8246 | Loss: 0.0929713100194931\n",
      "Batch：8247 | Loss: 0.09153900295495987\n",
      "Batch：8248 | Loss: 0.08663016557693481\n",
      "Batch：8249 | Loss: 0.09100693464279175\n",
      "Batch：8250 | Loss: 0.08596840500831604\n",
      "Batch：8251 | Loss: 0.08613678067922592\n",
      "Batch：8252 | Loss: 0.0974675789475441\n",
      "Batch：8253 | Loss: 0.0854121521115303\n",
      "Batch：8254 | Loss: 0.09120798856019974\n",
      "Batch：8255 | Loss: 0.07564090192317963\n",
      "Batch：8256 | Loss: 0.08036310225725174\n",
      "Batch：8257 | Loss: 0.08296749740839005\n",
      "Batch：8258 | Loss: 0.08593306690454483\n",
      "Batch：8259 | Loss: 0.08803137391805649\n",
      "Batch：8260 | Loss: 0.08279241621494293\n",
      "Batch：8261 | Loss: 0.07571157068014145\n",
      "Batch：8262 | Loss: 0.08627282828092575\n",
      "Batch：8263 | Loss: 0.09165629744529724\n",
      "Batch：8264 | Loss: 0.08208511769771576\n",
      "Batch：8265 | Loss: 0.07840501517057419\n",
      "Batch：8266 | Loss: 0.08235041052103043\n",
      "Batch：8267 | Loss: 0.09135511517524719\n",
      "Batch：8268 | Loss: 0.08948493003845215\n",
      "Batch：8269 | Loss: 0.10062947124242783\n",
      "Batch：8270 | Loss: 0.07835788279771805\n",
      "Batch：8271 | Loss: 0.09607242792844772\n",
      "Batch：8272 | Loss: 0.0848698541522026\n",
      "Batch：8273 | Loss: 0.08890940994024277\n",
      "Batch：8274 | Loss: 0.08475607633590698\n",
      "Batch：8275 | Loss: 0.0835975855588913\n",
      "Batch：8276 | Loss: 0.08877471834421158\n",
      "Batch：8277 | Loss: 0.08759300410747528\n",
      "Batch：8278 | Loss: 0.08022570610046387\n",
      "Batch：8279 | Loss: 0.08448446542024612\n",
      "Batch：8280 | Loss: 0.09445728361606598\n",
      "Batch：8281 | Loss: 0.0930209532380104\n",
      "Batch：8282 | Loss: 0.07422201335430145\n",
      "Batch：8283 | Loss: 0.06544924527406693\n",
      "Batch：8284 | Loss: 0.09808481484651566\n",
      "Batch：8285 | Loss: 0.07707676291465759\n",
      "Batch：8286 | Loss: 0.07611329853534698\n",
      "Batch：8287 | Loss: 0.09351613372564316\n",
      "Batch：8288 | Loss: 0.08381382375955582\n",
      "Batch：8289 | Loss: 0.08058016747236252\n",
      "Batch：8290 | Loss: 0.08442807197570801\n",
      "Batch：8291 | Loss: 0.09866241365671158\n",
      "Batch：8292 | Loss: 0.09048829972743988\n",
      "Batch：8293 | Loss: 0.08547497540712357\n",
      "Batch：8294 | Loss: 0.07905975729227066\n",
      "Batch：8295 | Loss: 0.07939371466636658\n",
      "Batch：8296 | Loss: 0.08257894963026047\n",
      "Batch：8297 | Loss: 0.08272378891706467\n",
      "Batch：8298 | Loss: 0.08202830702066422\n",
      "Batch：8299 | Loss: 0.08046773076057434\n",
      "Batch：8300 | Loss: 0.08456601947546005\n",
      "Batch：8301 | Loss: 0.08039360493421555\n",
      "Batch：8302 | Loss: 0.09074410796165466\n",
      "Batch：8303 | Loss: 0.09426137059926987\n",
      "Batch：8304 | Loss: 0.08310244977474213\n",
      "Batch：8305 | Loss: 0.07499450445175171\n",
      "Batch：8306 | Loss: 0.09168283641338348\n",
      "Batch：8307 | Loss: 0.0794672966003418\n",
      "Batch：8308 | Loss: 0.0909486711025238\n",
      "Batch：8309 | Loss: 0.0823715403676033\n",
      "Batch：8310 | Loss: 0.09289906919002533\n",
      "Batch：8311 | Loss: 0.0811392143368721\n",
      "Batch：8312 | Loss: 0.08628464490175247\n",
      "Batch：8313 | Loss: 0.08476395159959793\n",
      "Batch：8314 | Loss: 0.08553656190633774\n",
      "Batch：8315 | Loss: 0.09637552499771118\n",
      "Batch：8316 | Loss: 0.07858402281999588\n",
      "Batch：8317 | Loss: 0.09483066946268082\n",
      "Batch：8318 | Loss: 0.10037694871425629\n",
      "Batch：8319 | Loss: 0.08005903661251068\n",
      "Batch：8320 | Loss: 0.08038253337144852\n",
      "Batch：8321 | Loss: 0.08498410880565643\n",
      "Batch：8322 | Loss: 0.09310451149940491\n",
      "Batch：8323 | Loss: 0.07743413001298904\n",
      "Batch：8324 | Loss: 0.08404308557510376\n",
      "Batch：8325 | Loss: 0.08727490901947021\n",
      "Batch：8326 | Loss: 0.08077613264322281\n",
      "Batch：8327 | Loss: 0.08567091077566147\n",
      "Batch：8328 | Loss: 0.07747291028499603\n",
      "Batch：8329 | Loss: 0.09144946187734604\n",
      "Batch：8330 | Loss: 0.0900772288441658\n",
      "Batch：8331 | Loss: 0.07815858721733093\n",
      "Batch：8332 | Loss: 0.08913830667734146\n",
      "Batch：8333 | Loss: 0.08170997351408005\n",
      "Batch：8334 | Loss: 0.09799975156784058\n",
      "Batch：8335 | Loss: 0.09040771424770355\n",
      "Batch：8336 | Loss: 0.07705137878656387\n",
      "Batch：8337 | Loss: 0.08395788818597794\n",
      "Batch：8338 | Loss: 0.09552890807390213\n",
      "Batch：8339 | Loss: 0.07972743362188339\n",
      "Batch：8340 | Loss: 0.07888028025627136\n",
      "Batch：8341 | Loss: 0.0636807233095169\n",
      "Batch：8342 | Loss: 0.0858200192451477\n",
      "Batch：8343 | Loss: 0.08304648101329803\n",
      "Batch：8344 | Loss: 0.07151967287063599\n",
      "Batch：8345 | Loss: 0.08157310634851456\n",
      "Batch：8346 | Loss: 0.08529800921678543\n",
      "Batch：8347 | Loss: 0.08624425530433655\n",
      "Batch：8348 | Loss: 0.07674086093902588\n",
      "Batch：8349 | Loss: 0.0780717134475708\n",
      "Batch：8350 | Loss: 0.07650920748710632\n",
      "Batch：8351 | Loss: 0.09104756265878677\n",
      "Batch：8352 | Loss: 0.0814758911728859\n",
      "Batch：8353 | Loss: 0.08221426606178284\n",
      "Batch：8354 | Loss: 0.08007040619850159\n",
      "Batch：8355 | Loss: 0.0801781713962555\n",
      "Batch：8356 | Loss: 0.08143886923789978\n",
      "Batch：8357 | Loss: 0.08749554306268692\n",
      "Batch：8358 | Loss: 0.08675398677587509\n",
      "Batch：8359 | Loss: 0.09020672738552094\n",
      "Batch：8360 | Loss: 0.08155728876590729\n",
      "Batch：8361 | Loss: 0.09086339175701141\n",
      "Batch：8362 | Loss: 0.09201724827289581\n",
      "Batch：8363 | Loss: 0.08985944837331772\n",
      "Batch：8364 | Loss: 0.0841255858540535\n",
      "Batch：8365 | Loss: 0.07616034895181656\n",
      "Batch：8366 | Loss: 0.08090556412935257\n",
      "Batch：8367 | Loss: 0.0747632160782814\n",
      "Batch：8368 | Loss: 0.08524645119905472\n",
      "Batch：8369 | Loss: 0.07619277387857437\n",
      "Batch：8370 | Loss: 0.073857381939888\n",
      "Batch：8371 | Loss: 0.09094134718179703\n",
      "Batch：8372 | Loss: 0.09231105446815491\n",
      "Batch：8373 | Loss: 0.0670257955789566\n",
      "Batch：8374 | Loss: 0.08135934174060822\n",
      "Batch：8375 | Loss: 0.07908361405134201\n",
      "Batch：8376 | Loss: 0.08330239355564117\n",
      "Batch：8377 | Loss: 0.08410250395536423\n",
      "Batch：8378 | Loss: 0.08001256734132767\n",
      "Batch：8379 | Loss: 0.09775170683860779\n",
      "Batch：8380 | Loss: 0.07863321155309677\n",
      "Batch：8381 | Loss: 0.09317275881767273\n",
      "Batch：8382 | Loss: 0.07678685337305069\n",
      "Batch：8383 | Loss: 0.08326787501573563\n",
      "Batch：8384 | Loss: 0.08032863587141037\n",
      "Batch：8385 | Loss: 0.08508367091417313\n",
      "Batch：8386 | Loss: 0.09361254423856735\n",
      "Batch：8387 | Loss: 0.08485401421785355\n",
      "Batch：8388 | Loss: 0.10622216761112213\n",
      "Batch：8389 | Loss: 0.07736123353242874\n",
      "Batch：8390 | Loss: 0.07260085642337799\n",
      "Batch：8391 | Loss: 0.07433627545833588\n",
      "Batch：8392 | Loss: 0.07732588052749634\n",
      "Batch：8393 | Loss: 0.07636335492134094\n",
      "Batch：8394 | Loss: 0.09057002514600754\n",
      "Batch：8395 | Loss: 0.0945378988981247\n",
      "Batch：8396 | Loss: 0.07857002317905426\n",
      "Batch：8397 | Loss: 0.08294165134429932\n",
      "Batch：8398 | Loss: 0.08716234564781189\n",
      "Batch：8399 | Loss: 0.07348854839801788\n",
      "Batch：8400 | Loss: 0.09179982542991638\n",
      "Batch：8401 | Loss: 0.08310282975435257\n",
      "Batch：8402 | Loss: 0.0892510637640953\n",
      "Batch：8403 | Loss: 0.08042871952056885\n",
      "Batch：8404 | Loss: 0.08170098066329956\n",
      "Batch：8405 | Loss: 0.08444541692733765\n",
      "Batch：8406 | Loss: 0.08630440384149551\n",
      "Batch：8407 | Loss: 0.08793188631534576\n",
      "Batch：8408 | Loss: 0.08378328382968903\n",
      "Batch：8409 | Loss: 0.08921020478010178\n",
      "Batch：8410 | Loss: 0.07072795182466507\n",
      "Batch：8411 | Loss: 0.08436879515647888\n",
      "Batch：8412 | Loss: 0.07875547558069229\n",
      "Batch：8413 | Loss: 0.08201264590024948\n",
      "Batch：8414 | Loss: 0.09815814346075058\n",
      "Batch：8415 | Loss: 0.08808010071516037\n",
      "Batch：8416 | Loss: 0.09442681074142456\n",
      "Batch：8417 | Loss: 0.0858643501996994\n",
      "Batch：8418 | Loss: 0.07829674333333969\n",
      "Batch：8419 | Loss: 0.08154844492673874\n",
      "Batch：8420 | Loss: 0.07186216115951538\n",
      "Batch：8421 | Loss: 0.0735507681965828\n",
      "Batch：8422 | Loss: 0.07893809676170349\n",
      "Batch：8423 | Loss: 0.08194784075021744\n",
      "Batch：8424 | Loss: 0.09030797332525253\n",
      "Batch：8425 | Loss: 0.07623157650232315\n",
      "Batch：8426 | Loss: 0.08446182310581207\n",
      "Batch：8427 | Loss: 0.08432326465845108\n",
      "Batch：8428 | Loss: 0.08156644552946091\n",
      "Batch：8429 | Loss: 0.0817955955862999\n",
      "Batch：8430 | Loss: 0.07822394371032715\n",
      "Batch：8431 | Loss: 0.08767101913690567\n",
      "Batch：8432 | Loss: 0.07195719331502914\n",
      "Batch：8433 | Loss: 0.09043140709400177\n",
      "Batch：8434 | Loss: 0.08613873273134232\n",
      "Batch：8435 | Loss: 0.08548319339752197\n",
      "Batch：8436 | Loss: 0.0797574520111084\n",
      "Batch：8437 | Loss: 0.07736019790172577\n",
      "Batch：8438 | Loss: 0.09103575348854065\n",
      "Batch：8439 | Loss: 0.07578074187040329\n",
      "Batch：8440 | Loss: 0.08190713077783585\n",
      "Batch：8441 | Loss: 0.08603890240192413\n",
      "Batch：8442 | Loss: 0.08105826377868652\n",
      "Batch：8443 | Loss: 0.09169819205999374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：8444 | Loss: 0.07519593089818954\n",
      "Batch：8445 | Loss: 0.0801946371793747\n",
      "Batch：8446 | Loss: 0.08789122104644775\n",
      "Batch：8447 | Loss: 0.0840379148721695\n",
      "Batch：8448 | Loss: 0.09204433113336563\n",
      "Batch：8449 | Loss: 0.08988337218761444\n",
      "Batch：8450 | Loss: 0.09727469831705093\n",
      "Batch：8451 | Loss: 0.08868711441755295\n",
      "Batch：8452 | Loss: 0.07552824169397354\n",
      "Batch：8453 | Loss: 0.08105063438415527\n",
      "Batch：8454 | Loss: 0.08819251507520676\n",
      "Batch：8455 | Loss: 0.07995447516441345\n",
      "Batch：8456 | Loss: 0.08683732151985168\n",
      "Batch：8457 | Loss: 0.0863441750407219\n",
      "Batch：8458 | Loss: 0.08598639070987701\n",
      "Batch：8459 | Loss: 0.08319918066263199\n",
      "Batch：8460 | Loss: 0.07549300789833069\n",
      "Batch：8461 | Loss: 0.08480751514434814\n",
      "Batch：8462 | Loss: 0.08914856612682343\n",
      "Batch：8463 | Loss: 0.08604052662849426\n",
      "Batch：8464 | Loss: 0.08420364558696747\n",
      "Batch：8465 | Loss: 0.08653574436903\n",
      "Batch：8466 | Loss: 0.08144940435886383\n",
      "Batch：8467 | Loss: 0.07700657844543457\n",
      "Batch：8468 | Loss: 0.09345259517431259\n",
      "Batch：8469 | Loss: 0.08559738844633102\n",
      "Batch：8470 | Loss: 0.07868208736181259\n",
      "Batch：8471 | Loss: 0.0851975604891777\n",
      "Batch：8472 | Loss: 0.08013857156038284\n",
      "Batch：8473 | Loss: 0.08213029056787491\n",
      "Batch：8474 | Loss: 0.08507589250802994\n",
      "Batch：8475 | Loss: 0.09028393775224686\n",
      "Batch：8476 | Loss: 0.0777716189622879\n",
      "Batch：8477 | Loss: 0.08610699325799942\n",
      "Batch：8478 | Loss: 0.07434224337339401\n",
      "Batch：8479 | Loss: 0.08029051870107651\n",
      "Batch：8480 | Loss: 0.084809310734272\n",
      "Batch：8481 | Loss: 0.07589203119277954\n",
      "Batch：8482 | Loss: 0.0781184658408165\n",
      "Batch：8483 | Loss: 0.08332057297229767\n",
      "Batch：8484 | Loss: 0.0904514342546463\n",
      "Batch：8485 | Loss: 0.07708980143070221\n",
      "Batch：8486 | Loss: 0.07995627075433731\n",
      "Batch：8487 | Loss: 0.07812804728746414\n",
      "Batch：8488 | Loss: 0.06897934526205063\n",
      "Batch：8489 | Loss: 0.09146497398614883\n",
      "Batch：8490 | Loss: 0.07254009693861008\n",
      "Batch：8491 | Loss: 0.0865427553653717\n",
      "Batch：8492 | Loss: 0.07818622142076492\n",
      "Batch：8493 | Loss: 0.0848449245095253\n",
      "Batch：8494 | Loss: 0.08248122036457062\n",
      "Batch：8495 | Loss: 0.08662594854831696\n",
      "Batch：8496 | Loss: 0.0893874391913414\n",
      "Batch：8497 | Loss: 0.07184130698442459\n",
      "Batch：8498 | Loss: 0.08370359987020493\n",
      "Batch：8499 | Loss: 0.08897670358419418\n",
      "Batch：8500 | Loss: 0.08356992155313492\n",
      "Batch：8501 | Loss: 0.0822366252541542\n",
      "Batch：8502 | Loss: 0.08056806027889252\n",
      "Batch：8503 | Loss: 0.08015359193086624\n",
      "Batch：8504 | Loss: 0.08808227628469467\n",
      "Batch：8505 | Loss: 0.07851026207208633\n",
      "Batch：8506 | Loss: 0.08354984223842621\n",
      "Batch：8507 | Loss: 0.08458840101957321\n",
      "Batch：8508 | Loss: 0.09196297079324722\n",
      "Batch：8509 | Loss: 0.07811792939901352\n",
      "Batch：8510 | Loss: 0.06644884496927261\n",
      "Batch：8511 | Loss: 0.08588122576475143\n",
      "Batch：8512 | Loss: 0.08135408908128738\n",
      "Batch：8513 | Loss: 0.07981643825769424\n",
      "Batch：8514 | Loss: 0.07649367302656174\n",
      "Batch：8515 | Loss: 0.07626477628946304\n",
      "Batch：8516 | Loss: 0.08086948841810226\n",
      "Batch：8517 | Loss: 0.08952687680721283\n",
      "Batch：8518 | Loss: 0.0872073769569397\n",
      "Batch：8519 | Loss: 0.08869968354701996\n",
      "Batch：8520 | Loss: 0.08969676494598389\n",
      "Batch：8521 | Loss: 0.07465305179357529\n",
      "Batch：8522 | Loss: 0.07685798406600952\n",
      "Batch：8523 | Loss: 0.07335587590932846\n",
      "Batch：8524 | Loss: 0.085943304002285\n",
      "Batch：8525 | Loss: 0.07843061536550522\n",
      "Batch：8526 | Loss: 0.0781230628490448\n",
      "Batch：8527 | Loss: 0.08350128680467606\n",
      "Batch：8528 | Loss: 0.07901860773563385\n",
      "Batch：8529 | Loss: 0.0848124697804451\n",
      "Batch：8530 | Loss: 0.08445724099874496\n",
      "Batch：8531 | Loss: 0.08885368704795837\n",
      "Batch：8532 | Loss: 0.08813972771167755\n",
      "Batch：8533 | Loss: 0.08751878887414932\n",
      "Batch：8534 | Loss: 0.09024257212877274\n",
      "Batch：8535 | Loss: 0.08163286745548248\n",
      "Batch：8536 | Loss: 0.06853020936250687\n",
      "Batch：8537 | Loss: 0.08116661757230759\n",
      "Batch：8538 | Loss: 0.07253053039312363\n",
      "Batch：8539 | Loss: 0.09587827324867249\n",
      "Batch：8540 | Loss: 0.08215710520744324\n",
      "Batch：8541 | Loss: 0.0736328661441803\n",
      "Batch：8542 | Loss: 0.07639656960964203\n",
      "Batch：8543 | Loss: 0.08606316149234772\n",
      "Batch：8544 | Loss: 0.09532997757196426\n",
      "Batch：8545 | Loss: 0.08468026667833328\n",
      "Batch：8546 | Loss: 0.07543822377920151\n",
      "Batch：8547 | Loss: 0.07487000524997711\n",
      "Batch：8548 | Loss: 0.08109032362699509\n",
      "Batch：8549 | Loss: 0.07083872705698013\n",
      "Batch：8550 | Loss: 0.08452408760786057\n",
      "Batch：8551 | Loss: 0.0845632329583168\n",
      "Batch：8552 | Loss: 0.07108174264431\n",
      "Batch：8553 | Loss: 0.08862003684043884\n",
      "Batch：8554 | Loss: 0.0898052379488945\n",
      "Batch：8555 | Loss: 0.08762259781360626\n",
      "Batch：8556 | Loss: 0.07979588955640793\n",
      "Batch：8557 | Loss: 0.08104493468999863\n",
      "Batch：8558 | Loss: 0.08175135403871536\n",
      "Batch：8559 | Loss: 0.0829751268029213\n",
      "Batch：8560 | Loss: 0.09702380001544952\n",
      "Batch：8561 | Loss: 0.07180017232894897\n",
      "Batch：8562 | Loss: 0.09722495079040527\n",
      "Batch：8563 | Loss: 0.08781077712774277\n",
      "Batch：8564 | Loss: 0.07309196144342422\n",
      "Batch：8565 | Loss: 0.07944319397211075\n",
      "Batch：8566 | Loss: 0.09388785809278488\n",
      "Batch：8567 | Loss: 0.09048959612846375\n",
      "Batch：8568 | Loss: 0.08754897117614746\n",
      "Batch：8569 | Loss: 0.08161988109350204\n",
      "Batch：8570 | Loss: 0.08371031284332275\n",
      "Batch：8571 | Loss: 0.08664292097091675\n",
      "Batch：8572 | Loss: 0.08222153782844543\n",
      "Batch：8573 | Loss: 0.07621367275714874\n",
      "Batch：8574 | Loss: 0.07902499288320541\n",
      "Batch：8575 | Loss: 0.0816827192902565\n",
      "Batch：8576 | Loss: 0.08677670359611511\n",
      "Batch：8577 | Loss: 0.08375054597854614\n",
      "Batch：8578 | Loss: 0.07413803040981293\n",
      "Batch：8579 | Loss: 0.08310532569885254\n",
      "Batch：8580 | Loss: 0.07419807463884354\n",
      "Batch：8581 | Loss: 0.07397778332233429\n",
      "Batch：8582 | Loss: 0.09061318635940552\n",
      "Batch：8583 | Loss: 0.0888729840517044\n",
      "Batch：8584 | Loss: 0.07876923680305481\n",
      "Batch：8585 | Loss: 0.07487597316503525\n",
      "Batch：8586 | Loss: 0.08173248916864395\n",
      "Batch：8587 | Loss: 0.08785537630319595\n",
      "Batch：8588 | Loss: 0.08139851689338684\n",
      "Batch：8589 | Loss: 0.0740416944026947\n",
      "Batch：8590 | Loss: 0.0750763863325119\n",
      "Batch：8591 | Loss: 0.07037567347288132\n",
      "Batch：8592 | Loss: 0.0879044383764267\n",
      "Batch：8593 | Loss: 0.07832352817058563\n",
      "Batch：8594 | Loss: 0.0844341292977333\n",
      "Batch：8595 | Loss: 0.07926154136657715\n",
      "Batch：8596 | Loss: 0.09101616591215134\n",
      "Batch：8597 | Loss: 0.08395609259605408\n",
      "Batch：8598 | Loss: 0.07770916819572449\n",
      "Batch：8599 | Loss: 0.09290678054094315\n",
      "Batch：8600 | Loss: 0.08703722804784775\n",
      "Batch：8601 | Loss: 0.09368442744016647\n",
      "Batch：8602 | Loss: 0.08622574806213379\n",
      "Batch：8603 | Loss: 0.08019962161779404\n",
      "Batch：8604 | Loss: 0.07080232352018356\n",
      "Batch：8605 | Loss: 0.08960821479558945\n",
      "Batch：8606 | Loss: 0.0839846208691597\n",
      "Batch：8607 | Loss: 0.08342006802558899\n",
      "Batch：8608 | Loss: 0.08335937559604645\n",
      "Batch：8609 | Loss: 0.08324602991342545\n",
      "Batch：8610 | Loss: 0.08098112791776657\n",
      "Batch：8611 | Loss: 0.0787411779165268\n",
      "Batch：8612 | Loss: 0.08401588350534439\n",
      "Batch：8613 | Loss: 0.0832885205745697\n",
      "Batch：8614 | Loss: 0.08422635495662689\n",
      "Batch：8615 | Loss: 0.0733531266450882\n",
      "Batch：8616 | Loss: 0.09419290721416473\n",
      "Batch：8617 | Loss: 0.08561359345912933\n",
      "Batch：8618 | Loss: 0.07999531179666519\n",
      "Batch：8619 | Loss: 0.07908867299556732\n",
      "Batch：8620 | Loss: 0.08496975153684616\n",
      "Batch：8621 | Loss: 0.08354762196540833\n",
      "Batch：8622 | Loss: 0.08376458287239075\n",
      "Batch：8623 | Loss: 0.07357586920261383\n",
      "Batch：8624 | Loss: 0.07843400537967682\n",
      "Batch：8625 | Loss: 0.07894463837146759\n",
      "Batch：8626 | Loss: 0.08891088515520096\n",
      "Batch：8627 | Loss: 0.08523566275835037\n",
      "Batch：8628 | Loss: 0.07689321041107178\n",
      "Batch：8629 | Loss: 0.0751475915312767\n",
      "Batch：8630 | Loss: 0.07996825873851776\n",
      "Batch：8631 | Loss: 0.08357122540473938\n",
      "Batch：8632 | Loss: 0.09384637326002121\n",
      "Batch：8633 | Loss: 0.07591446489095688\n",
      "Batch：8634 | Loss: 0.07312504202127457\n",
      "Batch：8635 | Loss: 0.08896320313215256\n",
      "Batch：8636 | Loss: 0.0949261337518692\n",
      "Batch：8637 | Loss: 0.0845198705792427\n",
      "Batch：8638 | Loss: 0.0715242400765419\n",
      "Batch：8639 | Loss: 0.09391727298498154\n",
      "Batch：8640 | Loss: 0.08770626038312912\n",
      "Batch：8641 | Loss: 0.08691884577274323\n",
      "Batch：8642 | Loss: 0.08529196679592133\n",
      "Batch：8643 | Loss: 0.09095834940671921\n",
      "Batch：8644 | Loss: 0.07875511795282364\n",
      "Batch：8645 | Loss: 0.06700345128774643\n",
      "Batch：8646 | Loss: 0.07203445583581924\n",
      "Batch：8647 | Loss: 0.07271823287010193\n",
      "Batch：8648 | Loss: 0.0787724107503891\n",
      "Batch：8649 | Loss: 0.07660826295614243\n",
      "Batch：8650 | Loss: 0.0874084085226059\n",
      "Batch：8651 | Loss: 0.08915974944829941\n",
      "Batch：8652 | Loss: 0.07919267565011978\n",
      "Batch：8653 | Loss: 0.07837456464767456\n",
      "Batch：8654 | Loss: 0.08340159803628922\n",
      "Batch：8655 | Loss: 0.0836656391620636\n",
      "Batch：8656 | Loss: 0.09064552932977676\n",
      "Batch：8657 | Loss: 0.07271536439657211\n",
      "Batch：8658 | Loss: 0.09176365286111832\n",
      "Batch：8659 | Loss: 0.08244463801383972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：8660 | Loss: 0.0728570893406868\n",
      "Batch：8661 | Loss: 0.07095967233181\n",
      "Batch：8662 | Loss: 0.07409495115280151\n",
      "Batch：8663 | Loss: 0.08615399897098541\n",
      "Batch：8664 | Loss: 0.07760211825370789\n",
      "Batch：8665 | Loss: 0.08029139786958694\n",
      "Batch：8666 | Loss: 0.07604526728391647\n",
      "Batch：8667 | Loss: 0.09090939909219742\n",
      "Batch：8668 | Loss: 0.08024895936250687\n",
      "Batch：8669 | Loss: 0.08469823747873306\n",
      "Batch：8670 | Loss: 0.07087907940149307\n",
      "Batch：8671 | Loss: 0.08565238118171692\n",
      "Batch：8672 | Loss: 0.07252109050750732\n",
      "Batch：8673 | Loss: 0.0870402380824089\n",
      "Batch：8674 | Loss: 0.06762272864580154\n",
      "Batch：8675 | Loss: 0.08380560576915741\n",
      "Batch：8676 | Loss: 0.08457306027412415\n",
      "Batch：8677 | Loss: 0.07396528869867325\n",
      "Batch：8678 | Loss: 0.06889970600605011\n",
      "Batch：8679 | Loss: 0.08329903334379196\n",
      "Batch：8680 | Loss: 0.08127529174089432\n",
      "Batch：8681 | Loss: 0.08567284792661667\n",
      "Batch：8682 | Loss: 0.08259736746549606\n",
      "Batch：8683 | Loss: 0.08882228285074234\n",
      "Batch：8684 | Loss: 0.08364536613225937\n",
      "Batch：8685 | Loss: 0.07395235449075699\n",
      "Batch：8686 | Loss: 0.08039534091949463\n",
      "Batch：8687 | Loss: 0.07522333413362503\n",
      "Batch：8688 | Loss: 0.0812714695930481\n",
      "Batch：8689 | Loss: 0.09047690778970718\n",
      "Batch：8690 | Loss: 0.08580629527568817\n",
      "Batch：8691 | Loss: 0.07460584491491318\n",
      "Batch：8692 | Loss: 0.08979073166847229\n",
      "Batch：8693 | Loss: 0.08647904545068741\n",
      "Batch：8694 | Loss: 0.08763273805379868\n",
      "Batch：8695 | Loss: 0.08203984797000885\n",
      "Batch：8696 | Loss: 0.07293061912059784\n",
      "Batch：8697 | Loss: 0.08798150718212128\n",
      "Batch：8698 | Loss: 0.07796967774629593\n",
      "Batch：8699 | Loss: 0.07944904267787933\n",
      "Batch：8700 | Loss: 0.07457198947668076\n",
      "Batch：8701 | Loss: 0.07156180590391159\n",
      "Batch：8702 | Loss: 0.08547637611627579\n",
      "Batch：8703 | Loss: 0.08654030412435532\n",
      "Batch：8704 | Loss: 0.08759252727031708\n",
      "Batch：8705 | Loss: 0.08383875340223312\n",
      "Batch：8706 | Loss: 0.08803270012140274\n",
      "Batch：8707 | Loss: 0.09803161770105362\n",
      "Batch：8708 | Loss: 0.08427798748016357\n",
      "Batch：8709 | Loss: 0.07637988030910492\n",
      "Batch：8710 | Loss: 0.07656868547201157\n",
      "Batch：8711 | Loss: 0.07134386152029037\n",
      "Batch：8712 | Loss: 0.08336731046438217\n",
      "Batch：8713 | Loss: 0.08602260053157806\n",
      "Batch：8714 | Loss: 0.08064769953489304\n",
      "Batch：8715 | Loss: 0.08700673282146454\n",
      "Batch：8716 | Loss: 0.0802374929189682\n",
      "Batch：8717 | Loss: 0.07673349976539612\n",
      "Batch：8718 | Loss: 0.07091445475816727\n",
      "Batch：8719 | Loss: 0.0696161612868309\n",
      "Batch：8720 | Loss: 0.08765140920877457\n",
      "Batch：8721 | Loss: 0.07726041227579117\n",
      "Batch：8722 | Loss: 0.09153290838003159\n",
      "Batch：8723 | Loss: 0.07788711786270142\n",
      "Batch：8724 | Loss: 0.08658444881439209\n",
      "Batch：8725 | Loss: 0.07594160735607147\n",
      "Batch：8726 | Loss: 0.08196577429771423\n",
      "Batch：8727 | Loss: 0.09418769925832748\n",
      "Batch：8728 | Loss: 0.09158333390951157\n",
      "Batch：8729 | Loss: 0.07966488599777222\n",
      "Batch：8730 | Loss: 0.07745411247015\n",
      "Batch：8731 | Loss: 0.08771836012601852\n",
      "Batch：8732 | Loss: 0.08240224421024323\n",
      "Batch：8733 | Loss: 0.07838127762079239\n",
      "Batch：8734 | Loss: 0.08181876689195633\n",
      "Batch：8735 | Loss: 0.07549785077571869\n",
      "Batch：8736 | Loss: 0.08234387636184692\n",
      "Batch：8737 | Loss: 0.07725559920072556\n",
      "Batch：8738 | Loss: 0.08529465645551682\n",
      "Batch：8739 | Loss: 0.08516451716423035\n",
      "Batch：8740 | Loss: 0.08301404863595963\n",
      "Batch：8741 | Loss: 0.08213789016008377\n",
      "Batch：8742 | Loss: 0.08820123225450516\n",
      "Batch：8743 | Loss: 0.08621789515018463\n",
      "Batch：8744 | Loss: 0.07034732401371002\n",
      "Batch：8745 | Loss: 0.09521391987800598\n",
      "Batch：8746 | Loss: 0.08329109847545624\n",
      "Batch：8747 | Loss: 0.07973720133304596\n",
      "Batch：8748 | Loss: 0.08867814391851425\n",
      "Batch：8749 | Loss: 0.08829084038734436\n",
      "Batch：8750 | Loss: 0.07451300323009491\n",
      "Batch：8751 | Loss: 0.07207074016332626\n",
      "Batch：8752 | Loss: 0.09232853353023529\n",
      "Batch：8753 | Loss: 0.08586698025465012\n",
      "Batch：8754 | Loss: 0.06756330281496048\n",
      "Batch：8755 | Loss: 0.08822353184223175\n",
      "Batch：8756 | Loss: 0.09061529487371445\n",
      "Batch：8757 | Loss: 0.08406944572925568\n",
      "Batch：8758 | Loss: 0.07614918053150177\n",
      "Batch：8759 | Loss: 0.09147753566503525\n",
      "Batch：8760 | Loss: 0.08555831015110016\n",
      "Batch：8761 | Loss: 0.0776427835226059\n",
      "Batch：8762 | Loss: 0.08659324049949646\n",
      "Batch：8763 | Loss: 0.07743936777114868\n",
      "Batch：8764 | Loss: 0.07905263453722\n",
      "Batch：8765 | Loss: 0.07391877472400665\n",
      "Batch：8766 | Loss: 0.0898166373372078\n",
      "Batch：8767 | Loss: 0.08997462689876556\n",
      "Batch：8768 | Loss: 0.06730862706899643\n",
      "Batch：8769 | Loss: 0.07410626858472824\n",
      "Batch：8770 | Loss: 0.08313485980033875\n",
      "Batch：8771 | Loss: 0.07740000635385513\n",
      "Batch：8772 | Loss: 0.08121523261070251\n",
      "Batch：8773 | Loss: 0.08376996219158173\n",
      "Batch：8774 | Loss: 0.07863495498895645\n",
      "Batch：8775 | Loss: 0.08412047475576401\n",
      "Batch：8776 | Loss: 0.0775461494922638\n",
      "Batch：8777 | Loss: 0.08187289535999298\n",
      "Batch：8778 | Loss: 0.07455446571111679\n",
      "Batch：8779 | Loss: 0.08649914711713791\n",
      "Batch：8780 | Loss: 0.07802194356918335\n",
      "Batch：8781 | Loss: 0.08656396716833115\n",
      "Batch：8782 | Loss: 0.09053420275449753\n",
      "Batch：8783 | Loss: 0.07658896595239639\n",
      "Batch：8784 | Loss: 0.0783793032169342\n",
      "Batch：8785 | Loss: 0.0830596387386322\n",
      "Batch：8786 | Loss: 0.07344269752502441\n",
      "Batch：8787 | Loss: 0.07937350124120712\n",
      "Batch：8788 | Loss: 0.090000219643116\n",
      "Batch：8789 | Loss: 0.08611448109149933\n",
      "Batch：8790 | Loss: 0.07856972515583038\n",
      "Batch：8791 | Loss: 0.07610123604536057\n",
      "Batch：8792 | Loss: 0.08300043642520905\n",
      "Batch：8793 | Loss: 0.07245402038097382\n",
      "Batch：8794 | Loss: 0.0761704221367836\n",
      "Batch：8795 | Loss: 0.07834271341562271\n",
      "Batch：8796 | Loss: 0.08801423758268356\n",
      "Batch：8797 | Loss: 0.08009763807058334\n",
      "Batch：8798 | Loss: 0.07439112663269043\n",
      "Batch：8799 | Loss: 0.06340242177248001\n",
      "Batch：8800 | Loss: 0.08556868135929108\n",
      "Batch：8801 | Loss: 0.08168355375528336\n",
      "Batch：8802 | Loss: 0.08070078492164612\n",
      "Batch：8803 | Loss: 0.09445670247077942\n",
      "Batch：8804 | Loss: 0.08867639303207397\n",
      "Batch：8805 | Loss: 0.07117822021245956\n",
      "Batch：8806 | Loss: 0.09535247832536697\n",
      "Batch：8807 | Loss: 0.07257868349552155\n",
      "Batch：8808 | Loss: 0.08574178069829941\n",
      "Batch：8809 | Loss: 0.09337108582258224\n",
      "Batch：8810 | Loss: 0.08143866807222366\n",
      "Batch：8811 | Loss: 0.0918644368648529\n",
      "Batch：8812 | Loss: 0.08172960579395294\n",
      "Batch：8813 | Loss: 0.0777510404586792\n",
      "Batch：8814 | Loss: 0.07273940742015839\n",
      "Batch：8815 | Loss: 0.0756879448890686\n",
      "Batch：8816 | Loss: 0.08220748603343964\n",
      "Batch：8817 | Loss: 0.08316522091627121\n",
      "Batch：8818 | Loss: 0.08182059973478317\n",
      "Batch：8819 | Loss: 0.09101409465074539\n",
      "Batch：8820 | Loss: 0.07940485328435898\n",
      "Batch：8821 | Loss: 0.08660749346017838\n",
      "Batch：8822 | Loss: 0.07947602868080139\n",
      "Batch：8823 | Loss: 0.07527387142181396\n",
      "Batch：8824 | Loss: 0.07514040917158127\n",
      "Batch：8825 | Loss: 0.08841393887996674\n",
      "Batch：8826 | Loss: 0.08410951495170593\n",
      "Batch：8827 | Loss: 0.0780876949429512\n",
      "Batch：8828 | Loss: 0.08333106338977814\n",
      "Batch：8829 | Loss: 0.07491278648376465\n",
      "Batch：8830 | Loss: 0.07564868777990341\n",
      "Batch：8831 | Loss: 0.08538901805877686\n",
      "Batch：8832 | Loss: 0.07510459423065186\n",
      "Batch：8833 | Loss: 0.08397051692008972\n",
      "Batch：8834 | Loss: 0.09209131449460983\n",
      "Batch：8835 | Loss: 0.07716110348701477\n",
      "Batch：8836 | Loss: 0.07033389806747437\n",
      "Batch：8837 | Loss: 0.08487126976251602\n",
      "Batch：8838 | Loss: 0.08056443929672241\n",
      "Batch：8839 | Loss: 0.07724520564079285\n",
      "Batch：8840 | Loss: 0.07743698358535767\n",
      "Batch：8841 | Loss: 0.08379264920949936\n",
      "Batch：8842 | Loss: 0.0822141170501709\n",
      "Batch：8843 | Loss: 0.07943719625473022\n",
      "Batch：8844 | Loss: 0.0784660056233406\n",
      "Batch：8845 | Loss: 0.08273514360189438\n",
      "Batch：8846 | Loss: 0.07749858498573303\n",
      "Batch：8847 | Loss: 0.0902402326464653\n",
      "Batch：8848 | Loss: 0.08129746466875076\n",
      "Batch：8849 | Loss: 0.08590429276227951\n",
      "Batch：8850 | Loss: 0.0721479281783104\n",
      "Batch：8851 | Loss: 0.07028801739215851\n",
      "Batch：8852 | Loss: 0.08478354662656784\n",
      "Batch：8853 | Loss: 0.08474283665418625\n",
      "Batch：8854 | Loss: 0.06519343703985214\n",
      "Batch：8855 | Loss: 0.08722932636737823\n",
      "Batch：8856 | Loss: 0.07501837611198425\n",
      "Batch：8857 | Loss: 0.07529199868440628\n",
      "Batch：8858 | Loss: 0.08539588004350662\n",
      "Batch：8859 | Loss: 0.07614068686962128\n",
      "Batch：8860 | Loss: 0.07241898775100708\n",
      "Batch：8861 | Loss: 0.08447543531656265\n",
      "Batch：8862 | Loss: 0.08672559261322021\n",
      "Batch：8863 | Loss: 0.07818153500556946\n",
      "Batch：8864 | Loss: 0.07707634568214417\n",
      "Batch：8865 | Loss: 0.07296345382928848\n",
      "Batch：8866 | Loss: 0.06847956031560898\n",
      "Batch：8867 | Loss: 0.10061304271221161\n",
      "Batch：8868 | Loss: 0.08140235394239426\n",
      "Batch：8869 | Loss: 0.07555029541254044\n",
      "Batch：8870 | Loss: 0.07770417630672455\n",
      "Batch：8871 | Loss: 0.07074972242116928\n",
      "Batch：8872 | Loss: 0.08665001392364502\n",
      "Batch：8873 | Loss: 0.08793242275714874\n",
      "Batch：8874 | Loss: 0.07096238434314728\n",
      "Batch：8875 | Loss: 0.08603865653276443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：8876 | Loss: 0.08732045441865921\n",
      "Batch：8877 | Loss: 0.07319657504558563\n",
      "Batch：8878 | Loss: 0.08218438923358917\n",
      "Batch：8879 | Loss: 0.08894746750593185\n",
      "Batch：8880 | Loss: 0.07456108182668686\n",
      "Batch：8881 | Loss: 0.08291114866733551\n",
      "Batch：8882 | Loss: 0.07746909558773041\n",
      "Batch：8883 | Loss: 0.08774485439062119\n",
      "Batch：8884 | Loss: 0.08303186297416687\n",
      "Batch：8885 | Loss: 0.09218745678663254\n",
      "Batch：8886 | Loss: 0.07962354272603989\n",
      "Batch：8887 | Loss: 0.08198964595794678\n",
      "Batch：8888 | Loss: 0.08234184980392456\n",
      "Batch：8889 | Loss: 0.08455908298492432\n",
      "Batch：8890 | Loss: 0.07779942452907562\n",
      "Batch：8891 | Loss: 0.0722583457827568\n",
      "Batch：8892 | Loss: 0.0743740126490593\n",
      "Batch：8893 | Loss: 0.07791263610124588\n",
      "Batch：8894 | Loss: 0.062789686024189\n",
      "Batch：8895 | Loss: 0.07734226435422897\n",
      "Batch：8896 | Loss: 0.07450352609157562\n",
      "Batch：8897 | Loss: 0.06975684314966202\n",
      "Batch：8898 | Loss: 0.08408819139003754\n",
      "Batch：8899 | Loss: 0.07739009708166122\n",
      "Batch：8900 | Loss: 0.07138456404209137\n",
      "Batch：8901 | Loss: 0.09398303180932999\n",
      "Batch：8902 | Loss: 0.09169773012399673\n",
      "Batch：8903 | Loss: 0.08146029710769653\n",
      "Batch：8904 | Loss: 0.08425422757863998\n",
      "Batch：8905 | Loss: 0.0739617794752121\n",
      "Batch：8906 | Loss: 0.08430750668048859\n",
      "Batch：8907 | Loss: 0.08494874089956284\n",
      "Batch：8908 | Loss: 0.07955031096935272\n",
      "Batch：8909 | Loss: 0.0831257626414299\n",
      "Batch：8910 | Loss: 0.07504585385322571\n",
      "Batch：8911 | Loss: 0.08408968895673752\n",
      "Batch：8912 | Loss: 0.08251656591892242\n",
      "Batch：8913 | Loss: 0.07820357382297516\n",
      "Batch：8914 | Loss: 0.07795548439025879\n",
      "Batch：8915 | Loss: 0.07005470246076584\n",
      "Batch：8916 | Loss: 0.08316273242235184\n",
      "Batch：8917 | Loss: 0.0804746150970459\n",
      "Batch：8918 | Loss: 0.07639404386281967\n",
      "Batch：8919 | Loss: 0.08875790983438492\n",
      "Batch：8920 | Loss: 0.08556561172008514\n",
      "Batch：8921 | Loss: 0.07532874494791031\n",
      "Batch：8922 | Loss: 0.0858074501156807\n",
      "Batch：8923 | Loss: 0.08521368354558945\n",
      "Batch：8924 | Loss: 0.07967767119407654\n",
      "Batch：8925 | Loss: 0.07170427590608597\n",
      "Batch：8926 | Loss: 0.07413401454687119\n",
      "Batch：8927 | Loss: 0.08524587750434875\n",
      "Batch：8928 | Loss: 0.07619950920343399\n",
      "Batch：8929 | Loss: 0.09043367207050323\n",
      "Batch：8930 | Loss: 0.08385535329580307\n",
      "Batch：8931 | Loss: 0.07894901186227798\n",
      "Batch：8932 | Loss: 0.08325399458408356\n",
      "Batch：8933 | Loss: 0.08280692994594574\n",
      "Batch：8934 | Loss: 0.07447508722543716\n",
      "Batch：8935 | Loss: 0.07987986505031586\n",
      "Batch：8936 | Loss: 0.08137060701847076\n",
      "Batch：8937 | Loss: 0.08846589922904968\n",
      "Batch：8938 | Loss: 0.07929185032844543\n",
      "Batch：8939 | Loss: 0.07061679661273956\n",
      "Batch：8940 | Loss: 0.09808216243982315\n",
      "Batch：8941 | Loss: 0.07644485682249069\n",
      "Batch：8942 | Loss: 0.08896615356206894\n",
      "Batch：8943 | Loss: 0.0633990541100502\n",
      "Batch：8944 | Loss: 0.08653055876493454\n",
      "Batch：8945 | Loss: 0.0765361413359642\n",
      "Batch：8946 | Loss: 0.07639770954847336\n",
      "Batch：8947 | Loss: 0.07002246379852295\n",
      "Batch：8948 | Loss: 0.08166134357452393\n",
      "Batch：8949 | Loss: 0.07853812724351883\n",
      "Batch：8950 | Loss: 0.0928095355629921\n",
      "Batch：8951 | Loss: 0.08923161029815674\n",
      "Batch：8952 | Loss: 0.07835341989994049\n",
      "Batch：8953 | Loss: 0.06861020624637604\n",
      "Batch：8954 | Loss: 0.08484093844890594\n",
      "Batch：8955 | Loss: 0.07819093018770218\n",
      "Batch：8956 | Loss: 0.08172568678855896\n",
      "Batch：8957 | Loss: 0.07577527314424515\n",
      "Batch：8958 | Loss: 0.0719824954867363\n",
      "Batch：8959 | Loss: 0.08102360367774963\n",
      "Batch：8960 | Loss: 0.07893510162830353\n",
      "Batch：8961 | Loss: 0.0829395204782486\n",
      "Batch：8962 | Loss: 0.08212452381849289\n",
      "Batch：8963 | Loss: 0.08953434973955154\n",
      "Batch：8964 | Loss: 0.07475239783525467\n",
      "Batch：8965 | Loss: 0.07746218144893646\n",
      "Batch：8966 | Loss: 0.06901335716247559\n",
      "Batch：8967 | Loss: 0.08363727480173111\n",
      "Batch：8968 | Loss: 0.0846453309059143\n",
      "Batch：8969 | Loss: 0.07339761406183243\n",
      "Batch：8970 | Loss: 0.07490016520023346\n",
      "Batch：8971 | Loss: 0.07233737409114838\n",
      "Batch：8972 | Loss: 0.08008812367916107\n",
      "Batch：8973 | Loss: 0.07761306315660477\n",
      "Batch：8974 | Loss: 0.08369243144989014\n",
      "Batch：8975 | Loss: 0.08763489872217178\n",
      "Batch：8976 | Loss: 0.07785090059041977\n",
      "Batch：8977 | Loss: 0.07239047437906265\n",
      "Batch：8978 | Loss: 0.07066871225833893\n",
      "Batch：8979 | Loss: 0.07802914083003998\n",
      "Batch：8980 | Loss: 0.08450576663017273\n",
      "Batch：8981 | Loss: 0.0783543512225151\n",
      "Batch：8982 | Loss: 0.07932591438293457\n",
      "Batch：8983 | Loss: 0.07993818819522858\n",
      "Batch：8984 | Loss: 0.07712961733341217\n",
      "Batch：8985 | Loss: 0.07621552795171738\n",
      "Batch：8986 | Loss: 0.07970365136861801\n",
      "Batch：8987 | Loss: 0.08302629739046097\n",
      "Batch：8988 | Loss: 0.08589468151330948\n",
      "Batch：8989 | Loss: 0.08033899962902069\n",
      "Batch：8990 | Loss: 0.08538448065519333\n",
      "Batch：8991 | Loss: 0.08710817247629166\n",
      "Batch：8992 | Loss: 0.08515336364507675\n",
      "Batch：8993 | Loss: 0.07299438118934631\n",
      "Batch：8994 | Loss: 0.07759802788496017\n",
      "Batch：8995 | Loss: 0.07881190627813339\n",
      "Batch：8996 | Loss: 0.08291131258010864\n",
      "Batch：8997 | Loss: 0.08181915432214737\n",
      "Batch：8998 | Loss: 0.07591523975133896\n",
      "Batch：8999 | Loss: 0.10123083740472794\n",
      "Batch：9000 | Loss: 0.07955139875411987\n",
      "Batch：9001 | Loss: 0.08383932709693909\n",
      "Batch：9002 | Loss: 0.06847498565912247\n",
      "Batch：9003 | Loss: 0.061466850340366364\n",
      "Batch：9004 | Loss: 0.07438778877258301\n",
      "Batch：9005 | Loss: 0.07911475747823715\n",
      "Batch：9006 | Loss: 0.07284166663885117\n",
      "Batch：9007 | Loss: 0.07253904640674591\n",
      "Batch：9008 | Loss: 0.08181339502334595\n",
      "Batch：9009 | Loss: 0.08598794788122177\n",
      "Batch：9010 | Loss: 0.08744169026613235\n",
      "Batch：9011 | Loss: 0.07191891223192215\n",
      "Batch：9012 | Loss: 0.07733991742134094\n",
      "Batch：9013 | Loss: 0.07271851599216461\n",
      "Batch：9014 | Loss: 0.08068832010030746\n",
      "Batch：9015 | Loss: 0.0781053975224495\n",
      "Batch：9016 | Loss: 0.07707542181015015\n",
      "Batch：9017 | Loss: 0.07168959081172943\n",
      "Batch：9018 | Loss: 0.08361693471670151\n",
      "Batch：9019 | Loss: 0.0800577774643898\n",
      "Batch：9020 | Loss: 0.07663635164499283\n",
      "Batch：9021 | Loss: 0.07391739636659622\n",
      "Batch：9022 | Loss: 0.08444923162460327\n",
      "Batch：9023 | Loss: 0.07796507328748703\n",
      "Batch：9024 | Loss: 0.08023130893707275\n",
      "Batch：9025 | Loss: 0.0881514772772789\n",
      "Batch：9026 | Loss: 0.08891605585813522\n",
      "Batch：9027 | Loss: 0.07956241071224213\n",
      "Batch：9028 | Loss: 0.07531315088272095\n",
      "Batch：9029 | Loss: 0.08406907320022583\n",
      "Batch：9030 | Loss: 0.0749102234840393\n",
      "Batch：9031 | Loss: 0.08430622518062592\n",
      "Batch：9032 | Loss: 0.07001339644193649\n",
      "Batch：9033 | Loss: 0.07734743505716324\n",
      "Batch：9034 | Loss: 0.08160088211297989\n",
      "Batch：9035 | Loss: 0.08788488805294037\n",
      "Batch：9036 | Loss: 0.06799504160881042\n",
      "Batch：9037 | Loss: 0.08354087918996811\n",
      "Batch：9038 | Loss: 0.08867456018924713\n",
      "Batch：9039 | Loss: 0.08167089521884918\n",
      "Batch：9040 | Loss: 0.07972920686006546\n",
      "Batch：9041 | Loss: 0.07780778408050537\n",
      "Batch：9042 | Loss: 0.09815222024917603\n",
      "Batch：9043 | Loss: 0.07366332411766052\n",
      "Batch：9044 | Loss: 0.07841585576534271\n",
      "Batch：9045 | Loss: 0.07666628062725067\n",
      "Batch：9046 | Loss: 0.0701771005988121\n",
      "Batch：9047 | Loss: 0.07865295559167862\n",
      "Batch：9048 | Loss: 0.08519525825977325\n",
      "Batch：9049 | Loss: 0.07655657082796097\n",
      "Batch：9050 | Loss: 0.07507000118494034\n",
      "Batch：9051 | Loss: 0.07638297230005264\n",
      "Batch：9052 | Loss: 0.08064622431993484\n",
      "Batch：9053 | Loss: 0.07408353686332703\n",
      "Batch：9054 | Loss: 0.0811028704047203\n",
      "Batch：9055 | Loss: 0.08324939012527466\n",
      "Batch：9056 | Loss: 0.06793732196092606\n",
      "Batch：9057 | Loss: 0.07400590181350708\n",
      "Batch：9058 | Loss: 0.09169407188892365\n",
      "Batch：9059 | Loss: 0.08444321900606155\n",
      "Batch：9060 | Loss: 0.09040325880050659\n",
      "Batch：9061 | Loss: 0.08486786484718323\n",
      "Batch：9062 | Loss: 0.07483047246932983\n",
      "Batch：9063 | Loss: 0.08467554301023483\n",
      "Batch：9064 | Loss: 0.06684356927871704\n",
      "Batch：9065 | Loss: 0.08161584287881851\n",
      "Batch：9066 | Loss: 0.0921391174197197\n",
      "Batch：9067 | Loss: 0.07638008147478104\n",
      "Batch：9068 | Loss: 0.07378916442394257\n",
      "Batch：9069 | Loss: 0.08763214200735092\n",
      "Batch：9070 | Loss: 0.06351766735315323\n",
      "Batch：9071 | Loss: 0.07870005071163177\n",
      "Batch：9072 | Loss: 0.06442935019731522\n",
      "Batch：9073 | Loss: 0.09247332811355591\n",
      "Batch：9074 | Loss: 0.07976973056793213\n",
      "Batch：9075 | Loss: 0.07248935848474503\n",
      "Batch：9076 | Loss: 0.07022036612033844\n",
      "Batch：9077 | Loss: 0.06980939954519272\n",
      "Batch：9078 | Loss: 0.07927117496728897\n",
      "Batch：9079 | Loss: 0.07926224917173386\n",
      "Batch：9080 | Loss: 0.07100413739681244\n",
      "Batch：9081 | Loss: 0.08278115093708038\n",
      "Batch：9082 | Loss: 0.07790767401456833\n",
      "Batch：9083 | Loss: 0.0720595270395279\n",
      "Batch：9084 | Loss: 0.07423927634954453\n",
      "Batch：9085 | Loss: 0.0628802478313446\n",
      "Batch：9086 | Loss: 0.0766899436712265\n",
      "Batch：9087 | Loss: 0.08126326650381088\n",
      "Batch：9088 | Loss: 0.07424161583185196\n",
      "Batch：9089 | Loss: 0.07000818848609924\n",
      "Batch：9090 | Loss: 0.08775468170642853\n",
      "Batch：9091 | Loss: 0.08252190798521042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：9092 | Loss: 0.08119241893291473\n",
      "Batch：9093 | Loss: 0.0775638297200203\n",
      "Batch：9094 | Loss: 0.08740246295928955\n",
      "Batch：9095 | Loss: 0.06167815998196602\n",
      "Batch：9096 | Loss: 0.08158563822507858\n",
      "Batch：9097 | Loss: 0.06996988505125046\n",
      "Batch：9098 | Loss: 0.07585781812667847\n",
      "Batch：9099 | Loss: 0.07081123441457748\n",
      "Batch：9100 | Loss: 0.07801666855812073\n",
      "Batch：9101 | Loss: 0.07315987348556519\n",
      "Batch：9102 | Loss: 0.07881724089384079\n",
      "Batch：9103 | Loss: 0.06731680780649185\n",
      "Batch：9104 | Loss: 0.0707840844988823\n",
      "Batch：9105 | Loss: 0.07953643798828125\n",
      "Batch：9106 | Loss: 0.08771321177482605\n",
      "Batch：9107 | Loss: 0.0830049216747284\n",
      "Batch：9108 | Loss: 0.07395543158054352\n",
      "Batch：9109 | Loss: 0.07559531182050705\n",
      "Batch：9110 | Loss: 0.08424972742795944\n",
      "Batch：9111 | Loss: 0.06549287587404251\n",
      "Batch：9112 | Loss: 0.07961055636405945\n",
      "Batch：9113 | Loss: 0.07271032780408859\n",
      "Batch：9114 | Loss: 0.07633637636899948\n",
      "Batch：9115 | Loss: 0.08151336759328842\n",
      "Batch：9116 | Loss: 0.0686856061220169\n",
      "Batch：9117 | Loss: 0.07037216424942017\n",
      "Batch：9118 | Loss: 0.08781009167432785\n",
      "Batch：9119 | Loss: 0.07636769860982895\n",
      "Batch：9120 | Loss: 0.07697878777980804\n",
      "Batch：9121 | Loss: 0.08558710664510727\n",
      "Batch：9122 | Loss: 0.07348402589559555\n",
      "Batch：9123 | Loss: 0.08407033234834671\n",
      "Batch：9124 | Loss: 0.07541980594396591\n",
      "Batch：9125 | Loss: 0.07885762304067612\n",
      "Batch：9126 | Loss: 0.07360842078924179\n",
      "Batch：9127 | Loss: 0.07703633606433868\n",
      "Batch：9128 | Loss: 0.07300011813640594\n",
      "Batch：9129 | Loss: 0.0756438747048378\n",
      "Batch：9130 | Loss: 0.07001074403524399\n",
      "Batch：9131 | Loss: 0.08088355511426926\n",
      "Batch：9132 | Loss: 0.08722320199012756\n",
      "Batch：9133 | Loss: 0.0778079405426979\n",
      "Batch：9134 | Loss: 0.07724274694919586\n",
      "Batch：9135 | Loss: 0.0838196724653244\n",
      "Batch：9136 | Loss: 0.07857951521873474\n",
      "Batch：9137 | Loss: 0.07935649901628494\n",
      "Batch：9138 | Loss: 0.07181456685066223\n",
      "Batch：9139 | Loss: 0.0819832906126976\n",
      "Batch：9140 | Loss: 0.07350531965494156\n",
      "Batch：9141 | Loss: 0.0739341601729393\n",
      "Batch：9142 | Loss: 0.07569795846939087\n",
      "Batch：9143 | Loss: 0.08690768480300903\n",
      "Batch：9144 | Loss: 0.07996407151222229\n",
      "Batch：9145 | Loss: 0.08474113047122955\n",
      "Batch：9146 | Loss: 0.08091665059328079\n",
      "Batch：9147 | Loss: 0.08673625439405441\n",
      "Batch：9148 | Loss: 0.07629435509443283\n",
      "Batch：9149 | Loss: 0.08286289870738983\n",
      "Batch：9150 | Loss: 0.07725829631090164\n",
      "Batch：9151 | Loss: 0.08117908984422684\n",
      "Batch：9152 | Loss: 0.07590402662754059\n",
      "Batch：9153 | Loss: 0.08131849765777588\n",
      "Batch：9154 | Loss: 0.07147952169179916\n",
      "Batch：9155 | Loss: 0.07358662039041519\n",
      "Batch：9156 | Loss: 0.07407889515161514\n",
      "Batch：9157 | Loss: 0.06640270352363586\n",
      "Batch：9158 | Loss: 0.07278085500001907\n",
      "Batch：9159 | Loss: 0.06901185214519501\n",
      "Batch：9160 | Loss: 0.09530481696128845\n",
      "Batch：9161 | Loss: 0.07742981612682343\n",
      "Batch：9162 | Loss: 0.07936042547225952\n",
      "Batch：9163 | Loss: 0.0768180713057518\n",
      "Batch：9164 | Loss: 0.07464394718408585\n",
      "Batch：9165 | Loss: 0.07397525757551193\n",
      "Batch：9166 | Loss: 0.08443411439657211\n",
      "Batch：9167 | Loss: 0.08544092625379562\n",
      "Batch：9168 | Loss: 0.07059844583272934\n",
      "Batch：9169 | Loss: 0.08787784725427628\n",
      "Batch：9170 | Loss: 0.08555586636066437\n",
      "Batch：9171 | Loss: 0.07270479947328568\n",
      "Batch：9172 | Loss: 0.06907973438501358\n",
      "Batch：9173 | Loss: 0.08071602135896683\n",
      "Batch：9174 | Loss: 0.08101449906826019\n",
      "Batch：9175 | Loss: 0.07658909261226654\n",
      "Batch：9176 | Loss: 0.07434356212615967\n",
      "Batch：9177 | Loss: 0.0883752629160881\n",
      "Batch：9178 | Loss: 0.07835005223751068\n",
      "Batch：9179 | Loss: 0.08982738852500916\n",
      "Batch：9180 | Loss: 0.09142472594976425\n",
      "Batch：9181 | Loss: 0.07660097628831863\n",
      "Batch：9182 | Loss: 0.08765849471092224\n",
      "Batch：9183 | Loss: 0.08326422423124313\n",
      "Batch：9184 | Loss: 0.06854695081710815\n",
      "Batch：9185 | Loss: 0.08169731497764587\n",
      "Batch：9186 | Loss: 0.08218865096569061\n",
      "Batch：9187 | Loss: 0.07123228162527084\n",
      "Batch：9188 | Loss: 0.0870862528681755\n",
      "Batch：9189 | Loss: 0.07950116693973541\n",
      "Batch：9190 | Loss: 0.08221012353897095\n",
      "Batch：9191 | Loss: 0.08278957009315491\n",
      "Batch：9192 | Loss: 0.0770157128572464\n",
      "Batch：9193 | Loss: 0.08301772177219391\n",
      "Batch：9194 | Loss: 0.0694252997636795\n",
      "Batch：9195 | Loss: 0.07569541037082672\n",
      "Batch：9196 | Loss: 0.0817781314253807\n",
      "Batch：9197 | Loss: 0.0678132101893425\n",
      "Batch：9198 | Loss: 0.08757414668798447\n",
      "Batch：9199 | Loss: 0.06878362596035004\n",
      "Batch：9200 | Loss: 0.07798007875680923\n",
      "Batch：9201 | Loss: 0.07161042094230652\n",
      "Batch：9202 | Loss: 0.06599009782075882\n",
      "Batch：9203 | Loss: 0.08049776405096054\n",
      "Batch：9204 | Loss: 0.06966108083724976\n",
      "Batch：9205 | Loss: 0.0721283033490181\n",
      "Batch：9206 | Loss: 0.08290237933397293\n",
      "Batch：9207 | Loss: 0.08384222537279129\n",
      "Batch：9208 | Loss: 0.0644666776061058\n",
      "Batch：9209 | Loss: 0.07509579509496689\n",
      "Batch：9210 | Loss: 0.08015549927949905\n",
      "Batch：9211 | Loss: 0.0790654793381691\n",
      "Batch：9212 | Loss: 0.0801389291882515\n",
      "Batch：9213 | Loss: 0.08170348405838013\n",
      "Batch：9214 | Loss: 0.08829758316278458\n",
      "Batch：9215 | Loss: 0.09215536713600159\n",
      "Batch：9216 | Loss: 0.07357829809188843\n",
      "Batch：9217 | Loss: 0.08080827444791794\n",
      "Batch：9218 | Loss: 0.0748273953795433\n",
      "Batch：9219 | Loss: 0.07333587110042572\n",
      "Batch：9220 | Loss: 0.08118779212236404\n",
      "Batch：9221 | Loss: 0.0872451663017273\n",
      "Batch：9222 | Loss: 0.08411255478858948\n",
      "Batch：9223 | Loss: 0.08345357328653336\n",
      "Batch：9224 | Loss: 0.06558199971914291\n",
      "Batch：9225 | Loss: 0.07819018512964249\n",
      "Batch：9226 | Loss: 0.08709009736776352\n",
      "Batch：9227 | Loss: 0.07435886561870575\n",
      "Batch：9228 | Loss: 0.08883597701787949\n",
      "Batch：9229 | Loss: 0.0800880640745163\n",
      "Batch：9230 | Loss: 0.0651136189699173\n",
      "Batch：9231 | Loss: 0.07935167104005814\n",
      "Batch：9232 | Loss: 0.06974320113658905\n",
      "Batch：9233 | Loss: 0.06555797904729843\n",
      "Batch：9234 | Loss: 0.07000183314085007\n",
      "Batch：9235 | Loss: 0.0818726196885109\n",
      "Batch：9236 | Loss: 0.08033813536167145\n",
      "Batch：9237 | Loss: 0.07447456568479538\n",
      "Batch：9238 | Loss: 0.09469504654407501\n",
      "Batch：9239 | Loss: 0.07536186277866364\n",
      "Batch：9240 | Loss: 0.0744670107960701\n",
      "Batch：9241 | Loss: 0.09545916318893433\n",
      "Batch：9242 | Loss: 0.08022061735391617\n",
      "Batch：9243 | Loss: 0.08488191664218903\n",
      "Batch：9244 | Loss: 0.07382752001285553\n",
      "Batch：9245 | Loss: 0.06776316463947296\n",
      "Batch：9246 | Loss: 0.06962408125400543\n",
      "Batch：9247 | Loss: 0.07849430292844772\n",
      "Batch：9248 | Loss: 0.08685687929391861\n",
      "Batch：9249 | Loss: 0.08109041303396225\n",
      "Batch：9250 | Loss: 0.07885867357254028\n",
      "Batch：9251 | Loss: 0.07772299647331238\n",
      "Batch：9252 | Loss: 0.07476016879081726\n",
      "Batch：9253 | Loss: 0.07646454125642776\n",
      "Batch：9254 | Loss: 0.08401937782764435\n",
      "Batch：9255 | Loss: 0.08313994854688644\n",
      "Batch：9256 | Loss: 0.08533389866352081\n",
      "Batch：9257 | Loss: 0.07847145199775696\n",
      "Batch：9258 | Loss: 0.07445373386144638\n",
      "Batch：9259 | Loss: 0.07526367157697678\n",
      "Batch：9260 | Loss: 0.07845135033130646\n",
      "Batch：9261 | Loss: 0.07794886082410812\n",
      "Batch：9262 | Loss: 0.08015157282352448\n",
      "Batch：9263 | Loss: 0.07663695514202118\n",
      "Batch：9264 | Loss: 0.07223528623580933\n",
      "Batch：9265 | Loss: 0.08025136590003967\n",
      "Batch：9266 | Loss: 0.07039644569158554\n",
      "Batch：9267 | Loss: 0.07185620814561844\n",
      "Batch：9268 | Loss: 0.08025693893432617\n",
      "Batch：9269 | Loss: 0.07517148554325104\n",
      "Batch：9270 | Loss: 0.07155247032642365\n",
      "Batch：9271 | Loss: 0.06971532851457596\n",
      "Batch：9272 | Loss: 0.07576067745685577\n",
      "Batch：9273 | Loss: 0.08270750194787979\n",
      "Batch：9274 | Loss: 0.0812206119298935\n",
      "Batch：9275 | Loss: 0.08125442266464233\n",
      "Batch：9276 | Loss: 0.07593359053134918\n",
      "Batch：9277 | Loss: 0.06694167852401733\n",
      "Batch：9278 | Loss: 0.0784391537308693\n",
      "Batch：9279 | Loss: 0.07757642865180969\n",
      "Batch：9280 | Loss: 0.0733388364315033\n",
      "Batch：9281 | Loss: 0.08661153167486191\n",
      "Batch：9282 | Loss: 0.08275604993104935\n",
      "Batch：9283 | Loss: 0.07442153245210648\n",
      "Batch：9284 | Loss: 0.0811992958188057\n",
      "Batch：9285 | Loss: 0.07651501893997192\n",
      "Batch：9286 | Loss: 0.07242607325315475\n",
      "Batch：9287 | Loss: 0.07056093961000443\n",
      "Batch：9288 | Loss: 0.0735124796628952\n",
      "Batch：9289 | Loss: 0.07936859875917435\n",
      "Batch：9290 | Loss: 0.08251162618398666\n",
      "Batch：9291 | Loss: 0.07087120413780212\n",
      "Batch：9292 | Loss: 0.07294668257236481\n",
      "Batch：9293 | Loss: 0.08120770007371902\n",
      "Batch：9294 | Loss: 0.08582837134599686\n",
      "Batch：9295 | Loss: 0.07499724626541138\n",
      "Batch：9296 | Loss: 0.09063807129859924\n",
      "Batch：9297 | Loss: 0.07007454335689545\n",
      "Batch：9298 | Loss: 0.08083086460828781\n",
      "Batch：9299 | Loss: 0.07040590047836304\n",
      "Batch：9300 | Loss: 0.07030349969863892\n",
      "Batch：9301 | Loss: 0.07692637294530869\n",
      "Batch：9302 | Loss: 0.08086266368627548\n",
      "Batch：9303 | Loss: 0.0701301246881485\n",
      "Batch：9304 | Loss: 0.08360299468040466\n",
      "Batch：9305 | Loss: 0.07777903228998184\n",
      "Batch：9306 | Loss: 0.06999194622039795\n",
      "Batch：9307 | Loss: 0.06490647792816162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：9308 | Loss: 0.07318408787250519\n",
      "Batch：9309 | Loss: 0.07551544904708862\n",
      "Batch：9310 | Loss: 0.06344114243984222\n",
      "Batch：9311 | Loss: 0.07525148242712021\n",
      "Batch：9312 | Loss: 0.08319073170423508\n",
      "Batch：9313 | Loss: 0.08556076884269714\n",
      "Batch：9314 | Loss: 0.08929449319839478\n",
      "Batch：9315 | Loss: 0.07191386073827744\n",
      "Batch：9316 | Loss: 0.08268584311008453\n",
      "Batch：9317 | Loss: 0.07801131904125214\n",
      "Batch：9318 | Loss: 0.08368567377328873\n",
      "Batch：9319 | Loss: 0.07587013393640518\n",
      "Batch：9320 | Loss: 0.05943462997674942\n",
      "Batch：9321 | Loss: 0.07469654083251953\n",
      "Batch：9322 | Loss: 0.07415133714675903\n",
      "Batch：9323 | Loss: 0.07153636962175369\n",
      "Batch：9324 | Loss: 0.07270942628383636\n",
      "Batch：9325 | Loss: 0.08524797111749649\n",
      "Batch：9326 | Loss: 0.08409161865711212\n",
      "Batch：9327 | Loss: 0.0681426152586937\n",
      "Batch：9328 | Loss: 0.07708482444286346\n",
      "Batch：9329 | Loss: 0.0856134444475174\n",
      "Batch：9330 | Loss: 0.07521575689315796\n",
      "Batch：9331 | Loss: 0.08553755283355713\n",
      "Batch：9332 | Loss: 0.07857627421617508\n",
      "Batch：9333 | Loss: 0.06788132339715958\n",
      "Batch：9334 | Loss: 0.0763053447008133\n",
      "Batch：9335 | Loss: 0.07950655370950699\n",
      "Batch：9336 | Loss: 0.0779421404004097\n",
      "Batch：9337 | Loss: 0.08174454420804977\n",
      "Batch：9338 | Loss: 0.08168331533670425\n",
      "Batch：9339 | Loss: 0.08118366450071335\n",
      "Batch：9340 | Loss: 0.07796620577573776\n",
      "Batch：9341 | Loss: 0.06555699557065964\n",
      "Batch：9342 | Loss: 0.07791117578744888\n",
      "Batch：9343 | Loss: 0.0684666857123375\n",
      "Batch：9344 | Loss: 0.07908945530653\n",
      "Batch：9345 | Loss: 0.07448031008243561\n",
      "Batch：9346 | Loss: 0.07743851840496063\n",
      "Batch：9347 | Loss: 0.07919246703386307\n",
      "Batch：9348 | Loss: 0.07828833907842636\n",
      "Batch：9349 | Loss: 0.08033084869384766\n",
      "Batch：9350 | Loss: 0.07280563563108444\n",
      "Batch：9351 | Loss: 0.07629188150167465\n",
      "Batch：9352 | Loss: 0.07579948008060455\n",
      "Batch：9353 | Loss: 0.08159995824098587\n",
      "Batch：9354 | Loss: 0.07335775345563889\n",
      "Batch：9355 | Loss: 0.07818356901407242\n",
      "Batch：9356 | Loss: 0.08066392689943314\n",
      "Batch：9357 | Loss: 0.07516846805810928\n",
      "Batch：9358 | Loss: 0.07703166455030441\n",
      "Batch：9359 | Loss: 0.08396561443805695\n",
      "Batch：9360 | Loss: 0.08050377666950226\n",
      "Batch：9361 | Loss: 0.07747288793325424\n",
      "Batch：9362 | Loss: 0.0716627836227417\n",
      "Batch：9363 | Loss: 0.06748566776514053\n",
      "Batch：9364 | Loss: 0.0776602178812027\n",
      "Batch：9365 | Loss: 0.07854411005973816\n",
      "Batch：9366 | Loss: 0.07874707877635956\n",
      "Batch：9367 | Loss: 0.07196199148893356\n",
      "Batch：9368 | Loss: 0.0784517377614975\n",
      "Batch：9369 | Loss: 0.07481744140386581\n",
      "Batch：9370 | Loss: 0.07576826214790344\n",
      "Batch：9371 | Loss: 0.0792696550488472\n",
      "Batch：9372 | Loss: 0.07787173986434937\n",
      "Batch：9373 | Loss: 0.07873981446027756\n",
      "Batch：9374 | Loss: 0.09369911253452301\n",
      "Batch：9375 | Loss: 0.08861048519611359\n",
      "Batch：9376 | Loss: 0.07383954524993896\n",
      "Batch：9377 | Loss: 0.0798184871673584\n",
      "Batch：9378 | Loss: 0.08579795062541962\n",
      "Batch：9379 | Loss: 0.08058237284421921\n",
      "Batch：9380 | Loss: 0.0721316859126091\n",
      "Batch：9381 | Loss: 0.07967530190944672\n",
      "Batch：9382 | Loss: 0.06643214076757431\n",
      "Batch：9383 | Loss: 0.08994260430335999\n",
      "Batch：9384 | Loss: 0.07493861019611359\n",
      "Batch：9385 | Loss: 0.07594677805900574\n",
      "Batch：9386 | Loss: 0.07390189170837402\n",
      "Batch：9387 | Loss: 0.07419511675834656\n",
      "Batch：9388 | Loss: 0.07629703730344772\n",
      "Batch：9389 | Loss: 0.07264716178178787\n",
      "Batch：9390 | Loss: 0.0772874653339386\n",
      "Batch：9391 | Loss: 0.08130981773138046\n",
      "Batch：9392 | Loss: 0.07307102531194687\n",
      "Batch：9393 | Loss: 0.06933820247650146\n",
      "Batch：9394 | Loss: 0.07470214366912842\n",
      "Batch：9395 | Loss: 0.08606766909360886\n",
      "Batch：9396 | Loss: 0.07698696106672287\n",
      "Batch：9397 | Loss: 0.072621189057827\n",
      "Batch：9398 | Loss: 0.08088146150112152\n",
      "Batch：9399 | Loss: 0.08100049942731857\n",
      "Batch：9400 | Loss: 0.07385334372520447\n",
      "Batch：9401 | Loss: 0.07661128044128418\n",
      "Batch：9402 | Loss: 0.07791245728731155\n",
      "Batch：9403 | Loss: 0.07944708317518234\n",
      "Batch：9404 | Loss: 0.08048855513334274\n",
      "Batch：9405 | Loss: 0.085697241127491\n",
      "Batch：9406 | Loss: 0.08065599203109741\n",
      "Batch：9407 | Loss: 0.08343694359064102\n",
      "Batch：9408 | Loss: 0.09237461537122726\n",
      "Batch：9409 | Loss: 0.07041379809379578\n",
      "Batch：9410 | Loss: 0.07881985604763031\n",
      "Batch：9411 | Loss: 0.06727936863899231\n",
      "Batch：9412 | Loss: 0.0763673260807991\n",
      "Batch：9413 | Loss: 0.07449878007173538\n",
      "Batch：9414 | Loss: 0.0772603377699852\n",
      "Batch：9415 | Loss: 0.06445861607789993\n",
      "Batch：9416 | Loss: 0.07803235948085785\n",
      "Batch：9417 | Loss: 0.08190377801656723\n",
      "Batch：9418 | Loss: 0.08380620181560516\n",
      "Batch：9419 | Loss: 0.08000142872333527\n",
      "Batch：9420 | Loss: 0.08297118544578552\n",
      "Batch：9421 | Loss: 0.07925879955291748\n",
      "Batch：9422 | Loss: 0.08148269355297089\n",
      "Batch：9423 | Loss: 0.08292839676141739\n",
      "Batch：9424 | Loss: 0.08639900386333466\n",
      "Batch：9425 | Loss: 0.07400096207857132\n",
      "Batch：9426 | Loss: 0.0692753717303276\n",
      "Batch：9427 | Loss: 0.08044393360614777\n",
      "Batch：9428 | Loss: 0.08249403536319733\n",
      "Batch：9429 | Loss: 0.07793732732534409\n",
      "Batch：9430 | Loss: 0.06683236360549927\n",
      "Batch：9431 | Loss: 0.07745269685983658\n",
      "Batch：9432 | Loss: 0.07446256279945374\n",
      "Batch：9433 | Loss: 0.07100585103034973\n",
      "Batch：9434 | Loss: 0.07155470550060272\n",
      "Batch：9435 | Loss: 0.0753837525844574\n",
      "Batch：9436 | Loss: 0.06961634010076523\n",
      "Batch：9437 | Loss: 0.07526876032352448\n",
      "Batch：9438 | Loss: 0.07499078661203384\n",
      "Batch：9439 | Loss: 0.07140021026134491\n",
      "Batch：9440 | Loss: 0.07127726823091507\n",
      "Batch：9441 | Loss: 0.07875240594148636\n",
      "Batch：9442 | Loss: 0.08044926077127457\n",
      "Batch：9443 | Loss: 0.0741240531206131\n",
      "Batch：9444 | Loss: 0.07498137652873993\n",
      "Batch：9445 | Loss: 0.08460252732038498\n",
      "Batch：9446 | Loss: 0.07683652639389038\n",
      "Batch：9447 | Loss: 0.06491637229919434\n",
      "Batch：9448 | Loss: 0.07981318980455399\n",
      "Batch：9449 | Loss: 0.06930163502693176\n",
      "Batch：9450 | Loss: 0.07995085418224335\n",
      "Batch：9451 | Loss: 0.06543053686618805\n",
      "Batch：9452 | Loss: 0.08166324347257614\n",
      "Batch：9453 | Loss: 0.07850789278745651\n",
      "Batch：9454 | Loss: 0.07467197626829147\n",
      "Batch：9455 | Loss: 0.07457149028778076\n",
      "Batch：9456 | Loss: 0.07590297609567642\n",
      "Batch：9457 | Loss: 0.07806465774774551\n",
      "Batch：9458 | Loss: 0.07999870926141739\n",
      "Batch：9459 | Loss: 0.0835212916135788\n",
      "Batch：9460 | Loss: 0.0837063267827034\n",
      "Batch：9461 | Loss: 0.06631305068731308\n",
      "Batch：9462 | Loss: 0.069925956428051\n",
      "Batch：9463 | Loss: 0.07843417674303055\n",
      "Batch：9464 | Loss: 0.0756499245762825\n",
      "Batch：9465 | Loss: 0.08224409073591232\n",
      "Batch：9466 | Loss: 0.07974427193403244\n",
      "Batch：9467 | Loss: 0.08074919879436493\n",
      "Batch：9468 | Loss: 0.07706387341022491\n",
      "Batch：9469 | Loss: 0.06794385612010956\n",
      "Batch：9470 | Loss: 0.08070769160985947\n",
      "Batch：9471 | Loss: 0.0746670588850975\n",
      "Batch：9472 | Loss: 0.09331537038087845\n",
      "Batch：9473 | Loss: 0.0696277990937233\n",
      "Batch：9474 | Loss: 0.0680164247751236\n",
      "Batch：9475 | Loss: 0.07732485979795456\n",
      "Batch：9476 | Loss: 0.06989266723394394\n",
      "Batch：9477 | Loss: 0.08012037724256516\n",
      "Batch：9478 | Loss: 0.06821727752685547\n",
      "Batch：9479 | Loss: 0.06649795174598694\n",
      "Batch：9480 | Loss: 0.08329056948423386\n",
      "Batch：9481 | Loss: 0.07203451544046402\n",
      "Batch：9482 | Loss: 0.07381533086299896\n",
      "Batch：9483 | Loss: 0.07887466251850128\n",
      "Batch：9484 | Loss: 0.07615146785974503\n",
      "Batch：9485 | Loss: 0.0780089944601059\n",
      "Batch：9486 | Loss: 0.06918304413557053\n",
      "Batch：9487 | Loss: 0.07264722883701324\n",
      "Batch：9488 | Loss: 0.07103946059942245\n",
      "Batch：9489 | Loss: 0.07763146609067917\n",
      "Batch：9490 | Loss: 0.08702225983142853\n",
      "Batch：9491 | Loss: 0.06973113119602203\n",
      "Batch：9492 | Loss: 0.08374948799610138\n",
      "Batch：9493 | Loss: 0.06989521533250809\n",
      "Batch：9494 | Loss: 0.07708828896284103\n",
      "Batch：9495 | Loss: 0.07740850001573563\n",
      "Batch：9496 | Loss: 0.07003533840179443\n",
      "Batch：9497 | Loss: 0.0860976129770279\n",
      "Batch：9498 | Loss: 0.07269265502691269\n",
      "Batch：9499 | Loss: 0.07259130477905273\n",
      "Batch：9500 | Loss: 0.07327089458703995\n",
      "Batch：9501 | Loss: 0.074725441634655\n",
      "Batch：9502 | Loss: 0.07247310876846313\n",
      "Batch：9503 | Loss: 0.07347234338521957\n",
      "Batch：9504 | Loss: 0.06853468716144562\n",
      "Batch：9505 | Loss: 0.06764399260282516\n",
      "Batch：9506 | Loss: 0.07360941916704178\n",
      "Batch：9507 | Loss: 0.0850074291229248\n",
      "Batch：9508 | Loss: 0.07865121215581894\n",
      "Batch：9509 | Loss: 0.08593583106994629\n",
      "Batch：9510 | Loss: 0.07189279794692993\n",
      "Batch：9511 | Loss: 0.07681512087583542\n",
      "Batch：9512 | Loss: 0.06891734898090363\n",
      "Batch：9513 | Loss: 0.07418882101774216\n",
      "Batch：9514 | Loss: 0.08778306096792221\n",
      "Batch：9515 | Loss: 0.08124922215938568\n",
      "Batch：9516 | Loss: 0.0715542733669281\n",
      "Batch：9517 | Loss: 0.07738880068063736\n",
      "Batch：9518 | Loss: 0.0860367864370346\n",
      "Batch：9519 | Loss: 0.06983789801597595\n",
      "Batch：9520 | Loss: 0.058432165533304214\n",
      "Batch：9521 | Loss: 0.06678348034620285\n",
      "Batch：9522 | Loss: 0.09228833019733429\n",
      "Batch：9523 | Loss: 0.0712025836110115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：9524 | Loss: 0.08528926968574524\n",
      "Batch：9525 | Loss: 0.07584796845912933\n",
      "Batch：9526 | Loss: 0.0793854221701622\n",
      "Batch：9527 | Loss: 0.08668587356805801\n",
      "Batch：9528 | Loss: 0.07057281583547592\n",
      "Batch：9529 | Loss: 0.08298590779304504\n",
      "Batch：9530 | Loss: 0.07904471457004547\n",
      "Batch：9531 | Loss: 0.08248624205589294\n",
      "Batch：9532 | Loss: 0.06738156080245972\n",
      "Batch：9533 | Loss: 0.08191532641649246\n",
      "Batch：9534 | Loss: 0.08197664469480515\n",
      "Batch：9535 | Loss: 0.08785088360309601\n",
      "Batch：9536 | Loss: 0.08306601643562317\n",
      "Batch：9537 | Loss: 0.06978322565555573\n",
      "Batch：9538 | Loss: 0.08522935211658478\n",
      "Batch：9539 | Loss: 0.08513148128986359\n",
      "Batch：9540 | Loss: 0.07381374388933182\n",
      "Batch：9541 | Loss: 0.06512550264596939\n",
      "Batch：9542 | Loss: 0.07821013033390045\n",
      "Batch：9543 | Loss: 0.0690782368183136\n",
      "Batch：9544 | Loss: 0.07719897478818893\n",
      "Batch：9545 | Loss: 0.0711209625005722\n",
      "Batch：9546 | Loss: 0.0932534858584404\n",
      "Batch：9547 | Loss: 0.09217068552970886\n",
      "Batch：9548 | Loss: 0.0741758793592453\n",
      "Batch：9549 | Loss: 0.07940038293600082\n",
      "Batch：9550 | Loss: 0.07192322611808777\n",
      "Batch：9551 | Loss: 0.07633005082607269\n",
      "Batch：9552 | Loss: 0.08004935085773468\n",
      "Batch：9553 | Loss: 0.08460674434900284\n",
      "Batch：9554 | Loss: 0.08419597893953323\n",
      "Batch：9555 | Loss: 0.07017847895622253\n",
      "Batch：9556 | Loss: 0.06613608449697495\n",
      "Batch：9557 | Loss: 0.07688462734222412\n",
      "Batch：9558 | Loss: 0.061447009444236755\n",
      "Batch：9559 | Loss: 0.06872698664665222\n",
      "Batch：9560 | Loss: 0.08672745525836945\n",
      "Batch：9561 | Loss: 0.07589034736156464\n",
      "Batch：9562 | Loss: 0.07865368574857712\n",
      "Batch：9563 | Loss: 0.06954505294561386\n",
      "Batch：9564 | Loss: 0.08179601281881332\n",
      "Batch：9565 | Loss: 0.08580106496810913\n",
      "Batch：9566 | Loss: 0.0741114616394043\n",
      "Batch：9567 | Loss: 0.08704967796802521\n",
      "Batch：9568 | Loss: 0.06368495523929596\n",
      "Batch：9569 | Loss: 0.0802851989865303\n",
      "Batch：9570 | Loss: 0.07336178421974182\n",
      "Batch：9571 | Loss: 0.07850071787834167\n",
      "Batch：9572 | Loss: 0.08065684139728546\n",
      "Batch：9573 | Loss: 0.07368455827236176\n",
      "Batch：9574 | Loss: 0.08719568699598312\n",
      "Batch：9575 | Loss: 0.08087649196386337\n",
      "Batch：9576 | Loss: 0.08175712823867798\n",
      "Batch：9577 | Loss: 0.08055080473423004\n",
      "Batch：9578 | Loss: 0.06867063045501709\n",
      "Batch：9579 | Loss: 0.08196409046649933\n",
      "Batch：9580 | Loss: 0.08629162609577179\n",
      "Batch：9581 | Loss: 0.07985343039035797\n",
      "Batch：9582 | Loss: 0.08034241199493408\n",
      "Batch：9583 | Loss: 0.0702974870800972\n",
      "Batch：9584 | Loss: 0.0833626538515091\n",
      "Batch：9585 | Loss: 0.06734255701303482\n",
      "Batch：9586 | Loss: 0.07042188197374344\n",
      "Batch：9587 | Loss: 0.07883591204881668\n",
      "Batch：9588 | Loss: 0.06856995820999146\n",
      "Batch：9589 | Loss: 0.07662452757358551\n",
      "Batch：9590 | Loss: 0.08036647737026215\n",
      "Batch：9591 | Loss: 0.07429881393909454\n",
      "Batch：9592 | Loss: 0.08339649438858032\n",
      "Batch：9593 | Loss: 0.07074209302663803\n",
      "Batch：9594 | Loss: 0.08091933280229568\n",
      "Batch：9595 | Loss: 0.0870513841509819\n",
      "Batch：9596 | Loss: 0.06812117248773575\n",
      "Batch：9597 | Loss: 0.07854743301868439\n",
      "Batch：9598 | Loss: 0.0633958950638771\n",
      "Batch：9599 | Loss: 0.08742022514343262\n",
      "Batch：9600 | Loss: 0.06597334891557693\n",
      "Batch：9601 | Loss: 0.07978732883930206\n",
      "Batch：9602 | Loss: 0.06978782266378403\n",
      "Batch：9603 | Loss: 0.06120499223470688\n",
      "Batch：9604 | Loss: 0.08034636825323105\n",
      "Batch：9605 | Loss: 0.08078093081712723\n",
      "Batch：9606 | Loss: 0.0782322883605957\n",
      "Batch：9607 | Loss: 0.08176114410161972\n",
      "Batch：9608 | Loss: 0.06862832605838776\n",
      "Batch：9609 | Loss: 0.08399627357721329\n",
      "Batch：9610 | Loss: 0.07347416132688522\n",
      "Batch：9611 | Loss: 0.0672687217593193\n",
      "Batch：9612 | Loss: 0.07469654083251953\n",
      "Batch：9613 | Loss: 0.06290900707244873\n",
      "Batch：9614 | Loss: 0.07603184133768082\n",
      "Batch：9615 | Loss: 0.07907863706350327\n",
      "Batch：9616 | Loss: 0.06496014446020126\n",
      "Batch：9617 | Loss: 0.08548097312450409\n",
      "Batch：9618 | Loss: 0.0797162652015686\n",
      "Batch：9619 | Loss: 0.07823532074689865\n",
      "Batch：9620 | Loss: 0.06518037617206573\n",
      "Batch：9621 | Loss: 0.0814395472407341\n",
      "Batch：9622 | Loss: 0.07286221534013748\n",
      "Batch：9623 | Loss: 0.0804980993270874\n",
      "Batch：9624 | Loss: 0.07260462641716003\n",
      "Batch：9625 | Loss: 0.09007188677787781\n",
      "Batch：9626 | Loss: 0.06719093024730682\n",
      "Batch：9627 | Loss: 0.0763145163655281\n",
      "Batch：9628 | Loss: 0.062475573271512985\n",
      "Batch：9629 | Loss: 0.07348229736089706\n",
      "Batch：9630 | Loss: 0.07763926684856415\n",
      "Batch：9631 | Loss: 0.057844098657369614\n",
      "Batch：9632 | Loss: 0.08512552827596664\n",
      "Batch：9633 | Loss: 0.08165351301431656\n",
      "Batch：9634 | Loss: 0.07419928908348083\n",
      "Batch：9635 | Loss: 0.09201595187187195\n",
      "Batch：9636 | Loss: 0.07292857766151428\n",
      "Batch：9637 | Loss: 0.08038438856601715\n",
      "Batch：9638 | Loss: 0.06964701414108276\n",
      "Batch：9639 | Loss: 0.0790555477142334\n",
      "Batch：9640 | Loss: 0.08854007720947266\n",
      "Batch：9641 | Loss: 0.0694851204752922\n",
      "Batch：9642 | Loss: 0.06868615746498108\n",
      "Batch：9643 | Loss: 0.07519426196813583\n",
      "Batch：9644 | Loss: 0.06788800656795502\n",
      "Batch：9645 | Loss: 0.08087128400802612\n",
      "Batch：9646 | Loss: 0.07072616368532181\n",
      "Batch：9647 | Loss: 0.08251335471868515\n",
      "Batch：9648 | Loss: 0.07260889559984207\n",
      "Batch：9649 | Loss: 0.07437925785779953\n",
      "Batch：9650 | Loss: 0.0797124132514\n",
      "Batch：9651 | Loss: 0.0795484185218811\n",
      "Batch：9652 | Loss: 0.06446509063243866\n",
      "Batch：9653 | Loss: 0.06529509276151657\n",
      "Batch：9654 | Loss: 0.08080179989337921\n",
      "Batch：9655 | Loss: 0.063311368227005\n",
      "Batch：9656 | Loss: 0.07572948932647705\n",
      "Batch：9657 | Loss: 0.07820574194192886\n",
      "Batch：9658 | Loss: 0.08528530597686768\n",
      "Batch：9659 | Loss: 0.06698866933584213\n",
      "Batch：9660 | Loss: 0.07877804338932037\n",
      "Batch：9661 | Loss: 0.08210050314664841\n",
      "Batch：9662 | Loss: 0.06821681559085846\n",
      "Batch：9663 | Loss: 0.08201093226671219\n",
      "Batch：9664 | Loss: 0.06795758754014969\n",
      "Batch：9665 | Loss: 0.07273134589195251\n",
      "Batch：9666 | Loss: 0.07425715774297714\n",
      "Batch：9667 | Loss: 0.07425792515277863\n",
      "Batch：9668 | Loss: 0.07674549520015717\n",
      "Batch：9669 | Loss: 0.07589701563119888\n",
      "Batch：9670 | Loss: 0.08005428314208984\n",
      "Batch：9671 | Loss: 0.07172676920890808\n",
      "Batch：9672 | Loss: 0.07135424017906189\n",
      "Batch：9673 | Loss: 0.08984436094760895\n",
      "Batch：9674 | Loss: 0.07664278894662857\n",
      "Batch：9675 | Loss: 0.0675717294216156\n",
      "Batch：9676 | Loss: 0.08027627319097519\n",
      "Batch：9677 | Loss: 0.07715767621994019\n",
      "Batch：9678 | Loss: 0.07331401109695435\n",
      "Batch：9679 | Loss: 0.08334710448980331\n",
      "Batch：9680 | Loss: 0.08359090238809586\n",
      "Batch：9681 | Loss: 0.07680065929889679\n",
      "Batch：9682 | Loss: 0.07768645137548447\n",
      "Batch：9683 | Loss: 0.07853925973176956\n",
      "Batch：9684 | Loss: 0.08255426585674286\n",
      "Batch：9685 | Loss: 0.07679448276758194\n",
      "Batch：9686 | Loss: 0.07289866358041763\n",
      "Batch：9687 | Loss: 0.08328157663345337\n",
      "Batch：9688 | Loss: 0.07214754074811935\n",
      "Batch：9689 | Loss: 0.07977726310491562\n",
      "Batch：9690 | Loss: 0.07581833004951477\n",
      "Batch：9691 | Loss: 0.07184894382953644\n",
      "Batch：9692 | Loss: 0.0730876475572586\n",
      "Batch：9693 | Loss: 0.07527768611907959\n",
      "Batch：9694 | Loss: 0.07665997743606567\n",
      "Batch：9695 | Loss: 0.08697765320539474\n",
      "Batch：9696 | Loss: 0.0667906105518341\n",
      "Batch：9697 | Loss: 0.0750296413898468\n",
      "Batch：9698 | Loss: 0.07157441228628159\n",
      "Batch：9699 | Loss: 0.07749096304178238\n",
      "Batch：9700 | Loss: 0.07425770908594131\n",
      "Batch：9701 | Loss: 0.07634279131889343\n",
      "Batch：9702 | Loss: 0.07237014174461365\n",
      "Batch：9703 | Loss: 0.07415719330310822\n",
      "Batch：9704 | Loss: 0.0772942379117012\n",
      "Batch：9705 | Loss: 0.08871474117040634\n",
      "Batch：9706 | Loss: 0.08058726787567139\n",
      "Batch：9707 | Loss: 0.07443782687187195\n",
      "Batch：9708 | Loss: 0.0761289894580841\n",
      "Batch：9709 | Loss: 0.08160558342933655\n",
      "Batch：9710 | Loss: 0.07933248579502106\n",
      "Batch：9711 | Loss: 0.07518403232097626\n",
      "Batch：9712 | Loss: 0.07822547107934952\n",
      "Batch：9713 | Loss: 0.07173465937376022\n",
      "Batch：9714 | Loss: 0.07304685562849045\n",
      "Batch：9715 | Loss: 0.07658062875270844\n",
      "Batch：9716 | Loss: 0.07475435733795166\n",
      "Batch：9717 | Loss: 0.07582859694957733\n",
      "Batch：9718 | Loss: 0.08828515559434891\n",
      "Batch：9719 | Loss: 0.0784226804971695\n",
      "Batch：9720 | Loss: 0.07195354998111725\n",
      "Batch：9721 | Loss: 0.07868488878011703\n",
      "Batch：9722 | Loss: 0.07927548885345459\n",
      "Batch：9723 | Loss: 0.07837267220020294\n",
      "Batch：9724 | Loss: 0.0763973593711853\n",
      "Batch：9725 | Loss: 0.07169996947050095\n",
      "Batch：9726 | Loss: 0.06908895075321198\n",
      "Batch：9727 | Loss: 0.06564312428236008\n",
      "Batch：9728 | Loss: 0.06846380978822708\n",
      "Batch：9729 | Loss: 0.06906681507825851\n",
      "Batch：9730 | Loss: 0.08277232944965363\n",
      "Batch：9731 | Loss: 0.0811900645494461\n",
      "Batch：9732 | Loss: 0.06758685410022736\n",
      "Batch：9733 | Loss: 0.0790124386548996\n",
      "Batch：9734 | Loss: 0.06785669922828674\n",
      "Batch：9735 | Loss: 0.06533996760845184\n",
      "Batch：9736 | Loss: 0.07624238729476929\n",
      "Batch：9737 | Loss: 0.08489646762609482\n",
      "Batch：9738 | Loss: 0.06968249380588531\n",
      "Batch：9739 | Loss: 0.07401875406503677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：9740 | Loss: 0.07544446736574173\n",
      "Batch：9741 | Loss: 0.06843022257089615\n",
      "Batch：9742 | Loss: 0.07469891011714935\n",
      "Batch：9743 | Loss: 0.07557983696460724\n",
      "Batch：9744 | Loss: 0.0697873905301094\n",
      "Batch：9745 | Loss: 0.081009142100811\n",
      "Batch：9746 | Loss: 0.07481245696544647\n",
      "Batch：9747 | Loss: 0.07202830165624619\n",
      "Batch：9748 | Loss: 0.06757909804582596\n",
      "Batch：9749 | Loss: 0.07195442914962769\n",
      "Batch：9750 | Loss: 0.07785435765981674\n",
      "Batch：9751 | Loss: 0.07401333004236221\n",
      "Batch：9752 | Loss: 0.08387039601802826\n",
      "Batch：9753 | Loss: 0.07062958925962448\n",
      "Batch：9754 | Loss: 0.08135685324668884\n",
      "Batch：9755 | Loss: 0.08052240312099457\n",
      "Batch：9756 | Loss: 0.07290598750114441\n",
      "Batch：9757 | Loss: 0.06809201091527939\n",
      "Batch：9758 | Loss: 0.07504131644964218\n",
      "Batch：9759 | Loss: 0.07714283466339111\n",
      "Batch：9760 | Loss: 0.07481364160776138\n",
      "Batch：9761 | Loss: 0.07937653362751007\n",
      "Batch：9762 | Loss: 0.07966742664575577\n",
      "Batch：9763 | Loss: 0.06957269459962845\n",
      "Batch：9764 | Loss: 0.07775504887104034\n",
      "Batch：9765 | Loss: 0.07795528322458267\n",
      "Batch：9766 | Loss: 0.08301344513893127\n",
      "Batch：9767 | Loss: 0.06490879505872726\n",
      "Batch：9768 | Loss: 0.08280548453330994\n",
      "Batch：9769 | Loss: 0.08515676856040955\n",
      "Batch：9770 | Loss: 0.08799554407596588\n",
      "Batch：9771 | Loss: 0.0836138129234314\n",
      "Batch：9772 | Loss: 0.0641893520951271\n",
      "Batch：9773 | Loss: 0.08130305260419846\n",
      "Batch：9774 | Loss: 0.07696118205785751\n",
      "Batch：9775 | Loss: 0.07337278872728348\n",
      "Batch：9776 | Loss: 0.06978783756494522\n",
      "Batch：9777 | Loss: 0.07564567029476166\n",
      "Batch：9778 | Loss: 0.08699698001146317\n",
      "Batch：9779 | Loss: 0.06304837763309479\n",
      "Batch：9780 | Loss: 0.09099092334508896\n",
      "Batch：9781 | Loss: 0.06727486103773117\n",
      "Batch：9782 | Loss: 0.0653005912899971\n",
      "Batch：9783 | Loss: 0.07390595227479935\n",
      "Batch：9784 | Loss: 0.07632047683000565\n",
      "Batch：9785 | Loss: 0.06516028940677643\n",
      "Batch：9786 | Loss: 0.07103868573904037\n",
      "Batch：9787 | Loss: 0.07165215164422989\n",
      "Batch：9788 | Loss: 0.07608841359615326\n",
      "Batch：9789 | Loss: 0.08128827065229416\n",
      "Batch：9790 | Loss: 0.07952184230089188\n",
      "Batch：9791 | Loss: 0.07867851108312607\n",
      "Batch：9792 | Loss: 0.06769578903913498\n",
      "Batch：9793 | Loss: 0.07811842858791351\n",
      "Batch：9794 | Loss: 0.07177169620990753\n",
      "Batch：9795 | Loss: 0.06914107501506805\n",
      "Batch：9796 | Loss: 0.07158985733985901\n",
      "Batch：9797 | Loss: 0.07673365622758865\n",
      "Batch：9798 | Loss: 0.07508845627307892\n",
      "Batch：9799 | Loss: 0.0705038458108902\n",
      "Batch：9800 | Loss: 0.08979368954896927\n",
      "Batch：9801 | Loss: 0.07739368081092834\n",
      "Batch：9802 | Loss: 0.07462853938341141\n",
      "Batch：9803 | Loss: 0.06950682401657104\n",
      "Batch：9804 | Loss: 0.08199627697467804\n",
      "Batch：9805 | Loss: 0.06817290186882019\n",
      "Batch：9806 | Loss: 0.07099892199039459\n",
      "Batch：9807 | Loss: 0.07270483672618866\n",
      "Batch：9808 | Loss: 0.07580795139074326\n",
      "Batch：9809 | Loss: 0.07219085097312927\n",
      "Batch：9810 | Loss: 0.07419763505458832\n",
      "Batch：9811 | Loss: 0.0823945701122284\n",
      "Batch：9812 | Loss: 0.06754595041275024\n",
      "Batch：9813 | Loss: 0.07419336587190628\n",
      "Batch：9814 | Loss: 0.07899579405784607\n",
      "Batch：9815 | Loss: 0.07370463013648987\n",
      "Batch：9816 | Loss: 0.06683758646249771\n",
      "Batch：9817 | Loss: 0.07132206112146378\n",
      "Batch：9818 | Loss: 0.07959641516208649\n",
      "Batch：9819 | Loss: 0.08151598274707794\n",
      "Batch：9820 | Loss: 0.08126206696033478\n",
      "Batch：9821 | Loss: 0.07736142724752426\n",
      "Batch：9822 | Loss: 0.07358267903327942\n",
      "Batch：9823 | Loss: 0.07706575840711594\n",
      "Batch：9824 | Loss: 0.06994953006505966\n",
      "Batch：9825 | Loss: 0.07944544404745102\n",
      "Batch：9826 | Loss: 0.07328734546899796\n",
      "Batch：9827 | Loss: 0.07978392392396927\n",
      "Batch：9828 | Loss: 0.07659763097763062\n",
      "Batch：9829 | Loss: 0.0766470730304718\n",
      "Batch：9830 | Loss: 0.08079329133033752\n",
      "Batch：9831 | Loss: 0.06908781081438065\n",
      "Batch：9832 | Loss: 0.07716426253318787\n",
      "Batch：9833 | Loss: 0.07556337863206863\n",
      "Batch：9834 | Loss: 0.06467407941818237\n",
      "Batch：9835 | Loss: 0.07773587107658386\n",
      "Batch：9836 | Loss: 0.06420062482357025\n",
      "Batch：9837 | Loss: 0.08318828046321869\n",
      "Batch：9838 | Loss: 0.07740533351898193\n",
      "Batch：9839 | Loss: 0.06568910926580429\n",
      "Batch：9840 | Loss: 0.08124975860118866\n",
      "Batch：9841 | Loss: 0.07341039925813675\n",
      "Batch：9842 | Loss: 0.06626838445663452\n",
      "Batch：9843 | Loss: 0.06888780742883682\n",
      "Batch：9844 | Loss: 0.06437458097934723\n",
      "Batch：9845 | Loss: 0.07042849063873291\n",
      "Batch：9846 | Loss: 0.07052212208509445\n",
      "Batch：9847 | Loss: 0.07425321638584137\n",
      "Batch：9848 | Loss: 0.0855502039194107\n",
      "Batch：9849 | Loss: 0.0824085995554924\n",
      "Batch：9850 | Loss: 0.08758703619241714\n",
      "Batch：9851 | Loss: 0.07168839871883392\n",
      "Batch：9852 | Loss: 0.08321979641914368\n",
      "Batch：9853 | Loss: 0.07023525983095169\n",
      "Batch：9854 | Loss: 0.08629533648490906\n",
      "Batch：9855 | Loss: 0.08027830719947815\n",
      "Batch：9856 | Loss: 0.06862634420394897\n",
      "Batch：9857 | Loss: 0.07071159780025482\n",
      "Batch：9858 | Loss: 0.07257046550512314\n",
      "Batch：9859 | Loss: 0.07384300976991653\n",
      "Batch：9860 | Loss: 0.08312881737947464\n",
      "Batch：9861 | Loss: 0.0696210041642189\n",
      "Batch：9862 | Loss: 0.0839848592877388\n",
      "Batch：9863 | Loss: 0.0788271352648735\n",
      "Batch：9864 | Loss: 0.07506616413593292\n",
      "Batch：9865 | Loss: 0.08306224644184113\n",
      "Batch：9866 | Loss: 0.0784488394856453\n",
      "Batch：9867 | Loss: 0.0688222274184227\n",
      "Batch：9868 | Loss: 0.07483717054128647\n",
      "Batch：9869 | Loss: 0.07887890189886093\n",
      "Batch：9870 | Loss: 0.07970573753118515\n",
      "Batch：9871 | Loss: 0.08209452033042908\n",
      "Batch：9872 | Loss: 0.07302726805210114\n",
      "Batch：9873 | Loss: 0.07191571593284607\n",
      "Batch：9874 | Loss: 0.07939103245735168\n",
      "Batch：9875 | Loss: 0.07947289198637009\n",
      "Batch：9876 | Loss: 0.08056851476430893\n",
      "Batch：9877 | Loss: 0.07234629988670349\n",
      "Batch：9878 | Loss: 0.07791091501712799\n",
      "Batch：9879 | Loss: 0.06979156285524368\n",
      "Batch：9880 | Loss: 0.07386703044176102\n",
      "Batch：9881 | Loss: 0.07087628543376923\n",
      "Batch：9882 | Loss: 0.06085538491606712\n",
      "Batch：9883 | Loss: 0.07156956195831299\n",
      "Batch：9884 | Loss: 0.07142187654972076\n",
      "Batch：9885 | Loss: 0.06947395950555801\n",
      "Batch：9886 | Loss: 0.07354321330785751\n",
      "Batch：9887 | Loss: 0.08493431657552719\n",
      "Batch：9888 | Loss: 0.08210255950689316\n",
      "Batch：9889 | Loss: 0.08172409981489182\n",
      "Batch：9890 | Loss: 0.07885827869176865\n",
      "Batch：9891 | Loss: 0.0731796845793724\n",
      "Batch：9892 | Loss: 0.07148893922567368\n",
      "Batch：9893 | Loss: 0.07155370712280273\n",
      "Batch：9894 | Loss: 0.08161655813455582\n",
      "Batch：9895 | Loss: 0.066241055727005\n",
      "Batch：9896 | Loss: 0.07802404463291168\n",
      "Batch：9897 | Loss: 0.06795991957187653\n",
      "Batch：9898 | Loss: 0.07191038131713867\n",
      "Batch：9899 | Loss: 0.07890286296606064\n",
      "Batch：9900 | Loss: 0.06964635848999023\n",
      "Batch：9901 | Loss: 0.06129266694188118\n",
      "Batch：9902 | Loss: 0.07202212512493134\n",
      "Batch：9903 | Loss: 0.07420714944601059\n",
      "Batch：9904 | Loss: 0.06613454222679138\n",
      "Batch：9905 | Loss: 0.06935214251279831\n",
      "Batch：9906 | Loss: 0.0736517384648323\n",
      "Batch：9907 | Loss: 0.06325024366378784\n",
      "Batch：9908 | Loss: 0.07708361744880676\n",
      "Batch：9909 | Loss: 0.0645006000995636\n",
      "Batch：9910 | Loss: 0.0762692540884018\n",
      "Batch：9911 | Loss: 0.06669187545776367\n",
      "Batch：9912 | Loss: 0.07387473434209824\n",
      "Batch：9913 | Loss: 0.07848253101110458\n",
      "Batch：9914 | Loss: 0.08024977892637253\n",
      "Batch：9915 | Loss: 0.08336058259010315\n",
      "Batch：9916 | Loss: 0.07633601129055023\n",
      "Batch：9917 | Loss: 0.07318559288978577\n",
      "Batch：9918 | Loss: 0.07111093401908875\n",
      "Batch：9919 | Loss: 0.06827562302350998\n",
      "Batch：9920 | Loss: 0.05936598777770996\n",
      "Batch：9921 | Loss: 0.07562021911144257\n",
      "Batch：9922 | Loss: 0.07046520709991455\n",
      "Batch：9923 | Loss: 0.07506313174962997\n",
      "Batch：9924 | Loss: 0.07089199870824814\n",
      "Batch：9925 | Loss: 0.06786932051181793\n",
      "Batch：9926 | Loss: 0.061545923352241516\n",
      "Batch：9927 | Loss: 0.060351964086294174\n",
      "Batch：9928 | Loss: 0.06739504635334015\n",
      "Batch：9929 | Loss: 0.07656420022249222\n",
      "Batch：9930 | Loss: 0.07449398934841156\n",
      "Batch：9931 | Loss: 0.07274948805570602\n",
      "Batch：9932 | Loss: 0.06455788016319275\n",
      "Batch：9933 | Loss: 0.06900389492511749\n",
      "Batch：9934 | Loss: 0.08749028295278549\n",
      "Batch：9935 | Loss: 0.07966781407594681\n",
      "Batch：9936 | Loss: 0.07710781693458557\n",
      "Batch：9937 | Loss: 0.08211547881364822\n",
      "Batch：9938 | Loss: 0.06859159469604492\n",
      "Batch：9939 | Loss: 0.07891559600830078\n",
      "Batch：9940 | Loss: 0.0711992010474205\n",
      "Batch：9941 | Loss: 0.07160325348377228\n",
      "Batch：9942 | Loss: 0.08257736265659332\n",
      "Batch：9943 | Loss: 0.0715048611164093\n",
      "Batch：9944 | Loss: 0.07591333985328674\n",
      "Batch：9945 | Loss: 0.0716792568564415\n",
      "Batch：9946 | Loss: 0.07051218301057816\n",
      "Batch：9947 | Loss: 0.07078902423381805\n",
      "Batch：9948 | Loss: 0.06742580980062485\n",
      "Batch：9949 | Loss: 0.06278200447559357\n",
      "Batch：9950 | Loss: 0.0780726820230484\n",
      "Batch：9951 | Loss: 0.07674866169691086\n",
      "Batch：9952 | Loss: 0.07192181050777435\n",
      "Batch：9953 | Loss: 0.07713392376899719\n",
      "Batch：9954 | Loss: 0.06749416887760162\n",
      "Batch：9955 | Loss: 0.07430179417133331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：9956 | Loss: 0.07793938368558884\n",
      "Batch：9957 | Loss: 0.07570366561412811\n",
      "Batch：9958 | Loss: 0.0648927167057991\n",
      "Batch：9959 | Loss: 0.0674951896071434\n",
      "Batch：9960 | Loss: 0.0698111280798912\n",
      "Batch：9961 | Loss: 0.0728452056646347\n",
      "Batch：9962 | Loss: 0.057395730167627335\n",
      "Batch：9963 | Loss: 0.07502390444278717\n",
      "Batch：9964 | Loss: 0.07326878607273102\n",
      "Batch：9965 | Loss: 0.07847863435745239\n",
      "Batch：9966 | Loss: 0.07254155725240707\n",
      "Batch：9967 | Loss: 0.07062709331512451\n",
      "Batch：9968 | Loss: 0.07021196186542511\n",
      "Batch：9969 | Loss: 0.07021832466125488\n",
      "Batch：9970 | Loss: 0.07091283798217773\n",
      "Batch：9971 | Loss: 0.07937803119421005\n",
      "Batch：9972 | Loss: 0.0773945227265358\n",
      "Batch：9973 | Loss: 0.06463796645402908\n",
      "Batch：9974 | Loss: 0.07790932059288025\n",
      "Batch：9975 | Loss: 0.07298470288515091\n",
      "Batch：9976 | Loss: 0.06477449834346771\n",
      "Batch：9977 | Loss: 0.07185747474431992\n",
      "Batch：9978 | Loss: 0.07538728415966034\n",
      "Batch：9979 | Loss: 0.07027202099561691\n",
      "Batch：9980 | Loss: 0.07158437371253967\n",
      "Batch：9981 | Loss: 0.07728729397058487\n",
      "Batch：9982 | Loss: 0.0706019401550293\n",
      "Batch：9983 | Loss: 0.07387033849954605\n",
      "Batch：9984 | Loss: 0.07378445565700531\n",
      "Batch：9985 | Loss: 0.07302342355251312\n",
      "Batch：9986 | Loss: 0.07263046503067017\n",
      "Batch：9987 | Loss: 0.07513046264648438\n",
      "Batch：9988 | Loss: 0.07828907668590546\n",
      "Batch：9989 | Loss: 0.07021509110927582\n",
      "Batch：9990 | Loss: 0.06918176263570786\n",
      "Batch：9991 | Loss: 0.06835782527923584\n",
      "Batch：9992 | Loss: 0.06712564080953598\n",
      "Batch：9993 | Loss: 0.0664156824350357\n",
      "Batch：9994 | Loss: 0.07195135205984116\n",
      "Batch：9995 | Loss: 0.07220129668712616\n",
      "Batch：9996 | Loss: 0.07221303135156631\n",
      "Batch：9997 | Loss: 0.07805931568145752\n",
      "Batch：9998 | Loss: 0.08802325278520584\n",
      "Batch：9999 | Loss: 0.062441904097795486\n",
      "Batch：10000 | Loss: 0.07290389388799667\n",
      "Batch：10001 | Loss: 0.07663517445325851\n",
      "Batch：10002 | Loss: 0.07019086927175522\n",
      "Batch：10003 | Loss: 0.0705261155962944\n",
      "Batch：10004 | Loss: 0.07499831914901733\n",
      "Batch：10005 | Loss: 0.06892131268978119\n",
      "Batch：10006 | Loss: 0.07345747202634811\n",
      "Batch：10007 | Loss: 0.07123633474111557\n",
      "Batch：10008 | Loss: 0.07063904404640198\n",
      "Batch：10009 | Loss: 0.0771072506904602\n",
      "Batch：10010 | Loss: 0.07419732958078384\n",
      "Batch：10011 | Loss: 0.07998310029506683\n",
      "Batch：10012 | Loss: 0.07249940931797028\n",
      "Batch：10013 | Loss: 0.06863823533058167\n",
      "Batch：10014 | Loss: 0.08117985725402832\n",
      "Batch：10015 | Loss: 0.0692887008190155\n",
      "Batch：10016 | Loss: 0.08146507292985916\n",
      "Batch：10017 | Loss: 0.06536278873682022\n",
      "Batch：10018 | Loss: 0.0666356086730957\n",
      "Batch：10019 | Loss: 0.06202089786529541\n",
      "Batch：10020 | Loss: 0.06718148291110992\n",
      "Batch：10021 | Loss: 0.07451243698596954\n",
      "Batch：10022 | Loss: 0.08047736436128616\n",
      "Batch：10023 | Loss: 0.07188313454389572\n",
      "Batch：10024 | Loss: 0.08354159444570541\n",
      "Batch：10025 | Loss: 0.07565198093652725\n",
      "Batch：10026 | Loss: 0.08554823696613312\n",
      "Batch：10027 | Loss: 0.07001345604658127\n",
      "Batch：10028 | Loss: 0.06922967731952667\n",
      "Batch：10029 | Loss: 0.07767849415540695\n",
      "Batch：10030 | Loss: 0.06810469180345535\n",
      "Batch：10031 | Loss: 0.07562253624200821\n",
      "Batch：10032 | Loss: 0.0683734342455864\n",
      "Batch：10033 | Loss: 0.07075828313827515\n",
      "Batch：10034 | Loss: 0.07706943899393082\n",
      "Batch：10035 | Loss: 0.07617758214473724\n",
      "Batch：10036 | Loss: 0.07937159389257431\n",
      "Batch：10037 | Loss: 0.06626149266958237\n",
      "Batch：10038 | Loss: 0.08108337968587875\n",
      "Batch：10039 | Loss: 0.06713302433490753\n",
      "Batch：10040 | Loss: 0.08388998359441757\n",
      "Batch：10041 | Loss: 0.0756317675113678\n",
      "Batch：10042 | Loss: 0.06556883454322815\n",
      "Batch：10043 | Loss: 0.07975386083126068\n",
      "Batch：10044 | Loss: 0.0782407596707344\n",
      "Batch：10045 | Loss: 0.07066511362791061\n",
      "Batch：10046 | Loss: 0.06868496537208557\n",
      "Batch：10047 | Loss: 0.07548443228006363\n",
      "Batch：10048 | Loss: 0.07513314485549927\n",
      "Batch：10049 | Loss: 0.0795888602733612\n",
      "Batch：10050 | Loss: 0.06953568756580353\n",
      "Batch：10051 | Loss: 0.0767505094408989\n",
      "Batch：10052 | Loss: 0.05560460314154625\n",
      "Batch：10053 | Loss: 0.07712401449680328\n",
      "Batch：10054 | Loss: 0.06926749646663666\n",
      "Batch：10055 | Loss: 0.0756346806883812\n",
      "Batch：10056 | Loss: 0.0803234651684761\n",
      "Batch：10057 | Loss: 0.07648024708032608\n",
      "Batch：10058 | Loss: 0.06422830373048782\n",
      "Batch：10059 | Loss: 0.0849742516875267\n",
      "Batch：10060 | Loss: 0.07205812633037567\n",
      "Batch：10061 | Loss: 0.06006145104765892\n",
      "Batch：10062 | Loss: 0.07101479917764664\n",
      "Batch：10063 | Loss: 0.062169626355171204\n",
      "Batch：10064 | Loss: 0.07519996166229248\n",
      "Batch：10065 | Loss: 0.0799839198589325\n",
      "Batch：10066 | Loss: 0.07939404249191284\n",
      "Batch：10067 | Loss: 0.08225370943546295\n",
      "Batch：10068 | Loss: 0.069623664021492\n",
      "Batch：10069 | Loss: 0.09052795171737671\n",
      "Batch：10070 | Loss: 0.0799293965101242\n",
      "Batch：10071 | Loss: 0.07895636558532715\n",
      "Batch：10072 | Loss: 0.06735249608755112\n",
      "Batch：10073 | Loss: 0.07756108790636063\n",
      "Batch：10074 | Loss: 0.07078539580106735\n",
      "Batch：10075 | Loss: 0.0747230052947998\n",
      "Batch：10076 | Loss: 0.06752324104309082\n",
      "Batch：10077 | Loss: 0.08114945143461227\n",
      "Batch：10078 | Loss: 0.0737539753317833\n",
      "Batch：10079 | Loss: 0.07510969787836075\n",
      "Batch：10080 | Loss: 0.07088279724121094\n",
      "Batch：10081 | Loss: 0.07157082855701447\n",
      "Batch：10082 | Loss: 0.07844769954681396\n",
      "Batch：10083 | Loss: 0.06990830600261688\n",
      "Batch：10084 | Loss: 0.07848236709833145\n",
      "Batch：10085 | Loss: 0.07838045060634613\n",
      "Batch：10086 | Loss: 0.07454502582550049\n",
      "Batch：10087 | Loss: 0.07587539404630661\n",
      "Batch：10088 | Loss: 0.0735253393650055\n",
      "Batch：10089 | Loss: 0.07487843185663223\n",
      "Batch：10090 | Loss: 0.0729074627161026\n",
      "Batch：10091 | Loss: 0.06688494980335236\n",
      "Batch：10092 | Loss: 0.06126968935132027\n",
      "Batch：10093 | Loss: 0.06863315403461456\n",
      "Batch：10094 | Loss: 0.08135898411273956\n",
      "Batch：10095 | Loss: 0.0809125229716301\n",
      "Batch：10096 | Loss: 0.07110865414142609\n",
      "Batch：10097 | Loss: 0.07028645277023315\n",
      "Batch：10098 | Loss: 0.07318492233753204\n",
      "Batch：10099 | Loss: 0.08278732001781464\n",
      "Batch：10100 | Loss: 0.07317931950092316\n",
      "Batch：10101 | Loss: 0.07506117969751358\n",
      "Batch：10102 | Loss: 0.07768885046243668\n",
      "Batch：10103 | Loss: 0.06931790709495544\n",
      "Batch：10104 | Loss: 0.07265688478946686\n",
      "Batch：10105 | Loss: 0.06632339209318161\n",
      "Batch：10106 | Loss: 0.07328532636165619\n",
      "Batch：10107 | Loss: 0.07276000082492828\n",
      "Batch：10108 | Loss: 0.0748727098107338\n",
      "Batch：10109 | Loss: 0.07048407196998596\n",
      "Batch：10110 | Loss: 0.06845284253358841\n",
      "Batch：10111 | Loss: 0.07217693328857422\n",
      "Batch：10112 | Loss: 0.08458852767944336\n",
      "Batch：10113 | Loss: 0.06908781826496124\n",
      "Batch：10114 | Loss: 0.07087332755327225\n",
      "Batch：10115 | Loss: 0.0690794363617897\n",
      "Batch：10116 | Loss: 0.06463685631752014\n",
      "Batch：10117 | Loss: 0.07634139060974121\n",
      "Batch：10118 | Loss: 0.07260832190513611\n",
      "Batch：10119 | Loss: 0.0652199238538742\n",
      "Batch：10120 | Loss: 0.06914283335208893\n",
      "Batch：10121 | Loss: 0.08677119761705399\n",
      "Batch：10122 | Loss: 0.08138509839773178\n",
      "Batch：10123 | Loss: 0.07357311993837357\n",
      "Batch：10124 | Loss: 0.06418433785438538\n",
      "Batch：10125 | Loss: 0.07740700244903564\n",
      "Batch：10126 | Loss: 0.06276615709066391\n",
      "Batch：10127 | Loss: 0.07776227593421936\n",
      "Batch：10128 | Loss: 0.06855957210063934\n",
      "Batch：10129 | Loss: 0.06866522878408432\n",
      "Batch：10130 | Loss: 0.08208154886960983\n",
      "Batch：10131 | Loss: 0.06443691998720169\n",
      "Batch：10132 | Loss: 0.06409674137830734\n",
      "Batch：10133 | Loss: 0.07520152628421783\n",
      "Batch：10134 | Loss: 0.0705043151974678\n",
      "Batch：10135 | Loss: 0.07431206852197647\n",
      "Batch：10136 | Loss: 0.0793759673833847\n",
      "Batch：10137 | Loss: 0.06360645592212677\n",
      "Batch：10138 | Loss: 0.06953940540552139\n",
      "Batch：10139 | Loss: 0.06739779561758041\n",
      "Batch：10140 | Loss: 0.07834814488887787\n",
      "Batch：10141 | Loss: 0.06614943593740463\n",
      "Batch：10142 | Loss: 0.06669268757104874\n",
      "Batch：10143 | Loss: 0.06769564747810364\n",
      "Batch：10144 | Loss: 0.06473376601934433\n",
      "Batch：10145 | Loss: 0.07341532409191132\n",
      "Batch：10146 | Loss: 0.0625268742442131\n",
      "Batch：10147 | Loss: 0.07325835525989532\n",
      "Batch：10148 | Loss: 0.08161187916994095\n",
      "Batch：10149 | Loss: 0.05901963263750076\n",
      "Batch：10150 | Loss: 0.06647054105997086\n",
      "Batch：10151 | Loss: 0.07064138352870941\n",
      "Batch：10152 | Loss: 0.06875872611999512\n",
      "Batch：10153 | Loss: 0.07374147325754166\n",
      "Batch：10154 | Loss: 0.07214194536209106\n",
      "Batch：10155 | Loss: 0.07819532603025436\n",
      "Batch：10156 | Loss: 0.07751534879207611\n",
      "Batch：10157 | Loss: 0.06564334034919739\n",
      "Batch：10158 | Loss: 0.072657011449337\n",
      "Batch：10159 | Loss: 0.07167947292327881\n",
      "Batch：10160 | Loss: 0.07259531319141388\n",
      "Batch：10161 | Loss: 0.06716777384281158\n",
      "Batch：10162 | Loss: 0.07044936716556549\n",
      "Batch：10163 | Loss: 0.08121952414512634\n",
      "Batch：10164 | Loss: 0.06634344160556793\n",
      "Batch：10165 | Loss: 0.06388948857784271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：10166 | Loss: 0.06470281630754471\n",
      "Batch：10167 | Loss: 0.08814577013254166\n",
      "Batch：10168 | Loss: 0.07654393464326859\n",
      "Batch：10169 | Loss: 0.07394092530012131\n",
      "Batch：10170 | Loss: 0.08706659078598022\n",
      "Batch：10171 | Loss: 0.08978914469480515\n",
      "Batch：10172 | Loss: 0.07443735003471375\n",
      "Batch：10173 | Loss: 0.07307914644479752\n",
      "Batch：10174 | Loss: 0.07658959925174713\n",
      "Batch：10175 | Loss: 0.06448418647050858\n",
      "Batch：10176 | Loss: 0.07752729207277298\n",
      "Batch：10177 | Loss: 0.08271154016256332\n",
      "Batch：10178 | Loss: 0.06718245893716812\n",
      "Batch：10179 | Loss: 0.0723203718662262\n",
      "Batch：10180 | Loss: 0.07761060446500778\n",
      "Batch：10181 | Loss: 0.08388108015060425\n",
      "Batch：10182 | Loss: 0.10133282095193863\n",
      "Batch：10183 | Loss: 0.06660346686840057\n",
      "Batch：10184 | Loss: 0.06753604859113693\n",
      "Batch：10185 | Loss: 0.06267190724611282\n",
      "Batch：10186 | Loss: 0.0680248886346817\n",
      "Batch：10187 | Loss: 0.06511323153972626\n",
      "Batch：10188 | Loss: 0.062046051025390625\n",
      "Batch：10189 | Loss: 0.07506614923477173\n",
      "Batch：10190 | Loss: 0.07391577959060669\n",
      "Batch：10191 | Loss: 0.08338309824466705\n",
      "Batch：10192 | Loss: 0.06865352392196655\n",
      "Batch：10193 | Loss: 0.07289963960647583\n",
      "Batch：10194 | Loss: 0.06650031358003616\n",
      "Batch：10195 | Loss: 0.07434569299221039\n",
      "Batch：10196 | Loss: 0.06579145044088364\n",
      "Batch：10197 | Loss: 0.07799697667360306\n",
      "Batch：10198 | Loss: 0.0798807293176651\n",
      "Batch：10199 | Loss: 0.0730452686548233\n",
      "Batch：10200 | Loss: 0.08049210160970688\n",
      "Batch：10201 | Loss: 0.07461543381214142\n",
      "Batch：10202 | Loss: 0.06748037785291672\n",
      "Batch：10203 | Loss: 0.06759641319513321\n",
      "Batch：10204 | Loss: 0.08186391741037369\n",
      "Batch：10205 | Loss: 0.0779232606291771\n",
      "Batch：10206 | Loss: 0.06594496220350266\n",
      "Batch：10207 | Loss: 0.07388562709093094\n",
      "Batch：10208 | Loss: 0.0658717006444931\n",
      "Batch：10209 | Loss: 0.07302545756101608\n",
      "Batch：10210 | Loss: 0.06313304603099823\n",
      "Batch：10211 | Loss: 0.07084541022777557\n",
      "Batch：10212 | Loss: 0.07032972574234009\n",
      "Batch：10213 | Loss: 0.07399655133485794\n",
      "Batch：10214 | Loss: 0.08101372420787811\n",
      "Batch：10215 | Loss: 0.06792247295379639\n",
      "Batch：10216 | Loss: 0.06638545542955399\n",
      "Batch：10217 | Loss: 0.07412176579236984\n",
      "Batch：10218 | Loss: 0.07317039370536804\n",
      "Batch：10219 | Loss: 0.07594605535268784\n",
      "Batch：10220 | Loss: 0.07953772693872452\n",
      "Batch：10221 | Loss: 0.07436345517635345\n",
      "Batch：10222 | Loss: 0.06620371341705322\n",
      "Batch：10223 | Loss: 0.06907903403043747\n",
      "Batch：10224 | Loss: 0.06866167485713959\n",
      "Batch：10225 | Loss: 0.08139662444591522\n",
      "Batch：10226 | Loss: 0.06394818425178528\n",
      "Batch：10227 | Loss: 0.07675294578075409\n",
      "Batch：10228 | Loss: 0.06720004975795746\n",
      "Batch：10229 | Loss: 0.06598071753978729\n",
      "Batch：10230 | Loss: 0.07452277839183807\n",
      "Batch：10231 | Loss: 0.062129028141498566\n",
      "Batch：10232 | Loss: 0.07069896161556244\n",
      "Batch：10233 | Loss: 0.06194774806499481\n",
      "Batch：10234 | Loss: 0.06355177611112595\n",
      "Batch：10235 | Loss: 0.07272039353847504\n",
      "Batch：10236 | Loss: 0.07513095438480377\n",
      "Batch：10237 | Loss: 0.07734955847263336\n",
      "Batch：10238 | Loss: 0.07700573652982712\n",
      "Batch：10239 | Loss: 0.0722256749868393\n",
      "Batch：10240 | Loss: 0.07066851109266281\n",
      "Batch：10241 | Loss: 0.08064151555299759\n",
      "Batch：10242 | Loss: 0.06786678731441498\n",
      "Batch：10243 | Loss: 0.07082925736904144\n",
      "Batch：10244 | Loss: 0.07262575626373291\n",
      "Batch：10245 | Loss: 0.08345910906791687\n",
      "Batch：10246 | Loss: 0.07520610094070435\n",
      "Batch：10247 | Loss: 0.07141850143671036\n",
      "Batch：10248 | Loss: 0.08279725909233093\n",
      "Batch：10249 | Loss: 0.07345196604728699\n",
      "Batch：10250 | Loss: 0.07896317541599274\n",
      "Batch：10251 | Loss: 0.059233102947473526\n",
      "Batch：10252 | Loss: 0.07227975130081177\n",
      "Batch：10253 | Loss: 0.07770668715238571\n",
      "Batch：10254 | Loss: 0.07369603216648102\n",
      "Batch：10255 | Loss: 0.07726006209850311\n",
      "Batch：10256 | Loss: 0.060920603573322296\n",
      "Batch：10257 | Loss: 0.0671982541680336\n",
      "Batch：10258 | Loss: 0.07076852023601532\n",
      "Batch：10259 | Loss: 0.06238697096705437\n",
      "Batch：10260 | Loss: 0.06896042078733444\n",
      "Batch：10261 | Loss: 0.0819656029343605\n",
      "Batch：10262 | Loss: 0.06998977810144424\n",
      "Batch：10263 | Loss: 0.06012445688247681\n",
      "Batch：10264 | Loss: 0.0730462297797203\n",
      "Batch：10265 | Loss: 0.06776688247919083\n",
      "Batch：10266 | Loss: 0.06143289804458618\n",
      "Batch：10267 | Loss: 0.063074991106987\n",
      "Batch：10268 | Loss: 0.07206126302480698\n",
      "Batch：10269 | Loss: 0.07444790750741959\n",
      "Batch：10270 | Loss: 0.07921517640352249\n",
      "Batch：10271 | Loss: 0.07275746017694473\n",
      "Batch：10272 | Loss: 0.0754917785525322\n",
      "Batch：10273 | Loss: 0.07460815459489822\n",
      "Batch：10274 | Loss: 0.0616433210670948\n",
      "Batch：10275 | Loss: 0.06917960941791534\n",
      "Batch：10276 | Loss: 0.06471588462591171\n",
      "Batch：10277 | Loss: 0.08084993064403534\n",
      "Batch：10278 | Loss: 0.07367179542779922\n",
      "Batch：10279 | Loss: 0.06931297481060028\n",
      "Batch：10280 | Loss: 0.05945305898785591\n",
      "Batch：10281 | Loss: 0.06600731611251831\n",
      "Batch：10282 | Loss: 0.0746193453669548\n",
      "Batch：10283 | Loss: 0.07458242028951645\n",
      "Batch：10284 | Loss: 0.06511309742927551\n",
      "Batch：10285 | Loss: 0.07881868630647659\n",
      "Batch：10286 | Loss: 0.07794534415006638\n",
      "Batch：10287 | Loss: 0.06019861623644829\n",
      "Batch：10288 | Loss: 0.07273691892623901\n",
      "Batch：10289 | Loss: 0.08249162882566452\n",
      "Batch：10290 | Loss: 0.068817138671875\n",
      "Batch：10291 | Loss: 0.0692702978849411\n",
      "Batch：10292 | Loss: 0.07255538552999496\n",
      "Batch：10293 | Loss: 0.0739913359284401\n",
      "Batch：10294 | Loss: 0.05297992751002312\n",
      "Batch：10295 | Loss: 0.07854747027158737\n",
      "Batch：10296 | Loss: 0.0765371099114418\n",
      "Batch：10297 | Loss: 0.07989218086004257\n",
      "Batch：10298 | Loss: 0.08049046248197556\n",
      "Batch：10299 | Loss: 0.07532326132059097\n",
      "Batch：10300 | Loss: 0.0836796760559082\n",
      "Batch：10301 | Loss: 0.07077853381633759\n",
      "Batch：10302 | Loss: 0.06362610310316086\n",
      "Batch：10303 | Loss: 0.0782027617096901\n",
      "Batch：10304 | Loss: 0.07299214601516724\n",
      "Batch：10305 | Loss: 0.07625061273574829\n",
      "Batch：10306 | Loss: 0.06490453332662582\n",
      "Batch：10307 | Loss: 0.07493636757135391\n",
      "Batch：10308 | Loss: 0.08949129283428192\n",
      "Batch：10309 | Loss: 0.07602453231811523\n",
      "Batch：10310 | Loss: 0.06687426567077637\n",
      "Batch：10311 | Loss: 0.058991651982069016\n",
      "Batch：10312 | Loss: 0.07514012604951859\n",
      "Batch：10313 | Loss: 0.07046744972467422\n",
      "Batch：10314 | Loss: 0.08084676414728165\n",
      "Batch：10315 | Loss: 0.0678068995475769\n",
      "Batch：10316 | Loss: 0.07584822177886963\n",
      "Batch：10317 | Loss: 0.062291115522384644\n",
      "Batch：10318 | Loss: 0.0740683525800705\n",
      "Batch：10319 | Loss: 0.06794244050979614\n",
      "Batch：10320 | Loss: 0.06922924518585205\n",
      "Batch：10321 | Loss: 0.0795821025967598\n",
      "Batch：10322 | Loss: 0.07211880385875702\n",
      "Batch：10323 | Loss: 0.07624748349189758\n",
      "Batch：10324 | Loss: 0.07356858253479004\n",
      "Batch：10325 | Loss: 0.07708944380283356\n",
      "Batch：10326 | Loss: 0.07609833776950836\n",
      "Batch：10327 | Loss: 0.06840664893388748\n",
      "Batch：10328 | Loss: 0.0689317062497139\n",
      "Batch：10329 | Loss: 0.07254546880722046\n",
      "Batch：10330 | Loss: 0.07951748371124268\n",
      "Batch：10331 | Loss: 0.06738284975290298\n",
      "Batch：10332 | Loss: 0.07446550577878952\n",
      "Batch：10333 | Loss: 0.0717891976237297\n",
      "Batch：10334 | Loss: 0.07775949686765671\n",
      "Batch：10335 | Loss: 0.07102623581886292\n",
      "Batch：10336 | Loss: 0.07791925966739655\n",
      "Batch：10337 | Loss: 0.06474817544221878\n",
      "Batch：10338 | Loss: 0.06729035079479218\n",
      "Batch：10339 | Loss: 0.06592454761266708\n",
      "Batch：10340 | Loss: 0.0686858594417572\n",
      "Batch：10341 | Loss: 0.0684475228190422\n",
      "Batch：10342 | Loss: 0.07184731960296631\n",
      "Batch：10343 | Loss: 0.07656868547201157\n",
      "Batch：10344 | Loss: 0.06823419779539108\n",
      "Batch：10345 | Loss: 0.07493728399276733\n",
      "Batch：10346 | Loss: 0.07348886877298355\n",
      "Batch：10347 | Loss: 0.07827702909708023\n",
      "Batch：10348 | Loss: 0.07218611240386963\n",
      "Batch：10349 | Loss: 0.06694244593381882\n",
      "Batch：10350 | Loss: 0.07256881892681122\n",
      "Batch：10351 | Loss: 0.08502525091171265\n",
      "Batch：10352 | Loss: 0.06929279863834381\n",
      "Batch：10353 | Loss: 0.07355427742004395\n",
      "Batch：10354 | Loss: 0.07444179058074951\n",
      "Batch：10355 | Loss: 0.06689974665641785\n",
      "Batch：10356 | Loss: 0.07802663743495941\n",
      "Batch：10357 | Loss: 0.06748690456151962\n",
      "Batch：10358 | Loss: 0.06645680963993073\n",
      "Batch：10359 | Loss: 0.07047027349472046\n",
      "Batch：10360 | Loss: 0.07704025506973267\n",
      "Batch：10361 | Loss: 0.07438182830810547\n",
      "Batch：10362 | Loss: 0.07523173093795776\n",
      "Batch：10363 | Loss: 0.06538558006286621\n",
      "Batch：10364 | Loss: 0.07193205505609512\n",
      "Batch：10365 | Loss: 0.07218386977910995\n",
      "Batch：10366 | Loss: 0.06207656115293503\n",
      "Batch：10367 | Loss: 0.0712047889828682\n",
      "Batch：10368 | Loss: 0.0809696763753891\n",
      "Batch：10369 | Loss: 0.06253459304571152\n",
      "Batch：10370 | Loss: 0.07822730392217636\n",
      "Batch：10371 | Loss: 0.0729391798377037\n",
      "Batch：10372 | Loss: 0.08257150650024414\n",
      "Batch：10373 | Loss: 0.08007661998271942\n",
      "Batch：10374 | Loss: 0.0693017840385437\n",
      "Batch：10375 | Loss: 0.06986889243125916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：10376 | Loss: 0.07472983002662659\n",
      "Batch：10377 | Loss: 0.07122505456209183\n",
      "Batch：10378 | Loss: 0.06642112880945206\n",
      "Batch：10379 | Loss: 0.07162953913211823\n",
      "Batch：10380 | Loss: 0.07415438443422318\n",
      "Batch：10381 | Loss: 0.07543884962797165\n",
      "Batch：10382 | Loss: 0.0704844519495964\n",
      "Batch：10383 | Loss: 0.07096026837825775\n",
      "Batch：10384 | Loss: 0.06068948656320572\n",
      "Batch：10385 | Loss: 0.0720372125506401\n",
      "Batch：10386 | Loss: 0.07150048017501831\n",
      "Batch：10387 | Loss: 0.06966360658407211\n",
      "Batch：10388 | Loss: 0.07594455033540726\n",
      "Batch：10389 | Loss: 0.06375343352556229\n",
      "Batch：10390 | Loss: 0.0751451626420021\n",
      "Batch：10391 | Loss: 0.07274194061756134\n",
      "Batch：10392 | Loss: 0.07606910914182663\n",
      "Batch：10393 | Loss: 0.06961598992347717\n",
      "Batch：10394 | Loss: 0.07140452414751053\n",
      "Batch：10395 | Loss: 0.06956277042627335\n",
      "Batch：10396 | Loss: 0.07260962575674057\n",
      "Batch：10397 | Loss: 0.05314505845308304\n",
      "Batch：10398 | Loss: 0.06900802254676819\n",
      "Batch：10399 | Loss: 0.07325541973114014\n",
      "Batch：10400 | Loss: 0.07484148442745209\n",
      "Batch：10401 | Loss: 0.0667940154671669\n",
      "Batch：10402 | Loss: 0.07797746360301971\n",
      "Batch：10403 | Loss: 0.06909418851137161\n",
      "Batch：10404 | Loss: 0.0732068195939064\n",
      "Batch：10405 | Loss: 0.07578498125076294\n",
      "Batch：10406 | Loss: 0.07120679318904877\n",
      "Batch：10407 | Loss: 0.07113565504550934\n",
      "Batch：10408 | Loss: 0.0790819302201271\n",
      "Batch：10409 | Loss: 0.06610479205846786\n",
      "Batch：10410 | Loss: 0.062410689890384674\n",
      "Batch：10411 | Loss: 0.07361108064651489\n",
      "Batch：10412 | Loss: 0.07440929859876633\n",
      "Batch：10413 | Loss: 0.05727392062544823\n",
      "Batch：10414 | Loss: 0.07110059261322021\n",
      "Batch：10415 | Loss: 0.07288139313459396\n",
      "Batch：10416 | Loss: 0.06979405879974365\n",
      "Batch：10417 | Loss: 0.0814613625407219\n",
      "Batch：10418 | Loss: 0.07385482639074326\n",
      "Batch：10419 | Loss: 0.06117399036884308\n",
      "Batch：10420 | Loss: 0.07966926693916321\n",
      "Batch：10421 | Loss: 0.07322874665260315\n",
      "Batch：10422 | Loss: 0.06336360424757004\n",
      "Batch：10423 | Loss: 0.07120993733406067\n",
      "Batch：10424 | Loss: 0.06813336908817291\n",
      "Batch：10425 | Loss: 0.07850199192762375\n",
      "Batch：10426 | Loss: 0.07795736193656921\n",
      "Batch：10427 | Loss: 0.07941007614135742\n",
      "Batch：10428 | Loss: 0.06729474663734436\n",
      "Batch：10429 | Loss: 0.06750423461198807\n",
      "Batch：10430 | Loss: 0.07127384096384048\n",
      "Batch：10431 | Loss: 0.07499878853559494\n",
      "Batch：10432 | Loss: 0.06760921329259872\n",
      "Batch：10433 | Loss: 0.07471265643835068\n",
      "Batch：10434 | Loss: 0.07807003706693649\n",
      "Batch：10435 | Loss: 0.06637216359376907\n",
      "Batch：10436 | Loss: 0.07289233803749084\n",
      "Batch：10437 | Loss: 0.07023675739765167\n",
      "Batch：10438 | Loss: 0.060767557471990585\n",
      "Batch：10439 | Loss: 0.08019311726093292\n",
      "Batch：10440 | Loss: 0.06599956005811691\n",
      "Batch：10441 | Loss: 0.07995203882455826\n",
      "Batch：10442 | Loss: 0.06683650612831116\n",
      "Batch：10443 | Loss: 0.08276799321174622\n",
      "Batch：10444 | Loss: 0.06817182153463364\n",
      "Batch：10445 | Loss: 0.07811132073402405\n",
      "Batch：10446 | Loss: 0.08765874803066254\n",
      "Batch：10447 | Loss: 0.0782768726348877\n",
      "Batch：10448 | Loss: 0.06350462138652802\n",
      "Batch：10449 | Loss: 0.06522895395755768\n",
      "Batch：10450 | Loss: 0.06857385486364365\n",
      "Batch：10451 | Loss: 0.06677863001823425\n",
      "Batch：10452 | Loss: 0.06924934685230255\n",
      "Batch：10453 | Loss: 0.06818680465221405\n",
      "Batch：10454 | Loss: 0.07260771095752716\n",
      "Batch：10455 | Loss: 0.07610156387090683\n",
      "Batch：10456 | Loss: 0.08159370720386505\n",
      "Batch：10457 | Loss: 0.07494177669286728\n",
      "Batch：10458 | Loss: 0.06608133018016815\n",
      "Batch：10459 | Loss: 0.07450498640537262\n",
      "Batch：10460 | Loss: 0.0660472884774208\n",
      "Batch：10461 | Loss: 0.06893455982208252\n",
      "Batch：10462 | Loss: 0.07342598587274551\n",
      "Batch：10463 | Loss: 0.07194457203149796\n",
      "Batch：10464 | Loss: 0.0747535303235054\n",
      "Batch：10465 | Loss: 0.07639923691749573\n",
      "Batch：10466 | Loss: 0.06780419498682022\n",
      "Batch：10467 | Loss: 0.06779507547616959\n",
      "Batch：10468 | Loss: 0.08029747754335403\n",
      "Batch：10469 | Loss: 0.06485624611377716\n",
      "Batch：10470 | Loss: 0.07751408964395523\n",
      "Batch：10471 | Loss: 0.0694461390376091\n",
      "Batch：10472 | Loss: 0.0684131607413292\n",
      "Batch：10473 | Loss: 0.07362315058708191\n",
      "Batch：10474 | Loss: 0.06361200660467148\n",
      "Batch：10475 | Loss: 0.07951671630144119\n",
      "Batch：10476 | Loss: 0.06819161772727966\n",
      "Batch：10477 | Loss: 0.07540725916624069\n",
      "Batch：10478 | Loss: 0.08174087852239609\n",
      "Batch：10479 | Loss: 0.0815514400601387\n",
      "Batch：10480 | Loss: 0.06930325925350189\n",
      "Batch：10481 | Loss: 0.07625189423561096\n",
      "Batch：10482 | Loss: 0.08029479533433914\n",
      "Batch：10483 | Loss: 0.06914050132036209\n",
      "Batch：10484 | Loss: 0.06506986916065216\n",
      "Batch：10485 | Loss: 0.07308393716812134\n",
      "Batch：10486 | Loss: 0.06598607450723648\n",
      "Batch：10487 | Loss: 0.07389528304338455\n",
      "Batch：10488 | Loss: 0.07674539089202881\n",
      "Batch：10489 | Loss: 0.06932507455348969\n",
      "Batch：10490 | Loss: 0.0660887360572815\n",
      "Batch：10491 | Loss: 0.06464041024446487\n",
      "Batch：10492 | Loss: 0.06599897891283035\n",
      "Batch：10493 | Loss: 0.0756566971540451\n",
      "Batch：10494 | Loss: 0.0789373368024826\n",
      "Batch：10495 | Loss: 0.08064865320920944\n",
      "Batch：10496 | Loss: 0.06953943520784378\n",
      "Batch：10497 | Loss: 0.0663350448012352\n",
      "Batch：10498 | Loss: 0.07429715245962143\n",
      "Batch：10499 | Loss: 0.07318519800901413\n",
      "Batch：10500 | Loss: 0.07129694521427155\n",
      "Batch：10501 | Loss: 0.06888001412153244\n",
      "Batch：10502 | Loss: 0.06580321490764618\n",
      "Batch：10503 | Loss: 0.06773649901151657\n",
      "Batch：10504 | Loss: 0.061817754060029984\n",
      "Batch：10505 | Loss: 0.07169079780578613\n",
      "Batch：10506 | Loss: 0.06879130750894547\n",
      "Batch：10507 | Loss: 0.06803406029939651\n",
      "Batch：10508 | Loss: 0.06517979502677917\n",
      "Batch：10509 | Loss: 0.07587990164756775\n",
      "Batch：10510 | Loss: 0.06634420901536942\n",
      "Batch：10511 | Loss: 0.07523980736732483\n",
      "Batch：10512 | Loss: 0.07339955121278763\n",
      "Batch：10513 | Loss: 0.06571478396654129\n",
      "Batch：10514 | Loss: 0.06258559972047806\n",
      "Batch：10515 | Loss: 0.06835925579071045\n",
      "Batch：10516 | Loss: 0.0769324004650116\n",
      "Batch：10517 | Loss: 0.07182448357343674\n",
      "Batch：10518 | Loss: 0.07010158896446228\n",
      "Batch：10519 | Loss: 0.06955242156982422\n",
      "Batch：10520 | Loss: 0.07369612902402878\n",
      "Batch：10521 | Loss: 0.06676013022661209\n",
      "Batch：10522 | Loss: 0.07384533435106277\n",
      "Batch：10523 | Loss: 0.08176066726446152\n",
      "Batch：10524 | Loss: 0.0844094380736351\n",
      "Batch：10525 | Loss: 0.06729814410209656\n",
      "Batch：10526 | Loss: 0.05996973440051079\n",
      "Batch：10527 | Loss: 0.06573057174682617\n",
      "Batch：10528 | Loss: 0.06755641847848892\n",
      "Batch：10529 | Loss: 0.07487878203392029\n",
      "Batch：10530 | Loss: 0.07780512422323227\n",
      "Batch：10531 | Loss: 0.08072873950004578\n",
      "Batch：10532 | Loss: 0.06141803413629532\n",
      "Batch：10533 | Loss: 0.07232116907835007\n",
      "Batch：10534 | Loss: 0.07089418172836304\n",
      "Batch：10535 | Loss: 0.06630223244428635\n",
      "Batch：10536 | Loss: 0.06205088272690773\n",
      "Batch：10537 | Loss: 0.059762757271528244\n",
      "Batch：10538 | Loss: 0.06296885013580322\n",
      "Batch：10539 | Loss: 0.07294108718633652\n",
      "Batch：10540 | Loss: 0.06444787234067917\n",
      "Batch：10541 | Loss: 0.07640033215284348\n",
      "Batch：10542 | Loss: 0.06359367817640305\n",
      "Batch：10543 | Loss: 0.07252547889947891\n",
      "Batch：10544 | Loss: 0.06828698515892029\n",
      "Batch：10545 | Loss: 0.07210201770067215\n",
      "Batch：10546 | Loss: 0.06193886324763298\n",
      "Batch：10547 | Loss: 0.06549866497516632\n",
      "Batch：10548 | Loss: 0.06864485889673233\n",
      "Batch：10549 | Loss: 0.07777231931686401\n",
      "Batch：10550 | Loss: 0.07007631659507751\n",
      "Batch：10551 | Loss: 0.07693372666835785\n",
      "Batch：10552 | Loss: 0.07575274258852005\n",
      "Batch：10553 | Loss: 0.07764879614114761\n",
      "Batch：10554 | Loss: 0.07968388497829437\n",
      "Batch：10555 | Loss: 0.06543626636266708\n",
      "Batch：10556 | Loss: 0.06311102956533432\n",
      "Batch：10557 | Loss: 0.06976264715194702\n",
      "Batch：10558 | Loss: 0.06733352690935135\n",
      "Batch：10559 | Loss: 0.07218091934919357\n",
      "Batch：10560 | Loss: 0.07382451742887497\n",
      "Batch：10561 | Loss: 0.08693218231201172\n",
      "Batch：10562 | Loss: 0.058495938777923584\n",
      "Batch：10563 | Loss: 0.07238045334815979\n",
      "Batch：10564 | Loss: 0.06838195025920868\n",
      "Batch：10565 | Loss: 0.08518103510141373\n",
      "Batch：10566 | Loss: 0.0669536143541336\n",
      "Batch：10567 | Loss: 0.07106845080852509\n",
      "Batch：10568 | Loss: 0.05679040029644966\n",
      "Batch：10569 | Loss: 0.08022113144397736\n",
      "Batch：10570 | Loss: 0.05928019806742668\n",
      "Batch：10571 | Loss: 0.07218074053525925\n",
      "Batch：10572 | Loss: 0.07177820056676865\n",
      "Batch：10573 | Loss: 0.06819090992212296\n",
      "Batch：10574 | Loss: 0.06632786989212036\n",
      "Batch：10575 | Loss: 0.07432451099157333\n",
      "Batch：10576 | Loss: 0.0709342360496521\n",
      "Batch：10577 | Loss: 0.06771460175514221\n",
      "Batch：10578 | Loss: 0.07165287435054779\n",
      "Batch：10579 | Loss: 0.07585521042346954\n",
      "Batch：10580 | Loss: 0.07011695951223373\n",
      "Batch：10581 | Loss: 0.07650147378444672\n",
      "Batch：10582 | Loss: 0.07600127905607224\n",
      "Batch：10583 | Loss: 0.07102096080780029\n",
      "Batch：10584 | Loss: 0.06347748637199402\n",
      "Batch：10585 | Loss: 0.07214854657649994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：10586 | Loss: 0.07852095365524292\n",
      "Batch：10587 | Loss: 0.07565216720104218\n",
      "Batch：10588 | Loss: 0.07556270062923431\n",
      "Batch：10589 | Loss: 0.07133530080318451\n",
      "Batch：10590 | Loss: 0.06039801985025406\n",
      "Batch：10591 | Loss: 0.07303931564092636\n",
      "Batch：10592 | Loss: 0.07268279045820236\n",
      "Batch：10593 | Loss: 0.07132960855960846\n",
      "Batch：10594 | Loss: 0.07435984909534454\n",
      "Batch：10595 | Loss: 0.06474416702985764\n",
      "Batch：10596 | Loss: 0.0652938112616539\n",
      "Batch：10597 | Loss: 0.07153638452291489\n",
      "Batch：10598 | Loss: 0.06500527262687683\n",
      "Batch：10599 | Loss: 0.05824863538146019\n",
      "Batch：10600 | Loss: 0.07290676981210709\n",
      "Batch：10601 | Loss: 0.07542461901903152\n",
      "Batch：10602 | Loss: 0.06563877314329147\n",
      "Batch：10603 | Loss: 0.06654562056064606\n",
      "Batch：10604 | Loss: 0.06935355067253113\n",
      "Batch：10605 | Loss: 0.07989440113306046\n",
      "Batch：10606 | Loss: 0.08350921422243118\n",
      "Batch：10607 | Loss: 0.0675826445221901\n",
      "Batch：10608 | Loss: 0.077241450548172\n",
      "Batch：10609 | Loss: 0.06650269031524658\n",
      "Batch：10610 | Loss: 0.07732383161783218\n",
      "Batch：10611 | Loss: 0.0652875080704689\n",
      "Batch：10612 | Loss: 0.07665152102708817\n",
      "Batch：10613 | Loss: 0.06401284039020538\n",
      "Batch：10614 | Loss: 0.07670082151889801\n",
      "Batch：10615 | Loss: 0.070762999355793\n",
      "Batch：10616 | Loss: 0.07298040390014648\n",
      "Batch：10617 | Loss: 0.06845670938491821\n",
      "Batch：10618 | Loss: 0.0729697197675705\n",
      "Batch：10619 | Loss: 0.07348864525556564\n",
      "Batch：10620 | Loss: 0.07428184896707535\n",
      "Batch：10621 | Loss: 0.06600678712129593\n",
      "Batch：10622 | Loss: 0.07361956685781479\n",
      "Batch：10623 | Loss: 0.06882653385400772\n",
      "Batch：10624 | Loss: 0.06868133693933487\n",
      "Batch：10625 | Loss: 0.06299089640378952\n",
      "Batch：10626 | Loss: 0.0733506977558136\n",
      "Batch：10627 | Loss: 0.06744616478681564\n",
      "Batch：10628 | Loss: 0.07300712913274765\n",
      "Batch：10629 | Loss: 0.07203546166419983\n",
      "Batch：10630 | Loss: 0.072843998670578\n",
      "Batch：10631 | Loss: 0.06209966912865639\n",
      "Batch：10632 | Loss: 0.07325547933578491\n",
      "Batch：10633 | Loss: 0.0665971115231514\n",
      "Batch：10634 | Loss: 0.0639113187789917\n",
      "Batch：10635 | Loss: 0.07709227502346039\n",
      "Batch：10636 | Loss: 0.07034067064523697\n",
      "Batch：10637 | Loss: 0.054436877369880676\n",
      "Batch：10638 | Loss: 0.06319883465766907\n",
      "Batch：10639 | Loss: 0.07177089154720306\n",
      "Batch：10640 | Loss: 0.07329913228750229\n",
      "Batch：10641 | Loss: 0.0657258927822113\n",
      "Batch：10642 | Loss: 0.07031656801700592\n",
      "Batch：10643 | Loss: 0.06263796985149384\n",
      "Batch：10644 | Loss: 0.07377132028341293\n",
      "Batch：10645 | Loss: 0.07434942573308945\n",
      "Batch：10646 | Loss: 0.0685291588306427\n",
      "Batch：10647 | Loss: 0.07396134734153748\n",
      "Batch：10648 | Loss: 0.0807919129729271\n",
      "Batch：10649 | Loss: 0.08166100084781647\n",
      "Batch：10650 | Loss: 0.055307433009147644\n",
      "Batch：10651 | Loss: 0.06188121438026428\n",
      "Batch：10652 | Loss: 0.07588718086481094\n",
      "Batch：10653 | Loss: 0.06633658707141876\n",
      "Batch：10654 | Loss: 0.07767117023468018\n",
      "Batch：10655 | Loss: 0.0685064047574997\n",
      "Batch：10656 | Loss: 0.05975502356886864\n",
      "Batch：10657 | Loss: 0.07107759267091751\n",
      "Batch：10658 | Loss: 0.06886718422174454\n",
      "Batch：10659 | Loss: 0.06592930853366852\n",
      "Batch：10660 | Loss: 0.06639109551906586\n",
      "Batch：10661 | Loss: 0.07451418042182922\n",
      "Batch：10662 | Loss: 0.06389424949884415\n",
      "Batch：10663 | Loss: 0.06923282891511917\n",
      "Batch：10664 | Loss: 0.0655454471707344\n",
      "Batch：10665 | Loss: 0.06929806619882584\n",
      "Batch：10666 | Loss: 0.06718814373016357\n",
      "Batch：10667 | Loss: 0.07047447562217712\n",
      "Batch：10668 | Loss: 0.07164059579372406\n",
      "Batch：10669 | Loss: 0.06763122975826263\n",
      "Batch：10670 | Loss: 0.08113361150026321\n",
      "Batch：10671 | Loss: 0.08475092798471451\n",
      "Batch：10672 | Loss: 0.072088822722435\n",
      "Batch：10673 | Loss: 0.06191745027899742\n",
      "Batch：10674 | Loss: 0.06436312943696976\n",
      "Batch：10675 | Loss: 0.06532110273838043\n",
      "Batch：10676 | Loss: 0.08390824496746063\n",
      "Batch：10677 | Loss: 0.06273367255926132\n",
      "Batch：10678 | Loss: 0.07530783116817474\n",
      "Batch：10679 | Loss: 0.08095608651638031\n",
      "Batch：10680 | Loss: 0.06317106634378433\n",
      "Batch：10681 | Loss: 0.07206545025110245\n",
      "Batch：10682 | Loss: 0.07088112086057663\n",
      "Batch：10683 | Loss: 0.07741621881723404\n",
      "Batch：10684 | Loss: 0.06487537920475006\n",
      "Batch：10685 | Loss: 0.06891355663537979\n",
      "Batch：10686 | Loss: 0.06965222209692001\n",
      "Batch：10687 | Loss: 0.07712463289499283\n",
      "Batch：10688 | Loss: 0.06660239398479462\n",
      "Batch：10689 | Loss: 0.06000206619501114\n",
      "Batch：10690 | Loss: 0.07380518317222595\n",
      "Batch：10691 | Loss: 0.07360848039388657\n",
      "Batch：10692 | Loss: 0.06492451578378677\n",
      "Batch：10693 | Loss: 0.0611884742975235\n",
      "Batch：10694 | Loss: 0.06563376635313034\n",
      "Batch：10695 | Loss: 0.06829850375652313\n",
      "Batch：10696 | Loss: 0.06410181522369385\n",
      "Batch：10697 | Loss: 0.06118537485599518\n",
      "Batch：10698 | Loss: 0.079600989818573\n",
      "Batch：10699 | Loss: 0.07129117101430893\n",
      "Batch：10700 | Loss: 0.06604570150375366\n",
      "Batch：10701 | Loss: 0.06434104591608047\n",
      "Batch：10702 | Loss: 0.06295835971832275\n",
      "Batch：10703 | Loss: 0.06682655215263367\n",
      "Batch：10704 | Loss: 0.05738251283764839\n",
      "Batch：10705 | Loss: 0.06791538745164871\n",
      "Batch：10706 | Loss: 0.0695653036236763\n",
      "Batch：10707 | Loss: 0.06981020420789719\n",
      "Batch：10708 | Loss: 0.0663432702422142\n",
      "Batch：10709 | Loss: 0.07401138544082642\n",
      "Batch：10710 | Loss: 0.06877700984477997\n",
      "Batch：10711 | Loss: 0.07132968306541443\n",
      "Batch：10712 | Loss: 0.07743775844573975\n",
      "Batch：10713 | Loss: 0.07037722319364548\n",
      "Batch：10714 | Loss: 0.07181714475154877\n",
      "Batch：10715 | Loss: 0.06888540834188461\n",
      "Batch：10716 | Loss: 0.07401729375123978\n",
      "Batch：10717 | Loss: 0.07083289325237274\n",
      "Batch：10718 | Loss: 0.07220599800348282\n",
      "Batch：10719 | Loss: 0.06885737925767899\n",
      "Batch：10720 | Loss: 0.07543985545635223\n",
      "Batch：10721 | Loss: 0.07302360981702805\n",
      "Batch：10722 | Loss: 0.07327066361904144\n",
      "Batch：10723 | Loss: 0.07056263834238052\n",
      "Batch：10724 | Loss: 0.06487586349248886\n",
      "Batch：10725 | Loss: 0.06798406690359116\n",
      "Batch：10726 | Loss: 0.0748140886425972\n",
      "Batch：10727 | Loss: 0.061199430376291275\n",
      "Batch：10728 | Loss: 0.07480037212371826\n",
      "Batch：10729 | Loss: 0.06497533619403839\n",
      "Batch：10730 | Loss: 0.06715327501296997\n",
      "Batch：10731 | Loss: 0.06008869782090187\n",
      "Batch：10732 | Loss: 0.07268994301557541\n",
      "Batch：10733 | Loss: 0.07155356556177139\n",
      "Batch：10734 | Loss: 0.059270039200782776\n",
      "Batch：10735 | Loss: 0.07444669306278229\n",
      "Batch：10736 | Loss: 0.06553120166063309\n",
      "Batch：10737 | Loss: 0.07430904358625412\n",
      "Batch：10738 | Loss: 0.06864257901906967\n",
      "Batch：10739 | Loss: 0.06975582987070084\n",
      "Batch：10740 | Loss: 0.06958801299333572\n",
      "Batch：10741 | Loss: 0.06495346873998642\n",
      "Batch：10742 | Loss: 0.07596506923437119\n",
      "Batch：10743 | Loss: 0.06512708216905594\n",
      "Batch：10744 | Loss: 0.06335408240556717\n",
      "Batch：10745 | Loss: 0.059160053730010986\n",
      "Batch：10746 | Loss: 0.06248001009225845\n",
      "Batch：10747 | Loss: 0.06459327787160873\n",
      "Batch：10748 | Loss: 0.062497206032276154\n",
      "Batch：10749 | Loss: 0.05738025903701782\n",
      "Batch：10750 | Loss: 0.07119538635015488\n",
      "Batch：10751 | Loss: 0.06980752944946289\n",
      "Batch：10752 | Loss: 0.06717707961797714\n",
      "Batch：10753 | Loss: 0.051276762038469315\n",
      "Batch：10754 | Loss: 0.07977742701768875\n",
      "Batch：10755 | Loss: 0.0677490159869194\n",
      "Batch：10756 | Loss: 0.06092952936887741\n",
      "Batch：10757 | Loss: 0.0630461722612381\n",
      "Batch：10758 | Loss: 0.06475840508937836\n",
      "Batch：10759 | Loss: 0.07098852097988129\n",
      "Batch：10760 | Loss: 0.06476231664419174\n",
      "Batch：10761 | Loss: 0.07213211059570312\n",
      "Batch：10762 | Loss: 0.0656333789229393\n",
      "Batch：10763 | Loss: 0.0678362250328064\n",
      "Batch：10764 | Loss: 0.07692776620388031\n",
      "Batch：10765 | Loss: 0.06562509387731552\n",
      "Batch：10766 | Loss: 0.060028914362192154\n",
      "Batch：10767 | Loss: 0.06981174647808075\n",
      "Batch：10768 | Loss: 0.07725122570991516\n",
      "Batch：10769 | Loss: 0.06435786187648773\n",
      "Batch：10770 | Loss: 0.07454315572977066\n",
      "Batch：10771 | Loss: 0.08220229297876358\n",
      "Batch：10772 | Loss: 0.055254578590393066\n",
      "Batch：10773 | Loss: 0.0655762329697609\n",
      "Batch：10774 | Loss: 0.06898102909326553\n",
      "Batch：10775 | Loss: 0.06834147870540619\n",
      "Batch：10776 | Loss: 0.06635336577892303\n",
      "Batch：10777 | Loss: 0.06614977866411209\n",
      "Batch：10778 | Loss: 0.07952151447534561\n",
      "Batch：10779 | Loss: 0.061949193477630615\n",
      "Batch：10780 | Loss: 0.07135029882192612\n",
      "Batch：10781 | Loss: 0.07328635454177856\n",
      "Batch：10782 | Loss: 0.08069998025894165\n",
      "Batch：10783 | Loss: 0.06789267063140869\n",
      "Batch：10784 | Loss: 0.07884582132101059\n",
      "Batch：10785 | Loss: 0.06367983669042587\n",
      "Batch：10786 | Loss: 0.06739217042922974\n",
      "Batch：10787 | Loss: 0.06346455961465836\n",
      "Batch：10788 | Loss: 0.07529531419277191\n",
      "Batch：10789 | Loss: 0.06525789201259613\n",
      "Batch：10790 | Loss: 0.06263945996761322\n",
      "Batch：10791 | Loss: 0.073092021048069\n",
      "Batch：10792 | Loss: 0.0650511160492897\n",
      "Batch：10793 | Loss: 0.06718729436397552\n",
      "Batch：10794 | Loss: 0.07358327507972717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：10795 | Loss: 0.07072851061820984\n",
      "Batch：10796 | Loss: 0.057466477155685425\n",
      "Batch：10797 | Loss: 0.06316979974508286\n",
      "Batch：10798 | Loss: 0.0694461539387703\n",
      "Batch：10799 | Loss: 0.0775371789932251\n",
      "Batch：10800 | Loss: 0.07218258082866669\n",
      "Batch：10801 | Loss: 0.06879207491874695\n",
      "Batch：10802 | Loss: 0.07160740345716476\n",
      "Batch：10803 | Loss: 0.05980115011334419\n",
      "Batch：10804 | Loss: 0.07054144889116287\n",
      "Batch：10805 | Loss: 0.06498389691114426\n",
      "Batch：10806 | Loss: 0.06648784130811691\n",
      "Batch：10807 | Loss: 0.07019784301519394\n",
      "Batch：10808 | Loss: 0.06309641152620316\n",
      "Batch：10809 | Loss: 0.08366329222917557\n",
      "Batch：10810 | Loss: 0.06588750332593918\n",
      "Batch：10811 | Loss: 0.06818481534719467\n",
      "Batch：10812 | Loss: 0.06956960260868073\n",
      "Batch：10813 | Loss: 0.06734921038150787\n",
      "Batch：10814 | Loss: 0.08181077241897583\n",
      "Batch：10815 | Loss: 0.06329511106014252\n",
      "Batch：10816 | Loss: 0.06298917531967163\n",
      "Batch：10817 | Loss: 0.05878674238920212\n",
      "Batch：10818 | Loss: 0.0637754499912262\n",
      "Batch：10819 | Loss: 0.06960821896791458\n",
      "Batch：10820 | Loss: 0.06871774792671204\n",
      "Batch：10821 | Loss: 0.07262474298477173\n",
      "Batch：10822 | Loss: 0.07224615663290024\n",
      "Batch：10823 | Loss: 0.058471791446208954\n",
      "Batch：10824 | Loss: 0.07167144864797592\n",
      "Batch：10825 | Loss: 0.06765385717153549\n",
      "Batch：10826 | Loss: 0.08586999773979187\n",
      "Batch：10827 | Loss: 0.06755072623491287\n",
      "Batch：10828 | Loss: 0.06576557457447052\n",
      "Batch：10829 | Loss: 0.06499617546796799\n",
      "Batch：10830 | Loss: 0.05562140792608261\n",
      "Batch：10831 | Loss: 0.06765558570623398\n",
      "Batch：10832 | Loss: 0.058228809386491776\n",
      "Batch：10833 | Loss: 0.08262785524129868\n",
      "Batch：10834 | Loss: 0.07160978764295578\n",
      "Batch：10835 | Loss: 0.06434124708175659\n",
      "Batch：10836 | Loss: 0.06294384598731995\n",
      "Batch：10837 | Loss: 0.06773886829614639\n",
      "Batch：10838 | Loss: 0.06292470544576645\n",
      "Batch：10839 | Loss: 0.06916847825050354\n",
      "Batch：10840 | Loss: 0.0577487088739872\n",
      "Batch：10841 | Loss: 0.06447070091962814\n",
      "Batch：10842 | Loss: 0.055782195180654526\n",
      "Batch：10843 | Loss: 0.06709718704223633\n",
      "Batch：10844 | Loss: 0.06648610532283783\n",
      "Batch：10845 | Loss: 0.07187271863222122\n",
      "Batch：10846 | Loss: 0.06727642565965652\n",
      "Batch：10847 | Loss: 0.062015898525714874\n",
      "Batch：10848 | Loss: 0.07712901383638382\n",
      "Batch：10849 | Loss: 0.07118528336286545\n",
      "Batch：10850 | Loss: 0.06864704191684723\n",
      "Batch：10851 | Loss: 0.0728231742978096\n",
      "Batch：10852 | Loss: 0.05606652423739433\n",
      "Batch：10853 | Loss: 0.0701415166258812\n",
      "Batch：10854 | Loss: 0.059143178164958954\n",
      "Batch：10855 | Loss: 0.06842071563005447\n",
      "Batch：10856 | Loss: 0.07204484194517136\n",
      "Batch：10857 | Loss: 0.061669789254665375\n",
      "Batch：10858 | Loss: 0.06735413521528244\n",
      "Batch：10859 | Loss: 0.05633018910884857\n",
      "Batch：10860 | Loss: 0.07201036065816879\n",
      "Batch：10861 | Loss: 0.06882667541503906\n",
      "Batch：10862 | Loss: 0.08310584723949432\n",
      "Batch：10863 | Loss: 0.07433470338582993\n",
      "Batch：10864 | Loss: 0.06365516036748886\n",
      "Batch：10865 | Loss: 0.05980297923088074\n",
      "Batch：10866 | Loss: 0.07755366712808609\n",
      "Batch：10867 | Loss: 0.05429583042860031\n",
      "Batch：10868 | Loss: 0.07186231762170792\n",
      "Batch：10869 | Loss: 0.06558583676815033\n",
      "Batch：10870 | Loss: 0.06837718933820724\n",
      "Batch：10871 | Loss: 0.06727726757526398\n",
      "Batch：10872 | Loss: 0.06478383392095566\n",
      "Batch：10873 | Loss: 0.07856862246990204\n",
      "Batch：10874 | Loss: 0.07410234957933426\n",
      "Batch：10875 | Loss: 0.06298828125\n",
      "Batch：10876 | Loss: 0.08089566230773926\n",
      "Batch：10877 | Loss: 0.06361284106969833\n",
      "Batch：10878 | Loss: 0.06097548454999924\n",
      "Batch：10879 | Loss: 0.06929570436477661\n",
      "Batch：10880 | Loss: 0.08535248786211014\n",
      "Batch：10881 | Loss: 0.07522426545619965\n",
      "Batch：10882 | Loss: 0.06735922396183014\n",
      "Batch：10883 | Loss: 0.06545788794755936\n",
      "Batch：10884 | Loss: 0.056627050042152405\n",
      "Batch：10885 | Loss: 0.06689801067113876\n",
      "Batch：10886 | Loss: 0.0656011700630188\n",
      "Batch：10887 | Loss: 0.06569995731115341\n",
      "Batch：10888 | Loss: 0.08269284665584564\n",
      "Batch：10889 | Loss: 0.07088503986597061\n",
      "Batch：10890 | Loss: 0.06664387881755829\n",
      "Batch：10891 | Loss: 0.07479068636894226\n",
      "Batch：10892 | Loss: 0.07050198316574097\n",
      "Batch：10893 | Loss: 0.06358914822340012\n",
      "Batch：10894 | Loss: 0.06093676760792732\n",
      "Batch：10895 | Loss: 0.06285450607538223\n",
      "Batch：10896 | Loss: 0.06263644248247147\n",
      "Batch：10897 | Loss: 0.06840028613805771\n",
      "Batch：10898 | Loss: 0.07131065428256989\n",
      "Batch：10899 | Loss: 0.06717000901699066\n",
      "Batch：10900 | Loss: 0.06491129845380783\n",
      "Batch：10901 | Loss: 0.06053517758846283\n",
      "Batch：10902 | Loss: 0.06578141450881958\n",
      "Batch：10903 | Loss: 0.06184924766421318\n",
      "Batch：10904 | Loss: 0.06084775552153587\n",
      "Batch：10905 | Loss: 0.07365009188652039\n",
      "Batch：10906 | Loss: 0.06917592138051987\n",
      "Batch：10907 | Loss: 0.06733718514442444\n",
      "Batch：10908 | Loss: 0.0632680356502533\n",
      "Batch：10909 | Loss: 0.07095787674188614\n",
      "Batch：10910 | Loss: 0.06964235007762909\n",
      "Batch：10911 | Loss: 0.06929226219654083\n",
      "Batch：10912 | Loss: 0.07306326925754547\n",
      "Batch：10913 | Loss: 0.06841777265071869\n",
      "Batch：10914 | Loss: 0.07041934877634048\n",
      "Batch：10915 | Loss: 0.06553219258785248\n",
      "Batch：10916 | Loss: 0.06892675906419754\n",
      "Batch：10917 | Loss: 0.07372956722974777\n",
      "Batch：10918 | Loss: 0.0644737258553505\n",
      "Batch：10919 | Loss: 0.05987932160496712\n",
      "Batch：10920 | Loss: 0.08245868980884552\n",
      "Batch：10921 | Loss: 0.07193204015493393\n",
      "Batch：10922 | Loss: 0.06624185293912888\n",
      "Batch：10923 | Loss: 0.05950063467025757\n",
      "Batch：10924 | Loss: 0.06522145867347717\n",
      "Batch：10925 | Loss: 0.06635595113039017\n",
      "Batch：10926 | Loss: 0.07493256032466888\n",
      "Batch：10927 | Loss: 0.05835320055484772\n",
      "Batch：10928 | Loss: 0.06940007209777832\n",
      "Batch：10929 | Loss: 0.060659829527139664\n",
      "Batch：10930 | Loss: 0.07440265268087387\n",
      "Batch：10931 | Loss: 0.06974927335977554\n",
      "Batch：10932 | Loss: 0.06458906084299088\n",
      "Batch：10933 | Loss: 0.0634661614894867\n",
      "Batch：10934 | Loss: 0.05378866568207741\n",
      "Batch：10935 | Loss: 0.07280569523572922\n",
      "Batch：10936 | Loss: 0.06679759919643402\n",
      "Batch：10937 | Loss: 0.06504234671592712\n",
      "Batch：10938 | Loss: 0.06439970433712006\n",
      "Batch：10939 | Loss: 0.07527849078178406\n",
      "Batch：10940 | Loss: 0.06116217002272606\n",
      "Batch：10941 | Loss: 0.05820754915475845\n",
      "Batch：10942 | Loss: 0.056516438722610474\n",
      "Batch：10943 | Loss: 0.057545267045497894\n",
      "Batch：10944 | Loss: 0.07237362116575241\n",
      "Batch：10945 | Loss: 0.07406685501337051\n",
      "Batch：10946 | Loss: 0.06274132430553436\n",
      "Batch：10947 | Loss: 0.06941614300012589\n",
      "Batch：10948 | Loss: 0.08104116469621658\n",
      "Batch：10949 | Loss: 0.06964536756277084\n",
      "Batch：10950 | Loss: 0.08535438776016235\n",
      "Batch：10951 | Loss: 0.06464643031358719\n",
      "Batch：10952 | Loss: 0.07098202407360077\n",
      "Batch：10953 | Loss: 0.06609233468770981\n",
      "Batch：10954 | Loss: 0.06467467546463013\n",
      "Batch：10955 | Loss: 0.05799682438373566\n",
      "Batch：10956 | Loss: 0.05908806622028351\n",
      "Batch：10957 | Loss: 0.06390898674726486\n",
      "Batch：10958 | Loss: 0.06554348766803741\n",
      "Batch：10959 | Loss: 0.08131884783506393\n",
      "Batch：10960 | Loss: 0.06093492731451988\n",
      "Batch：10961 | Loss: 0.0724681168794632\n",
      "Batch：10962 | Loss: 0.07783110439777374\n",
      "Batch：10963 | Loss: 0.059660833328962326\n",
      "Batch：10964 | Loss: 0.0713772401213646\n",
      "Batch：10965 | Loss: 0.0629466101527214\n",
      "Batch：10966 | Loss: 0.07841123640537262\n",
      "Batch：10967 | Loss: 0.059788063168525696\n",
      "Batch：10968 | Loss: 0.06608447432518005\n",
      "Batch：10969 | Loss: 0.06362275779247284\n",
      "Batch：10970 | Loss: 0.06642667204141617\n",
      "Batch：10971 | Loss: 0.05799756944179535\n",
      "Batch：10972 | Loss: 0.0751941129565239\n",
      "Batch：10973 | Loss: 0.06231206655502319\n",
      "Batch：10974 | Loss: 0.057277750223875046\n",
      "Batch：10975 | Loss: 0.05525761842727661\n",
      "Batch：10976 | Loss: 0.07251977920532227\n",
      "Batch：10977 | Loss: 0.058974552899599075\n",
      "Batch：10978 | Loss: 0.07642862945795059\n",
      "Batch：10979 | Loss: 0.06854657083749771\n",
      "Batch：10980 | Loss: 0.06341460347175598\n",
      "Batch：10981 | Loss: 0.06458689272403717\n",
      "Batch：10982 | Loss: 0.07317230850458145\n",
      "Batch：10983 | Loss: 0.07221175730228424\n",
      "Batch：10984 | Loss: 0.07864760607481003\n",
      "Batch：10985 | Loss: 0.06992127746343613\n",
      "Batch：10986 | Loss: 0.06419224292039871\n",
      "Batch：10987 | Loss: 0.06107734143733978\n",
      "Batch：10988 | Loss: 0.06156034395098686\n",
      "Batch：10989 | Loss: 0.08273056149482727\n",
      "Batch：10990 | Loss: 0.06845051795244217\n",
      "Batch：10991 | Loss: 0.0722435936331749\n",
      "Batch：10992 | Loss: 0.07240784913301468\n",
      "Batch：10993 | Loss: 0.06611970067024231\n",
      "Batch：10994 | Loss: 0.07035113126039505\n",
      "Batch：10995 | Loss: 0.06712643057107925\n",
      "Batch：10996 | Loss: 0.06676914542913437\n",
      "Batch：10997 | Loss: 0.06263162195682526\n",
      "Batch：10998 | Loss: 0.07431042194366455\n",
      "Batch：10999 | Loss: 0.06729426234960556\n",
      "Batch：11000 | Loss: 0.06587086617946625\n",
      "Batch：11001 | Loss: 0.07591589540243149\n",
      "Batch：11002 | Loss: 0.06266950070858002\n",
      "Batch：11003 | Loss: 0.05866057425737381\n",
      "Batch：11004 | Loss: 0.0731588751077652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：11005 | Loss: 0.06082425266504288\n",
      "Batch：11006 | Loss: 0.06664073467254639\n",
      "Batch：11007 | Loss: 0.061519403010606766\n",
      "Batch：11008 | Loss: 0.07558687031269073\n",
      "Batch：11009 | Loss: 0.07926151156425476\n",
      "Batch：11010 | Loss: 0.06635528802871704\n",
      "Batch：11011 | Loss: 0.06613849848508835\n",
      "Batch：11012 | Loss: 0.06836674362421036\n",
      "Batch：11013 | Loss: 0.056394774466753006\n",
      "Batch：11014 | Loss: 0.0652129277586937\n",
      "Batch：11015 | Loss: 0.07097762823104858\n",
      "Batch：11016 | Loss: 0.07522040605545044\n",
      "Batch：11017 | Loss: 0.07109557837247849\n",
      "Batch：11018 | Loss: 0.06720452010631561\n",
      "Batch：11019 | Loss: 0.07908591628074646\n",
      "Batch：11020 | Loss: 0.06525830179452896\n",
      "Batch：11021 | Loss: 0.06906954199075699\n",
      "Batch：11022 | Loss: 0.07271687686443329\n",
      "Batch：11023 | Loss: 0.06431323289871216\n",
      "Batch：11024 | Loss: 0.0644204169511795\n",
      "Batch：11025 | Loss: 0.07103193551301956\n",
      "Batch：11026 | Loss: 0.062054798007011414\n",
      "Batch：11027 | Loss: 0.0667491927742958\n",
      "Batch：11028 | Loss: 0.06784600764513016\n",
      "Batch：11029 | Loss: 0.06074373424053192\n",
      "Batch：11030 | Loss: 0.07642684131860733\n",
      "Batch：11031 | Loss: 0.07930350303649902\n",
      "Batch：11032 | Loss: 0.0789269432425499\n",
      "Batch：11033 | Loss: 0.05891966074705124\n",
      "Batch：11034 | Loss: 0.06717468053102493\n",
      "Batch：11035 | Loss: 0.06806115806102753\n",
      "Batch：11036 | Loss: 0.06428711861371994\n",
      "Batch：11037 | Loss: 0.0676417350769043\n",
      "Batch：11038 | Loss: 0.06383342295885086\n",
      "Batch：11039 | Loss: 0.07041743397712708\n",
      "Batch：11040 | Loss: 0.07127866894006729\n",
      "Batch：11041 | Loss: 0.08237650245428085\n",
      "Batch：11042 | Loss: 0.0653165876865387\n",
      "Batch：11043 | Loss: 0.06513496488332748\n",
      "Batch：11044 | Loss: 0.06913162022829056\n",
      "Batch：11045 | Loss: 0.0705426037311554\n",
      "Batch：11046 | Loss: 0.06339289993047714\n",
      "Batch：11047 | Loss: 0.06939742714166641\n",
      "Batch：11048 | Loss: 0.06314714252948761\n",
      "Batch：11049 | Loss: 0.07173797488212585\n",
      "Batch：11050 | Loss: 0.06037318706512451\n",
      "Batch：11051 | Loss: 0.057971298694610596\n",
      "Batch：11052 | Loss: 0.060831401497125626\n",
      "Batch：11053 | Loss: 0.06517188251018524\n",
      "Batch：11054 | Loss: 0.07185805588960648\n",
      "Batch：11055 | Loss: 0.05709788575768471\n",
      "Batch：11056 | Loss: 0.07203686237335205\n",
      "Batch：11057 | Loss: 0.06960169970989227\n",
      "Batch：11058 | Loss: 0.06382358074188232\n",
      "Batch：11059 | Loss: 0.07028014957904816\n",
      "Batch：11060 | Loss: 0.06648866087198257\n",
      "Batch：11061 | Loss: 0.0689527615904808\n",
      "Batch：11062 | Loss: 0.06777042895555496\n",
      "Batch：11063 | Loss: 0.06885910779237747\n",
      "Batch：11064 | Loss: 0.06291082501411438\n",
      "Batch：11065 | Loss: 0.06267455965280533\n",
      "Batch：11066 | Loss: 0.07453225553035736\n",
      "Batch：11067 | Loss: 0.06476053595542908\n",
      "Batch：11068 | Loss: 0.060618601739406586\n",
      "Batch：11069 | Loss: 0.07505575567483902\n",
      "Batch：11070 | Loss: 0.06190638616681099\n",
      "Batch：11071 | Loss: 0.06509009748697281\n",
      "Batch：11072 | Loss: 0.0769747868180275\n",
      "Batch：11073 | Loss: 0.07387479394674301\n",
      "Batch：11074 | Loss: 0.05742832273244858\n",
      "Batch：11075 | Loss: 0.06831846386194229\n",
      "Batch：11076 | Loss: 0.0644383653998375\n",
      "Batch：11077 | Loss: 0.07426755875349045\n",
      "Batch：11078 | Loss: 0.06895360350608826\n",
      "Batch：11079 | Loss: 0.06519094109535217\n",
      "Batch：11080 | Loss: 0.06739328801631927\n",
      "Batch：11081 | Loss: 0.06726144254207611\n",
      "Batch：11082 | Loss: 0.059529419988393784\n",
      "Batch：11083 | Loss: 0.07006105035543442\n",
      "Batch：11084 | Loss: 0.06870017200708389\n",
      "Batch：11085 | Loss: 0.06129225715994835\n",
      "Batch：11086 | Loss: 0.05694272741675377\n",
      "Batch：11087 | Loss: 0.06654789298772812\n",
      "Batch：11088 | Loss: 0.07166686654090881\n",
      "Batch：11089 | Loss: 0.06213521212339401\n",
      "Batch：11090 | Loss: 0.06744971871376038\n",
      "Batch：11091 | Loss: 0.0695105716586113\n",
      "Batch：11092 | Loss: 0.07512997090816498\n",
      "Batch：11093 | Loss: 0.06035463884472847\n",
      "Batch：11094 | Loss: 0.07029686123132706\n",
      "Batch：11095 | Loss: 0.0705837830901146\n",
      "Batch：11096 | Loss: 0.06116073578596115\n",
      "Batch：11097 | Loss: 0.07528726756572723\n",
      "Batch：11098 | Loss: 0.07123260200023651\n",
      "Batch：11099 | Loss: 0.07241034507751465\n",
      "Batch：11100 | Loss: 0.0621432401239872\n",
      "Batch：11101 | Loss: 0.07244755327701569\n",
      "Batch：11102 | Loss: 0.06214480474591255\n",
      "Batch：11103 | Loss: 0.05876172333955765\n",
      "Batch：11104 | Loss: 0.06941638141870499\n",
      "Batch：11105 | Loss: 0.06814689934253693\n",
      "Batch：11106 | Loss: 0.063860684633255\n",
      "Batch：11107 | Loss: 0.06414187699556351\n",
      "Batch：11108 | Loss: 0.058678608387708664\n",
      "Batch：11109 | Loss: 0.055145710706710815\n",
      "Batch：11110 | Loss: 0.05810653045773506\n",
      "Batch：11111 | Loss: 0.08141837269067764\n",
      "Batch：11112 | Loss: 0.055193979293107986\n",
      "Batch：11113 | Loss: 0.06860801577568054\n",
      "Batch：11114 | Loss: 0.06476716697216034\n",
      "Batch：11115 | Loss: 0.05677294358611107\n",
      "Batch：11116 | Loss: 0.07375796139240265\n",
      "Batch：11117 | Loss: 0.06986204534769058\n",
      "Batch：11118 | Loss: 0.06111319735646248\n",
      "Batch：11119 | Loss: 0.06146906316280365\n",
      "Batch：11120 | Loss: 0.06792104989290237\n",
      "Batch：11121 | Loss: 0.06391733884811401\n",
      "Batch：11122 | Loss: 0.07124180346727371\n",
      "Batch：11123 | Loss: 0.0602472685277462\n",
      "Batch：11124 | Loss: 0.06670812517404556\n",
      "Batch：11125 | Loss: 0.06236116588115692\n",
      "Batch：11126 | Loss: 0.0680675283074379\n",
      "Batch：11127 | Loss: 0.05734673887491226\n",
      "Batch：11128 | Loss: 0.06742250919342041\n",
      "Batch：11129 | Loss: 0.06371842324733734\n",
      "Batch：11130 | Loss: 0.05881290137767792\n",
      "Batch：11131 | Loss: 0.06643544882535934\n",
      "Batch：11132 | Loss: 0.07529153674840927\n",
      "Batch：11133 | Loss: 0.07392510771751404\n",
      "Batch：11134 | Loss: 0.05766250565648079\n",
      "Batch：11135 | Loss: 0.061299193650484085\n",
      "Batch：11136 | Loss: 0.07832188904285431\n",
      "Batch：11137 | Loss: 0.06872205436229706\n",
      "Batch：11138 | Loss: 0.06772726029157639\n",
      "Batch：11139 | Loss: 0.05698515847325325\n",
      "Batch：11140 | Loss: 0.06078653037548065\n",
      "Batch：11141 | Loss: 0.060719795525074005\n",
      "Batch：11142 | Loss: 0.06182858720421791\n",
      "Batch：11143 | Loss: 0.07649526745080948\n",
      "Batch：11144 | Loss: 0.07657799124717712\n",
      "Batch：11145 | Loss: 0.06789880245923996\n",
      "Batch：11146 | Loss: 0.05225873738527298\n",
      "Batch：11147 | Loss: 0.064434714615345\n",
      "Batch：11148 | Loss: 0.05815356224775314\n",
      "Batch：11149 | Loss: 0.06871400028467178\n",
      "Batch：11150 | Loss: 0.06780335307121277\n",
      "Batch：11151 | Loss: 0.05600418150424957\n",
      "Batch：11152 | Loss: 0.06224527582526207\n",
      "Batch：11153 | Loss: 0.0891244113445282\n",
      "Batch：11154 | Loss: 0.06957286596298218\n",
      "Batch：11155 | Loss: 0.06845328211784363\n",
      "Batch：11156 | Loss: 0.05954866483807564\n",
      "Batch：11157 | Loss: 0.06743660569190979\n",
      "Batch：11158 | Loss: 0.061259422451257706\n",
      "Batch：11159 | Loss: 0.06411784142255783\n",
      "Batch：11160 | Loss: 0.05449208989739418\n",
      "Batch：11161 | Loss: 0.07059444487094879\n",
      "Batch：11162 | Loss: 0.0594608299434185\n",
      "Batch：11163 | Loss: 0.07105275243520737\n",
      "Batch：11164 | Loss: 0.06399980932474136\n",
      "Batch：11165 | Loss: 0.05841589719057083\n",
      "Batch：11166 | Loss: 0.07844553887844086\n",
      "Batch：11167 | Loss: 0.05715925991535187\n",
      "Batch：11168 | Loss: 0.06517209857702255\n",
      "Batch：11169 | Loss: 0.06209101155400276\n",
      "Batch：11170 | Loss: 0.0625801607966423\n",
      "Batch：11171 | Loss: 0.07247189432382584\n",
      "Batch：11172 | Loss: 0.07254041731357574\n",
      "Batch：11173 | Loss: 0.06834691762924194\n",
      "Batch：11174 | Loss: 0.056144822388887405\n",
      "Batch：11175 | Loss: 0.060538582503795624\n",
      "Batch：11176 | Loss: 0.06594958156347275\n",
      "Batch：11177 | Loss: 0.06086718663573265\n",
      "Batch：11178 | Loss: 0.06847834587097168\n",
      "Batch：11179 | Loss: 0.07237159460783005\n",
      "Batch：11180 | Loss: 0.06718001514673233\n",
      "Batch：11181 | Loss: 0.05764514207839966\n",
      "Batch：11182 | Loss: 0.08213399350643158\n",
      "Batch：11183 | Loss: 0.07212898880243301\n",
      "Batch：11184 | Loss: 0.05326968431472778\n",
      "Batch：11185 | Loss: 0.059329017996788025\n",
      "Batch：11186 | Loss: 0.06577655673027039\n",
      "Batch：11187 | Loss: 0.07010107487440109\n",
      "Batch：11188 | Loss: 0.07443248480558395\n",
      "Batch：11189 | Loss: 0.06752108037471771\n",
      "Batch：11190 | Loss: 0.06431759893894196\n",
      "Batch：11191 | Loss: 0.06007188931107521\n",
      "Batch：11192 | Loss: 0.06400257349014282\n",
      "Batch：11193 | Loss: 0.07040376961231232\n",
      "Batch：11194 | Loss: 0.0701129138469696\n",
      "Batch：11195 | Loss: 0.06879198551177979\n",
      "Batch：11196 | Loss: 0.06647954136133194\n",
      "Batch：11197 | Loss: 0.06639503687620163\n",
      "Batch：11198 | Loss: 0.06911419332027435\n",
      "Batch：11199 | Loss: 0.06357278674840927\n",
      "Batch：11200 | Loss: 0.07507506012916565\n",
      "Batch：11201 | Loss: 0.06122083589434624\n",
      "Batch：11202 | Loss: 0.06619875133037567\n",
      "Batch：11203 | Loss: 0.07197300344705582\n",
      "Batch：11204 | Loss: 0.06346587091684341\n",
      "Batch：11205 | Loss: 0.06357265263795853\n",
      "Batch：11206 | Loss: 0.056251514703035355\n",
      "Batch：11207 | Loss: 0.0733092874288559\n",
      "Batch：11208 | Loss: 0.06965740025043488\n",
      "Batch：11209 | Loss: 0.0708250030875206\n",
      "Batch：11210 | Loss: 0.06775183230638504\n",
      "Batch：11211 | Loss: 0.06476359814405441\n",
      "Batch：11212 | Loss: 0.0687471479177475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：11213 | Loss: 0.06619590520858765\n",
      "Batch：11214 | Loss: 0.06294852495193481\n",
      "Batch：11215 | Loss: 0.06690868735313416\n",
      "Batch：11216 | Loss: 0.06512042135000229\n",
      "Batch：11217 | Loss: 0.062971331179142\n",
      "Batch：11218 | Loss: 0.06715834140777588\n",
      "Batch：11219 | Loss: 0.06519052386283875\n",
      "Batch：11220 | Loss: 0.07359589636325836\n",
      "Batch：11221 | Loss: 0.06847640126943588\n",
      "Batch：11222 | Loss: 0.0536990761756897\n",
      "Batch：11223 | Loss: 0.06917931139469147\n",
      "Batch：11224 | Loss: 0.06539101898670197\n",
      "Batch：11225 | Loss: 0.05983772873878479\n",
      "Batch：11226 | Loss: 0.06062397360801697\n",
      "Batch：11227 | Loss: 0.06955914944410324\n",
      "Batch：11228 | Loss: 0.07220537960529327\n",
      "Batch：11229 | Loss: 0.06286884844303131\n",
      "Batch：11230 | Loss: 0.05967606604099274\n",
      "Batch：11231 | Loss: 0.06386468559503555\n",
      "Batch：11232 | Loss: 0.07257737219333649\n",
      "Batch：11233 | Loss: 0.0827278271317482\n",
      "Batch：11234 | Loss: 0.06978879868984222\n",
      "Batch：11235 | Loss: 0.07241258025169373\n",
      "Batch：11236 | Loss: 0.06975127756595612\n",
      "Batch：11237 | Loss: 0.06618206948041916\n",
      "Batch：11238 | Loss: 0.07131356745958328\n",
      "Batch：11239 | Loss: 0.054865382611751556\n",
      "Batch：11240 | Loss: 0.07143016159534454\n",
      "Batch：11241 | Loss: 0.07714471220970154\n",
      "Batch：11242 | Loss: 0.06483153253793716\n",
      "Batch：11243 | Loss: 0.06337929517030716\n",
      "Batch：11244 | Loss: 0.0617973692715168\n",
      "Batch：11245 | Loss: 0.06399179250001907\n",
      "Batch：11246 | Loss: 0.074974425137043\n",
      "Batch：11247 | Loss: 0.0737447515130043\n",
      "Batch：11248 | Loss: 0.06603503227233887\n",
      "Batch：11249 | Loss: 0.06715469062328339\n",
      "Batch：11250 | Loss: 0.06473822146654129\n",
      "Batch：11251 | Loss: 0.05487801507115364\n",
      "Batch：11252 | Loss: 0.06866423040628433\n",
      "Batch：11253 | Loss: 0.06494549661874771\n",
      "Batch：11254 | Loss: 0.0696767270565033\n",
      "Batch：11255 | Loss: 0.08304539322853088\n",
      "Batch：11256 | Loss: 0.06826577335596085\n",
      "Batch：11257 | Loss: 0.060349393635988235\n",
      "Batch：11258 | Loss: 0.07501032203435898\n",
      "Batch：11259 | Loss: 0.06662707775831223\n",
      "Batch：11260 | Loss: 0.06264688819646835\n",
      "Batch：11261 | Loss: 0.0664495974779129\n",
      "Batch：11262 | Loss: 0.07158651947975159\n",
      "Batch：11263 | Loss: 0.074394591152668\n",
      "Batch：11264 | Loss: 0.07393520325422287\n",
      "Batch：11265 | Loss: 0.07445976138114929\n",
      "Batch：11266 | Loss: 0.07153298705816269\n",
      "Batch：11267 | Loss: 0.07224779576063156\n",
      "Batch：11268 | Loss: 0.06347852200269699\n",
      "Batch：11269 | Loss: 0.06732586771249771\n",
      "Batch：11270 | Loss: 0.07541782408952713\n",
      "Batch：11271 | Loss: 0.059229373931884766\n",
      "Batch：11272 | Loss: 0.05496738478541374\n",
      "Batch：11273 | Loss: 0.06832083314657211\n",
      "Batch：11274 | Loss: 0.06346257776021957\n",
      "Batch：11275 | Loss: 0.06684152036905289\n",
      "Batch：11276 | Loss: 0.06920047104358673\n",
      "Batch：11277 | Loss: 0.0551258847117424\n",
      "Batch：11278 | Loss: 0.05696660280227661\n",
      "Batch：11279 | Loss: 0.06728895753622055\n",
      "Batch：11280 | Loss: 0.05777563527226448\n",
      "Batch：11281 | Loss: 0.07455549389123917\n",
      "Batch：11282 | Loss: 0.06178418919444084\n",
      "Batch：11283 | Loss: 0.0651850774884224\n",
      "Batch：11284 | Loss: 0.06818326562643051\n",
      "Batch：11285 | Loss: 0.06458316743373871\n",
      "Batch：11286 | Loss: 0.07202266901731491\n",
      "Batch：11287 | Loss: 0.06676611304283142\n",
      "Batch：11288 | Loss: 0.06391489505767822\n",
      "Batch：11289 | Loss: 0.06545912474393845\n",
      "Batch：11290 | Loss: 0.07387187331914902\n",
      "Batch：11291 | Loss: 0.06907594949007034\n",
      "Batch：11292 | Loss: 0.06213165074586868\n",
      "Batch：11293 | Loss: 0.05852639675140381\n",
      "Batch：11294 | Loss: 0.06884179264307022\n",
      "Batch：11295 | Loss: 0.05727001279592514\n",
      "Batch：11296 | Loss: 0.07351011037826538\n",
      "Batch：11297 | Loss: 0.05674373358488083\n",
      "Batch：11298 | Loss: 0.06655660271644592\n",
      "Batch：11299 | Loss: 0.06957624107599258\n",
      "Batch：11300 | Loss: 0.057702403515577316\n",
      "Batch：11301 | Loss: 0.064165860414505\n",
      "Batch：11302 | Loss: 0.06744314730167389\n",
      "Batch：11303 | Loss: 0.06524716317653656\n",
      "Batch：11304 | Loss: 0.07680337131023407\n",
      "Batch：11305 | Loss: 0.06631576269865036\n",
      "Batch：11306 | Loss: 0.07236593216657639\n",
      "Batch：11307 | Loss: 0.060357920825481415\n",
      "Batch：11308 | Loss: 0.06971167027950287\n",
      "Batch：11309 | Loss: 0.06195515766739845\n",
      "Batch：11310 | Loss: 0.07942500710487366\n",
      "Batch：11311 | Loss: 0.07389487326145172\n",
      "Batch：11312 | Loss: 0.050560351461172104\n",
      "Batch：11313 | Loss: 0.08009475469589233\n",
      "Batch：11314 | Loss: 0.073581263422966\n",
      "Batch：11315 | Loss: 0.06858710944652557\n",
      "Batch：11316 | Loss: 0.06856903433799744\n",
      "Batch：11317 | Loss: 0.0725364089012146\n",
      "Batch：11318 | Loss: 0.058496683835983276\n",
      "Batch：11319 | Loss: 0.06766818463802338\n",
      "Batch：11320 | Loss: 0.06567493081092834\n",
      "Batch：11321 | Loss: 0.07039395719766617\n",
      "Batch：11322 | Loss: 0.06427646428346634\n",
      "Batch：11323 | Loss: 0.06474711745977402\n",
      "Batch：11324 | Loss: 0.07355652004480362\n",
      "Batch：11325 | Loss: 0.07980795204639435\n",
      "Batch：11326 | Loss: 0.056094612926244736\n",
      "Batch：11327 | Loss: 0.06437757611274719\n",
      "Batch：11328 | Loss: 0.06943237781524658\n",
      "Batch：11329 | Loss: 0.0721156895160675\n",
      "Batch：11330 | Loss: 0.07895300537347794\n",
      "Batch：11331 | Loss: 0.07065580785274506\n",
      "Batch：11332 | Loss: 0.06593490391969681\n",
      "Batch：11333 | Loss: 0.07356033474206924\n",
      "Batch：11334 | Loss: 0.0676841139793396\n",
      "Batch：11335 | Loss: 0.0693708136677742\n",
      "Batch：11336 | Loss: 0.05910979583859444\n",
      "Batch：11337 | Loss: 0.059238314628601074\n",
      "Batch：11338 | Loss: 0.0701366439461708\n",
      "Batch：11339 | Loss: 0.07279051840305328\n",
      "Batch：11340 | Loss: 0.06216861307621002\n",
      "Batch：11341 | Loss: 0.06881312280893326\n",
      "Batch：11342 | Loss: 0.07373698800802231\n",
      "Batch：11343 | Loss: 0.056929342448711395\n",
      "Batch：11344 | Loss: 0.0613296702504158\n",
      "Batch：11345 | Loss: 0.07322637736797333\n",
      "Batch：11346 | Loss: 0.0580129399895668\n",
      "Batch：11347 | Loss: 0.062215231359004974\n",
      "Batch：11348 | Loss: 0.059357091784477234\n",
      "Batch：11349 | Loss: 0.06651512533426285\n",
      "Batch：11350 | Loss: 0.07241086661815643\n",
      "Batch：11351 | Loss: 0.058198414742946625\n",
      "Batch：11352 | Loss: 0.05589616298675537\n",
      "Batch：11353 | Loss: 0.0702049732208252\n",
      "Batch：11354 | Loss: 0.06484092026948929\n",
      "Batch：11355 | Loss: 0.07643076777458191\n",
      "Batch：11356 | Loss: 0.06223156675696373\n",
      "Batch：11357 | Loss: 0.06066036969423294\n",
      "Batch：11358 | Loss: 0.06689377129077911\n",
      "Batch：11359 | Loss: 0.06540331244468689\n",
      "Batch：11360 | Loss: 0.05256109684705734\n",
      "Batch：11361 | Loss: 0.061075013130903244\n",
      "Batch：11362 | Loss: 0.06515498459339142\n",
      "Batch：11363 | Loss: 0.06566709280014038\n",
      "Batch：11364 | Loss: 0.06922075152397156\n",
      "Batch：11365 | Loss: 0.07533587515354156\n",
      "Batch：11366 | Loss: 0.06628605723381042\n",
      "Batch：11367 | Loss: 0.07518751174211502\n",
      "Batch：11368 | Loss: 0.07011336833238602\n",
      "Batch：11369 | Loss: 0.07519294321537018\n",
      "Batch：11370 | Loss: 0.06774573028087616\n",
      "Batch：11371 | Loss: 0.06753693521022797\n",
      "Batch：11372 | Loss: 0.06091263145208359\n",
      "Batch：11373 | Loss: 0.0671379417181015\n",
      "Batch：11374 | Loss: 0.07274352759122849\n",
      "Batch：11375 | Loss: 0.06881996244192123\n",
      "Batch：11376 | Loss: 0.0555284321308136\n",
      "Batch：11377 | Loss: 0.06949273496866226\n",
      "Batch：11378 | Loss: 0.05892947316169739\n",
      "Batch：11379 | Loss: 0.06564488261938095\n",
      "Batch：11380 | Loss: 0.07165969908237457\n",
      "Batch：11381 | Loss: 0.06277621537446976\n",
      "Batch：11382 | Loss: 0.064675472676754\n",
      "Batch：11383 | Loss: 0.06251247227191925\n",
      "Batch：11384 | Loss: 0.06486596912145615\n",
      "Batch：11385 | Loss: 0.07577440142631531\n",
      "Batch：11386 | Loss: 0.06757614761590958\n",
      "Batch：11387 | Loss: 0.06425058096647263\n",
      "Batch：11388 | Loss: 0.06262952834367752\n",
      "Batch：11389 | Loss: 0.06561611592769623\n",
      "Batch：11390 | Loss: 0.07079686969518661\n",
      "Batch：11391 | Loss: 0.06462649255990982\n",
      "Batch：11392 | Loss: 0.053743671625852585\n",
      "Batch：11393 | Loss: 0.06047879531979561\n",
      "Batch：11394 | Loss: 0.06356748193502426\n",
      "Batch：11395 | Loss: 0.070855051279068\n",
      "Batch：11396 | Loss: 0.07106976956129074\n",
      "Batch：11397 | Loss: 0.07363632321357727\n",
      "Batch：11398 | Loss: 0.06314769387245178\n",
      "Batch：11399 | Loss: 0.06577692180871964\n",
      "Batch：11400 | Loss: 0.06619682908058167\n",
      "Batch：11401 | Loss: 0.06095166876912117\n",
      "Batch：11402 | Loss: 0.05879760533571243\n",
      "Batch：11403 | Loss: 0.06658844649791718\n",
      "Batch：11404 | Loss: 0.06887655705213547\n",
      "Batch：11405 | Loss: 0.07503897696733475\n",
      "Batch：11406 | Loss: 0.06812264770269394\n",
      "Batch：11407 | Loss: 0.05681372061371803\n",
      "Batch：11408 | Loss: 0.06739576160907745\n",
      "Batch：11409 | Loss: 0.055650655180215836\n",
      "Batch：11410 | Loss: 0.06821552664041519\n",
      "Batch：11411 | Loss: 0.06349828094244003\n",
      "Batch：11412 | Loss: 0.059221602976322174\n",
      "Batch：11413 | Loss: 0.06125007942318916\n",
      "Batch：11414 | Loss: 0.06269688159227371\n",
      "Batch：11415 | Loss: 0.06875056773424149\n",
      "Batch：11416 | Loss: 0.06295503675937653\n",
      "Batch：11417 | Loss: 0.06608694046735764\n",
      "Batch：11418 | Loss: 0.06109640374779701\n",
      "Batch：11419 | Loss: 0.06539243459701538\n",
      "Batch：11420 | Loss: 0.06595052778720856\n",
      "Batch：11421 | Loss: 0.07025256007909775\n",
      "Batch：11422 | Loss: 0.06469141691923141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：11423 | Loss: 0.057697854936122894\n",
      "Batch：11424 | Loss: 0.06824924051761627\n",
      "Batch：11425 | Loss: 0.0612584613263607\n",
      "Batch：11426 | Loss: 0.0582425519824028\n",
      "Batch：11427 | Loss: 0.0719122588634491\n",
      "Batch：11428 | Loss: 0.07597637176513672\n",
      "Batch：11429 | Loss: 0.061123304069042206\n",
      "Batch：11430 | Loss: 0.0692496970295906\n",
      "Batch：11431 | Loss: 0.06940719485282898\n",
      "Batch：11432 | Loss: 0.06817199289798737\n",
      "Batch：11433 | Loss: 0.06528930366039276\n",
      "Batch：11434 | Loss: 0.07117760181427002\n",
      "Batch：11435 | Loss: 0.06162060424685478\n",
      "Batch：11436 | Loss: 0.06794186681509018\n",
      "Batch：11437 | Loss: 0.057586975395679474\n",
      "Batch：11438 | Loss: 0.06548750400543213\n",
      "Batch：11439 | Loss: 0.06565006077289581\n",
      "Batch：11440 | Loss: 0.06238933280110359\n",
      "Batch：11441 | Loss: 0.06334885954856873\n",
      "Batch：11442 | Loss: 0.0648433044552803\n",
      "Batch：11443 | Loss: 0.06125584989786148\n",
      "Batch：11444 | Loss: 0.07131331413984299\n",
      "Batch：11445 | Loss: 0.05973703786730766\n",
      "Batch：11446 | Loss: 0.07132130861282349\n",
      "Batch：11447 | Loss: 0.06577055901288986\n",
      "Batch：11448 | Loss: 0.06554913520812988\n",
      "Batch：11449 | Loss: 0.06678509712219238\n",
      "Batch：11450 | Loss: 0.06405322253704071\n",
      "Batch：11451 | Loss: 0.06477753818035126\n",
      "Batch：11452 | Loss: 0.04919959604740143\n",
      "Batch：11453 | Loss: 0.07221245020627975\n",
      "Batch：11454 | Loss: 0.06658326089382172\n",
      "Batch：11455 | Loss: 0.07672169804573059\n",
      "Batch：11456 | Loss: 0.06106563284993172\n",
      "Batch：11457 | Loss: 0.07304518669843674\n",
      "Batch：11458 | Loss: 0.07260680943727493\n",
      "Batch：11459 | Loss: 0.059534952044487\n",
      "Batch：11460 | Loss: 0.06414352357387543\n",
      "Batch：11461 | Loss: 0.06768589466810226\n",
      "Batch：11462 | Loss: 0.06739188730716705\n",
      "Batch：11463 | Loss: 0.07127999514341354\n",
      "Batch：11464 | Loss: 0.05088086053729057\n",
      "Batch：11465 | Loss: 0.07297474890947342\n",
      "Batch：11466 | Loss: 0.06973184645175934\n",
      "Batch：11467 | Loss: 0.06602270901203156\n",
      "Batch：11468 | Loss: 0.06811285763978958\n",
      "Batch：11469 | Loss: 0.07057369500398636\n",
      "Batch：11470 | Loss: 0.07068052142858505\n",
      "Batch：11471 | Loss: 0.08239716291427612\n",
      "Batch：11472 | Loss: 0.0659337267279625\n",
      "Batch：11473 | Loss: 0.0731208473443985\n",
      "Batch：11474 | Loss: 0.057988330721855164\n",
      "Batch：11475 | Loss: 0.05504828691482544\n",
      "Batch：11476 | Loss: 0.06843320280313492\n",
      "Batch：11477 | Loss: 0.06106003373861313\n",
      "Batch：11478 | Loss: 0.06801149994134903\n",
      "Batch：11479 | Loss: 0.07012105733156204\n",
      "Batch：11480 | Loss: 0.059747181832790375\n",
      "Batch：11481 | Loss: 0.05530857294797897\n",
      "Batch：11482 | Loss: 0.06245778873562813\n",
      "Batch：11483 | Loss: 0.07387639582157135\n",
      "Batch：11484 | Loss: 0.06395719945430756\n",
      "Batch：11485 | Loss: 0.06153763830661774\n",
      "Batch：11486 | Loss: 0.054747119545936584\n",
      "Batch：11487 | Loss: 0.07032404839992523\n",
      "Batch：11488 | Loss: 0.06278461962938309\n",
      "Batch：11489 | Loss: 0.06245686113834381\n",
      "Batch：11490 | Loss: 0.06762732565402985\n",
      "Batch：11491 | Loss: 0.0674319639801979\n",
      "Batch：11492 | Loss: 0.06415409594774246\n",
      "Batch：11493 | Loss: 0.05906597897410393\n",
      "Batch：11494 | Loss: 0.06828353554010391\n",
      "Batch：11495 | Loss: 0.05190269276499748\n",
      "Batch：11496 | Loss: 0.07124713063240051\n",
      "Batch：11497 | Loss: 0.07570900022983551\n",
      "Batch：11498 | Loss: 0.05858100205659866\n",
      "Batch：11499 | Loss: 0.07003787904977798\n",
      "Batch：11500 | Loss: 0.06707390397787094\n",
      "Batch：11501 | Loss: 0.06270943582057953\n",
      "Batch：11502 | Loss: 0.05067810043692589\n",
      "Batch：11503 | Loss: 0.06520445644855499\n",
      "Batch：11504 | Loss: 0.0686977207660675\n",
      "Batch：11505 | Loss: 0.0660928338766098\n",
      "Batch：11506 | Loss: 0.08074343949556351\n",
      "Batch：11507 | Loss: 0.06817662715911865\n",
      "Batch：11508 | Loss: 0.06495320796966553\n",
      "Batch：11509 | Loss: 0.07707957178354263\n",
      "Batch：11510 | Loss: 0.05745669826865196\n",
      "Batch：11511 | Loss: 0.060325223952531815\n",
      "Batch：11512 | Loss: 0.06631966680288315\n",
      "Batch：11513 | Loss: 0.07829289883375168\n",
      "Batch：11514 | Loss: 0.06864248216152191\n",
      "Batch：11515 | Loss: 0.06796805560588837\n",
      "Batch：11516 | Loss: 0.06840164959430695\n",
      "Batch：11517 | Loss: 0.06063174456357956\n",
      "Batch：11518 | Loss: 0.061357513070106506\n",
      "Batch：11519 | Loss: 0.07161819934844971\n",
      "Batch：11520 | Loss: 0.07086092233657837\n",
      "Batch：11521 | Loss: 0.072458915412426\n",
      "Batch：11522 | Loss: 0.06185479089617729\n",
      "Batch：11523 | Loss: 0.06416682153940201\n",
      "Batch：11524 | Loss: 0.05977959185838699\n",
      "Batch：11525 | Loss: 0.07224390655755997\n",
      "Batch：11526 | Loss: 0.07820829004049301\n",
      "Batch：11527 | Loss: 0.06383338570594788\n",
      "Batch：11528 | Loss: 0.05615048483014107\n",
      "Batch：11529 | Loss: 0.05630865320563316\n",
      "Batch：11530 | Loss: 0.05782691389322281\n",
      "Batch：11531 | Loss: 0.07420658320188522\n",
      "Batch：11532 | Loss: 0.07272441685199738\n",
      "Batch：11533 | Loss: 0.06229999661445618\n",
      "Batch：11534 | Loss: 0.05668802186846733\n",
      "Batch：11535 | Loss: 0.06414266675710678\n",
      "Batch：11536 | Loss: 0.0690193697810173\n",
      "Batch：11537 | Loss: 0.05826784670352936\n",
      "Batch：11538 | Loss: 0.07086142152547836\n",
      "Batch：11539 | Loss: 0.056059639900922775\n",
      "Batch：11540 | Loss: 0.05863140895962715\n",
      "Batch：11541 | Loss: 0.07169290632009506\n",
      "Batch：11542 | Loss: 0.06940179318189621\n",
      "Batch：11543 | Loss: 0.0721292644739151\n",
      "Batch：11544 | Loss: 0.06595921516418457\n",
      "Batch：11545 | Loss: 0.06357280164957047\n",
      "Batch：11546 | Loss: 0.07857412844896317\n",
      "Batch：11547 | Loss: 0.0611044205725193\n",
      "Batch：11548 | Loss: 0.07069896161556244\n",
      "Batch：11549 | Loss: 0.049746714532375336\n",
      "Batch：11550 | Loss: 0.06926558166742325\n",
      "Batch：11551 | Loss: 0.06603741645812988\n",
      "Batch：11552 | Loss: 0.06953956186771393\n",
      "Batch：11553 | Loss: 0.0639980286359787\n",
      "Batch：11554 | Loss: 0.072444848716259\n",
      "Batch：11555 | Loss: 0.059298619627952576\n",
      "Batch：11556 | Loss: 0.054083842784166336\n",
      "Batch：11557 | Loss: 0.06619083881378174\n",
      "Batch：11558 | Loss: 0.06441081315279007\n",
      "Batch：11559 | Loss: 0.07395866513252258\n",
      "Batch：11560 | Loss: 0.06575743854045868\n",
      "Batch：11561 | Loss: 0.07176848500967026\n",
      "Batch：11562 | Loss: 0.06311079859733582\n",
      "Batch：11563 | Loss: 0.06597120314836502\n",
      "Batch：11564 | Loss: 0.06929821521043777\n",
      "Batch：11565 | Loss: 0.06404668092727661\n",
      "Batch：11566 | Loss: 0.0723600685596466\n",
      "Batch：11567 | Loss: 0.07366977632045746\n",
      "Batch：11568 | Loss: 0.06896434724330902\n",
      "Batch：11569 | Loss: 0.05729298293590546\n",
      "Batch：11570 | Loss: 0.05836023762822151\n",
      "Batch：11571 | Loss: 0.05569247528910637\n",
      "Batch：11572 | Loss: 0.06017133593559265\n",
      "Batch：11573 | Loss: 0.06485604494810104\n",
      "Batch：11574 | Loss: 0.07294654846191406\n",
      "Batch：11575 | Loss: 0.055046334862709045\n",
      "Batch：11576 | Loss: 0.05576513707637787\n",
      "Batch：11577 | Loss: 0.07345519959926605\n",
      "Batch：11578 | Loss: 0.06489700078964233\n",
      "Batch：11579 | Loss: 0.06046092510223389\n",
      "Batch：11580 | Loss: 0.06846218556165695\n",
      "Batch：11581 | Loss: 0.05734194815158844\n",
      "Batch：11582 | Loss: 0.06400604546070099\n",
      "Batch：11583 | Loss: 0.06793294847011566\n",
      "Batch：11584 | Loss: 0.06568076461553574\n",
      "Batch：11585 | Loss: 0.06177610531449318\n",
      "Batch：11586 | Loss: 0.07279536128044128\n",
      "Batch：11587 | Loss: 0.07143382728099823\n",
      "Batch：11588 | Loss: 0.06440142542123795\n",
      "Batch：11589 | Loss: 0.07217070460319519\n",
      "Batch：11590 | Loss: 0.06724105030298233\n",
      "Batch：11591 | Loss: 0.06181137636303902\n",
      "Batch：11592 | Loss: 0.06822265684604645\n",
      "Batch：11593 | Loss: 0.06437122821807861\n",
      "Batch：11594 | Loss: 0.06585585325956345\n",
      "Batch：11595 | Loss: 0.057879313826560974\n",
      "Batch：11596 | Loss: 0.06614016741514206\n",
      "Batch：11597 | Loss: 0.06714629381895065\n",
      "Batch：11598 | Loss: 0.06358879804611206\n",
      "Batch：11599 | Loss: 0.0693964958190918\n",
      "Batch：11600 | Loss: 0.06814441084861755\n",
      "Batch：11601 | Loss: 0.06533346325159073\n",
      "Batch：11602 | Loss: 0.07034745812416077\n",
      "Batch：11603 | Loss: 0.06132077798247337\n",
      "Batch：11604 | Loss: 0.07341033965349197\n",
      "Batch：11605 | Loss: 0.07019605487585068\n",
      "Batch：11606 | Loss: 0.061325475573539734\n",
      "Batch：11607 | Loss: 0.08137011528015137\n",
      "Batch：11608 | Loss: 0.07025937736034393\n",
      "Batch：11609 | Loss: 0.0602879635989666\n",
      "Batch：11610 | Loss: 0.06365704536437988\n",
      "Batch：11611 | Loss: 0.062011320143938065\n",
      "Batch：11612 | Loss: 0.06292072683572769\n",
      "Batch：11613 | Loss: 0.06919927150011063\n",
      "Batch：11614 | Loss: 0.07721950113773346\n",
      "Batch：11615 | Loss: 0.06543511152267456\n",
      "Batch：11616 | Loss: 0.06939730793237686\n",
      "Batch：11617 | Loss: 0.056267522275447845\n",
      "Batch：11618 | Loss: 0.06580653041601181\n",
      "Batch：11619 | Loss: 0.06971471011638641\n",
      "Batch：11620 | Loss: 0.06453967094421387\n",
      "Batch：11621 | Loss: 0.06864380091428757\n",
      "Batch：11622 | Loss: 0.07011540979146957\n",
      "Batch：11623 | Loss: 0.06343093514442444\n",
      "Batch：11624 | Loss: 0.06306450068950653\n",
      "Batch：11625 | Loss: 0.06286640465259552\n",
      "Batch：11626 | Loss: 0.06528718769550323\n",
      "Batch：11627 | Loss: 0.059646863490343094\n",
      "Batch：11628 | Loss: 0.0641055628657341\n",
      "Batch：11629 | Loss: 0.06934668123722076\n",
      "Batch：11630 | Loss: 0.06641757488250732\n",
      "Batch：11631 | Loss: 0.07391000539064407\n",
      "Batch：11632 | Loss: 0.057126808911561966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：11633 | Loss: 0.05214760825037956\n",
      "Batch：11634 | Loss: 0.05694444850087166\n",
      "Batch：11635 | Loss: 0.0610976442694664\n",
      "Batch：11636 | Loss: 0.060854896903038025\n",
      "Batch：11637 | Loss: 0.056347016245126724\n",
      "Batch：11638 | Loss: 0.056817397475242615\n",
      "Batch：11639 | Loss: 0.07338441908359528\n",
      "Batch：11640 | Loss: 0.06312838196754456\n",
      "Batch：11641 | Loss: 0.05906844511628151\n",
      "Batch：11642 | Loss: 0.07924582809209824\n",
      "Batch：11643 | Loss: 0.06760483980178833\n",
      "Batch：11644 | Loss: 0.06650202721357346\n",
      "Batch：11645 | Loss: 0.06615554541349411\n",
      "Batch：11646 | Loss: 0.06682418286800385\n",
      "Batch：11647 | Loss: 0.052500415593385696\n",
      "Batch：11648 | Loss: 0.06055525690317154\n",
      "Batch：11649 | Loss: 0.06619415432214737\n",
      "Batch：11650 | Loss: 0.0671573132276535\n",
      "Batch：11651 | Loss: 0.06486776471138\n",
      "Batch：11652 | Loss: 0.06377893686294556\n",
      "Batch：11653 | Loss: 0.06509390473365784\n",
      "Batch：11654 | Loss: 0.07201448082923889\n",
      "Batch：11655 | Loss: 0.06668289750814438\n",
      "Batch：11656 | Loss: 0.061927430331707\n",
      "Batch：11657 | Loss: 0.06773622334003448\n",
      "Batch：11658 | Loss: 0.06334532797336578\n",
      "Batch：11659 | Loss: 0.06584320962429047\n",
      "Batch：11660 | Loss: 0.06911247223615646\n",
      "Batch：11661 | Loss: 0.06717851758003235\n",
      "Batch：11662 | Loss: 0.05897340923547745\n",
      "Batch：11663 | Loss: 0.07175803184509277\n",
      "Batch：11664 | Loss: 0.05752791464328766\n",
      "Batch：11665 | Loss: 0.06946506351232529\n",
      "Batch：11666 | Loss: 0.06308820843696594\n",
      "Batch：11667 | Loss: 0.06462937593460083\n",
      "Batch：11668 | Loss: 0.06312742084264755\n",
      "Batch：11669 | Loss: 0.05536171793937683\n",
      "Batch：11670 | Loss: 0.056893616914749146\n",
      "Batch：11671 | Loss: 0.060822319239377975\n",
      "Batch：11672 | Loss: 0.0648096427321434\n",
      "Batch：11673 | Loss: 0.060493405908346176\n",
      "Batch：11674 | Loss: 0.07175880670547485\n",
      "Batch：11675 | Loss: 0.0645451471209526\n",
      "Batch：11676 | Loss: 0.0608782134950161\n",
      "Batch：11677 | Loss: 0.062108114361763\n",
      "Batch：11678 | Loss: 0.06598521769046783\n",
      "Batch：11679 | Loss: 0.07855959981679916\n",
      "Batch：11680 | Loss: 0.06871114671230316\n",
      "Batch：11681 | Loss: 0.06375544518232346\n",
      "Batch：11682 | Loss: 0.06961652636528015\n",
      "Batch：11683 | Loss: 0.062246885150671005\n",
      "Batch：11684 | Loss: 0.06932460516691208\n",
      "Batch：11685 | Loss: 0.05990633741021156\n",
      "Batch：11686 | Loss: 0.06436879932880402\n",
      "Batch：11687 | Loss: 0.05909976735711098\n",
      "Batch：11688 | Loss: 0.06542685627937317\n",
      "Batch：11689 | Loss: 0.07562445849180222\n",
      "Batch：11690 | Loss: 0.06010662764310837\n",
      "Batch：11691 | Loss: 0.06453447043895721\n",
      "Batch：11692 | Loss: 0.07617373019456863\n",
      "Batch：11693 | Loss: 0.060942549258470535\n",
      "Batch：11694 | Loss: 0.06660260260105133\n",
      "Batch：11695 | Loss: 0.06863103061914444\n",
      "Batch：11696 | Loss: 0.06932470947504044\n",
      "Batch：11697 | Loss: 0.06869720667600632\n",
      "Batch：11698 | Loss: 0.06634624302387238\n",
      "Batch：11699 | Loss: 0.0692552775144577\n",
      "Batch：11700 | Loss: 0.06227798014879227\n",
      "Batch：11701 | Loss: 0.06406882405281067\n",
      "Batch：11702 | Loss: 0.07281201332807541\n",
      "Batch：11703 | Loss: 0.059111468493938446\n",
      "Batch：11704 | Loss: 0.05748661234974861\n",
      "Batch：11705 | Loss: 0.06130405142903328\n",
      "Batch：11706 | Loss: 0.06359946727752686\n",
      "Batch：11707 | Loss: 0.06148208677768707\n",
      "Batch：11708 | Loss: 0.05895252898335457\n",
      "Batch：11709 | Loss: 0.06495726108551025\n",
      "Batch：11710 | Loss: 0.05661929398775101\n",
      "Batch：11711 | Loss: 0.07674247771501541\n",
      "Batch：11712 | Loss: 0.06721825152635574\n",
      "Batch：11713 | Loss: 0.06986478716135025\n",
      "Batch：11714 | Loss: 0.049515970051288605\n",
      "Batch：11715 | Loss: 0.06457922607660294\n",
      "Batch：11716 | Loss: 0.07467248290777206\n",
      "Batch：11717 | Loss: 0.06563272327184677\n",
      "Batch：11718 | Loss: 0.06722364574670792\n",
      "Batch：11719 | Loss: 0.06433913856744766\n",
      "Batch：11720 | Loss: 0.06902553886175156\n",
      "Batch：11721 | Loss: 0.05673481151461601\n",
      "Batch：11722 | Loss: 0.0682702511548996\n",
      "Batch：11723 | Loss: 0.06145108491182327\n",
      "Batch：11724 | Loss: 0.07590528577566147\n",
      "Batch：11725 | Loss: 0.06318381428718567\n",
      "Batch：11726 | Loss: 0.0656067281961441\n",
      "Batch：11727 | Loss: 0.06319211423397064\n",
      "Batch：11728 | Loss: 0.06383319944143295\n",
      "Batch：11729 | Loss: 0.0665275901556015\n",
      "Batch：11730 | Loss: 0.06800206750631332\n",
      "Batch：11731 | Loss: 0.08184029906988144\n",
      "Batch：11732 | Loss: 0.0629383847117424\n",
      "Batch：11733 | Loss: 0.06692071259021759\n",
      "Batch：11734 | Loss: 0.062219928950071335\n",
      "Batch：11735 | Loss: 0.061613086611032486\n",
      "Batch：11736 | Loss: 0.07398270070552826\n",
      "Batch：11737 | Loss: 0.06777942180633545\n",
      "Batch：11738 | Loss: 0.0627405196428299\n",
      "Batch：11739 | Loss: 0.07757213711738586\n",
      "Batch：11740 | Loss: 0.05490916967391968\n",
      "Batch：11741 | Loss: 0.06389934569597244\n",
      "Batch：11742 | Loss: 0.06414760649204254\n",
      "Batch：11743 | Loss: 0.06821993738412857\n",
      "Batch：11744 | Loss: 0.07367292046546936\n",
      "Batch：11745 | Loss: 0.05991917848587036\n",
      "Batch：11746 | Loss: 0.0639718547463417\n",
      "Batch：11747 | Loss: 0.06361384689807892\n",
      "Batch：11748 | Loss: 0.06082078814506531\n",
      "Batch：11749 | Loss: 0.05809801071882248\n",
      "Batch：11750 | Loss: 0.054113443940877914\n",
      "Batch：11751 | Loss: 0.06622376292943954\n",
      "Batch：11752 | Loss: 0.06332715600728989\n",
      "Batch：11753 | Loss: 0.06593278050422668\n",
      "Batch：11754 | Loss: 0.0710335448384285\n",
      "Batch：11755 | Loss: 0.06628280133008957\n",
      "Batch：11756 | Loss: 0.059589557349681854\n",
      "Batch：11757 | Loss: 0.0627797320485115\n",
      "Batch：11758 | Loss: 0.06547653675079346\n",
      "Batch：11759 | Loss: 0.0681503415107727\n",
      "Batch：11760 | Loss: 0.06312577426433563\n",
      "Batch：11761 | Loss: 0.06140512973070145\n",
      "Batch：11762 | Loss: 0.06614788621664047\n",
      "Batch：11763 | Loss: 0.064254529774189\n",
      "Batch：11764 | Loss: 0.0702875554561615\n",
      "Batch：11765 | Loss: 0.06438809633255005\n",
      "Batch：11766 | Loss: 0.05639238283038139\n",
      "Batch：11767 | Loss: 0.052867334336042404\n",
      "Batch：11768 | Loss: 0.06158720701932907\n",
      "Batch：11769 | Loss: 0.06436514854431152\n",
      "Batch：11770 | Loss: 0.06280409544706345\n",
      "Batch：11771 | Loss: 0.05203206464648247\n",
      "Batch：11772 | Loss: 0.061785705387592316\n",
      "Batch：11773 | Loss: 0.05991058424115181\n",
      "Batch：11774 | Loss: 0.07840806990861893\n",
      "Batch：11775 | Loss: 0.06466981023550034\n",
      "Batch：11776 | Loss: 0.05859590694308281\n",
      "Batch：11777 | Loss: 0.06067826598882675\n",
      "Batch：11778 | Loss: 0.06154568865895271\n",
      "Batch：11779 | Loss: 0.06457460671663284\n",
      "Batch：11780 | Loss: 0.051237791776657104\n",
      "Batch：11781 | Loss: 0.059202875941991806\n",
      "Batch：11782 | Loss: 0.06923180818557739\n",
      "Batch：11783 | Loss: 0.060571737587451935\n",
      "Batch：11784 | Loss: 0.06227120757102966\n",
      "Batch：11785 | Loss: 0.06707938760519028\n",
      "Batch：11786 | Loss: 0.06247911602258682\n",
      "Batch：11787 | Loss: 0.06889808923006058\n",
      "Batch：11788 | Loss: 0.0704711377620697\n",
      "Batch：11789 | Loss: 0.05936058610677719\n",
      "Batch：11790 | Loss: 0.05952583625912666\n",
      "Batch：11791 | Loss: 0.06643150001764297\n",
      "Batch：11792 | Loss: 0.05843831226229668\n",
      "Batch：11793 | Loss: 0.062340058386325836\n",
      "Batch：11794 | Loss: 0.06206345558166504\n",
      "Batch：11795 | Loss: 0.07337352633476257\n",
      "Batch：11796 | Loss: 0.06371695548295975\n",
      "Batch：11797 | Loss: 0.06653059273958206\n",
      "Batch：11798 | Loss: 0.05760366842150688\n",
      "Batch：11799 | Loss: 0.058078400790691376\n",
      "Batch：11800 | Loss: 0.0630156472325325\n",
      "Batch：11801 | Loss: 0.06472057849168777\n",
      "Batch：11802 | Loss: 0.06373322755098343\n",
      "Batch：11803 | Loss: 0.06719610095024109\n",
      "Batch：11804 | Loss: 0.057803161442279816\n",
      "Batch：11805 | Loss: 0.06237994134426117\n",
      "Batch：11806 | Loss: 0.07881370931863785\n",
      "Batch：11807 | Loss: 0.06055561825633049\n",
      "Batch：11808 | Loss: 0.06897798180580139\n",
      "Batch：11809 | Loss: 0.06823629885911942\n",
      "Batch：11810 | Loss: 0.07748839259147644\n",
      "Batch：11811 | Loss: 0.06523826718330383\n",
      "Batch：11812 | Loss: 0.07638256996870041\n",
      "Batch：11813 | Loss: 0.06303325295448303\n",
      "Batch：11814 | Loss: 0.057679563760757446\n",
      "Batch：11815 | Loss: 0.05981070548295975\n",
      "Batch：11816 | Loss: 0.06099614500999451\n",
      "Batch：11817 | Loss: 0.06291744112968445\n",
      "Batch：11818 | Loss: 0.06195775419473648\n",
      "Batch：11819 | Loss: 0.06494367122650146\n",
      "Batch：11820 | Loss: 0.06290341913700104\n",
      "Batch：11821 | Loss: 0.06586923450231552\n",
      "Batch：11822 | Loss: 0.058061808347702026\n",
      "Batch：11823 | Loss: 0.061278894543647766\n",
      "Batch：11824 | Loss: 0.06630583852529526\n",
      "Batch：11825 | Loss: 0.06344648450613022\n",
      "Batch：11826 | Loss: 0.06349628418684006\n",
      "Batch：11827 | Loss: 0.06148198992013931\n",
      "Batch：11828 | Loss: 0.06013137847185135\n",
      "Batch：11829 | Loss: 0.06450951844453812\n",
      "Batch：11830 | Loss: 0.06386715918779373\n",
      "Batch：11831 | Loss: 0.06315693259239197\n",
      "Batch：11832 | Loss: 0.07774598151445389\n",
      "Batch：11833 | Loss: 0.06415127217769623\n",
      "Batch：11834 | Loss: 0.06161081790924072\n",
      "Batch：11835 | Loss: 0.07195408642292023\n",
      "Batch：11836 | Loss: 0.05960027128458023\n",
      "Batch：11837 | Loss: 0.060474902391433716\n",
      "Batch：11838 | Loss: 0.06793007999658585\n",
      "Batch：11839 | Loss: 0.08008940517902374\n",
      "Batch：11840 | Loss: 0.06156504154205322\n",
      "Batch：11841 | Loss: 0.06328942626714706\n",
      "Batch：11842 | Loss: 0.06581803411245346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：11843 | Loss: 0.06301891058683395\n",
      "Batch：11844 | Loss: 0.06281439960002899\n",
      "Batch：11845 | Loss: 0.07073665410280228\n",
      "Batch：11846 | Loss: 0.07251925766468048\n",
      "Batch：11847 | Loss: 0.052650704979896545\n",
      "Batch：11848 | Loss: 0.06017336621880531\n",
      "Batch：11849 | Loss: 0.05485893785953522\n",
      "Batch：11850 | Loss: 0.06318730860948563\n",
      "Batch：11851 | Loss: 0.07568506896495819\n",
      "Batch：11852 | Loss: 0.0653560683131218\n",
      "Batch：11853 | Loss: 0.06822669506072998\n",
      "Batch：11854 | Loss: 0.07937824726104736\n",
      "Batch：11855 | Loss: 0.06645499914884567\n",
      "Batch：11856 | Loss: 0.06657278537750244\n",
      "Batch：11857 | Loss: 0.06229053810238838\n",
      "Batch：11858 | Loss: 0.06123974546790123\n",
      "Batch：11859 | Loss: 0.05953134968876839\n",
      "Batch：11860 | Loss: 0.06535618752241135\n",
      "Batch：11861 | Loss: 0.06388410180807114\n",
      "Batch：11862 | Loss: 0.06083814054727554\n",
      "Batch：11863 | Loss: 0.07380520552396774\n",
      "Batch：11864 | Loss: 0.06466978788375854\n",
      "Batch：11865 | Loss: 0.05272528529167175\n",
      "Batch：11866 | Loss: 0.07222163677215576\n",
      "Batch：11867 | Loss: 0.060657478868961334\n",
      "Batch：11868 | Loss: 0.06795718520879745\n",
      "Batch：11869 | Loss: 0.05969316512346268\n",
      "Batch：11870 | Loss: 0.06939271837472916\n",
      "Batch：11871 | Loss: 0.05462254211306572\n",
      "Batch：11872 | Loss: 0.06412915140390396\n",
      "Batch：11873 | Loss: 0.07045804709196091\n",
      "Batch：11874 | Loss: 0.06871296465396881\n",
      "Batch：11875 | Loss: 0.0638907179236412\n",
      "Batch：11876 | Loss: 0.059346843510866165\n",
      "Batch：11877 | Loss: 0.0739564523100853\n",
      "Batch：11878 | Loss: 0.06196827068924904\n",
      "Batch：11879 | Loss: 0.06889615952968597\n",
      "Batch：11880 | Loss: 0.05930659547448158\n",
      "Batch：11881 | Loss: 0.06466536223888397\n",
      "Batch：11882 | Loss: 0.06309831887483597\n",
      "Batch：11883 | Loss: 0.06256582587957382\n",
      "Batch：11884 | Loss: 0.05094123259186745\n",
      "Batch：11885 | Loss: 0.05973740667104721\n",
      "Batch：11886 | Loss: 0.06421104073524475\n",
      "Batch：11887 | Loss: 0.06968670338392258\n",
      "Batch：11888 | Loss: 0.07209810614585876\n",
      "Batch：11889 | Loss: 0.05933316424489021\n",
      "Batch：11890 | Loss: 0.05613364651799202\n",
      "Batch：11891 | Loss: 0.05990725755691528\n",
      "Batch：11892 | Loss: 0.06165837496519089\n",
      "Batch：11893 | Loss: 0.0635187029838562\n",
      "Batch：11894 | Loss: 0.0705488920211792\n",
      "Batch：11895 | Loss: 0.062111373990774155\n",
      "Batch：11896 | Loss: 0.06072477996349335\n",
      "Batch：11897 | Loss: 0.06638394296169281\n",
      "Batch：11898 | Loss: 0.06335637718439102\n",
      "Batch：11899 | Loss: 0.06811098754405975\n",
      "Batch：11900 | Loss: 0.06416395306587219\n",
      "Batch：11901 | Loss: 0.05683673173189163\n",
      "Batch：11902 | Loss: 0.05154908075928688\n",
      "Batch：11903 | Loss: 0.06695601344108582\n",
      "Batch：11904 | Loss: 0.06470540910959244\n",
      "Batch：11905 | Loss: 0.051586560904979706\n",
      "Batch：11906 | Loss: 0.060191500931978226\n",
      "Batch：11907 | Loss: 0.054647527635097504\n",
      "Batch：11908 | Loss: 0.05921481177210808\n",
      "Batch：11909 | Loss: 0.05383624881505966\n",
      "Batch：11910 | Loss: 0.06082317605614662\n",
      "Batch：11911 | Loss: 0.06463874876499176\n",
      "Batch：11912 | Loss: 0.05622730404138565\n",
      "Batch：11913 | Loss: 0.06900214403867722\n",
      "Batch：11914 | Loss: 0.06294116377830505\n",
      "Batch：11915 | Loss: 0.06222039833664894\n",
      "Batch：11916 | Loss: 0.06370101124048233\n",
      "Batch：11917 | Loss: 0.0613449290394783\n",
      "Batch：11918 | Loss: 0.06895031780004501\n",
      "Batch：11919 | Loss: 0.05716181546449661\n",
      "Batch：11920 | Loss: 0.07837983965873718\n",
      "Batch：11921 | Loss: 0.05980705842375755\n",
      "Batch：11922 | Loss: 0.06770012527704239\n",
      "Batch：11923 | Loss: 0.06270859390497208\n",
      "Batch：11924 | Loss: 0.060721687972545624\n",
      "Batch：11925 | Loss: 0.05290749669075012\n",
      "Batch：11926 | Loss: 0.05922030657529831\n",
      "Batch：11927 | Loss: 0.05464773625135422\n",
      "Batch：11928 | Loss: 0.0715402141213417\n",
      "Batch：11929 | Loss: 0.07076319307088852\n",
      "Batch：11930 | Loss: 0.06063474342226982\n",
      "Batch：11931 | Loss: 0.06891433894634247\n",
      "Batch：11932 | Loss: 0.06152752786874771\n",
      "Batch：11933 | Loss: 0.06397134065628052\n",
      "Batch：11934 | Loss: 0.06927434355020523\n",
      "Batch：11935 | Loss: 0.06853275746107101\n",
      "Batch：11936 | Loss: 0.07212682068347931\n",
      "Batch：11937 | Loss: 0.06072065606713295\n",
      "Batch：11938 | Loss: 0.06173143908381462\n",
      "Batch：11939 | Loss: 0.06580160558223724\n",
      "Batch：11940 | Loss: 0.06076575070619583\n",
      "Batch：11941 | Loss: 0.060807373374700546\n",
      "Batch：11942 | Loss: 0.061806824058294296\n",
      "Batch：11943 | Loss: 0.07631533592939377\n",
      "Batch：11944 | Loss: 0.06808937340974808\n",
      "Batch：11945 | Loss: 0.06619582325220108\n",
      "Batch：11946 | Loss: 0.06356606632471085\n",
      "Batch：11947 | Loss: 0.05699024349451065\n",
      "Batch：11948 | Loss: 0.06257911771535873\n",
      "Batch：11949 | Loss: 0.06626129150390625\n",
      "Batch：11950 | Loss: 0.0632089152932167\n",
      "Batch：11951 | Loss: 0.05980335548520088\n",
      "Batch：11952 | Loss: 0.0479641817510128\n",
      "Batch：11953 | Loss: 0.06664498150348663\n",
      "Batch：11954 | Loss: 0.04421916604042053\n",
      "Batch：11955 | Loss: 0.06720508635044098\n",
      "Batch：11956 | Loss: 0.059447579085826874\n",
      "Batch：11957 | Loss: 0.05947362631559372\n",
      "Batch：11958 | Loss: 0.055112600326538086\n",
      "Batch：11959 | Loss: 0.06377893686294556\n",
      "Batch：11960 | Loss: 0.07690217345952988\n",
      "Batch：11961 | Loss: 0.05079330503940582\n",
      "Batch：11962 | Loss: 0.06291040033102036\n",
      "Batch：11963 | Loss: 0.05862986296415329\n",
      "Batch：11964 | Loss: 0.06874454766511917\n",
      "Batch：11965 | Loss: 0.0620824359357357\n",
      "Batch：11966 | Loss: 0.060945525765419006\n",
      "Batch：11967 | Loss: 0.05761856958270073\n",
      "Batch：11968 | Loss: 0.06067394092679024\n",
      "Batch：11969 | Loss: 0.06310804933309555\n",
      "Batch：11970 | Loss: 0.06372591108083725\n",
      "Batch：11971 | Loss: 0.05405229702591896\n",
      "Batch：11972 | Loss: 0.064570352435112\n",
      "Batch：11973 | Loss: 0.055845342576503754\n",
      "Batch：11974 | Loss: 0.06834520399570465\n",
      "Batch：11975 | Loss: 0.05757502093911171\n",
      "Batch：11976 | Loss: 0.06405572593212128\n",
      "Batch：11977 | Loss: 0.06540966778993607\n",
      "Batch：11978 | Loss: 0.056908681988716125\n",
      "Batch：11979 | Loss: 0.07377377152442932\n",
      "Batch：11980 | Loss: 0.06707320362329483\n",
      "Batch：11981 | Loss: 0.06369226425886154\n",
      "Batch：11982 | Loss: 0.052092283964157104\n",
      "Batch：11983 | Loss: 0.0571434386074543\n",
      "Batch：11984 | Loss: 0.06200249120593071\n",
      "Batch：11985 | Loss: 0.0665699690580368\n",
      "Batch：11986 | Loss: 0.056473713368177414\n",
      "Batch：11987 | Loss: 0.07345519214868546\n",
      "Batch：11988 | Loss: 0.06428582221269608\n",
      "Batch：11989 | Loss: 0.06206144765019417\n",
      "Batch：11990 | Loss: 0.0586356483399868\n",
      "Batch：11991 | Loss: 0.0657014325261116\n",
      "Batch：11992 | Loss: 0.06220138445496559\n",
      "Batch：11993 | Loss: 0.06564740091562271\n",
      "Batch：11994 | Loss: 0.060921791940927505\n",
      "Batch：11995 | Loss: 0.05827205255627632\n",
      "Batch：11996 | Loss: 0.07702664285898209\n",
      "Batch：11997 | Loss: 0.05607301741838455\n",
      "Batch：11998 | Loss: 0.05867365375161171\n",
      "Batch：11999 | Loss: 0.06307512521743774\n",
      "Batch：12000 | Loss: 0.06299719214439392\n",
      "Batch：12001 | Loss: 0.05209009349346161\n",
      "Batch：12002 | Loss: 0.055457815527915955\n",
      "Batch：12003 | Loss: 0.0680801197886467\n",
      "Batch：12004 | Loss: 0.06404497474431992\n",
      "Batch：12005 | Loss: 0.071326844394207\n",
      "Batch：12006 | Loss: 0.061044514179229736\n",
      "Batch：12007 | Loss: 0.06344441324472427\n",
      "Batch：12008 | Loss: 0.05530086159706116\n",
      "Batch：12009 | Loss: 0.061694491654634476\n",
      "Batch：12010 | Loss: 0.06191343069076538\n",
      "Batch：12011 | Loss: 0.07543272525072098\n",
      "Batch：12012 | Loss: 0.06498648971319199\n",
      "Batch：12013 | Loss: 0.0626763328909874\n",
      "Batch：12014 | Loss: 0.07330689579248428\n",
      "Batch：12015 | Loss: 0.06386011838912964\n",
      "Batch：12016 | Loss: 0.0609961599111557\n",
      "Batch：12017 | Loss: 0.06081313639879227\n",
      "Batch：12018 | Loss: 0.059204619377851486\n",
      "Batch：12019 | Loss: 0.06356021016836166\n",
      "Batch：12020 | Loss: 0.06254851818084717\n",
      "Batch：12021 | Loss: 0.07019846886396408\n",
      "Batch：12022 | Loss: 0.06637358665466309\n",
      "Batch：12023 | Loss: 0.0569620244204998\n",
      "Batch：12024 | Loss: 0.054293353110551834\n",
      "Batch：12025 | Loss: 0.06573368608951569\n",
      "Batch：12026 | Loss: 0.06244369596242905\n",
      "Batch：12027 | Loss: 0.06697840243577957\n",
      "Batch：12028 | Loss: 0.07915296405553818\n",
      "Batch：12029 | Loss: 0.06469543278217316\n",
      "Batch：12030 | Loss: 0.061587728559970856\n",
      "Batch：12031 | Loss: 0.06214099004864693\n",
      "Batch：12032 | Loss: 0.05936732515692711\n",
      "Batch：12033 | Loss: 0.06221996992826462\n",
      "Batch：12034 | Loss: 0.07804960757493973\n",
      "Batch：12035 | Loss: 0.06730841100215912\n",
      "Batch：12036 | Loss: 0.07193160057067871\n",
      "Batch：12037 | Loss: 0.0630507692694664\n",
      "Batch：12038 | Loss: 0.06169482320547104\n",
      "Batch：12039 | Loss: 0.06377476453781128\n",
      "Batch：12040 | Loss: 0.06585448980331421\n",
      "Batch：12041 | Loss: 0.06909103691577911\n",
      "Batch：12042 | Loss: 0.06124022230505943\n",
      "Batch：12043 | Loss: 0.07438762485980988\n",
      "Batch：12044 | Loss: 0.06985075771808624\n",
      "Batch：12045 | Loss: 0.06060071662068367\n",
      "Batch：12046 | Loss: 0.059635039418935776\n",
      "Batch：12047 | Loss: 0.07230744510889053\n",
      "Batch：12048 | Loss: 0.06191828474402428\n",
      "Batch：12049 | Loss: 0.07505135983228683\n",
      "Batch：12050 | Loss: 0.0631527379155159\n",
      "Batch：12051 | Loss: 0.06907898932695389\n",
      "Batch：12052 | Loss: 0.06456407904624939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：12053 | Loss: 0.054669901728630066\n",
      "Batch：12054 | Loss: 0.06793928891420364\n",
      "Batch：12055 | Loss: 0.06046444550156593\n",
      "Batch：12056 | Loss: 0.07211627811193466\n",
      "Batch：12057 | Loss: 0.053224582225084305\n",
      "Batch：12058 | Loss: 0.05860114470124245\n",
      "Batch：12059 | Loss: 0.06769411265850067\n",
      "Batch：12060 | Loss: 0.0763232633471489\n",
      "Batch：12061 | Loss: 0.06320294737815857\n",
      "Batch：12062 | Loss: 0.06408391892910004\n",
      "Batch：12063 | Loss: 0.05955317243933678\n",
      "Batch：12064 | Loss: 0.06159069389104843\n",
      "Batch：12065 | Loss: 0.06680657714605331\n",
      "Batch：12066 | Loss: 0.061933014541864395\n",
      "Batch：12067 | Loss: 0.0669458881020546\n",
      "Batch：12068 | Loss: 0.07528800517320633\n",
      "Batch：12069 | Loss: 0.05479215085506439\n",
      "Batch：12070 | Loss: 0.0680805891752243\n",
      "Batch：12071 | Loss: 0.06321360915899277\n",
      "Batch：12072 | Loss: 0.0643012672662735\n",
      "Batch：12073 | Loss: 0.06299843639135361\n",
      "Batch：12074 | Loss: 0.06700585037469864\n",
      "Batch：12075 | Loss: 0.06929338723421097\n",
      "Batch：12076 | Loss: 0.06534147262573242\n",
      "Batch：12077 | Loss: 0.06055062264204025\n",
      "Batch：12078 | Loss: 0.05812999978661537\n",
      "Batch：12079 | Loss: 0.06832855194807053\n",
      "Batch：12080 | Loss: 0.0685550719499588\n",
      "Batch：12081 | Loss: 0.06935055553913116\n",
      "Batch：12082 | Loss: 0.06499055027961731\n",
      "Batch：12083 | Loss: 0.05953481048345566\n",
      "Batch：12084 | Loss: 0.059749990701675415\n",
      "Batch：12085 | Loss: 0.06419522315263748\n",
      "Batch：12086 | Loss: 0.06498771160840988\n",
      "Batch：12087 | Loss: 0.06497479975223541\n",
      "Batch：12088 | Loss: 0.04917091876268387\n",
      "Batch：12089 | Loss: 0.04766073077917099\n",
      "Batch：12090 | Loss: 0.07701031118631363\n",
      "Batch：12091 | Loss: 0.0684237852692604\n",
      "Batch：12092 | Loss: 0.0674993097782135\n",
      "Batch：12093 | Loss: 0.05434374883770943\n",
      "Batch：12094 | Loss: 0.0737709328532219\n",
      "Batch：12095 | Loss: 0.06562596559524536\n",
      "Batch：12096 | Loss: 0.06967408210039139\n",
      "Batch：12097 | Loss: 0.06881009042263031\n",
      "Batch：12098 | Loss: 0.06331320106983185\n",
      "Batch：12099 | Loss: 0.06519720703363419\n",
      "Batch：12100 | Loss: 0.06464942544698715\n",
      "Batch：12101 | Loss: 0.06891187280416489\n",
      "Batch：12102 | Loss: 0.06016462296247482\n",
      "Batch：12103 | Loss: 0.05464135855436325\n",
      "Batch：12104 | Loss: 0.05865970626473427\n",
      "Batch：12105 | Loss: 0.0696633830666542\n",
      "Batch：12106 | Loss: 0.07718183845281601\n",
      "Batch：12107 | Loss: 0.06387434154748917\n",
      "Batch：12108 | Loss: 0.059821877628564835\n",
      "Batch：12109 | Loss: 0.06325825303792953\n",
      "Batch：12110 | Loss: 0.0673583596944809\n",
      "Batch：12111 | Loss: 0.0620897151529789\n",
      "Batch：12112 | Loss: 0.058084819465875626\n",
      "Batch：12113 | Loss: 0.054798513650894165\n",
      "Batch：12114 | Loss: 0.06146487221121788\n",
      "Batch：12115 | Loss: 0.05188937485218048\n",
      "Batch：12116 | Loss: 0.05590464174747467\n",
      "Batch：12117 | Loss: 0.06393824517726898\n",
      "Batch：12118 | Loss: 0.06228512525558472\n",
      "Batch：12119 | Loss: 0.07019198685884476\n",
      "Batch：12120 | Loss: 0.06583236902952194\n",
      "Batch：12121 | Loss: 0.06189704313874245\n",
      "Batch：12122 | Loss: 0.059017159044742584\n",
      "Batch：12123 | Loss: 0.06313290446996689\n",
      "Batch：12124 | Loss: 0.06271334737539291\n",
      "Batch：12125 | Loss: 0.05722201615571976\n",
      "Batch：12126 | Loss: 0.06766733527183533\n",
      "Batch：12127 | Loss: 0.05253642797470093\n",
      "Batch：12128 | Loss: 0.055409662425518036\n",
      "Batch：12129 | Loss: 0.065996915102005\n",
      "Batch：12130 | Loss: 0.0555405355989933\n",
      "Batch：12131 | Loss: 0.07529935985803604\n",
      "Batch：12132 | Loss: 0.05627935752272606\n",
      "Batch：12133 | Loss: 0.05812160298228264\n",
      "Batch：12134 | Loss: 0.056147150695323944\n",
      "Batch：12135 | Loss: 0.0662582591176033\n",
      "Batch：12136 | Loss: 0.06222262978553772\n",
      "Batch：12137 | Loss: 0.05381650850176811\n",
      "Batch：12138 | Loss: 0.06503675132989883\n",
      "Batch：12139 | Loss: 0.06056564301252365\n",
      "Batch：12140 | Loss: 0.07048426568508148\n",
      "Batch：12141 | Loss: 0.06778077781200409\n",
      "Batch：12142 | Loss: 0.06861765682697296\n",
      "Batch：12143 | Loss: 0.06013104319572449\n",
      "Batch：12144 | Loss: 0.05904949828982353\n",
      "Batch：12145 | Loss: 0.0649375468492508\n",
      "Batch：12146 | Loss: 0.06164087727665901\n",
      "Batch：12147 | Loss: 0.05848468467593193\n",
      "Batch：12148 | Loss: 0.08629070967435837\n",
      "Batch：12149 | Loss: 0.06220775097608566\n",
      "Batch：12150 | Loss: 0.06543407589197159\n",
      "Batch：12151 | Loss: 0.05501198396086693\n",
      "Batch：12152 | Loss: 0.06342633068561554\n",
      "Batch：12153 | Loss: 0.04540050029754639\n",
      "Batch：12154 | Loss: 0.061320699751377106\n",
      "Batch：12155 | Loss: 0.06771403551101685\n",
      "Batch：12156 | Loss: 0.05855649337172508\n",
      "Batch：12157 | Loss: 0.06104687973856926\n",
      "Batch：12158 | Loss: 0.06068950891494751\n",
      "Batch：12159 | Loss: 0.05628476291894913\n",
      "Batch：12160 | Loss: 0.0646628886461258\n",
      "Batch：12161 | Loss: 0.06765145808458328\n",
      "Batch：12162 | Loss: 0.06331387907266617\n",
      "Batch：12163 | Loss: 0.06933591514825821\n",
      "Batch：12164 | Loss: 0.060901083052158356\n",
      "Batch：12165 | Loss: 0.059338588267564774\n",
      "Batch：12166 | Loss: 0.053143538534641266\n",
      "Batch：12167 | Loss: 0.055651258677244186\n",
      "Batch：12168 | Loss: 0.06340928375720978\n",
      "Batch：12169 | Loss: 0.057133905589580536\n",
      "Batch：12170 | Loss: 0.07238941639661789\n",
      "Batch：12171 | Loss: 0.06054665148258209\n",
      "Batch：12172 | Loss: 0.06156034767627716\n",
      "Batch：12173 | Loss: 0.05122196301817894\n",
      "Batch：12174 | Loss: 0.0625634714961052\n",
      "Batch：12175 | Loss: 0.05696026608347893\n",
      "Batch：12176 | Loss: 0.061141785234212875\n",
      "Batch：12177 | Loss: 0.05468638986349106\n",
      "Batch：12178 | Loss: 0.06939112395048141\n",
      "Batch：12179 | Loss: 0.06983403116464615\n",
      "Batch：12180 | Loss: 0.061670031398534775\n",
      "Batch：12181 | Loss: 0.06027217581868172\n",
      "Batch：12182 | Loss: 0.05496403947472572\n",
      "Batch：12183 | Loss: 0.05602261424064636\n",
      "Batch：12184 | Loss: 0.06462311744689941\n",
      "Batch：12185 | Loss: 0.06778010725975037\n",
      "Batch：12186 | Loss: 0.08224257081747055\n",
      "Batch：12187 | Loss: 0.06191866844892502\n",
      "Batch：12188 | Loss: 0.05927601084113121\n",
      "Batch：12189 | Loss: 0.06493327766656876\n",
      "Batch：12190 | Loss: 0.059661801904439926\n",
      "Batch：12191 | Loss: 0.05626092478632927\n",
      "Batch：12192 | Loss: 0.05275006964802742\n",
      "Batch：12193 | Loss: 0.06391643732786179\n",
      "Batch：12194 | Loss: 0.06845942884683609\n",
      "Batch：12195 | Loss: 0.06324201822280884\n",
      "Batch：12196 | Loss: 0.063595712184906\n",
      "Batch：12197 | Loss: 0.06371752172708511\n",
      "Batch：12198 | Loss: 0.06109129264950752\n",
      "Batch：12199 | Loss: 0.06655710935592651\n",
      "Batch：12200 | Loss: 0.058510441333055496\n",
      "Batch：12201 | Loss: 0.06970379501581192\n",
      "Batch：12202 | Loss: 0.06450886279344559\n",
      "Batch：12203 | Loss: 0.058055926114320755\n",
      "Batch：12204 | Loss: 0.06471353024244308\n",
      "Batch：12205 | Loss: 0.0652620866894722\n",
      "Batch：12206 | Loss: 0.06167612597346306\n",
      "Batch：12207 | Loss: 0.06866507232189178\n",
      "Batch：12208 | Loss: 0.054956309497356415\n",
      "Batch：12209 | Loss: 0.0682777613401413\n",
      "Batch：12210 | Loss: 0.0660196840763092\n",
      "Batch：12211 | Loss: 0.06569419801235199\n",
      "Batch：12212 | Loss: 0.0636763945221901\n",
      "Batch：12213 | Loss: 0.06476807594299316\n",
      "Batch：12214 | Loss: 0.05750468745827675\n",
      "Batch：12215 | Loss: 0.06568735837936401\n",
      "Batch：12216 | Loss: 0.06604873389005661\n",
      "Batch：12217 | Loss: 0.06266721338033676\n",
      "Batch：12218 | Loss: 0.053582824766635895\n",
      "Batch：12219 | Loss: 0.06421259790658951\n",
      "Batch：12220 | Loss: 0.06858326494693756\n",
      "Batch：12221 | Loss: 0.06889040768146515\n",
      "Batch：12222 | Loss: 0.06631495803594589\n",
      "Batch：12223 | Loss: 0.06571289151906967\n",
      "Batch：12224 | Loss: 0.05468112975358963\n",
      "Batch：12225 | Loss: 0.06396230310201645\n",
      "Batch：12226 | Loss: 0.06375990808010101\n",
      "Batch：12227 | Loss: 0.06281780451536179\n",
      "Batch：12228 | Loss: 0.06828828155994415\n",
      "Batch：12229 | Loss: 0.06528867036104202\n",
      "Batch：12230 | Loss: 0.06969571858644485\n",
      "Batch：12231 | Loss: 0.06104373559355736\n",
      "Batch：12232 | Loss: 0.0629730299115181\n",
      "Batch：12233 | Loss: 0.05445891246199608\n",
      "Batch：12234 | Loss: 0.05892503261566162\n",
      "Batch：12235 | Loss: 0.06919438391923904\n",
      "Batch：12236 | Loss: 0.0604247972369194\n",
      "Batch：12237 | Loss: 0.05158993601799011\n",
      "Batch：12238 | Loss: 0.05624929070472717\n",
      "Batch：12239 | Loss: 0.06966608017683029\n",
      "Batch：12240 | Loss: 0.06986836344003677\n",
      "Batch：12241 | Loss: 0.05684024840593338\n",
      "Batch：12242 | Loss: 0.07039306312799454\n",
      "Batch：12243 | Loss: 0.06389930099248886\n",
      "Batch：12244 | Loss: 0.05361808091402054\n",
      "Batch：12245 | Loss: 0.06430833041667938\n",
      "Batch：12246 | Loss: 0.06200765445828438\n",
      "Batch：12247 | Loss: 0.06467100232839584\n",
      "Batch：12248 | Loss: 0.06671396642923355\n",
      "Batch：12249 | Loss: 0.05963713675737381\n",
      "Batch：12250 | Loss: 0.06428096443414688\n",
      "Batch：12251 | Loss: 0.05499858409166336\n",
      "Batch：12252 | Loss: 0.06348375231027603\n",
      "Batch：12253 | Loss: 0.05570480227470398\n",
      "Batch：12254 | Loss: 0.05497634783387184\n",
      "Batch：12255 | Loss: 0.06441634893417358\n",
      "Batch：12256 | Loss: 0.0624518021941185\n",
      "Batch：12257 | Loss: 0.0586693212389946\n",
      "Batch：12258 | Loss: 0.05949361249804497\n",
      "Batch：12259 | Loss: 0.06592144817113876\n",
      "Batch：12260 | Loss: 0.05569453537464142\n",
      "Batch：12261 | Loss: 0.06147899478673935\n",
      "Batch：12262 | Loss: 0.05895719677209854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：12263 | Loss: 0.05522375926375389\n",
      "Batch：12264 | Loss: 0.06817754358053207\n",
      "Batch：12265 | Loss: 0.06563691794872284\n",
      "Batch：12266 | Loss: 0.05669542774558067\n",
      "Batch：12267 | Loss: 0.06568844616413116\n",
      "Batch：12268 | Loss: 0.06045470014214516\n",
      "Batch：12269 | Loss: 0.06155306100845337\n",
      "Batch：12270 | Loss: 0.0715961903333664\n",
      "Batch：12271 | Loss: 0.05617298185825348\n",
      "Batch：12272 | Loss: 0.05162545666098595\n",
      "Batch：12273 | Loss: 0.0652686133980751\n",
      "Batch：12274 | Loss: 0.05691143870353699\n",
      "Batch：12275 | Loss: 0.049200430512428284\n",
      "Batch：12276 | Loss: 0.05315933749079704\n",
      "Batch：12277 | Loss: 0.06275461614131927\n",
      "Batch：12278 | Loss: 0.06028826907277107\n",
      "Batch：12279 | Loss: 0.06345690786838531\n",
      "Batch：12280 | Loss: 0.058436375111341476\n",
      "Batch：12281 | Loss: 0.07192464917898178\n",
      "Batch：12282 | Loss: 0.05686226859688759\n",
      "Batch：12283 | Loss: 0.05703272297978401\n",
      "Batch：12284 | Loss: 0.06786146014928818\n",
      "Batch：12285 | Loss: 0.06078934669494629\n",
      "Batch：12286 | Loss: 0.06286905705928802\n",
      "Batch：12287 | Loss: 0.06020313873887062\n",
      "Batch：12288 | Loss: 0.06387098133563995\n",
      "Batch：12289 | Loss: 0.05670945718884468\n",
      "Batch：12290 | Loss: 0.0615423284471035\n",
      "Batch：12291 | Loss: 0.061483848839998245\n",
      "Batch：12292 | Loss: 0.06061169505119324\n",
      "Batch：12293 | Loss: 0.06994979083538055\n",
      "Batch：12294 | Loss: 0.06647565960884094\n",
      "Batch：12295 | Loss: 0.05972128361463547\n",
      "Batch：12296 | Loss: 0.06867042183876038\n",
      "Batch：12297 | Loss: 0.05805720388889313\n",
      "Batch：12298 | Loss: 0.06529005616903305\n",
      "Batch：12299 | Loss: 0.06435295194387436\n",
      "Batch：12300 | Loss: 0.06056353077292442\n",
      "Batch：12301 | Loss: 0.06355699896812439\n",
      "Batch：12302 | Loss: 0.06287422776222229\n",
      "Batch：12303 | Loss: 0.06105998530983925\n",
      "Batch：12304 | Loss: 0.07227029651403427\n",
      "Batch：12305 | Loss: 0.05581652373075485\n",
      "Batch：12306 | Loss: 0.06515533477067947\n",
      "Batch：12307 | Loss: 0.05800069496035576\n",
      "Batch：12308 | Loss: 0.054411448538303375\n",
      "Batch：12309 | Loss: 0.06809140741825104\n",
      "Batch：12310 | Loss: 0.06196819990873337\n",
      "Batch：12311 | Loss: 0.06444341689348221\n",
      "Batch：12312 | Loss: 0.06701072305440903\n",
      "Batch：12313 | Loss: 0.07183706760406494\n",
      "Batch：12314 | Loss: 0.05093676596879959\n",
      "Batch：12315 | Loss: 0.06074513867497444\n",
      "Batch：12316 | Loss: 0.058418747037649155\n",
      "Batch：12317 | Loss: 0.06821545958518982\n",
      "Batch：12318 | Loss: 0.06159131973981857\n",
      "Batch：12319 | Loss: 0.05991220101714134\n",
      "Batch：12320 | Loss: 0.06305412948131561\n",
      "Batch：12321 | Loss: 0.06679258495569229\n",
      "Batch：12322 | Loss: 0.06527732312679291\n",
      "Batch：12323 | Loss: 0.058295998722314835\n",
      "Batch：12324 | Loss: 0.07536730170249939\n",
      "Batch：12325 | Loss: 0.07249997556209564\n",
      "Batch：12326 | Loss: 0.06611093133687973\n",
      "Batch：12327 | Loss: 0.05713534355163574\n",
      "Batch：12328 | Loss: 0.052650727331638336\n",
      "Batch：12329 | Loss: 0.05660289525985718\n",
      "Batch：12330 | Loss: 0.0686250850558281\n",
      "Batch：12331 | Loss: 0.062370665371418\n",
      "Batch：12332 | Loss: 0.06436387449502945\n",
      "Batch：12333 | Loss: 0.05594857782125473\n",
      "Batch：12334 | Loss: 0.05275284871459007\n",
      "Batch：12335 | Loss: 0.06574104726314545\n",
      "Batch：12336 | Loss: 0.05757111683487892\n",
      "Batch：12337 | Loss: 0.0696428194642067\n",
      "Batch：12338 | Loss: 0.056110017001628876\n",
      "Batch：12339 | Loss: 0.06183823570609093\n",
      "Batch：12340 | Loss: 0.06805469840765\n",
      "Batch：12341 | Loss: 0.05732816457748413\n",
      "Batch：12342 | Loss: 0.06459037959575653\n",
      "Batch：12343 | Loss: 0.06195220351219177\n",
      "Batch：12344 | Loss: 0.06400971114635468\n",
      "Batch：12345 | Loss: 0.06621026992797852\n",
      "Batch：12346 | Loss: 0.05834680050611496\n",
      "Batch：12347 | Loss: 0.07056842744350433\n",
      "Batch：12348 | Loss: 0.05823546648025513\n",
      "Batch：12349 | Loss: 0.06809183955192566\n",
      "Batch：12350 | Loss: 0.06252990663051605\n",
      "Batch：12351 | Loss: 0.07108206301927567\n",
      "Batch：12352 | Loss: 0.06224121153354645\n",
      "Batch：12353 | Loss: 0.06152084469795227\n",
      "Batch：12354 | Loss: 0.0756031721830368\n",
      "Batch：12355 | Loss: 0.06862930953502655\n",
      "Batch：12356 | Loss: 0.05522624030709267\n",
      "Batch：12357 | Loss: 0.06164921075105667\n",
      "Batch：12358 | Loss: 0.05550704523921013\n",
      "Batch：12359 | Loss: 0.06643930077552795\n",
      "Batch：12360 | Loss: 0.07125075906515121\n",
      "Batch：12361 | Loss: 0.060106780380010605\n",
      "Batch：12362 | Loss: 0.05548662319779396\n",
      "Batch：12363 | Loss: 0.0576244592666626\n",
      "Batch：12364 | Loss: 0.07471376657485962\n",
      "Batch：12365 | Loss: 0.056435007601976395\n",
      "Batch：12366 | Loss: 0.07029465585947037\n",
      "Batch：12367 | Loss: 0.06811270117759705\n",
      "Batch：12368 | Loss: 0.04411182552576065\n",
      "Batch：12369 | Loss: 0.059316955506801605\n",
      "Batch：12370 | Loss: 0.06968138366937637\n",
      "Batch：12371 | Loss: 0.07064416259527206\n",
      "Batch：12372 | Loss: 0.05960794910788536\n",
      "Batch：12373 | Loss: 0.06380613893270493\n",
      "Batch：12374 | Loss: 0.06030329316854477\n",
      "Batch：12375 | Loss: 0.07012706249952316\n",
      "Batch：12376 | Loss: 0.0646841749548912\n",
      "Batch：12377 | Loss: 0.06255912035703659\n",
      "Batch：12378 | Loss: 0.055234115570783615\n",
      "Batch：12379 | Loss: 0.05599542334675789\n",
      "Batch：12380 | Loss: 0.06759053468704224\n",
      "Batch：12381 | Loss: 0.0644841194152832\n",
      "Batch：12382 | Loss: 0.06226640194654465\n",
      "Batch：12383 | Loss: 0.05865265429019928\n",
      "Batch：12384 | Loss: 0.061508916318416595\n",
      "Batch：12385 | Loss: 0.06432133913040161\n",
      "Batch：12386 | Loss: 0.06143293157219887\n",
      "Batch：12387 | Loss: 0.06723509728908539\n",
      "Batch：12388 | Loss: 0.06662996113300323\n",
      "Batch：12389 | Loss: 0.05888443440198898\n",
      "Batch：12390 | Loss: 0.07334502786397934\n",
      "Batch：12391 | Loss: 0.05208888649940491\n",
      "Batch：12392 | Loss: 0.07380879670381546\n",
      "Batch：12393 | Loss: 0.05663008987903595\n",
      "Batch：12394 | Loss: 0.07186536490917206\n",
      "Batch：12395 | Loss: 0.06487917900085449\n",
      "Batch：12396 | Loss: 0.06823413819074631\n",
      "Batch：12397 | Loss: 0.05819035321474075\n",
      "Batch：12398 | Loss: 0.05269308388233185\n",
      "Batch：12399 | Loss: 0.058625079691410065\n",
      "Batch：12400 | Loss: 0.06544708460569382\n",
      "Batch：12401 | Loss: 0.06905417889356613\n",
      "Batch：12402 | Loss: 0.06609019637107849\n",
      "Batch：12403 | Loss: 0.06981992721557617\n",
      "Batch：12404 | Loss: 0.05467354133725166\n",
      "Batch：12405 | Loss: 0.068763367831707\n",
      "Batch：12406 | Loss: 0.06840749084949493\n",
      "Batch：12407 | Loss: 0.06632858514785767\n",
      "Batch：12408 | Loss: 0.06367131322622299\n",
      "Batch：12409 | Loss: 0.0646594688296318\n",
      "Batch：12410 | Loss: 0.057356078177690506\n",
      "Batch：12411 | Loss: 0.056228119879961014\n",
      "Batch：12412 | Loss: 0.05948781222105026\n",
      "Batch：12413 | Loss: 0.06923199445009232\n",
      "Batch：12414 | Loss: 0.06042087823152542\n",
      "Batch：12415 | Loss: 0.05729822814464569\n",
      "Batch：12416 | Loss: 0.05476133152842522\n",
      "Batch：12417 | Loss: 0.06607162207365036\n",
      "Batch：12418 | Loss: 0.06880563497543335\n",
      "Batch：12419 | Loss: 0.05413910001516342\n",
      "Batch：12420 | Loss: 0.06465548276901245\n",
      "Batch：12421 | Loss: 0.06360238790512085\n",
      "Batch：12422 | Loss: 0.05487814173102379\n",
      "Batch：12423 | Loss: 0.0804833397269249\n",
      "Batch：12424 | Loss: 0.06203922629356384\n",
      "Batch：12425 | Loss: 0.06981933861970901\n",
      "Batch：12426 | Loss: 0.06565679609775543\n",
      "Batch：12427 | Loss: 0.07395753264427185\n",
      "Batch：12428 | Loss: 0.055626291781663895\n",
      "Batch：12429 | Loss: 0.06853438913822174\n",
      "Batch：12430 | Loss: 0.06551218777894974\n",
      "Batch：12431 | Loss: 0.05360884964466095\n",
      "Batch：12432 | Loss: 0.061587072908878326\n",
      "Batch：12433 | Loss: 0.05880862474441528\n",
      "Batch：12434 | Loss: 0.0648023784160614\n",
      "Batch：12435 | Loss: 0.06487911939620972\n",
      "Batch：12436 | Loss: 0.06693608313798904\n",
      "Batch：12437 | Loss: 0.0779305025935173\n",
      "Batch：12438 | Loss: 0.05295451357960701\n",
      "Batch：12439 | Loss: 0.06076973304152489\n",
      "Batch：12440 | Loss: 0.06146179512143135\n",
      "Batch：12441 | Loss: 0.06536179780960083\n",
      "Batch：12442 | Loss: 0.054702166467905045\n",
      "Batch：12443 | Loss: 0.06370367854833603\n",
      "Batch：12444 | Loss: 0.06286012381315231\n",
      "Batch：12445 | Loss: 0.07124485075473785\n",
      "Batch：12446 | Loss: 0.07345274835824966\n",
      "Batch：12447 | Loss: 0.05590365082025528\n",
      "Batch：12448 | Loss: 0.05943043902516365\n",
      "Batch：12449 | Loss: 0.061165641993284225\n",
      "Batch：12450 | Loss: 0.06678248196840286\n",
      "Batch：12451 | Loss: 0.059404823929071426\n",
      "Batch：12452 | Loss: 0.05996951088309288\n",
      "Batch：12453 | Loss: 0.06229907274246216\n",
      "Batch：12454 | Loss: 0.05463061481714249\n",
      "Batch：12455 | Loss: 0.06071104854345322\n",
      "Batch：12456 | Loss: 0.06962467730045319\n",
      "Batch：12457 | Loss: 0.06417015194892883\n",
      "Batch：12458 | Loss: 0.0486360564827919\n",
      "Batch：12459 | Loss: 0.06705865263938904\n",
      "Batch：12460 | Loss: 0.057604800909757614\n",
      "Batch：12461 | Loss: 0.06284903734922409\n",
      "Batch：12462 | Loss: 0.05451938882470131\n",
      "Batch：12463 | Loss: 0.06935009360313416\n",
      "Batch：12464 | Loss: 0.054540004581213\n",
      "Batch：12465 | Loss: 0.06046386808156967\n",
      "Batch：12466 | Loss: 0.07358480989933014\n",
      "Batch：12467 | Loss: 0.07105991244316101\n",
      "Batch：12468 | Loss: 0.05705627053976059\n",
      "Batch：12469 | Loss: 0.06688883155584335\n",
      "Batch：12470 | Loss: 0.06200626492500305\n",
      "Batch：12471 | Loss: 0.05888409540057182\n",
      "Batch：12472 | Loss: 0.05178619176149368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：12473 | Loss: 0.05497394874691963\n",
      "Batch：12474 | Loss: 0.06949760019779205\n",
      "Batch：12475 | Loss: 0.06777093559503555\n",
      "Batch：12476 | Loss: 0.06738036870956421\n",
      "Batch：12477 | Loss: 0.0626460388302803\n",
      "Batch：12478 | Loss: 0.05920647084712982\n",
      "Batch：12479 | Loss: 0.062352344393730164\n",
      "Batch：12480 | Loss: 0.06570614874362946\n",
      "Batch：12481 | Loss: 0.07457376271486282\n",
      "Batch：12482 | Loss: 0.06789027899503708\n",
      "Batch：12483 | Loss: 0.05492618307471275\n",
      "Batch：12484 | Loss: 0.05623482167720795\n",
      "Batch：12485 | Loss: 0.05448157712817192\n",
      "Batch：12486 | Loss: 0.060349058359861374\n",
      "Batch：12487 | Loss: 0.06195962801575661\n",
      "Batch：12488 | Loss: 0.07391194254159927\n",
      "Batch：12489 | Loss: 0.06265778839588165\n",
      "Batch：12490 | Loss: 0.07528167963027954\n",
      "Batch：12491 | Loss: 0.0627904012799263\n",
      "Batch：12492 | Loss: 0.06623628735542297\n",
      "Batch：12493 | Loss: 0.05649168789386749\n",
      "Batch：12494 | Loss: 0.054881706833839417\n",
      "Batch：12495 | Loss: 0.07022760063409805\n",
      "Batch：12496 | Loss: 0.05858832225203514\n",
      "Batch：12497 | Loss: 0.05612209066748619\n",
      "Batch：12498 | Loss: 0.051871173083782196\n",
      "Batch：12499 | Loss: 0.05252712965011597\n",
      "Batch：12500 | Loss: 0.0480956956744194\n",
      "Batch：12501 | Loss: 0.06545166671276093\n",
      "Batch：12502 | Loss: 0.06125926226377487\n",
      "Batch：12503 | Loss: 0.05850766599178314\n",
      "Batch：12504 | Loss: 0.0732891634106636\n",
      "Batch：12505 | Loss: 0.05744072049856186\n",
      "Batch：12506 | Loss: 0.05548008158802986\n",
      "Batch：12507 | Loss: 0.06035223230719566\n",
      "Batch：12508 | Loss: 0.06248749792575836\n",
      "Batch：12509 | Loss: 0.05657143518328667\n",
      "Batch：12510 | Loss: 0.07467854768037796\n",
      "Batch：12511 | Loss: 0.05012785643339157\n",
      "Batch：12512 | Loss: 0.0588320717215538\n",
      "Batch：12513 | Loss: 0.058713529258966446\n",
      "Batch：12514 | Loss: 0.05839396268129349\n",
      "Batch：12515 | Loss: 0.0551268495619297\n",
      "Batch：12516 | Loss: 0.07113754004240036\n",
      "Batch：12517 | Loss: 0.055128224194049835\n",
      "Batch：12518 | Loss: 0.05826718732714653\n",
      "Batch：12519 | Loss: 0.06086238473653793\n",
      "Batch：12520 | Loss: 0.0678945928812027\n",
      "Batch：12521 | Loss: 0.056062325835227966\n",
      "Batch：12522 | Loss: 0.06839645653963089\n",
      "Batch：12523 | Loss: 0.055258940905332565\n",
      "Batch：12524 | Loss: 0.05813342332839966\n",
      "Batch：12525 | Loss: 0.06935766339302063\n",
      "Batch：12526 | Loss: 0.05831970274448395\n",
      "Batch：12527 | Loss: 0.057597167789936066\n",
      "Batch：12528 | Loss: 0.06147855520248413\n",
      "Batch：12529 | Loss: 0.044882241636514664\n",
      "Batch：12530 | Loss: 0.06658203154802322\n",
      "Batch：12531 | Loss: 0.05659657344222069\n",
      "Batch：12532 | Loss: 0.06694075465202332\n",
      "Batch：12533 | Loss: 0.0727376788854599\n",
      "Batch：12534 | Loss: 0.05294477939605713\n",
      "Batch：12535 | Loss: 0.062161702662706375\n",
      "Batch：12536 | Loss: 0.06167493760585785\n",
      "Batch：12537 | Loss: 0.0547773651778698\n",
      "Batch：12538 | Loss: 0.05347669869661331\n",
      "Batch：12539 | Loss: 0.06471171975135803\n",
      "Batch：12540 | Loss: 0.054583221673965454\n",
      "Batch：12541 | Loss: 0.05972536280751228\n",
      "Batch：12542 | Loss: 0.05822952091693878\n",
      "Batch：12543 | Loss: 0.0666845515370369\n",
      "Batch：12544 | Loss: 0.05326268449425697\n",
      "Batch：12545 | Loss: 0.06471604108810425\n",
      "Batch：12546 | Loss: 0.06980407983064651\n",
      "Batch：12547 | Loss: 0.060764845460653305\n",
      "Batch：12548 | Loss: 0.06390991806983948\n",
      "Batch：12549 | Loss: 0.05228038504719734\n",
      "Batch：12550 | Loss: 0.06587458401918411\n",
      "Batch：12551 | Loss: 0.0680982917547226\n",
      "Batch：12552 | Loss: 0.05569873005151749\n",
      "Batch：12553 | Loss: 0.06500661373138428\n",
      "Batch：12554 | Loss: 0.0637095719575882\n",
      "Batch：12555 | Loss: 0.06456020474433899\n",
      "Batch：12556 | Loss: 0.07144881784915924\n",
      "Batch：12557 | Loss: 0.07690704613924026\n",
      "Batch：12558 | Loss: 0.054569631814956665\n",
      "Batch：12559 | Loss: 0.055959928780794144\n",
      "Batch：12560 | Loss: 0.06792647391557693\n",
      "Batch：12561 | Loss: 0.0676785260438919\n",
      "Batch：12562 | Loss: 0.06273287534713745\n",
      "Batch：12563 | Loss: 0.06345609575510025\n",
      "Batch：12564 | Loss: 0.06062495708465576\n",
      "Batch：12565 | Loss: 0.06747861951589584\n",
      "Batch：12566 | Loss: 0.06419935077428818\n",
      "Batch：12567 | Loss: 0.061494506895542145\n",
      "Batch：12568 | Loss: 0.0600249283015728\n",
      "Batch：12569 | Loss: 0.06184808909893036\n",
      "Batch：12570 | Loss: 0.06033265218138695\n",
      "Batch：12571 | Loss: 0.06085352599620819\n",
      "Batch：12572 | Loss: 0.07875590026378632\n",
      "Batch：12573 | Loss: 0.06657382100820541\n",
      "Batch：12574 | Loss: 0.056574199348688126\n",
      "Batch：12575 | Loss: 0.053914256393909454\n",
      "Batch：12576 | Loss: 0.06580380350351334\n",
      "Batch：12577 | Loss: 0.06502773612737656\n",
      "Batch：12578 | Loss: 0.05441110581159592\n",
      "Batch：12579 | Loss: 0.07176794111728668\n",
      "Batch：12580 | Loss: 0.06335990130901337\n",
      "Batch：12581 | Loss: 0.05076974257826805\n",
      "Batch：12582 | Loss: 0.06143591180443764\n",
      "Batch：12583 | Loss: 0.0485881045460701\n",
      "Batch：12584 | Loss: 0.05626230686903\n",
      "Batch：12585 | Loss: 0.06672985851764679\n",
      "Batch：12586 | Loss: 0.059172749519348145\n",
      "Batch：12587 | Loss: 0.05866077169775963\n",
      "Batch：12588 | Loss: 0.0664418414235115\n",
      "Batch：12589 | Loss: 0.06670566648244858\n",
      "Batch：12590 | Loss: 0.05990825220942497\n",
      "Batch：12591 | Loss: 0.062181610614061356\n",
      "Batch：12592 | Loss: 0.06531362980604172\n",
      "Batch：12593 | Loss: 0.06103687360882759\n",
      "Batch：12594 | Loss: 0.06224441900849342\n",
      "Batch：12595 | Loss: 0.05918106064200401\n",
      "Batch：12596 | Loss: 0.061045706272125244\n",
      "Batch：12597 | Loss: 0.056223347783088684\n",
      "Batch：12598 | Loss: 0.06327798217535019\n",
      "Batch：12599 | Loss: 0.0619584396481514\n",
      "Batch：12600 | Loss: 0.05179612338542938\n",
      "Batch：12601 | Loss: 0.06920501589775085\n",
      "Batch：12602 | Loss: 0.058080628514289856\n",
      "Batch：12603 | Loss: 0.05339259281754494\n",
      "Batch：12604 | Loss: 0.07417874038219452\n",
      "Batch：12605 | Loss: 0.06884440034627914\n",
      "Batch：12606 | Loss: 0.06157485395669937\n",
      "Batch：12607 | Loss: 0.06466995179653168\n",
      "Batch：12608 | Loss: 0.04936129227280617\n",
      "Batch：12609 | Loss: 0.06543445587158203\n",
      "Batch：12610 | Loss: 0.05499444156885147\n",
      "Batch：12611 | Loss: 0.06845902651548386\n",
      "Batch：12612 | Loss: 0.06063764542341232\n",
      "Batch：12613 | Loss: 0.06149521842598915\n",
      "Batch：12614 | Loss: 0.06998319923877716\n",
      "Batch：12615 | Loss: 0.06952544301748276\n",
      "Batch：12616 | Loss: 0.0535629577934742\n",
      "Batch：12617 | Loss: 0.06004603952169418\n",
      "Batch：12618 | Loss: 0.056753214448690414\n",
      "Batch：12619 | Loss: 0.06774444878101349\n",
      "Batch：12620 | Loss: 0.05892288312315941\n",
      "Batch：12621 | Loss: 0.059272632002830505\n",
      "Batch：12622 | Loss: 0.06922203302383423\n",
      "Batch：12623 | Loss: 0.058184605091810226\n",
      "Batch：12624 | Loss: 0.04402356967329979\n",
      "Batch：12625 | Loss: 0.057237766683101654\n",
      "Batch：12626 | Loss: 0.06410672515630722\n",
      "Batch：12627 | Loss: 0.06019926443696022\n",
      "Batch：12628 | Loss: 0.057462453842163086\n",
      "Batch：12629 | Loss: 0.05805199220776558\n",
      "Batch：12630 | Loss: 0.06765764206647873\n",
      "Batch：12631 | Loss: 0.06077362969517708\n",
      "Batch：12632 | Loss: 0.05531172454357147\n",
      "Batch：12633 | Loss: 0.07048927247524261\n",
      "Batch：12634 | Loss: 0.05768955871462822\n",
      "Batch：12635 | Loss: 0.0513339526951313\n",
      "Batch：12636 | Loss: 0.06357589364051819\n",
      "Batch：12637 | Loss: 0.0706404596567154\n",
      "Batch：12638 | Loss: 0.05722678452730179\n",
      "Batch：12639 | Loss: 0.05369095876812935\n",
      "Batch：12640 | Loss: 0.05759195238351822\n",
      "Batch：12641 | Loss: 0.049746397882699966\n",
      "Batch：12642 | Loss: 0.06622672826051712\n",
      "Batch：12643 | Loss: 0.06608612090349197\n",
      "Batch：12644 | Loss: 0.06343986093997955\n",
      "Batch：12645 | Loss: 0.06750965863466263\n",
      "Batch：12646 | Loss: 0.060783710330724716\n",
      "Batch：12647 | Loss: 0.07561013847589493\n",
      "Batch：12648 | Loss: 0.0625162124633789\n",
      "Batch：12649 | Loss: 0.06354992836713791\n",
      "Batch：12650 | Loss: 0.06548871845006943\n",
      "Batch：12651 | Loss: 0.06254000216722488\n",
      "Batch：12652 | Loss: 0.05586523562669754\n",
      "Batch：12653 | Loss: 0.06841328740119934\n",
      "Batch：12654 | Loss: 0.05960271507501602\n",
      "Batch：12655 | Loss: 0.06090342998504639\n",
      "Batch：12656 | Loss: 0.06283745914697647\n",
      "Batch：12657 | Loss: 0.07481692731380463\n",
      "Batch：12658 | Loss: 0.06319649517536163\n",
      "Batch：12659 | Loss: 0.05337120592594147\n",
      "Batch：12660 | Loss: 0.06040123850107193\n",
      "Batch：12661 | Loss: 0.061682455241680145\n",
      "Batch：12662 | Loss: 0.06170157715678215\n",
      "Batch：12663 | Loss: 0.06761050224304199\n",
      "Batch：12664 | Loss: 0.05438809469342232\n",
      "Batch：12665 | Loss: 0.05837976932525635\n",
      "Batch：12666 | Loss: 0.06087560951709747\n",
      "Batch：12667 | Loss: 0.06092839315533638\n",
      "Batch：12668 | Loss: 0.06307945400476456\n",
      "Batch：12669 | Loss: 0.06897293031215668\n",
      "Batch：12670 | Loss: 0.057803068310022354\n",
      "Batch：12671 | Loss: 0.06002290919423103\n",
      "Batch：12672 | Loss: 0.051259081810712814\n",
      "Batch：12673 | Loss: 0.05772384628653526\n",
      "Batch：12674 | Loss: 0.06346122175455093\n",
      "Batch：12675 | Loss: 0.05740141123533249\n",
      "Batch：12676 | Loss: 0.06051425635814667\n",
      "Batch：12677 | Loss: 0.06665722280740738\n",
      "Batch：12678 | Loss: 0.06097760424017906\n",
      "Batch：12679 | Loss: 0.06464189291000366\n",
      "Batch：12680 | Loss: 0.05511143431067467\n",
      "Batch：12681 | Loss: 0.06811217963695526\n",
      "Batch：12682 | Loss: 0.06336186826229095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：12683 | Loss: 0.06615050882101059\n",
      "Batch：12684 | Loss: 0.06065790727734566\n",
      "Batch：12685 | Loss: 0.05739349126815796\n",
      "Batch：12686 | Loss: 0.07037369161844254\n",
      "Batch：12687 | Loss: 0.06255953758955002\n",
      "Batch：12688 | Loss: 0.0649440735578537\n",
      "Batch：12689 | Loss: 0.06786391139030457\n",
      "Batch：12690 | Loss: 0.05502591282129288\n",
      "Batch：12691 | Loss: 0.05644957348704338\n",
      "Batch：12692 | Loss: 0.05824270471930504\n",
      "Batch：12693 | Loss: 0.0630641058087349\n",
      "Batch：12694 | Loss: 0.05567649379372597\n",
      "Batch：12695 | Loss: 0.06022283807396889\n",
      "Batch：12696 | Loss: 0.051373280584812164\n",
      "Batch：12697 | Loss: 0.05770770087838173\n",
      "Batch：12698 | Loss: 0.07200077176094055\n",
      "Batch：12699 | Loss: 0.05413782596588135\n",
      "Batch：12700 | Loss: 0.05869638919830322\n",
      "Batch：12701 | Loss: 0.057065922766923904\n",
      "Batch：12702 | Loss: 0.053389668464660645\n",
      "Batch：12703 | Loss: 0.07892915606498718\n",
      "Batch：12704 | Loss: 0.06073525547981262\n",
      "Batch：12705 | Loss: 0.0547599233686924\n",
      "Batch：12706 | Loss: 0.06637817621231079\n",
      "Batch：12707 | Loss: 0.05745343863964081\n",
      "Batch：12708 | Loss: 0.05727940797805786\n",
      "Batch：12709 | Loss: 0.05719330906867981\n",
      "Batch：12710 | Loss: 0.05816791579127312\n",
      "Batch：12711 | Loss: 0.04792589321732521\n",
      "Batch：12712 | Loss: 0.07130491733551025\n",
      "Batch：12713 | Loss: 0.06692385673522949\n",
      "Batch：12714 | Loss: 0.04912649095058441\n",
      "Batch：12715 | Loss: 0.05934329330921173\n",
      "Batch：12716 | Loss: 0.06702949851751328\n",
      "Batch：12717 | Loss: 0.04947556182742119\n",
      "Batch：12718 | Loss: 0.06076173856854439\n",
      "Batch：12719 | Loss: 0.060175374150276184\n",
      "Batch：12720 | Loss: 0.06130647286772728\n",
      "Batch：12721 | Loss: 0.06131177023053169\n",
      "Batch：12722 | Loss: 0.05745812878012657\n",
      "Batch：12723 | Loss: 0.05192779377102852\n",
      "Batch：12724 | Loss: 0.05846356973052025\n",
      "Batch：12725 | Loss: 0.05085328221321106\n",
      "Batch：12726 | Loss: 0.07322373241186142\n",
      "Batch：12727 | Loss: 0.05750376358628273\n",
      "Batch：12728 | Loss: 0.0596289224922657\n",
      "Batch：12729 | Loss: 0.07278495281934738\n",
      "Batch：12730 | Loss: 0.05373591557145119\n",
      "Batch：12731 | Loss: 0.05859917029738426\n",
      "Batch：12732 | Loss: 0.062085676938295364\n",
      "Batch：12733 | Loss: 0.06742162257432938\n",
      "Batch：12734 | Loss: 0.06338275969028473\n",
      "Batch：12735 | Loss: 0.06706324219703674\n",
      "Batch：12736 | Loss: 0.0569007508456707\n",
      "Batch：12737 | Loss: 0.06599606573581696\n",
      "Batch：12738 | Loss: 0.06820403784513474\n",
      "Batch：12739 | Loss: 0.05873279273509979\n",
      "Batch：12740 | Loss: 0.056922465562820435\n",
      "Batch：12741 | Loss: 0.05722934752702713\n",
      "Batch：12742 | Loss: 0.05089187994599342\n",
      "Batch：12743 | Loss: 0.05719581991434097\n",
      "Batch：12744 | Loss: 0.062379397451877594\n",
      "Batch：12745 | Loss: 0.05665379390120506\n",
      "Batch：12746 | Loss: 0.0598190501332283\n",
      "Batch：12747 | Loss: 0.05755976215004921\n",
      "Batch：12748 | Loss: 0.06017456576228142\n",
      "Batch：12749 | Loss: 0.06421727687120438\n",
      "Batch：12750 | Loss: 0.07139391452074051\n",
      "Batch：12751 | Loss: 0.053268879652023315\n",
      "Batch：12752 | Loss: 0.06972311437129974\n",
      "Batch：12753 | Loss: 0.06527449190616608\n",
      "Batch：12754 | Loss: 0.06600385159254074\n",
      "Batch：12755 | Loss: 0.06849025934934616\n",
      "Batch：12756 | Loss: 0.055226363241672516\n",
      "Batch：12757 | Loss: 0.06313002854585648\n",
      "Batch：12758 | Loss: 0.05894212797284126\n",
      "Batch：12759 | Loss: 0.07229383289813995\n",
      "Batch：12760 | Loss: 0.06150582805275917\n",
      "Batch：12761 | Loss: 0.0657452717423439\n",
      "Batch：12762 | Loss: 0.06419990211725235\n",
      "Batch：12763 | Loss: 0.05152582749724388\n",
      "Batch：12764 | Loss: 0.06970751285552979\n",
      "Batch：12765 | Loss: 0.06082984432578087\n",
      "Batch：12766 | Loss: 0.06043620407581329\n",
      "Batch：12767 | Loss: 0.05487919971346855\n",
      "Batch：12768 | Loss: 0.06443474441766739\n",
      "Batch：12769 | Loss: 0.0573623850941658\n",
      "Batch：12770 | Loss: 0.06919045746326447\n",
      "Batch：12771 | Loss: 0.06180981919169426\n",
      "Batch：12772 | Loss: 0.05849015340209007\n",
      "Batch：12773 | Loss: 0.05611278861761093\n",
      "Batch：12774 | Loss: 0.05796874314546585\n",
      "Batch：12775 | Loss: 0.0531172901391983\n",
      "Batch：12776 | Loss: 0.0673094093799591\n",
      "Batch：12777 | Loss: 0.055491890758275986\n",
      "Batch：12778 | Loss: 0.0678602084517479\n",
      "Batch：12779 | Loss: 0.05784623324871063\n",
      "Batch：12780 | Loss: 0.049083322286605835\n",
      "Batch：12781 | Loss: 0.056899167597293854\n",
      "Batch：12782 | Loss: 0.06198355555534363\n",
      "Batch：12783 | Loss: 0.051750894635915756\n",
      "Batch：12784 | Loss: 0.04934753477573395\n",
      "Batch：12785 | Loss: 0.05967016518115997\n",
      "Batch：12786 | Loss: 0.06594036519527435\n",
      "Batch：12787 | Loss: 0.05854582041501999\n",
      "Batch：12788 | Loss: 0.05796219781041145\n",
      "Batch：12789 | Loss: 0.04952728748321533\n",
      "Batch：12790 | Loss: 0.06258352845907211\n",
      "Batch：12791 | Loss: 0.05425146594643593\n",
      "Batch：12792 | Loss: 0.0587608627974987\n",
      "Batch：12793 | Loss: 0.06340065598487854\n",
      "Batch：12794 | Loss: 0.05882267281413078\n",
      "Batch：12795 | Loss: 0.06521090865135193\n",
      "Batch：12796 | Loss: 0.04934060946106911\n",
      "Batch：12797 | Loss: 0.04853750020265579\n",
      "Batch：12798 | Loss: 0.0476505421102047\n",
      "Batch：12799 | Loss: 0.0625602975487709\n",
      "Batch：12800 | Loss: 0.06405884027481079\n",
      "Batch：12801 | Loss: 0.05990532413125038\n",
      "Batch：12802 | Loss: 0.06550915539264679\n",
      "Batch：12803 | Loss: 0.06752370297908783\n",
      "Batch：12804 | Loss: 0.05397158861160278\n",
      "Batch：12805 | Loss: 0.05708061158657074\n",
      "Batch：12806 | Loss: 0.058999933302402496\n",
      "Batch：12807 | Loss: 0.06540073454380035\n",
      "Batch：12808 | Loss: 0.0657506138086319\n",
      "Batch：12809 | Loss: 0.05891172215342522\n",
      "Batch：12810 | Loss: 0.06298962980508804\n",
      "Batch：12811 | Loss: 0.06619101017713547\n",
      "Batch：12812 | Loss: 0.05167045444250107\n",
      "Batch：12813 | Loss: 0.06079390272498131\n",
      "Batch：12814 | Loss: 0.06859871000051498\n",
      "Batch：12815 | Loss: 0.04834916070103645\n",
      "Batch：12816 | Loss: 0.05979177728295326\n",
      "Batch：12817 | Loss: 0.05620376020669937\n",
      "Batch：12818 | Loss: 0.06002004072070122\n",
      "Batch：12819 | Loss: 0.065727598965168\n",
      "Batch：12820 | Loss: 0.06384389102458954\n",
      "Batch：12821 | Loss: 0.05742193013429642\n",
      "Batch：12822 | Loss: 0.059616412967443466\n",
      "Batch：12823 | Loss: 0.06337475776672363\n",
      "Batch：12824 | Loss: 0.05542552471160889\n",
      "Batch：12825 | Loss: 0.05845118686556816\n",
      "Batch：12826 | Loss: 0.06304607540369034\n",
      "Batch：12827 | Loss: 0.05335218086838722\n",
      "Batch：12828 | Loss: 0.057932719588279724\n",
      "Batch：12829 | Loss: 0.0565158985555172\n",
      "Batch：12830 | Loss: 0.06630010902881622\n",
      "Batch：12831 | Loss: 0.06357423961162567\n",
      "Batch：12832 | Loss: 0.058963265269994736\n",
      "Batch：12833 | Loss: 0.05889473482966423\n",
      "Batch：12834 | Loss: 0.0666927769780159\n",
      "Batch：12835 | Loss: 0.05398579686880112\n",
      "Batch：12836 | Loss: 0.06805574148893356\n",
      "Batch：12837 | Loss: 0.05955832824110985\n",
      "Batch：12838 | Loss: 0.054624032229185104\n",
      "Batch：12839 | Loss: 0.054482847452163696\n",
      "Batch：12840 | Loss: 0.06202299892902374\n",
      "Batch：12841 | Loss: 0.0667266771197319\n",
      "Batch：12842 | Loss: 0.07118386030197144\n",
      "Batch：12843 | Loss: 0.0536964014172554\n",
      "Batch：12844 | Loss: 0.059129077941179276\n",
      "Batch：12845 | Loss: 0.06230366975069046\n",
      "Batch：12846 | Loss: 0.05976344645023346\n",
      "Batch：12847 | Loss: 0.05063324049115181\n",
      "Batch：12848 | Loss: 0.055438537150621414\n",
      "Batch：12849 | Loss: 0.057037148624658585\n",
      "Batch：12850 | Loss: 0.06589814275503159\n",
      "Batch：12851 | Loss: 0.06364981830120087\n",
      "Batch：12852 | Loss: 0.06447356194257736\n",
      "Batch：12853 | Loss: 0.04943940043449402\n",
      "Batch：12854 | Loss: 0.0648791491985321\n",
      "Batch：12855 | Loss: 0.0794999971985817\n",
      "Batch：12856 | Loss: 0.05844258517026901\n",
      "Batch：12857 | Loss: 0.0504872091114521\n",
      "Batch：12858 | Loss: 0.06361811608076096\n",
      "Batch：12859 | Loss: 0.07302817702293396\n",
      "Batch：12860 | Loss: 0.07028768956661224\n",
      "Batch：12861 | Loss: 0.05438545346260071\n",
      "Batch：12862 | Loss: 0.051474735140800476\n",
      "Batch：12863 | Loss: 0.05228358879685402\n",
      "Batch：12864 | Loss: 0.0599818117916584\n",
      "Batch：12865 | Loss: 0.07414086163043976\n",
      "Batch：12866 | Loss: 0.06392702460289001\n",
      "Batch：12867 | Loss: 0.060708314180374146\n",
      "Batch：12868 | Loss: 0.0790424570441246\n",
      "Batch：12869 | Loss: 0.05671112984418869\n",
      "Batch：12870 | Loss: 0.05610579252243042\n",
      "Batch：12871 | Loss: 0.061190973967313766\n",
      "Batch：12872 | Loss: 0.06770084798336029\n",
      "Batch：12873 | Loss: 0.05801110342144966\n",
      "Batch：12874 | Loss: 0.05448126047849655\n",
      "Batch：12875 | Loss: 0.06355496495962143\n",
      "Batch：12876 | Loss: 0.05621565133333206\n",
      "Batch：12877 | Loss: 0.06517599523067474\n",
      "Batch：12878 | Loss: 0.06899763643741608\n",
      "Batch：12879 | Loss: 0.06945546716451645\n",
      "Batch：12880 | Loss: 0.05381299927830696\n",
      "Batch：12881 | Loss: 0.06096866726875305\n",
      "Batch：12882 | Loss: 0.06424951553344727\n",
      "Batch：12883 | Loss: 0.054657503962516785\n",
      "Batch：12884 | Loss: 0.06520512700080872\n",
      "Batch：12885 | Loss: 0.055737558752298355\n",
      "Batch：12886 | Loss: 0.05464606732130051\n",
      "Batch：12887 | Loss: 0.06648313254117966\n",
      "Batch：12888 | Loss: 0.06205574423074722\n",
      "Batch：12889 | Loss: 0.07460092753171921\n",
      "Batch：12890 | Loss: 0.054439447820186615\n",
      "Batch：12891 | Loss: 0.055361852049827576\n",
      "Batch：12892 | Loss: 0.05068334937095642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：12893 | Loss: 0.05839996784925461\n",
      "Batch：12894 | Loss: 0.04954131692647934\n",
      "Batch：12895 | Loss: 0.06002721190452576\n",
      "Batch：12896 | Loss: 0.06368611752986908\n",
      "Batch：12897 | Loss: 0.05340316891670227\n",
      "Batch：12898 | Loss: 0.060921549797058105\n",
      "Batch：12899 | Loss: 0.06017802283167839\n",
      "Batch：12900 | Loss: 0.05709008872509003\n",
      "Batch：12901 | Loss: 0.049962371587753296\n",
      "Batch：12902 | Loss: 0.05753273516893387\n",
      "Batch：12903 | Loss: 0.0662321150302887\n",
      "Batch：12904 | Loss: 0.06146753206849098\n",
      "Batch：12905 | Loss: 0.05180628225207329\n",
      "Batch：12906 | Loss: 0.05776040628552437\n",
      "Batch：12907 | Loss: 0.06573669612407684\n",
      "Batch：12908 | Loss: 0.0647726058959961\n",
      "Batch：12909 | Loss: 0.058138132095336914\n",
      "Batch：12910 | Loss: 0.05908040329813957\n",
      "Batch：12911 | Loss: 0.06671219319105148\n",
      "Batch：12912 | Loss: 0.0605899803340435\n",
      "Batch：12913 | Loss: 0.06049368157982826\n",
      "Batch：12914 | Loss: 0.060322828590869904\n",
      "Batch：12915 | Loss: 0.07159385830163956\n",
      "Batch：12916 | Loss: 0.06185086444020271\n",
      "Batch：12917 | Loss: 0.058726921677589417\n",
      "Batch：12918 | Loss: 0.061109039932489395\n",
      "Batch：12919 | Loss: 0.06914058327674866\n",
      "Batch：12920 | Loss: 0.06259487569332123\n",
      "Batch：12921 | Loss: 0.06403091549873352\n",
      "Batch：12922 | Loss: 0.0687965601682663\n",
      "Batch：12923 | Loss: 0.06259381026029587\n",
      "Batch：12924 | Loss: 0.06442887336015701\n",
      "Batch：12925 | Loss: 0.05637490749359131\n",
      "Batch：12926 | Loss: 0.06850767135620117\n",
      "Batch：12927 | Loss: 0.0564713217318058\n",
      "Batch：12928 | Loss: 0.0668167769908905\n",
      "Batch：12929 | Loss: 0.058612994849681854\n",
      "Batch：12930 | Loss: 0.05871155858039856\n",
      "Batch：12931 | Loss: 0.05631553754210472\n",
      "Batch：12932 | Loss: 0.057577311992645264\n",
      "Batch：12933 | Loss: 0.06639476120471954\n",
      "Batch：12934 | Loss: 0.048633985221385956\n",
      "Batch：12935 | Loss: 0.05827482044696808\n",
      "Batch：12936 | Loss: 0.046304941177368164\n",
      "Batch：12937 | Loss: 0.06339406967163086\n",
      "Batch：12938 | Loss: 0.04952603206038475\n",
      "Batch：12939 | Loss: 0.05924895778298378\n",
      "Batch：12940 | Loss: 0.05596290901303291\n",
      "Batch：12941 | Loss: 0.06573984026908875\n",
      "Batch：12942 | Loss: 0.05047900229692459\n",
      "Batch：12943 | Loss: 0.06530376523733139\n",
      "Batch：12944 | Loss: 0.06020088493824005\n",
      "Batch：12945 | Loss: 0.05938071757555008\n",
      "Batch：12946 | Loss: 0.05912729725241661\n",
      "Batch：12947 | Loss: 0.05953667312860489\n",
      "Batch：12948 | Loss: 0.06717515736818314\n",
      "Batch：12949 | Loss: 0.059205230325460434\n",
      "Batch：12950 | Loss: 0.06952202320098877\n",
      "Batch：12951 | Loss: 0.05816015601158142\n",
      "Batch：12952 | Loss: 0.06681805104017258\n",
      "Batch：12953 | Loss: 0.06707041710615158\n",
      "Batch：12954 | Loss: 0.05712074786424637\n",
      "Batch：12955 | Loss: 0.058737512677907944\n",
      "Batch：12956 | Loss: 0.06162912771105766\n",
      "Batch：12957 | Loss: 0.05770580843091011\n",
      "Batch：12958 | Loss: 0.06140431761741638\n",
      "Batch：12959 | Loss: 0.05310329794883728\n",
      "Batch：12960 | Loss: 0.0543404296040535\n",
      "Batch：12961 | Loss: 0.06839432567358017\n",
      "Batch：12962 | Loss: 0.056932225823402405\n",
      "Batch：12963 | Loss: 0.06468185037374496\n",
      "Batch：12964 | Loss: 0.06435389071702957\n",
      "Batch：12965 | Loss: 0.05552079156041145\n",
      "Batch：12966 | Loss: 0.05495487526059151\n",
      "Batch：12967 | Loss: 0.053592659533023834\n",
      "Batch：12968 | Loss: 0.06420612335205078\n",
      "Batch：12969 | Loss: 0.058724287897348404\n",
      "Batch：12970 | Loss: 0.05911654978990555\n",
      "Batch：12971 | Loss: 0.053932078182697296\n",
      "Batch：12972 | Loss: 0.06861845403909683\n",
      "Batch：12973 | Loss: 0.06570412218570709\n",
      "Batch：12974 | Loss: 0.05526619404554367\n",
      "Batch：12975 | Loss: 0.051236845552921295\n",
      "Batch：12976 | Loss: 0.05831828713417053\n",
      "Batch：12977 | Loss: 0.06009272113442421\n",
      "Batch：12978 | Loss: 0.0658584013581276\n",
      "Batch：12979 | Loss: 0.06366325169801712\n",
      "Batch：12980 | Loss: 0.06914696842432022\n",
      "Batch：12981 | Loss: 0.058692533522844315\n",
      "Batch：12982 | Loss: 0.05589628964662552\n",
      "Batch：12983 | Loss: 0.047839656472206116\n",
      "Batch：12984 | Loss: 0.055533234030008316\n",
      "Batch：12985 | Loss: 0.052747342735528946\n",
      "Batch：12986 | Loss: 0.05126975104212761\n",
      "Batch：12987 | Loss: 0.06281925737857819\n",
      "Batch：12988 | Loss: 0.05006366968154907\n",
      "Batch：12989 | Loss: 0.0461544394493103\n",
      "Batch：12990 | Loss: 0.05908055603504181\n",
      "Batch：12991 | Loss: 0.057423755526542664\n",
      "Batch：12992 | Loss: 0.06148795410990715\n",
      "Batch：12993 | Loss: 0.06506408005952835\n",
      "Batch：12994 | Loss: 0.05376046150922775\n",
      "Batch：12995 | Loss: 0.061854973435401917\n",
      "Batch：12996 | Loss: 0.06382723897695541\n",
      "Batch：12997 | Loss: 0.048892535269260406\n",
      "Batch：12998 | Loss: 0.05478586256504059\n",
      "Batch：12999 | Loss: 0.06001134216785431\n",
      "Batch：13000 | Loss: 0.06286182254552841\n",
      "Batch：13001 | Loss: 0.060064733028411865\n",
      "Batch：13002 | Loss: 0.054983656853437424\n",
      "Batch：13003 | Loss: 0.056461233645677567\n",
      "Batch：13004 | Loss: 0.05687744542956352\n",
      "Batch：13005 | Loss: 0.05594157800078392\n",
      "Batch：13006 | Loss: 0.061416711658239365\n",
      "Batch：13007 | Loss: 0.05096905305981636\n",
      "Batch：13008 | Loss: 0.06082196906208992\n",
      "Batch：13009 | Loss: 0.0577593632042408\n",
      "Batch：13010 | Loss: 0.05891916900873184\n",
      "Batch：13011 | Loss: 0.06808473914861679\n",
      "Batch：13012 | Loss: 0.061439625918865204\n",
      "Batch：13013 | Loss: 0.05744495615363121\n",
      "Batch：13014 | Loss: 0.055232878774404526\n",
      "Batch：13015 | Loss: 0.06249774992465973\n",
      "Batch：13016 | Loss: 0.06725182384252548\n",
      "Batch：13017 | Loss: 0.058400958776474\n",
      "Batch：13018 | Loss: 0.05641564726829529\n",
      "Batch：13019 | Loss: 0.054338399320840836\n",
      "Batch：13020 | Loss: 0.06770570576190948\n",
      "Batch：13021 | Loss: 0.05323563516139984\n",
      "Batch：13022 | Loss: 0.0508536770939827\n",
      "Batch：13023 | Loss: 0.07017391920089722\n",
      "Batch：13024 | Loss: 0.04888221248984337\n",
      "Batch：13025 | Loss: 0.05793076381087303\n",
      "Batch：13026 | Loss: 0.06424930691719055\n",
      "Batch：13027 | Loss: 0.06827782839536667\n",
      "Batch：13028 | Loss: 0.06325415521860123\n",
      "Batch：13029 | Loss: 0.057430002838373184\n",
      "Batch：13030 | Loss: 0.05572071298956871\n",
      "Batch：13031 | Loss: 0.060711272060871124\n",
      "Batch：13032 | Loss: 0.0561734102666378\n",
      "Batch：13033 | Loss: 0.06826949864625931\n",
      "Batch：13034 | Loss: 0.0706973448395729\n",
      "Batch：13035 | Loss: 0.06636166572570801\n",
      "Batch：13036 | Loss: 0.057762645184993744\n",
      "Batch：13037 | Loss: 0.05598476156592369\n",
      "Batch：13038 | Loss: 0.04916080832481384\n",
      "Batch：13039 | Loss: 0.050034839659929276\n",
      "Batch：13040 | Loss: 0.05803821608424187\n",
      "Batch：13041 | Loss: 0.05489205941557884\n",
      "Batch：13042 | Loss: 0.05292627960443497\n",
      "Batch：13043 | Loss: 0.059201858937740326\n",
      "Batch：13044 | Loss: 0.06606179475784302\n",
      "Batch：13045 | Loss: 0.05270598456263542\n",
      "Batch：13046 | Loss: 0.06437190622091293\n",
      "Batch：13047 | Loss: 0.05924573168158531\n",
      "Batch：13048 | Loss: 0.06273841112852097\n",
      "Batch：13049 | Loss: 0.0672655925154686\n",
      "Batch：13050 | Loss: 0.05869128927588463\n",
      "Batch：13051 | Loss: 0.05937904119491577\n",
      "Batch：13052 | Loss: 0.06707785278558731\n",
      "Batch：13053 | Loss: 0.05738552659749985\n",
      "Batch：13054 | Loss: 0.061011869460344315\n",
      "Batch：13055 | Loss: 0.049123622477054596\n",
      "Batch：13056 | Loss: 0.06049796938896179\n",
      "Batch：13057 | Loss: 0.06523267924785614\n",
      "Batch：13058 | Loss: 0.051521070301532745\n",
      "Batch：13059 | Loss: 0.056964024901390076\n",
      "Batch：13060 | Loss: 0.0618291012942791\n",
      "Batch：13061 | Loss: 0.06454887986183167\n",
      "Batch：13062 | Loss: 0.05807073041796684\n",
      "Batch：13063 | Loss: 0.0695110335946083\n",
      "Batch：13064 | Loss: 0.0688486099243164\n",
      "Batch：13065 | Loss: 0.057774618268013\n",
      "Batch：13066 | Loss: 0.057376615703105927\n",
      "Batch：13067 | Loss: 0.05856916308403015\n",
      "Batch：13068 | Loss: 0.05296614021062851\n",
      "Batch：13069 | Loss: 0.06366438418626785\n",
      "Batch：13070 | Loss: 0.06473807245492935\n",
      "Batch：13071 | Loss: 0.057695209980010986\n",
      "Batch：13072 | Loss: 0.05603087320923805\n",
      "Batch：13073 | Loss: 0.06873271614313126\n",
      "Batch：13074 | Loss: 0.06707994639873505\n",
      "Batch：13075 | Loss: 0.05595306307077408\n",
      "Batch：13076 | Loss: 0.056904688477516174\n",
      "Batch：13077 | Loss: 0.06292164325714111\n",
      "Batch：13078 | Loss: 0.06014836207032204\n",
      "Batch：13079 | Loss: 0.05188995227217674\n",
      "Batch：13080 | Loss: 0.06428706645965576\n",
      "Batch：13081 | Loss: 0.055857107043266296\n",
      "Batch：13082 | Loss: 0.05997411534190178\n",
      "Batch：13083 | Loss: 0.05694548413157463\n",
      "Batch：13084 | Loss: 0.06195809692144394\n",
      "Batch：13085 | Loss: 0.05739947780966759\n",
      "Batch：13086 | Loss: 0.057537104934453964\n",
      "Batch：13087 | Loss: 0.057396549731492996\n",
      "Batch：13088 | Loss: 0.05780168995261192\n",
      "Batch：13089 | Loss: 0.05975263565778732\n",
      "Batch：13090 | Loss: 0.06533455103635788\n",
      "Batch：13091 | Loss: 0.05908144637942314\n",
      "Batch：13092 | Loss: 0.056679874658584595\n",
      "Batch：13093 | Loss: 0.06143868342041969\n",
      "Batch：13094 | Loss: 0.05977558717131615\n",
      "Batch：13095 | Loss: 0.05082911252975464\n",
      "Batch：13096 | Loss: 0.07228156179189682\n",
      "Batch：13097 | Loss: 0.05961444601416588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：13098 | Loss: 0.06481307744979858\n",
      "Batch：13099 | Loss: 0.050643645226955414\n",
      "Batch：13100 | Loss: 0.05376530811190605\n",
      "Batch：13101 | Loss: 0.05001010745763779\n",
      "Batch：13102 | Loss: 0.06385421007871628\n",
      "Batch：13103 | Loss: 0.05414323881268501\n",
      "Batch：13104 | Loss: 0.056647889316082\n",
      "Batch：13105 | Loss: 0.04711100086569786\n",
      "Batch：13106 | Loss: 0.061921101063489914\n",
      "Batch：13107 | Loss: 0.05140240490436554\n",
      "Batch：13108 | Loss: 0.05953638628125191\n",
      "Batch：13109 | Loss: 0.06653187423944473\n",
      "Batch：13110 | Loss: 0.0596284382045269\n",
      "Batch：13111 | Loss: 0.05893946439027786\n",
      "Batch：13112 | Loss: 0.06098172068595886\n",
      "Batch：13113 | Loss: 0.07150142639875412\n",
      "Batch：13114 | Loss: 0.06310871988534927\n",
      "Batch：13115 | Loss: 0.05950634554028511\n",
      "Batch：13116 | Loss: 0.06138084828853607\n",
      "Batch：13117 | Loss: 0.0595453642308712\n",
      "Batch：13118 | Loss: 0.05214809626340866\n",
      "Batch：13119 | Loss: 0.061418019235134125\n",
      "Batch：13120 | Loss: 0.06194112077355385\n",
      "Batch：13121 | Loss: 0.05346372351050377\n",
      "Batch：13122 | Loss: 0.05809689313173294\n",
      "Batch：13123 | Loss: 0.05739516019821167\n",
      "Batch：13124 | Loss: 0.05760587006807327\n",
      "Batch：13125 | Loss: 0.05527813732624054\n",
      "Batch：13126 | Loss: 0.06663186848163605\n",
      "Batch：13127 | Loss: 0.06208173558115959\n",
      "Batch：13128 | Loss: 0.06908034533262253\n",
      "Batch：13129 | Loss: 0.05418720468878746\n",
      "Batch：13130 | Loss: 0.05892515555024147\n",
      "Batch：13131 | Loss: 0.05587417632341385\n",
      "Batch：13132 | Loss: 0.06711234152317047\n",
      "Batch：13133 | Loss: 0.06450464576482773\n",
      "Batch：13134 | Loss: 0.05977482721209526\n",
      "Batch：13135 | Loss: 0.06147606298327446\n",
      "Batch：13136 | Loss: 0.05956050381064415\n",
      "Batch：13137 | Loss: 0.04517343267798424\n",
      "Batch：13138 | Loss: 0.0646282508969307\n",
      "Batch：13139 | Loss: 0.05544399097561836\n",
      "Batch：13140 | Loss: 0.06102119758725166\n",
      "Batch：13141 | Loss: 0.061969686299562454\n",
      "Batch：13142 | Loss: 0.04872562736272812\n",
      "Batch：13143 | Loss: 0.057397834956645966\n",
      "Batch：13144 | Loss: 0.052087992429733276\n",
      "Batch：13145 | Loss: 0.06186874210834503\n",
      "Batch：13146 | Loss: 0.05868120864033699\n",
      "Batch：13147 | Loss: 0.05764145776629448\n",
      "Batch：13148 | Loss: 0.054596077650785446\n",
      "Batch：13149 | Loss: 0.06127353012561798\n",
      "Batch：13150 | Loss: 0.06568266451358795\n",
      "Batch：13151 | Loss: 0.06453914195299149\n",
      "Batch：13152 | Loss: 0.06200030446052551\n",
      "Batch：13153 | Loss: 0.06197468936443329\n",
      "Batch：13154 | Loss: 0.049687180668115616\n",
      "Batch：13155 | Loss: 0.065003901720047\n",
      "Batch：13156 | Loss: 0.0631382167339325\n",
      "Batch：13157 | Loss: 0.05948806554079056\n",
      "Batch：13158 | Loss: 0.05400923267006874\n",
      "Batch：13159 | Loss: 0.06559234857559204\n",
      "Batch：13160 | Loss: 0.053072307258844376\n",
      "Batch：13161 | Loss: 0.06142028793692589\n",
      "Batch：13162 | Loss: 0.06069536134600639\n",
      "Batch：13163 | Loss: 0.05994869023561478\n",
      "Batch：13164 | Loss: 0.0584850050508976\n",
      "Batch：13165 | Loss: 0.07142496109008789\n",
      "Batch：13166 | Loss: 0.053106795996427536\n",
      "Batch：13167 | Loss: 0.06657179445028305\n",
      "Batch：13168 | Loss: 0.052584026008844376\n",
      "Batch：13169 | Loss: 0.06320572644472122\n",
      "Batch：13170 | Loss: 0.0596647746860981\n",
      "Batch：13171 | Loss: 0.05884925648570061\n",
      "Batch：13172 | Loss: 0.05460184067487717\n",
      "Batch：13173 | Loss: 0.04874175041913986\n",
      "Batch：13174 | Loss: 0.05714675411581993\n",
      "Batch：13175 | Loss: 0.04579877853393555\n",
      "Batch：13176 | Loss: 0.05839291214942932\n",
      "Batch：13177 | Loss: 0.06259075552225113\n",
      "Batch：13178 | Loss: 0.07059874385595322\n",
      "Batch：13179 | Loss: 0.05839326232671738\n",
      "Batch：13180 | Loss: 0.06450413912534714\n",
      "Batch：13181 | Loss: 0.049986448138952255\n",
      "Batch：13182 | Loss: 0.05033409595489502\n",
      "Batch：13183 | Loss: 0.06444571167230606\n",
      "Batch：13184 | Loss: 0.053688470274209976\n",
      "Batch：13185 | Loss: 0.06218082457780838\n",
      "Batch：13186 | Loss: 0.05071914941072464\n",
      "Batch：13187 | Loss: 0.057904865592718124\n",
      "Batch：13188 | Loss: 0.0682729110121727\n",
      "Batch：13189 | Loss: 0.05923396721482277\n",
      "Batch：13190 | Loss: 0.062198933213949203\n",
      "Batch：13191 | Loss: 0.06427989900112152\n",
      "Batch：13192 | Loss: 0.06155560165643692\n",
      "Batch：13193 | Loss: 0.05334966629743576\n",
      "Batch：13194 | Loss: 0.06885227560997009\n",
      "Batch：13195 | Loss: 0.06610680371522903\n",
      "Batch：13196 | Loss: 0.06019920855760574\n",
      "Batch：13197 | Loss: 0.0570991188287735\n",
      "Batch：13198 | Loss: 0.05127371847629547\n",
      "Batch：13199 | Loss: 0.04929070919752121\n",
      "Batch：13200 | Loss: 0.05653781071305275\n",
      "Batch：13201 | Loss: 0.07793112099170685\n",
      "Batch：13202 | Loss: 0.056440308690071106\n",
      "Batch：13203 | Loss: 0.05878043547272682\n",
      "Batch：13204 | Loss: 0.057726938277482986\n",
      "Batch：13205 | Loss: 0.06678248196840286\n",
      "Batch：13206 | Loss: 0.05564511939883232\n",
      "Batch：13207 | Loss: 0.05300245061516762\n",
      "Batch：13208 | Loss: 0.06116378679871559\n",
      "Batch：13209 | Loss: 0.06256645917892456\n",
      "Batch：13210 | Loss: 0.041892942041158676\n",
      "Batch：13211 | Loss: 0.05389808490872383\n",
      "Batch：13212 | Loss: 0.055758118629455566\n",
      "Batch：13213 | Loss: 0.05529581755399704\n",
      "Batch：13214 | Loss: 0.06069643050432205\n",
      "Batch：13215 | Loss: 0.05961265042424202\n",
      "Batch：13216 | Loss: 0.053337253630161285\n",
      "Batch：13217 | Loss: 0.06812453269958496\n",
      "Batch：13218 | Loss: 0.0556265190243721\n",
      "Batch：13219 | Loss: 0.06539969146251678\n",
      "Batch：13220 | Loss: 0.06153137981891632\n",
      "Batch：13221 | Loss: 0.059106554836034775\n",
      "Batch：13222 | Loss: 0.06677763909101486\n",
      "Batch：13223 | Loss: 0.055522024631500244\n",
      "Batch：13224 | Loss: 0.05499546229839325\n",
      "Batch：13225 | Loss: 0.050025105476379395\n",
      "Batch：13226 | Loss: 0.05642275884747505\n",
      "Batch：13227 | Loss: 0.049405887722969055\n",
      "Batch：13228 | Loss: 0.05951019749045372\n",
      "Batch：13229 | Loss: 0.056803710758686066\n",
      "Batch：13230 | Loss: 0.05464953929185867\n",
      "Batch：13231 | Loss: 0.06255802512168884\n",
      "Batch：13232 | Loss: 0.05341780558228493\n",
      "Batch：13233 | Loss: 0.06849377602338791\n",
      "Batch：13234 | Loss: 0.05657603219151497\n",
      "Batch：13235 | Loss: 0.060975946485996246\n",
      "Batch：13236 | Loss: 0.058382485061883926\n",
      "Batch：13237 | Loss: 0.055565860122442245\n",
      "Batch：13238 | Loss: 0.05003214627504349\n",
      "Batch：13239 | Loss: 0.05734064057469368\n",
      "Batch：13240 | Loss: 0.056880466639995575\n",
      "Batch：13241 | Loss: 0.05774931237101555\n",
      "Batch：13242 | Loss: 0.0677434653043747\n",
      "Batch：13243 | Loss: 0.0644746720790863\n",
      "Batch：13244 | Loss: 0.04960693418979645\n",
      "Batch：13245 | Loss: 0.06275808066129684\n",
      "Batch：13246 | Loss: 0.04898906499147415\n",
      "Batch：13247 | Loss: 0.05184490978717804\n",
      "Batch：13248 | Loss: 0.05820564553141594\n",
      "Batch：13249 | Loss: 0.06658612936735153\n",
      "Batch：13250 | Loss: 0.054564863443374634\n",
      "Batch：13251 | Loss: 0.050915252417325974\n",
      "Batch：13252 | Loss: 0.07959558069705963\n",
      "Batch：13253 | Loss: 0.0726887434720993\n",
      "Batch：13254 | Loss: 0.059993792325258255\n",
      "Batch：13255 | Loss: 0.06530100852251053\n",
      "Batch：13256 | Loss: 0.05288490280508995\n",
      "Batch：13257 | Loss: 0.06136564165353775\n",
      "Batch：13258 | Loss: 0.067662812769413\n",
      "Batch：13259 | Loss: 0.053400468081235886\n",
      "Batch：13260 | Loss: 0.0576687715947628\n",
      "Batch：13261 | Loss: 0.06140035763382912\n",
      "Batch：13262 | Loss: 0.06444893032312393\n",
      "Batch：13263 | Loss: 0.0562310591340065\n",
      "Batch：13264 | Loss: 0.06153736263513565\n",
      "Batch：13265 | Loss: 0.06788481771945953\n",
      "Batch：13266 | Loss: 0.06252879649400711\n",
      "Batch：13267 | Loss: 0.06016720458865166\n",
      "Batch：13268 | Loss: 0.04812039062380791\n",
      "Batch：13269 | Loss: 0.0688311979174614\n",
      "Batch：13270 | Loss: 0.055559396743774414\n",
      "Batch：13271 | Loss: 0.06832993775606155\n",
      "Batch：13272 | Loss: 0.05851438269019127\n",
      "Batch：13273 | Loss: 0.06970108300447464\n",
      "Batch：13274 | Loss: 0.05515671893954277\n",
      "Batch：13275 | Loss: 0.05942661315202713\n",
      "Batch：13276 | Loss: 0.05932042375206947\n",
      "Batch：13277 | Loss: 0.060203876346349716\n",
      "Batch：13278 | Loss: 0.056467652320861816\n",
      "Batch：13279 | Loss: 0.06496776640415192\n",
      "Batch：13280 | Loss: 0.06172454357147217\n",
      "Batch：13281 | Loss: 0.060947783291339874\n",
      "Batch：13282 | Loss: 0.053472328931093216\n",
      "Batch：13283 | Loss: 0.060173310339450836\n",
      "Batch：13284 | Loss: 0.048890914767980576\n",
      "Batch：13285 | Loss: 0.044318392872810364\n",
      "Batch：13286 | Loss: 0.06779741495847702\n",
      "Batch：13287 | Loss: 0.056154292076826096\n",
      "Batch：13288 | Loss: 0.05622714012861252\n",
      "Batch：13289 | Loss: 0.06369302421808243\n",
      "Batch：13290 | Loss: 0.05442497879266739\n",
      "Batch：13291 | Loss: 0.06073502078652382\n",
      "Batch：13292 | Loss: 0.04913577064871788\n",
      "Batch：13293 | Loss: 0.05416421592235565\n",
      "Batch：13294 | Loss: 0.05903509631752968\n",
      "Batch：13295 | Loss: 0.06754063814878464\n",
      "Batch：13296 | Loss: 0.0594051368534565\n",
      "Batch：13297 | Loss: 0.05894387885928154\n",
      "Batch：13298 | Loss: 0.061185531318187714\n",
      "Batch：13299 | Loss: 0.05976385995745659\n",
      "Batch：13300 | Loss: 0.0586361400783062\n",
      "Batch：13301 | Loss: 0.04990314319729805\n",
      "Batch：13302 | Loss: 0.06254874914884567\n",
      "Batch：13303 | Loss: 0.06372767686843872\n",
      "Batch：13304 | Loss: 0.06681263446807861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：13305 | Loss: 0.05369497463107109\n",
      "Batch：13306 | Loss: 0.05157775804400444\n",
      "Batch：13307 | Loss: 0.0652303472161293\n",
      "Batch：13308 | Loss: 0.05986172333359718\n",
      "Batch：13309 | Loss: 0.06291938573122025\n",
      "Batch：13310 | Loss: 0.054646652191877365\n",
      "Batch：13311 | Loss: 0.0554678849875927\n",
      "Batch：13312 | Loss: 0.052043549716472626\n",
      "Batch：13313 | Loss: 0.0569029226899147\n",
      "Batch：13314 | Loss: 0.058729495853185654\n",
      "Batch：13315 | Loss: 0.057428374886512756\n",
      "Batch：13316 | Loss: 0.054239846765995026\n",
      "Batch：13317 | Loss: 0.058765217661857605\n",
      "Batch：13318 | Loss: 0.06877779215574265\n",
      "Batch：13319 | Loss: 0.06232783570885658\n",
      "Batch：13320 | Loss: 0.0718211829662323\n",
      "Batch：13321 | Loss: 0.060846567153930664\n",
      "Batch：13322 | Loss: 0.05298560485243797\n",
      "Batch：13323 | Loss: 0.05680960416793823\n",
      "Batch：13324 | Loss: 0.06477581709623337\n",
      "Batch：13325 | Loss: 0.04985439032316208\n",
      "Batch：13326 | Loss: 0.06413069367408752\n",
      "Batch：13327 | Loss: 0.06038319692015648\n",
      "Batch：13328 | Loss: 0.04861167445778847\n",
      "Batch：13329 | Loss: 0.05382135137915611\n",
      "Batch：13330 | Loss: 0.06110844761133194\n",
      "Batch：13331 | Loss: 0.058933135122060776\n",
      "Batch：13332 | Loss: 0.06185675412416458\n",
      "Batch：13333 | Loss: 0.053239040076732635\n",
      "Batch：13334 | Loss: 0.05160380154848099\n",
      "Batch：13335 | Loss: 0.057417213916778564\n",
      "Batch：13336 | Loss: 0.052975527942180634\n",
      "Batch：13337 | Loss: 0.06782977283000946\n",
      "Batch：13338 | Loss: 0.06206874921917915\n",
      "Batch：13339 | Loss: 0.061496783047914505\n",
      "Batch：13340 | Loss: 0.051970548927783966\n",
      "Batch：13341 | Loss: 0.06014036387205124\n",
      "Batch：13342 | Loss: 0.059671979397535324\n",
      "Batch：13343 | Loss: 0.04548376426100731\n",
      "Batch：13344 | Loss: 0.05715421587228775\n",
      "Batch：13345 | Loss: 0.05548270046710968\n",
      "Batch：13346 | Loss: 0.06355161964893341\n",
      "Batch：13347 | Loss: 0.05119892209768295\n",
      "Batch：13348 | Loss: 0.06299003958702087\n",
      "Batch：13349 | Loss: 0.057274363934993744\n",
      "Batch：13350 | Loss: 0.05476529896259308\n",
      "Batch：13351 | Loss: 0.06345342099666595\n",
      "Batch：13352 | Loss: 0.058086443692445755\n",
      "Batch：13353 | Loss: 0.05702918395400047\n",
      "Batch：13354 | Loss: 0.06064867228269577\n",
      "Batch：13355 | Loss: 0.05451475828886032\n",
      "Batch：13356 | Loss: 0.06510207056999207\n",
      "Batch：13357 | Loss: 0.07172096520662308\n",
      "Batch：13358 | Loss: 0.0588359534740448\n",
      "Batch：13359 | Loss: 0.05446070432662964\n",
      "Batch：13360 | Loss: 0.055556364357471466\n",
      "Batch：13361 | Loss: 0.05709968879818916\n",
      "Batch：13362 | Loss: 0.054393064230680466\n",
      "Batch：13363 | Loss: 0.060428883880376816\n",
      "Batch：13364 | Loss: 0.053424347192049026\n",
      "Batch：13365 | Loss: 0.06030571460723877\n",
      "Batch：13366 | Loss: 0.059652041643857956\n",
      "Batch：13367 | Loss: 0.0517452172935009\n",
      "Batch：13368 | Loss: 0.059788502752780914\n",
      "Batch：13369 | Loss: 0.0716504231095314\n",
      "Batch：13370 | Loss: 0.058560870587825775\n",
      "Batch：13371 | Loss: 0.05903742462396622\n",
      "Batch：13372 | Loss: 0.06258995831012726\n",
      "Batch：13373 | Loss: 0.05593418702483177\n",
      "Batch：13374 | Loss: 0.068682000041008\n",
      "Batch：13375 | Loss: 0.061176519840955734\n",
      "Batch：13376 | Loss: 0.058318428695201874\n",
      "Batch：13377 | Loss: 0.06028647720813751\n",
      "Batch：13378 | Loss: 0.07180722802877426\n",
      "Batch：13379 | Loss: 0.06023101881146431\n",
      "Batch：13380 | Loss: 0.06577497720718384\n",
      "Batch：13381 | Loss: 0.0521998293697834\n",
      "Batch：13382 | Loss: 0.0690988227725029\n",
      "Batch：13383 | Loss: 0.063385508954525\n",
      "Batch：13384 | Loss: 0.04903247952461243\n",
      "Batch：13385 | Loss: 0.06112539768218994\n",
      "Batch：13386 | Loss: 0.058474425226449966\n",
      "Batch：13387 | Loss: 0.06072428449988365\n",
      "Batch：13388 | Loss: 0.05656560882925987\n",
      "Batch：13389 | Loss: 0.05682697892189026\n",
      "Batch：13390 | Loss: 0.05611158162355423\n",
      "Batch：13391 | Loss: 0.05907365679740906\n",
      "Batch：13392 | Loss: 0.05841720104217529\n",
      "Batch：13393 | Loss: 0.05241779610514641\n",
      "Batch：13394 | Loss: 0.0623619481921196\n",
      "Batch：13395 | Loss: 0.057880666106939316\n",
      "Batch：13396 | Loss: 0.05576946958899498\n",
      "Batch：13397 | Loss: 0.0616658516228199\n",
      "Batch：13398 | Loss: 0.058116525411605835\n",
      "Batch：13399 | Loss: 0.05968962609767914\n",
      "Batch：13400 | Loss: 0.050955742597579956\n",
      "Batch：13401 | Loss: 0.06519340723752975\n",
      "Batch：13402 | Loss: 0.061813075095415115\n",
      "Batch：13403 | Loss: 0.05417657271027565\n",
      "Batch：13404 | Loss: 0.05097990855574608\n",
      "Batch：13405 | Loss: 0.05476771667599678\n",
      "Batch：13406 | Loss: 0.06281204521656036\n",
      "Batch：13407 | Loss: 0.04554598405957222\n",
      "Batch：13408 | Loss: 0.058566682040691376\n",
      "Batch：13409 | Loss: 0.06008205562829971\n",
      "Batch：13410 | Loss: 0.058208491653203964\n",
      "Batch：13411 | Loss: 0.06293721497058868\n",
      "Batch：13412 | Loss: 0.06926273554563522\n",
      "Batch：13413 | Loss: 0.05304383859038353\n",
      "Batch：13414 | Loss: 0.06927716732025146\n",
      "Batch：13415 | Loss: 0.050792183727025986\n",
      "Batch：13416 | Loss: 0.045305948704481125\n",
      "Batch：13417 | Loss: 0.05674184113740921\n",
      "Batch：13418 | Loss: 0.06837255507707596\n",
      "Batch：13419 | Loss: 0.05722616985440254\n",
      "Batch：13420 | Loss: 0.051236484199762344\n",
      "Batch：13421 | Loss: 0.06409206986427307\n",
      "Batch：13422 | Loss: 0.05790390446782112\n",
      "Batch：13423 | Loss: 0.057860080152750015\n",
      "Batch：13424 | Loss: 0.04827960208058357\n",
      "Batch：13425 | Loss: 0.05520125851035118\n",
      "Batch：13426 | Loss: 0.05028146132826805\n",
      "Batch：13427 | Loss: 0.05447755008935928\n",
      "Batch：13428 | Loss: 0.055721480399370193\n",
      "Batch：13429 | Loss: 0.05290475860238075\n",
      "Batch：13430 | Loss: 0.045790400356054306\n",
      "Batch：13431 | Loss: 0.05214596912264824\n",
      "Batch：13432 | Loss: 0.05172070115804672\n",
      "Batch：13433 | Loss: 0.06254655122756958\n",
      "Batch：13434 | Loss: 0.05640816688537598\n",
      "Batch：13435 | Loss: 0.05574634671211243\n",
      "Batch：13436 | Loss: 0.05974680557847023\n",
      "Batch：13437 | Loss: 0.05301149562001228\n",
      "Batch：13438 | Loss: 0.05565354973077774\n",
      "Batch：13439 | Loss: 0.06535657495260239\n",
      "Batch：13440 | Loss: 0.058274056762456894\n",
      "Batch：13441 | Loss: 0.06589733064174652\n",
      "Batch：13442 | Loss: 0.05513943359255791\n",
      "Batch：13443 | Loss: 0.059409718960523605\n",
      "Batch：13444 | Loss: 0.05432441830635071\n",
      "Batch：13445 | Loss: 0.062308795750141144\n",
      "Batch：13446 | Loss: 0.048748284578323364\n",
      "Batch：13447 | Loss: 0.053155262023210526\n",
      "Batch：13448 | Loss: 0.06859719753265381\n",
      "Batch：13449 | Loss: 0.06098945066332817\n",
      "Batch：13450 | Loss: 0.05640044063329697\n",
      "Batch：13451 | Loss: 0.05257850140333176\n",
      "Batch：13452 | Loss: 0.06261494010686874\n",
      "Batch：13453 | Loss: 0.0630350187420845\n",
      "Batch：13454 | Loss: 0.05245354026556015\n",
      "Batch：13455 | Loss: 0.07190237194299698\n",
      "Batch：13456 | Loss: 0.0568033792078495\n",
      "Batch：13457 | Loss: 0.05470426008105278\n",
      "Batch：13458 | Loss: 0.0526459701359272\n",
      "Batch：13459 | Loss: 0.06553437560796738\n",
      "Batch：13460 | Loss: 0.05939459055662155\n",
      "Batch：13461 | Loss: 0.06048601120710373\n",
      "Batch：13462 | Loss: 0.05651652067899704\n",
      "Batch：13463 | Loss: 0.0592452809214592\n",
      "Batch：13464 | Loss: 0.07053514569997787\n",
      "Batch：13465 | Loss: 0.04906516894698143\n",
      "Batch：13466 | Loss: 0.05473925545811653\n",
      "Batch：13467 | Loss: 0.05702383443713188\n",
      "Batch：13468 | Loss: 0.07455021142959595\n",
      "Batch：13469 | Loss: 0.05337199941277504\n",
      "Batch：13470 | Loss: 0.06346666067838669\n",
      "Batch：13471 | Loss: 0.06408191472291946\n",
      "Batch：13472 | Loss: 0.06311558187007904\n",
      "Batch：13473 | Loss: 0.05305042490363121\n",
      "Batch：13474 | Loss: 0.052448634058237076\n",
      "Batch：13475 | Loss: 0.052828215062618256\n",
      "Batch：13476 | Loss: 0.06488725543022156\n",
      "Batch：13477 | Loss: 0.056444160640239716\n",
      "Batch：13478 | Loss: 0.05877041071653366\n",
      "Batch：13479 | Loss: 0.05919351056218147\n",
      "Batch：13480 | Loss: 0.06106771156191826\n",
      "Batch：13481 | Loss: 0.059488121420145035\n",
      "Batch：13482 | Loss: 0.06222842261195183\n",
      "Batch：13483 | Loss: 0.05652818828821182\n",
      "Batch：13484 | Loss: 0.055240243673324585\n",
      "Batch：13485 | Loss: 0.060786839574575424\n",
      "Batch：13486 | Loss: 0.05759051442146301\n",
      "Batch：13487 | Loss: 0.06007931008934975\n",
      "Batch：13488 | Loss: 0.07535114139318466\n",
      "Batch：13489 | Loss: 0.054436370730400085\n",
      "Batch：13490 | Loss: 0.06159167364239693\n",
      "Batch：13491 | Loss: 0.0651988685131073\n",
      "Batch：13492 | Loss: 0.07381750643253326\n",
      "Batch：13493 | Loss: 0.06356685608625412\n",
      "Batch：13494 | Loss: 0.05194694921374321\n",
      "Batch：13495 | Loss: 0.05120192468166351\n",
      "Batch：13496 | Loss: 0.05675378441810608\n",
      "Batch：13497 | Loss: 0.0597088523209095\n",
      "Batch：13498 | Loss: 0.061014849692583084\n",
      "Batch：13499 | Loss: 0.06247779354453087\n",
      "Batch：13500 | Loss: 0.05753596872091293\n",
      "Batch：13501 | Loss: 0.054970163851976395\n",
      "Batch：13502 | Loss: 0.06301163882017136\n",
      "Batch：13503 | Loss: 0.05102468654513359\n",
      "Batch：13504 | Loss: 0.06093953549861908\n",
      "Batch：13505 | Loss: 0.06051498278975487\n",
      "Batch：13506 | Loss: 0.059010449796915054\n",
      "Batch：13507 | Loss: 0.057350464165210724\n",
      "Batch：13508 | Loss: 0.06011755391955376\n",
      "Batch：13509 | Loss: 0.056661609560251236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：13510 | Loss: 0.05890387296676636\n",
      "Batch：13511 | Loss: 0.05822072923183441\n",
      "Batch：13512 | Loss: 0.0643615648150444\n",
      "Batch：13513 | Loss: 0.05911584571003914\n",
      "Batch：13514 | Loss: 0.05747445672750473\n",
      "Batch：13515 | Loss: 0.051417481154203415\n",
      "Batch：13516 | Loss: 0.05162128806114197\n",
      "Batch：13517 | Loss: 0.05835550278425217\n",
      "Batch：13518 | Loss: 0.06325118243694305\n",
      "Batch：13519 | Loss: 0.06055653840303421\n",
      "Batch：13520 | Loss: 0.05763828381896019\n",
      "Batch：13521 | Loss: 0.055308688431978226\n",
      "Batch：13522 | Loss: 0.05926498398184776\n",
      "Batch：13523 | Loss: 0.06636857986450195\n",
      "Batch：13524 | Loss: 0.05735807120800018\n",
      "Batch：13525 | Loss: 0.061277836561203\n",
      "Batch：13526 | Loss: 0.05846722424030304\n",
      "Batch：13527 | Loss: 0.044358666986227036\n",
      "Batch：13528 | Loss: 0.051487527787685394\n",
      "Batch：13529 | Loss: 0.06386861950159073\n",
      "Batch：13530 | Loss: 0.06663713604211807\n",
      "Batch：13531 | Loss: 0.060217101126909256\n",
      "Batch：13532 | Loss: 0.050895556807518005\n",
      "Batch：13533 | Loss: 0.05307747423648834\n",
      "Batch：13534 | Loss: 0.05415015667676926\n",
      "Batch：13535 | Loss: 0.05478290840983391\n",
      "Batch：13536 | Loss: 0.04706721007823944\n",
      "Batch：13537 | Loss: 0.05362359434366226\n",
      "Batch：13538 | Loss: 0.0628049448132515\n",
      "Batch：13539 | Loss: 0.06314964592456818\n",
      "Batch：13540 | Loss: 0.05698240175843239\n",
      "Batch：13541 | Loss: 0.07173401862382889\n",
      "Batch：13542 | Loss: 0.06189450994133949\n",
      "Batch：13543 | Loss: 0.06314685195684433\n",
      "Batch：13544 | Loss: 0.06192668527364731\n",
      "Batch：13545 | Loss: 0.049070872366428375\n",
      "Batch：13546 | Loss: 0.05670133978128433\n",
      "Batch：13547 | Loss: 0.05467404052615166\n",
      "Batch：13548 | Loss: 0.05734999477863312\n",
      "Batch：13549 | Loss: 0.06605906784534454\n",
      "Batch：13550 | Loss: 0.06471537053585052\n",
      "Batch：13551 | Loss: 0.055643197149038315\n",
      "Batch：13552 | Loss: 0.060467593371868134\n",
      "Batch：13553 | Loss: 0.05541911721229553\n",
      "Batch：13554 | Loss: 0.055647969245910645\n",
      "Batch：13555 | Loss: 0.06469894200563431\n",
      "Batch：13556 | Loss: 0.06175056844949722\n",
      "Batch：13557 | Loss: 0.06034072861075401\n",
      "Batch：13558 | Loss: 0.06322426348924637\n",
      "Batch：13559 | Loss: 0.060194700956344604\n",
      "Batch：13560 | Loss: 0.0598391629755497\n",
      "Batch：13561 | Loss: 0.05756354704499245\n",
      "Batch：13562 | Loss: 0.06043331325054169\n",
      "Batch：13563 | Loss: 0.052911873906850815\n",
      "Batch：13564 | Loss: 0.049801599234342575\n",
      "Batch：13565 | Loss: 0.05620342493057251\n",
      "Batch：13566 | Loss: 0.06208593770861626\n",
      "Batch：13567 | Loss: 0.052230894565582275\n",
      "Batch：13568 | Loss: 0.05757320672273636\n",
      "Batch：13569 | Loss: 0.0535157211124897\n",
      "Batch：13570 | Loss: 0.05352329462766647\n",
      "Batch：13571 | Loss: 0.06311655789613724\n",
      "Batch：13572 | Loss: 0.06125225871801376\n",
      "Batch：13573 | Loss: 0.051765333861112595\n",
      "Batch：13574 | Loss: 0.0480809360742569\n",
      "Batch：13575 | Loss: 0.050462476909160614\n",
      "Batch：13576 | Loss: 0.05967571958899498\n",
      "Batch：13577 | Loss: 0.058780841529369354\n",
      "Batch：13578 | Loss: 0.06376820057630539\n",
      "Batch：13579 | Loss: 0.06905947625637054\n",
      "Batch：13580 | Loss: 0.059232473373413086\n",
      "Batch：13581 | Loss: 0.05140843614935875\n",
      "Batch：13582 | Loss: 0.052218761295080185\n",
      "Batch：13583 | Loss: 0.05463399738073349\n",
      "Batch：13584 | Loss: 0.0609811507165432\n",
      "Batch：13585 | Loss: 0.056129515171051025\n",
      "Batch：13586 | Loss: 0.06111331656575203\n",
      "Batch：13587 | Loss: 0.05846457928419113\n",
      "Batch：13588 | Loss: 0.052444733679294586\n",
      "Batch：13589 | Loss: 0.057343170046806335\n",
      "Batch：13590 | Loss: 0.05146187171339989\n",
      "Batch：13591 | Loss: 0.057233329862356186\n",
      "Batch：13592 | Loss: 0.06681864708662033\n",
      "Batch：13593 | Loss: 0.05158797279000282\n",
      "Batch：13594 | Loss: 0.053919702768325806\n",
      "Batch：13595 | Loss: 0.05747789517045021\n",
      "Batch：13596 | Loss: 0.05083081126213074\n",
      "Batch：13597 | Loss: 0.06420795619487762\n",
      "Batch：13598 | Loss: 0.05853499472141266\n",
      "Batch：13599 | Loss: 0.05893877148628235\n",
      "Batch：13600 | Loss: 0.0580330565571785\n",
      "Batch：13601 | Loss: 0.06416485458612442\n",
      "Batch：13602 | Loss: 0.0663757249712944\n",
      "Batch：13603 | Loss: 0.06453832238912582\n",
      "Batch：13604 | Loss: 0.05056189373135567\n",
      "Batch：13605 | Loss: 0.05706889182329178\n",
      "Batch：13606 | Loss: 0.05960505083203316\n",
      "Batch：13607 | Loss: 0.05506179854273796\n",
      "Batch：13608 | Loss: 0.055085666477680206\n",
      "Batch：13609 | Loss: 0.053246255964040756\n",
      "Batch：13610 | Loss: 0.05486634373664856\n",
      "Batch：13611 | Loss: 0.04563717171549797\n",
      "Batch：13612 | Loss: 0.05799032375216484\n",
      "Batch：13613 | Loss: 0.05522921308875084\n",
      "Batch：13614 | Loss: 0.053960151970386505\n",
      "Batch：13615 | Loss: 0.05389862135052681\n",
      "Batch：13616 | Loss: 0.05552375316619873\n",
      "Batch：13617 | Loss: 0.05602813512086868\n",
      "Batch：13618 | Loss: 0.052663013339042664\n",
      "Batch：13619 | Loss: 0.05976928770542145\n",
      "Batch：13620 | Loss: 0.06197705119848251\n",
      "Batch：13621 | Loss: 0.06380034238100052\n",
      "Batch：13622 | Loss: 0.0541226901113987\n",
      "Batch：13623 | Loss: 0.05408993363380432\n",
      "Batch：13624 | Loss: 0.05989078804850578\n",
      "Batch：13625 | Loss: 0.055117230862379074\n",
      "Batch：13626 | Loss: 0.05824167653918266\n",
      "Batch：13627 | Loss: 0.06691494584083557\n",
      "Batch：13628 | Loss: 0.06559144705533981\n",
      "Batch：13629 | Loss: 0.06717023998498917\n",
      "Batch：13630 | Loss: 0.057025086134672165\n",
      "Batch：13631 | Loss: 0.05580386146903038\n",
      "Batch：13632 | Loss: 0.0555199459195137\n",
      "Batch：13633 | Loss: 0.06757497787475586\n",
      "Batch：13634 | Loss: 0.052589986473321915\n",
      "Batch：13635 | Loss: 0.06236385181546211\n",
      "Batch：13636 | Loss: 0.049190230667591095\n",
      "Batch：13637 | Loss: 0.04961342364549637\n",
      "Batch：13638 | Loss: 0.051755473017692566\n",
      "Batch：13639 | Loss: 0.05498770251870155\n",
      "Batch：13640 | Loss: 0.058423034846782684\n",
      "Batch：13641 | Loss: 0.04858613386750221\n",
      "Batch：13642 | Loss: 0.057265400886535645\n",
      "Batch：13643 | Loss: 0.0668579638004303\n",
      "Batch：13644 | Loss: 0.04822470620274544\n",
      "Batch：13645 | Loss: 0.04904063418507576\n",
      "Batch：13646 | Loss: 0.06385985016822815\n",
      "Batch：13647 | Loss: 0.06250592321157455\n",
      "Batch：13648 | Loss: 0.06488543748855591\n",
      "Batch：13649 | Loss: 0.07018878310918808\n",
      "Batch：13650 | Loss: 0.05372018367052078\n",
      "Batch：13651 | Loss: 0.054954227060079575\n",
      "Batch：13652 | Loss: 0.06427296251058578\n",
      "Batch：13653 | Loss: 0.05148901417851448\n",
      "Batch：13654 | Loss: 0.061774369329214096\n",
      "Batch：13655 | Loss: 0.07271624356508255\n",
      "Batch：13656 | Loss: 0.05486743152141571\n",
      "Batch：13657 | Loss: 0.05599195137619972\n",
      "Batch：13658 | Loss: 0.0530879907310009\n",
      "Batch：13659 | Loss: 0.06281302124261856\n",
      "Batch：13660 | Loss: 0.05457918345928192\n",
      "Batch：13661 | Loss: 0.05630701780319214\n",
      "Batch：13662 | Loss: 0.06711038202047348\n",
      "Batch：13663 | Loss: 0.06326158344745636\n",
      "Batch：13664 | Loss: 0.07441677898168564\n",
      "Batch：13665 | Loss: 0.058504361659288406\n",
      "Batch：13666 | Loss: 0.06003030389547348\n",
      "Batch：13667 | Loss: 0.04788290336728096\n",
      "Batch：13668 | Loss: 0.04864249750971794\n",
      "Batch：13669 | Loss: 0.06019534170627594\n",
      "Batch：13670 | Loss: 0.04272434860467911\n",
      "Batch：13671 | Loss: 0.05734587088227272\n",
      "Batch：13672 | Loss: 0.05012030899524689\n",
      "Batch：13673 | Loss: 0.047102995216846466\n",
      "Batch：13674 | Loss: 0.05268176272511482\n",
      "Batch：13675 | Loss: 0.05162163823843002\n",
      "Batch：13676 | Loss: 0.05181877687573433\n",
      "Batch：13677 | Loss: 0.054204925894737244\n",
      "Batch：13678 | Loss: 0.0662505105137825\n",
      "Batch：13679 | Loss: 0.050756487995386124\n",
      "Batch：13680 | Loss: 0.06095650792121887\n",
      "Batch：13681 | Loss: 0.06108419597148895\n",
      "Batch：13682 | Loss: 0.06094033643603325\n",
      "Batch：13683 | Loss: 0.05177841708064079\n",
      "Batch：13684 | Loss: 0.056463535875082016\n",
      "Batch：13685 | Loss: 0.06160648912191391\n",
      "Batch：13686 | Loss: 0.07081448286771774\n",
      "Batch：13687 | Loss: 0.05362129583954811\n",
      "Batch：13688 | Loss: 0.05629391968250275\n",
      "Batch：13689 | Loss: 0.07206247746944427\n",
      "Batch：13690 | Loss: 0.05146355181932449\n",
      "Batch：13691 | Loss: 0.04830673336982727\n",
      "Batch：13692 | Loss: 0.06139877438545227\n",
      "Batch：13693 | Loss: 0.058080434799194336\n",
      "Batch：13694 | Loss: 0.05837741121649742\n",
      "Batch：13695 | Loss: 0.05967598780989647\n",
      "Batch：13696 | Loss: 0.06672927737236023\n",
      "Batch：13697 | Loss: 0.056907206773757935\n",
      "Batch：13698 | Loss: 0.057618554681539536\n",
      "Batch：13699 | Loss: 0.06839970499277115\n",
      "Batch：13700 | Loss: 0.06305072456598282\n",
      "Batch：13701 | Loss: 0.05665142089128494\n",
      "Batch：13702 | Loss: 0.05248306319117546\n",
      "Batch：13703 | Loss: 0.048288777470588684\n",
      "Batch：13704 | Loss: 0.04801633581519127\n",
      "Batch：13705 | Loss: 0.06264437735080719\n",
      "Batch：13706 | Loss: 0.05988822504878044\n",
      "Batch：13707 | Loss: 0.053265076130628586\n",
      "Batch：13708 | Loss: 0.05552837625145912\n",
      "Batch：13709 | Loss: 0.06395649164915085\n",
      "Batch：13710 | Loss: 0.059372130781412125\n",
      "Batch：13711 | Loss: 0.06079969182610512\n",
      "Batch：13712 | Loss: 0.04823140427470207\n",
      "Batch：13713 | Loss: 0.06849942356348038\n",
      "Batch：13714 | Loss: 0.054123494774103165\n",
      "Batch：13715 | Loss: 0.05896102264523506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：13716 | Loss: 0.06128586083650589\n",
      "Batch：13717 | Loss: 0.05354790762066841\n",
      "Batch：13718 | Loss: 0.05131591111421585\n",
      "Batch：13719 | Loss: 0.06014837697148323\n",
      "Batch：13720 | Loss: 0.06425263732671738\n",
      "Batch：13721 | Loss: 0.06529872864484787\n",
      "Batch：13722 | Loss: 0.05471732094883919\n",
      "Batch：13723 | Loss: 0.05147482082247734\n",
      "Batch：13724 | Loss: 0.06265955418348312\n",
      "Batch：13725 | Loss: 0.05222160369157791\n",
      "Batch：13726 | Loss: 0.06226425617933273\n",
      "Batch：13727 | Loss: 0.05050450935959816\n",
      "Batch：13728 | Loss: 0.04647209495306015\n",
      "Batch：13729 | Loss: 0.0558461993932724\n",
      "Batch：13730 | Loss: 0.06006264314055443\n",
      "Batch：13731 | Loss: 0.04967183247208595\n",
      "Batch：13732 | Loss: 0.055567480623722076\n",
      "Batch：13733 | Loss: 0.05580554157495499\n",
      "Batch：13734 | Loss: 0.06289166957139969\n",
      "Batch：13735 | Loss: 0.06460810452699661\n",
      "Batch：13736 | Loss: 0.05942663550376892\n",
      "Batch：13737 | Loss: 0.05425605550408363\n",
      "Batch：13738 | Loss: 0.05723296478390694\n",
      "Batch：13739 | Loss: 0.04730615019798279\n",
      "Batch：13740 | Loss: 0.051266785711050034\n",
      "Batch：13741 | Loss: 0.051640577614307404\n",
      "Batch：13742 | Loss: 0.05712345242500305\n",
      "Batch：13743 | Loss: 0.05525902286171913\n",
      "Batch：13744 | Loss: 0.06585528701543808\n",
      "Batch：13745 | Loss: 0.054404910653829575\n",
      "Batch：13746 | Loss: 0.05679415166378021\n",
      "Batch：13747 | Loss: 0.054078105837106705\n",
      "Batch：13748 | Loss: 0.05095507204532623\n",
      "Batch：13749 | Loss: 0.05999256297945976\n",
      "Batch：13750 | Loss: 0.06855134665966034\n",
      "Batch：13751 | Loss: 0.056553665548563004\n",
      "Batch：13752 | Loss: 0.0690603032708168\n",
      "Batch：13753 | Loss: 0.054265160113573074\n",
      "Batch：13754 | Loss: 0.05326191708445549\n",
      "Batch：13755 | Loss: 0.057754550129175186\n",
      "Batch：13756 | Loss: 0.049751974642276764\n",
      "Batch：13757 | Loss: 0.06014451012015343\n",
      "Batch：13758 | Loss: 0.06000247597694397\n",
      "Batch：13759 | Loss: 0.05374922603368759\n",
      "Batch：13760 | Loss: 0.058258045464754105\n",
      "Batch：13761 | Loss: 0.05827553570270538\n",
      "Batch：13762 | Loss: 0.055359385907649994\n",
      "Batch：13763 | Loss: 0.05557014048099518\n",
      "Batch：13764 | Loss: 0.04969583451747894\n",
      "Batch：13765 | Loss: 0.05915587395429611\n",
      "Batch：13766 | Loss: 0.058251332491636276\n",
      "Batch：13767 | Loss: 0.0607701875269413\n",
      "Batch：13768 | Loss: 0.0636381134390831\n",
      "Batch：13769 | Loss: 0.05008966103196144\n",
      "Batch：13770 | Loss: 0.045322809368371964\n",
      "Batch：13771 | Loss: 0.04463643208146095\n",
      "Batch：13772 | Loss: 0.05626969784498215\n",
      "Batch：13773 | Loss: 0.053998712450265884\n",
      "Batch：13774 | Loss: 0.059358712285757065\n",
      "Batch：13775 | Loss: 0.059515684843063354\n",
      "Batch：13776 | Loss: 0.055129602551460266\n",
      "Batch：13777 | Loss: 0.06692071259021759\n",
      "Batch：13778 | Loss: 0.0549565926194191\n",
      "Batch：13779 | Loss: 0.05799395591020584\n",
      "Batch：13780 | Loss: 0.050996582955121994\n",
      "Batch：13781 | Loss: 0.0581204928457737\n",
      "Batch：13782 | Loss: 0.05816248431801796\n",
      "Batch：13783 | Loss: 0.05826061964035034\n",
      "Batch：13784 | Loss: 0.07028626650571823\n",
      "Batch：13785 | Loss: 0.05344312638044357\n",
      "Batch：13786 | Loss: 0.05835258960723877\n",
      "Batch：13787 | Loss: 0.05799239128828049\n",
      "Batch：13788 | Loss: 0.05107215791940689\n",
      "Batch：13789 | Loss: 0.05331273004412651\n",
      "Batch：13790 | Loss: 0.06154560297727585\n",
      "Batch：13791 | Loss: 0.04957093670964241\n",
      "Batch：13792 | Loss: 0.059359222650527954\n",
      "Batch：13793 | Loss: 0.0629194974899292\n",
      "Batch：13794 | Loss: 0.056303996592760086\n",
      "Batch：13795 | Loss: 0.059083037078380585\n",
      "Batch：13796 | Loss: 0.051861900836229324\n",
      "Batch：13797 | Loss: 0.063887819647789\n",
      "Batch：13798 | Loss: 0.06137557327747345\n",
      "Batch：13799 | Loss: 0.061046019196510315\n",
      "Batch：13800 | Loss: 0.061357077211141586\n",
      "Batch：13801 | Loss: 0.05698136240243912\n",
      "Batch：13802 | Loss: 0.04879864305257797\n",
      "Batch：13803 | Loss: 0.06483623385429382\n",
      "Batch：13804 | Loss: 0.061388395726680756\n",
      "Batch：13805 | Loss: 0.05398288741707802\n",
      "Batch：13806 | Loss: 0.051480844616889954\n",
      "Batch：13807 | Loss: 0.0645967572927475\n",
      "Batch：13808 | Loss: 0.061452869325876236\n",
      "Batch：13809 | Loss: 0.06264130771160126\n",
      "Batch：13810 | Loss: 0.06012968719005585\n",
      "Batch：13811 | Loss: 0.05553806945681572\n",
      "Batch：13812 | Loss: 0.04846123605966568\n",
      "Batch：13813 | Loss: 0.05697271600365639\n",
      "Batch：13814 | Loss: 0.05287262052297592\n",
      "Batch：13815 | Loss: 0.05267598479986191\n",
      "Batch：13816 | Loss: 0.05244820564985275\n",
      "Batch：13817 | Loss: 0.057095158845186234\n",
      "Batch：13818 | Loss: 0.06000616401433945\n",
      "Batch：13819 | Loss: 0.057116951793432236\n",
      "Batch：13820 | Loss: 0.07387886196374893\n",
      "Batch：13821 | Loss: 0.0638030469417572\n",
      "Batch：13822 | Loss: 0.06397930532693863\n",
      "Batch：13823 | Loss: 0.0671268180012703\n",
      "Batch：13824 | Loss: 0.05578716844320297\n",
      "Batch：13825 | Loss: 0.06404055655002594\n",
      "Batch：13826 | Loss: 0.05299882963299751\n",
      "Batch：13827 | Loss: 0.05288832634687424\n",
      "Batch：13828 | Loss: 0.055980611592531204\n",
      "Batch：13829 | Loss: 0.05802290886640549\n",
      "Batch：13830 | Loss: 0.05785490944981575\n",
      "Batch：13831 | Loss: 0.05688359588384628\n",
      "Batch：13832 | Loss: 0.05676170811057091\n",
      "Batch：13833 | Loss: 0.05407707765698433\n",
      "Batch：13834 | Loss: 0.06932854652404785\n",
      "Batch：13835 | Loss: 0.061758168041706085\n",
      "Batch：13836 | Loss: 0.0571499839425087\n",
      "Batch：13837 | Loss: 0.04516085237264633\n",
      "Batch：13838 | Loss: 0.05605859309434891\n",
      "Batch：13839 | Loss: 0.04993964731693268\n",
      "Batch：13840 | Loss: 0.066330686211586\n",
      "Batch：13841 | Loss: 0.053093958646059036\n",
      "Batch：13842 | Loss: 0.06455997377634048\n",
      "Batch：13843 | Loss: 0.04821914806962013\n",
      "Batch：13844 | Loss: 0.05689419433474541\n",
      "Batch：13845 | Loss: 0.05250908434391022\n",
      "Batch：13846 | Loss: 0.053148768842220306\n",
      "Batch：13847 | Loss: 0.061537377536296844\n",
      "Batch：13848 | Loss: 0.0540948286652565\n",
      "Batch：13849 | Loss: 0.04477110132575035\n",
      "Batch：13850 | Loss: 0.05743536725640297\n",
      "Batch：13851 | Loss: 0.06673455983400345\n",
      "Batch：13852 | Loss: 0.056634124368429184\n",
      "Batch：13853 | Loss: 0.04778008535504341\n",
      "Batch：13854 | Loss: 0.06602875888347626\n",
      "Batch：13855 | Loss: 0.056506287306547165\n",
      "Batch：13856 | Loss: 0.0626341924071312\n",
      "Batch：13857 | Loss: 0.06543387472629547\n",
      "Batch：13858 | Loss: 0.05910876393318176\n",
      "Batch：13859 | Loss: 0.055548135191202164\n",
      "Batch：13860 | Loss: 0.05646486207842827\n",
      "Batch：13861 | Loss: 0.049759697169065475\n",
      "Batch：13862 | Loss: 0.052915461361408234\n",
      "Batch：13863 | Loss: 0.05888412892818451\n",
      "Batch：13864 | Loss: 0.06888216733932495\n",
      "Batch：13865 | Loss: 0.05871545895934105\n",
      "Batch：13866 | Loss: 0.05589968338608742\n",
      "Batch：13867 | Loss: 0.05930384248495102\n",
      "Batch：13868 | Loss: 0.04562947899103165\n",
      "Batch：13869 | Loss: 0.061728719621896744\n",
      "Batch：13870 | Loss: 0.052403733134269714\n",
      "Batch：13871 | Loss: 0.05525018647313118\n",
      "Batch：13872 | Loss: 0.05735337361693382\n",
      "Batch：13873 | Loss: 0.05691971629858017\n",
      "Batch：13874 | Loss: 0.06232370808720589\n",
      "Batch：13875 | Loss: 0.059667184948921204\n",
      "Batch：13876 | Loss: 0.061963003128767014\n",
      "Batch：13877 | Loss: 0.05062982067465782\n",
      "Batch：13878 | Loss: 0.05977362021803856\n",
      "Batch：13879 | Loss: 0.05571483448147774\n",
      "Batch：13880 | Loss: 0.05082884803414345\n",
      "Batch：13881 | Loss: 0.05314129590988159\n",
      "Batch：13882 | Loss: 0.059133756905794144\n",
      "Batch：13883 | Loss: 0.06725689023733139\n",
      "Batch：13884 | Loss: 0.05243385583162308\n",
      "Batch：13885 | Loss: 0.05908086150884628\n",
      "Batch：13886 | Loss: 0.06114060431718826\n",
      "Batch：13887 | Loss: 0.05144388601183891\n",
      "Batch：13888 | Loss: 0.06357070803642273\n",
      "Batch：13889 | Loss: 0.06270061433315277\n",
      "Batch：13890 | Loss: 0.05278097465634346\n",
      "Batch：13891 | Loss: 0.05808650329709053\n",
      "Batch：13892 | Loss: 0.05725094676017761\n",
      "Batch：13893 | Loss: 0.049626994878053665\n",
      "Batch：13894 | Loss: 0.057242926210165024\n",
      "Batch：13895 | Loss: 0.05108150839805603\n",
      "Batch：13896 | Loss: 0.05166231095790863\n",
      "Batch：13897 | Loss: 0.06137474626302719\n",
      "Batch：13898 | Loss: 0.05799078196287155\n",
      "Batch：13899 | Loss: 0.06461496651172638\n",
      "Batch：13900 | Loss: 0.07101963460445404\n",
      "Batch：13901 | Loss: 0.05940767377614975\n",
      "Batch：13902 | Loss: 0.05859190225601196\n",
      "Batch：13903 | Loss: 0.054663002490997314\n",
      "Batch：13904 | Loss: 0.06113500893115997\n",
      "Batch：13905 | Loss: 0.05972961336374283\n",
      "Batch：13906 | Loss: 0.05123550817370415\n",
      "Batch：13907 | Loss: 0.06678315997123718\n",
      "Batch：13908 | Loss: 0.056871671229600906\n",
      "Batch：13909 | Loss: 0.0555853508412838\n",
      "Batch：13910 | Loss: 0.06216505914926529\n",
      "Batch：13911 | Loss: 0.059379830956459045\n",
      "Batch：13912 | Loss: 0.04803575575351715\n",
      "Batch：13913 | Loss: 0.05503208935260773\n",
      "Batch：13914 | Loss: 0.05625174567103386\n",
      "Batch：13915 | Loss: 0.056075260043144226\n",
      "Batch：13916 | Loss: 0.05269060283899307\n",
      "Batch：13917 | Loss: 0.06315387040376663\n",
      "Batch：13918 | Loss: 0.05560774728655815\n",
      "Batch：13919 | Loss: 0.051036544144153595\n",
      "Batch：13920 | Loss: 0.052112553268671036\n",
      "Batch：13921 | Loss: 0.05920639634132385\n",
      "Batch：13922 | Loss: 0.05200273171067238\n",
      "Batch：13923 | Loss: 0.054930441081523895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：13924 | Loss: 0.04788966849446297\n",
      "Batch：13925 | Loss: 0.05714806914329529\n",
      "Batch：13926 | Loss: 0.06442256271839142\n",
      "Batch：13927 | Loss: 0.05373105779290199\n",
      "Batch：13928 | Loss: 0.05380025506019592\n",
      "Batch：13929 | Loss: 0.05629432573914528\n",
      "Batch：13930 | Loss: 0.052806951105594635\n",
      "Batch：13931 | Loss: 0.05748523026704788\n",
      "Batch：13932 | Loss: 0.054458629339933395\n",
      "Batch：13933 | Loss: 0.059412840753793716\n",
      "Batch：13934 | Loss: 0.0550508126616478\n",
      "Batch：13935 | Loss: 0.0521620437502861\n",
      "Batch：13936 | Loss: 0.05909236520528793\n",
      "Batch：13937 | Loss: 0.05678347125649452\n",
      "Batch：13938 | Loss: 0.05768681690096855\n",
      "Batch：13939 | Loss: 0.045765504240989685\n",
      "Batch：13940 | Loss: 0.05713198333978653\n",
      "Batch：13941 | Loss: 0.05565108358860016\n",
      "Batch：13942 | Loss: 0.05206165835261345\n",
      "Batch：13943 | Loss: 0.06001030281186104\n",
      "Batch：13944 | Loss: 0.054836902767419815\n",
      "Batch：13945 | Loss: 0.06316018849611282\n",
      "Batch：13946 | Loss: 0.06129327416419983\n",
      "Batch：13947 | Loss: 0.07140049338340759\n",
      "Batch：13948 | Loss: 0.058762986212968826\n",
      "Batch：13949 | Loss: 0.06668992340564728\n",
      "Batch：13950 | Loss: 0.06523088365793228\n",
      "Batch：13951 | Loss: 0.062270522117614746\n",
      "Batch：13952 | Loss: 0.06463015079498291\n",
      "Batch：13953 | Loss: 0.047450315207242966\n",
      "Batch：13954 | Loss: 0.05830177292227745\n",
      "Batch：13955 | Loss: 0.05612650513648987\n",
      "Batch：13956 | Loss: 0.06747168302536011\n",
      "Batch：13957 | Loss: 0.06411013007164001\n",
      "Batch：13958 | Loss: 0.055377762764692307\n",
      "Batch：13959 | Loss: 0.056986551731824875\n",
      "Batch：13960 | Loss: 0.05898832157254219\n",
      "Batch：13961 | Loss: 0.05329761281609535\n",
      "Batch：13962 | Loss: 0.05848553031682968\n",
      "Batch：13963 | Loss: 0.058156680315732956\n",
      "Batch：13964 | Loss: 0.04319396987557411\n",
      "Batch：13965 | Loss: 0.06155160069465637\n",
      "Batch：13966 | Loss: 0.052427344024181366\n",
      "Batch：13967 | Loss: 0.0499286912381649\n",
      "Batch：13968 | Loss: 0.05087408423423767\n",
      "Batch：13969 | Loss: 0.043946292251348495\n",
      "Batch：13970 | Loss: 0.06433677673339844\n",
      "Batch：13971 | Loss: 0.048974934965372086\n",
      "Batch：13972 | Loss: 0.05973241105675697\n",
      "Batch：13973 | Loss: 0.05922316387295723\n",
      "Batch：13974 | Loss: 0.05787549912929535\n",
      "Batch：13975 | Loss: 0.059101931750774384\n",
      "Batch：13976 | Loss: 0.05572213605046272\n",
      "Batch：13977 | Loss: 0.05589376762509346\n",
      "Batch：13978 | Loss: 0.063059501349926\n",
      "Batch：13979 | Loss: 0.053582772612571716\n",
      "Batch：13980 | Loss: 0.062209513038396835\n",
      "Batch：13981 | Loss: 0.06544701009988785\n",
      "Batch：13982 | Loss: 0.0562056265771389\n",
      "Batch：13983 | Loss: 0.059190183877944946\n",
      "Batch：13984 | Loss: 0.0635492131114006\n",
      "Batch：13985 | Loss: 0.04936143010854721\n",
      "Batch：13986 | Loss: 0.05290045961737633\n",
      "Batch：13987 | Loss: 0.04930518567562103\n",
      "Batch：13988 | Loss: 0.05704537406563759\n",
      "Batch：13989 | Loss: 0.05437607690691948\n",
      "Batch：13990 | Loss: 0.06822985410690308\n",
      "Batch：13991 | Loss: 0.051601387560367584\n",
      "Batch：13992 | Loss: 0.05644844472408295\n",
      "Batch：13993 | Loss: 0.05535188317298889\n",
      "Batch：13994 | Loss: 0.0629427582025528\n",
      "Batch：13995 | Loss: 0.05237787961959839\n",
      "Batch：13996 | Loss: 0.05599755421280861\n",
      "Batch：13997 | Loss: 0.05427246913313866\n",
      "Batch：13998 | Loss: 0.04589943215250969\n",
      "Batch：13999 | Loss: 0.051922544836997986\n",
      "Batch：14000 | Loss: 0.06519139558076859\n",
      "Batch：14001 | Loss: 0.06253261119127274\n",
      "Batch：14002 | Loss: 0.05635752156376839\n",
      "Batch：14003 | Loss: 0.052256662398576736\n",
      "Batch：14004 | Loss: 0.05914654955267906\n",
      "Batch：14005 | Loss: 0.05073215812444687\n",
      "Batch：14006 | Loss: 0.06064743548631668\n",
      "Batch：14007 | Loss: 0.060771189630031586\n",
      "Batch：14008 | Loss: 0.049975961446762085\n",
      "Batch：14009 | Loss: 0.061030175536870956\n",
      "Batch：14010 | Loss: 0.05617450550198555\n",
      "Batch：14011 | Loss: 0.052232593297958374\n",
      "Batch：14012 | Loss: 0.05449885502457619\n",
      "Batch：14013 | Loss: 0.05269845575094223\n",
      "Batch：14014 | Loss: 0.050464946776628494\n",
      "Batch：14015 | Loss: 0.05587930232286453\n",
      "Batch：14016 | Loss: 0.059357237070798874\n",
      "Batch：14017 | Loss: 0.048323094844818115\n",
      "Batch：14018 | Loss: 0.06264258921146393\n",
      "Batch：14019 | Loss: 0.04980137571692467\n",
      "Batch：14020 | Loss: 0.05635352060198784\n",
      "Batch：14021 | Loss: 0.056006673723459244\n",
      "Batch：14022 | Loss: 0.060367487370967865\n",
      "Batch：14023 | Loss: 0.06090228259563446\n",
      "Batch：14024 | Loss: 0.05340883508324623\n",
      "Batch：14025 | Loss: 0.0637354701757431\n",
      "Batch：14026 | Loss: 0.05177730321884155\n",
      "Batch：14027 | Loss: 0.05742289125919342\n",
      "Batch：14028 | Loss: 0.06090735271573067\n",
      "Batch：14029 | Loss: 0.06620494276285172\n",
      "Batch：14030 | Loss: 0.06532584875822067\n",
      "Batch：14031 | Loss: 0.061078306287527084\n",
      "Batch：14032 | Loss: 0.05881662294268608\n",
      "Batch：14033 | Loss: 0.05118996277451515\n",
      "Batch：14034 | Loss: 0.0625624880194664\n",
      "Batch：14035 | Loss: 0.05154936760663986\n",
      "Batch：14036 | Loss: 0.05501268059015274\n",
      "Batch：14037 | Loss: 0.06009657680988312\n",
      "Batch：14038 | Loss: 0.06022441387176514\n",
      "Batch：14039 | Loss: 0.06507149338722229\n",
      "Batch：14040 | Loss: 0.0568508617579937\n",
      "Batch：14041 | Loss: 0.04977327957749367\n",
      "Batch：14042 | Loss: 0.05796771124005318\n",
      "Batch：14043 | Loss: 0.05659056082367897\n",
      "Batch：14044 | Loss: 0.06000534072518349\n",
      "Batch：14045 | Loss: 0.0578252412378788\n",
      "Batch：14046 | Loss: 0.059672530740499496\n",
      "Batch：14047 | Loss: 0.04580221325159073\n",
      "Batch：14048 | Loss: 0.057356201112270355\n",
      "Batch：14049 | Loss: 0.05096372589468956\n",
      "Batch：14050 | Loss: 0.05526364967226982\n",
      "Batch：14051 | Loss: 0.05391140654683113\n",
      "Batch：14052 | Loss: 0.052080750465393066\n",
      "Batch：14053 | Loss: 0.05160526558756828\n",
      "Batch：14054 | Loss: 0.06354385614395142\n",
      "Batch：14055 | Loss: 0.060598067939281464\n",
      "Batch：14056 | Loss: 0.05193983390927315\n",
      "Batch：14057 | Loss: 0.05171039327979088\n",
      "Batch：14058 | Loss: 0.051873963326215744\n",
      "Batch：14059 | Loss: 0.060081981122493744\n",
      "Batch：14060 | Loss: 0.04915158078074455\n",
      "Batch：14061 | Loss: 0.051511965692043304\n",
      "Batch：14062 | Loss: 0.057202983647584915\n",
      "Batch：14063 | Loss: 0.04795058071613312\n",
      "Batch：14064 | Loss: 0.05163116008043289\n",
      "Batch：14065 | Loss: 0.06462971121072769\n",
      "Batch：14066 | Loss: 0.05800595134496689\n",
      "Batch：14067 | Loss: 0.05644946172833443\n",
      "Batch：14068 | Loss: 0.058533065021038055\n",
      "Batch：14069 | Loss: 0.06272571533918381\n",
      "Batch：14070 | Loss: 0.05995422229170799\n",
      "Batch：14071 | Loss: 0.05471688136458397\n",
      "Batch：14072 | Loss: 0.053296320140361786\n",
      "Batch：14073 | Loss: 0.060620859265327454\n",
      "Batch：14074 | Loss: 0.054100703448057175\n",
      "Batch：14075 | Loss: 0.06693271547555923\n",
      "Batch：14076 | Loss: 0.04451523348689079\n",
      "Batch：14077 | Loss: 0.056815896183252335\n",
      "Batch：14078 | Loss: 0.055603984743356705\n",
      "Batch：14079 | Loss: 0.05831679329276085\n",
      "Batch：14080 | Loss: 0.05052400007843971\n",
      "Batch：14081 | Loss: 0.05892433598637581\n",
      "Batch：14082 | Loss: 0.05897068232297897\n",
      "Batch：14083 | Loss: 0.05363154038786888\n",
      "Batch：14084 | Loss: 0.05504889041185379\n",
      "Batch：14085 | Loss: 0.06119717285037041\n",
      "Batch：14086 | Loss: 0.04792248085141182\n",
      "Batch：14087 | Loss: 0.04818541556596756\n",
      "Batch：14088 | Loss: 0.05836116895079613\n",
      "Batch：14089 | Loss: 0.05715354532003403\n",
      "Batch：14090 | Loss: 0.06100054457783699\n",
      "Batch：14091 | Loss: 0.05827302485704422\n",
      "Batch：14092 | Loss: 0.06339997798204422\n",
      "Batch：14093 | Loss: 0.055716533213853836\n",
      "Batch：14094 | Loss: 0.06365584582090378\n",
      "Batch：14095 | Loss: 0.06574457883834839\n",
      "Batch：14096 | Loss: 0.05384302884340286\n",
      "Batch：14097 | Loss: 0.05259636044502258\n",
      "Batch：14098 | Loss: 0.057731423527002335\n",
      "Batch：14099 | Loss: 0.059175822883844376\n",
      "Batch：14100 | Loss: 0.06841541826725006\n",
      "Batch：14101 | Loss: 0.05464807152748108\n",
      "Batch：14102 | Loss: 0.06056201085448265\n",
      "Batch：14103 | Loss: 0.05065803974866867\n",
      "Batch：14104 | Loss: 0.06364118307828903\n",
      "Batch：14105 | Loss: 0.05931055545806885\n",
      "Batch：14106 | Loss: 0.05286868289113045\n",
      "Batch：14107 | Loss: 0.055368468165397644\n",
      "Batch：14108 | Loss: 0.044514723122119904\n",
      "Batch：14109 | Loss: 0.05223201960325241\n",
      "Batch：14110 | Loss: 0.048952437937259674\n",
      "Batch：14111 | Loss: 0.05840517207980156\n",
      "Batch：14112 | Loss: 0.054347772151231766\n",
      "Batch：14113 | Loss: 0.06600667536258698\n",
      "Batch：14114 | Loss: 0.04910453408956528\n",
      "Batch：14115 | Loss: 0.0551171749830246\n",
      "Batch：14116 | Loss: 0.04835996404290199\n",
      "Batch：14117 | Loss: 0.06522028893232346\n",
      "Batch：14118 | Loss: 0.06350257992744446\n",
      "Batch：14119 | Loss: 0.060807038098573685\n",
      "Batch：14120 | Loss: 0.04314802959561348\n",
      "Batch：14121 | Loss: 0.05864482745528221\n",
      "Batch：14122 | Loss: 0.061223480850458145\n",
      "Batch：14123 | Loss: 0.05447404086589813\n",
      "Batch：14124 | Loss: 0.06208564341068268\n",
      "Batch：14125 | Loss: 0.07078193128108978\n",
      "Batch：14126 | Loss: 0.05728212371468544\n",
      "Batch：14127 | Loss: 0.047357089817523956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：14128 | Loss: 0.056290216743946075\n",
      "Batch：14129 | Loss: 0.05413016676902771\n",
      "Batch：14130 | Loss: 0.046283699572086334\n",
      "Batch：14131 | Loss: 0.05599074065685272\n",
      "Batch：14132 | Loss: 0.05483240634202957\n",
      "Batch：14133 | Loss: 0.055090177804231644\n",
      "Batch：14134 | Loss: 0.06066323444247246\n",
      "Batch：14135 | Loss: 0.05230674520134926\n",
      "Batch：14136 | Loss: 0.06263293325901031\n",
      "Batch：14137 | Loss: 0.06650380045175552\n",
      "Batch：14138 | Loss: 0.05441742017865181\n",
      "Batch：14139 | Loss: 0.06391359120607376\n",
      "Batch：14140 | Loss: 0.05787394195795059\n",
      "Batch：14141 | Loss: 0.057931117713451385\n",
      "Batch：14142 | Loss: 0.05754292756319046\n",
      "Batch：14143 | Loss: 0.05422215536236763\n",
      "Batch：14144 | Loss: 0.061752915382385254\n",
      "Batch：14145 | Loss: 0.053187668323516846\n",
      "Batch：14146 | Loss: 0.05040871724486351\n",
      "Batch：14147 | Loss: 0.06154891848564148\n",
      "Batch：14148 | Loss: 0.05480736866593361\n",
      "Batch：14149 | Loss: 0.062273427844047546\n",
      "Batch：14150 | Loss: 0.05764539912343025\n",
      "Batch：14151 | Loss: 0.053876880556344986\n",
      "Batch：14152 | Loss: 0.054461944848299026\n",
      "Batch：14153 | Loss: 0.06483546644449234\n",
      "Batch：14154 | Loss: 0.05722302198410034\n",
      "Batch：14155 | Loss: 0.06466808170080185\n",
      "Batch：14156 | Loss: 0.06079357862472534\n",
      "Batch：14157 | Loss: 0.05422347038984299\n",
      "Batch：14158 | Loss: 0.04654370993375778\n",
      "Batch：14159 | Loss: 0.057921476662158966\n",
      "Batch：14160 | Loss: 0.06610353291034698\n",
      "Batch：14161 | Loss: 0.053885411471128464\n",
      "Batch：14162 | Loss: 0.04777556657791138\n",
      "Batch：14163 | Loss: 0.05202249065041542\n",
      "Batch：14164 | Loss: 0.06932452321052551\n",
      "Batch：14165 | Loss: 0.058481909334659576\n",
      "Batch：14166 | Loss: 0.05583018437027931\n",
      "Batch：14167 | Loss: 0.05783972144126892\n",
      "Batch：14168 | Loss: 0.06195555627346039\n",
      "Batch：14169 | Loss: 0.06371884793043137\n",
      "Batch：14170 | Loss: 0.04898538067936897\n",
      "Batch：14171 | Loss: 0.05686527490615845\n",
      "Batch：14172 | Loss: 0.06656196713447571\n",
      "Batch：14173 | Loss: 0.054506272077560425\n",
      "Batch：14174 | Loss: 0.05655166506767273\n",
      "Batch：14175 | Loss: 0.06555813550949097\n",
      "Batch：14176 | Loss: 0.05187796428799629\n",
      "Batch：14177 | Loss: 0.05717429891228676\n",
      "Batch：14178 | Loss: 0.04747488722205162\n",
      "Batch：14179 | Loss: 0.05811677500605583\n",
      "Batch：14180 | Loss: 0.051064860075712204\n",
      "Batch：14181 | Loss: 0.05830899998545647\n",
      "Batch：14182 | Loss: 0.061180662363767624\n",
      "Batch：14183 | Loss: 0.050586018711328506\n",
      "Batch：14184 | Loss: 0.06439967453479767\n",
      "Batch：14185 | Loss: 0.06322868168354034\n",
      "Batch：14186 | Loss: 0.061401814222335815\n",
      "Batch：14187 | Loss: 0.04581849277019501\n",
      "Batch：14188 | Loss: 0.05812437832355499\n",
      "Batch：14189 | Loss: 0.05580611154437065\n",
      "Batch：14190 | Loss: 0.06896020472049713\n",
      "Batch：14191 | Loss: 0.05008848011493683\n",
      "Batch：14192 | Loss: 0.06145703047513962\n",
      "Batch：14193 | Loss: 0.05500735342502594\n",
      "Batch：14194 | Loss: 0.061210040003061295\n",
      "Batch：14195 | Loss: 0.05882583558559418\n",
      "Batch：14196 | Loss: 0.05145019292831421\n",
      "Batch：14197 | Loss: 0.062276825308799744\n",
      "Batch：14198 | Loss: 0.06064258888363838\n",
      "Batch：14199 | Loss: 0.051060646772384644\n",
      "Batch：14200 | Loss: 0.059716831892728806\n",
      "Batch：14201 | Loss: 0.052669890224933624\n",
      "Batch：14202 | Loss: 0.05686981603503227\n",
      "Batch：14203 | Loss: 0.05271274596452713\n",
      "Batch：14204 | Loss: 0.04474040865898132\n",
      "Batch：14205 | Loss: 0.06638776510953903\n",
      "Batch：14206 | Loss: 0.060025084763765335\n",
      "Batch：14207 | Loss: 0.05858805403113365\n",
      "Batch：14208 | Loss: 0.06070585921406746\n",
      "Batch：14209 | Loss: 0.049621064215898514\n",
      "Batch：14210 | Loss: 0.05433148145675659\n",
      "Batch：14211 | Loss: 0.07506542652845383\n",
      "Batch：14212 | Loss: 0.046570345759391785\n",
      "Batch：14213 | Loss: 0.05557611584663391\n",
      "Batch：14214 | Loss: 0.06296522170305252\n",
      "Batch：14215 | Loss: 0.06429047882556915\n",
      "Batch：14216 | Loss: 0.05617798864841461\n",
      "Batch：14217 | Loss: 0.05608410760760307\n",
      "Batch：14218 | Loss: 0.056738030165433884\n",
      "Batch：14219 | Loss: 0.06131407245993614\n",
      "Batch：14220 | Loss: 0.06082388386130333\n",
      "Batch：14221 | Loss: 0.05627342686057091\n",
      "Batch：14222 | Loss: 0.05627674236893654\n",
      "Batch：14223 | Loss: 0.05519554764032364\n",
      "Batch：14224 | Loss: 0.05029589682817459\n",
      "Batch：14225 | Loss: 0.053798552602529526\n",
      "Batch：14226 | Loss: 0.04861805588006973\n",
      "Batch：14227 | Loss: 0.049826253205537796\n",
      "Batch：14228 | Loss: 0.05360265076160431\n",
      "Batch：14229 | Loss: 0.05218293145298958\n",
      "Batch：14230 | Loss: 0.05502653867006302\n",
      "Batch：14231 | Loss: 0.06427804380655289\n",
      "Batch：14232 | Loss: 0.05026952177286148\n",
      "Batch：14233 | Loss: 0.05416015535593033\n",
      "Batch：14234 | Loss: 0.05619092658162117\n",
      "Batch：14235 | Loss: 0.05580675229430199\n",
      "Batch：14236 | Loss: 0.04935959726572037\n",
      "Batch：14237 | Loss: 0.053090743720531464\n",
      "Batch：14238 | Loss: 0.05427710339426994\n",
      "Batch：14239 | Loss: 0.05345870926976204\n",
      "Batch：14240 | Loss: 0.0566558763384819\n",
      "Batch：14241 | Loss: 0.05091940239071846\n",
      "Batch：14242 | Loss: 0.06583106517791748\n",
      "Batch：14243 | Loss: 0.05658968538045883\n",
      "Batch：14244 | Loss: 0.061761509627103806\n",
      "Batch：14245 | Loss: 0.04797117039561272\n",
      "Batch：14246 | Loss: 0.05462101101875305\n",
      "Batch：14247 | Loss: 0.050214242190122604\n",
      "Batch：14248 | Loss: 0.04920897260308266\n",
      "Batch：14249 | Loss: 0.04731285944581032\n",
      "Batch：14250 | Loss: 0.04953783005475998\n",
      "Batch：14251 | Loss: 0.05568644031882286\n",
      "Batch：14252 | Loss: 0.06215444952249527\n",
      "Batch：14253 | Loss: 0.059048719704151154\n",
      "Batch：14254 | Loss: 0.06229721009731293\n",
      "Batch：14255 | Loss: 0.05536411330103874\n",
      "Batch：14256 | Loss: 0.05632425844669342\n",
      "Batch：14257 | Loss: 0.07730869203805923\n",
      "Batch：14258 | Loss: 0.051619626581668854\n",
      "Batch：14259 | Loss: 0.06052388623356819\n",
      "Batch：14260 | Loss: 0.06058831885457039\n",
      "Batch：14261 | Loss: 0.05045159533619881\n",
      "Batch：14262 | Loss: 0.06085968017578125\n",
      "Batch：14263 | Loss: 0.059913430362939835\n",
      "Batch：14264 | Loss: 0.052210886031389236\n",
      "Batch：14265 | Loss: 0.06174536421895027\n",
      "Batch：14266 | Loss: 0.052062880247831345\n",
      "Batch：14267 | Loss: 0.050154540687799454\n",
      "Batch：14268 | Loss: 0.056920479983091354\n",
      "Batch：14269 | Loss: 0.06199484318494797\n",
      "Batch：14270 | Loss: 0.05999213457107544\n",
      "Batch：14271 | Loss: 0.059799715876579285\n",
      "Batch：14272 | Loss: 0.05152865871787071\n",
      "Batch：14273 | Loss: 0.06320325285196304\n",
      "Batch：14274 | Loss: 0.050526805222034454\n",
      "Batch：14275 | Loss: 0.053096771240234375\n",
      "Batch：14276 | Loss: 0.06320784240961075\n",
      "Batch：14277 | Loss: 0.06244722381234169\n",
      "Batch：14278 | Loss: 0.04414968192577362\n",
      "Batch：14279 | Loss: 0.046450015157461166\n",
      "Batch：14280 | Loss: 0.06147848442196846\n",
      "Batch：14281 | Loss: 0.050418831408023834\n",
      "Batch：14282 | Loss: 0.05641757324337959\n",
      "Batch：14283 | Loss: 0.049387939274311066\n",
      "Batch：14284 | Loss: 0.05872185155749321\n",
      "Batch：14285 | Loss: 0.05260321870446205\n",
      "Batch：14286 | Loss: 0.05344807356595993\n",
      "Batch：14287 | Loss: 0.05340738967061043\n",
      "Batch：14288 | Loss: 0.050495464354753494\n",
      "Batch：14289 | Loss: 0.05306604877114296\n",
      "Batch：14290 | Loss: 0.05470362678170204\n",
      "Batch：14291 | Loss: 0.0611453503370285\n",
      "Batch：14292 | Loss: 0.047988880425691605\n",
      "Batch：14293 | Loss: 0.06225592643022537\n",
      "Batch：14294 | Loss: 0.047705769538879395\n",
      "Batch：14295 | Loss: 0.05269971117377281\n",
      "Batch：14296 | Loss: 0.05318242684006691\n",
      "Batch：14297 | Loss: 0.061604540795087814\n",
      "Batch：14298 | Loss: 0.06039716675877571\n",
      "Batch：14299 | Loss: 0.07213397324085236\n",
      "Batch：14300 | Loss: 0.05835004523396492\n",
      "Batch：14301 | Loss: 0.055908024311065674\n",
      "Batch：14302 | Loss: 0.049168556928634644\n",
      "Batch：14303 | Loss: 0.05098658800125122\n",
      "Batch：14304 | Loss: 0.061360955238342285\n",
      "Batch：14305 | Loss: 0.05526202172040939\n",
      "Batch：14306 | Loss: 0.05614449828863144\n",
      "Batch：14307 | Loss: 0.048798106610774994\n",
      "Batch：14308 | Loss: 0.04760109260678291\n",
      "Batch：14309 | Loss: 0.04968848079442978\n",
      "Batch：14310 | Loss: 0.0649140402674675\n",
      "Batch：14311 | Loss: 0.05379973724484444\n",
      "Batch：14312 | Loss: 0.07050009816884995\n",
      "Batch：14313 | Loss: 0.042627181857824326\n",
      "Batch：14314 | Loss: 0.06151808053255081\n",
      "Batch：14315 | Loss: 0.048237066715955734\n",
      "Batch：14316 | Loss: 0.056971170008182526\n",
      "Batch：14317 | Loss: 0.04812397062778473\n",
      "Batch：14318 | Loss: 0.04170266166329384\n",
      "Batch：14319 | Loss: 0.056081440299749374\n",
      "Batch：14320 | Loss: 0.056539688259363174\n",
      "Batch：14321 | Loss: 0.058419905602931976\n",
      "Batch：14322 | Loss: 0.06010126695036888\n",
      "Batch：14323 | Loss: 0.05403108149766922\n",
      "Batch：14324 | Loss: 0.06491538137197495\n",
      "Batch：14325 | Loss: 0.05764605104923248\n",
      "Batch：14326 | Loss: 0.06061650067567825\n",
      "Batch：14327 | Loss: 0.056718964129686356\n",
      "Batch：14328 | Loss: 0.05203556641936302\n",
      "Batch：14329 | Loss: 0.060072436928749084\n",
      "Batch：14330 | Loss: 0.05230914428830147\n",
      "Batch：14331 | Loss: 0.06826936453580856\n",
      "Batch：14332 | Loss: 0.05720740184187889\n",
      "Batch：14333 | Loss: 0.057883113622665405\n",
      "Batch：14334 | Loss: 0.04834463819861412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：14335 | Loss: 0.05375286936759949\n",
      "Batch：14336 | Loss: 0.06361529231071472\n",
      "Batch：14337 | Loss: 0.056170374155044556\n",
      "Batch：14338 | Loss: 0.04814735800027847\n",
      "Batch：14339 | Loss: 0.052600860595703125\n",
      "Batch：14340 | Loss: 0.06270752102136612\n",
      "Batch：14341 | Loss: 0.05552518740296364\n",
      "Batch：14342 | Loss: 0.05690748989582062\n",
      "Batch：14343 | Loss: 0.06529954075813293\n",
      "Batch：14344 | Loss: 0.05137323960661888\n",
      "Batch：14345 | Loss: 0.05349119007587433\n",
      "Batch：14346 | Loss: 0.06526338309049606\n",
      "Batch：14347 | Loss: 0.04681030288338661\n",
      "Batch：14348 | Loss: 0.05289667844772339\n",
      "Batch：14349 | Loss: 0.06075424700975418\n",
      "Batch：14350 | Loss: 0.052514318376779556\n",
      "Batch：14351 | Loss: 0.05360013619065285\n",
      "Batch：14352 | Loss: 0.0658140480518341\n",
      "Batch：14353 | Loss: 0.059726886451244354\n",
      "Batch：14354 | Loss: 0.0540657714009285\n",
      "Batch：14355 | Loss: 0.052695371210575104\n",
      "Batch：14356 | Loss: 0.06005905941128731\n",
      "Batch：14357 | Loss: 0.05652128905057907\n",
      "Batch：14358 | Loss: 0.06397711485624313\n",
      "Batch：14359 | Loss: 0.0600670762360096\n",
      "Batch：14360 | Loss: 0.05360284820199013\n",
      "Batch：14361 | Loss: 0.05143125355243683\n",
      "Batch：14362 | Loss: 0.063114233314991\n",
      "Batch：14363 | Loss: 0.047896891832351685\n",
      "Batch：14364 | Loss: 0.05834261327981949\n",
      "Batch：14365 | Loss: 0.05812032148241997\n",
      "Batch：14366 | Loss: 0.055852316319942474\n",
      "Batch：14367 | Loss: 0.06625403463840485\n",
      "Batch：14368 | Loss: 0.05570118501782417\n",
      "Batch：14369 | Loss: 0.05694906413555145\n",
      "Batch：14370 | Loss: 0.04964050278067589\n",
      "Batch：14371 | Loss: 0.0636521726846695\n",
      "Batch：14372 | Loss: 0.05007968097925186\n",
      "Batch：14373 | Loss: 0.047515008598566055\n",
      "Batch：14374 | Loss: 0.05156588554382324\n",
      "Batch：14375 | Loss: 0.05436183512210846\n",
      "Batch：14376 | Loss: 0.06641758233308792\n",
      "Batch：14377 | Loss: 0.04403384402394295\n",
      "Batch：14378 | Loss: 0.05228297784924507\n",
      "Batch：14379 | Loss: 0.05433713644742966\n",
      "Batch：14380 | Loss: 0.055718302726745605\n",
      "Batch：14381 | Loss: 0.05235787853598595\n",
      "Batch：14382 | Loss: 0.05457178130745888\n",
      "Batch：14383 | Loss: 0.05102083459496498\n",
      "Batch：14384 | Loss: 0.055802032351493835\n",
      "Batch：14385 | Loss: 0.05676129087805748\n",
      "Batch：14386 | Loss: 0.05358084663748741\n",
      "Batch：14387 | Loss: 0.05908988416194916\n",
      "Batch：14388 | Loss: 0.05877202749252319\n",
      "Batch：14389 | Loss: 0.05691784620285034\n",
      "Batch：14390 | Loss: 0.06993798911571503\n",
      "Batch：14391 | Loss: 0.05561411380767822\n",
      "Batch：14392 | Loss: 0.056485362350940704\n",
      "Batch：14393 | Loss: 0.05618499591946602\n",
      "Batch：14394 | Loss: 0.05225981026887894\n",
      "Batch：14395 | Loss: 0.055545512586832047\n",
      "Batch：14396 | Loss: 0.053781066089868546\n",
      "Batch：14397 | Loss: 0.05975409224629402\n",
      "Batch：14398 | Loss: 0.05712202936410904\n",
      "Batch：14399 | Loss: 0.05490376055240631\n",
      "Batch：14400 | Loss: 0.048604175448417664\n",
      "Batch：14401 | Loss: 0.06185528635978699\n",
      "Batch：14402 | Loss: 0.06009247899055481\n",
      "Batch：14403 | Loss: 0.056146640330553055\n",
      "Batch：14404 | Loss: 0.05736009031534195\n",
      "Batch：14405 | Loss: 0.05980895087122917\n",
      "Batch：14406 | Loss: 0.046356067061424255\n",
      "Batch：14407 | Loss: 0.06204964593052864\n",
      "Batch：14408 | Loss: 0.059889983385801315\n",
      "Batch：14409 | Loss: 0.06258907914161682\n",
      "Batch：14410 | Loss: 0.05411680042743683\n",
      "Batch：14411 | Loss: 0.054688699543476105\n",
      "Batch：14412 | Loss: 0.05944051221013069\n",
      "Batch：14413 | Loss: 0.052374184131622314\n",
      "Batch：14414 | Loss: 0.056298308074474335\n",
      "Batch：14415 | Loss: 0.055253639817237854\n",
      "Batch：14416 | Loss: 0.056585341691970825\n",
      "Batch：14417 | Loss: 0.058386411517858505\n",
      "Batch：14418 | Loss: 0.05278068408370018\n",
      "Batch：14419 | Loss: 0.05028022080659866\n",
      "Batch：14420 | Loss: 0.05089136213064194\n",
      "Batch：14421 | Loss: 0.05285850539803505\n",
      "Batch：14422 | Loss: 0.05407879501581192\n",
      "Batch：14423 | Loss: 0.05757901817560196\n",
      "Batch：14424 | Loss: 0.05426653102040291\n",
      "Batch：14425 | Loss: 0.05282566696405411\n",
      "Batch：14426 | Loss: 0.060744404792785645\n",
      "Batch：14427 | Loss: 0.05773795396089554\n",
      "Batch：14428 | Loss: 0.05994149670004845\n",
      "Batch：14429 | Loss: 0.05616287142038345\n",
      "Batch：14430 | Loss: 0.05006271228194237\n",
      "Batch：14431 | Loss: 0.05534961819648743\n",
      "Batch：14432 | Loss: 0.05447565019130707\n",
      "Batch：14433 | Loss: 0.06017635390162468\n",
      "Batch：14434 | Loss: 0.050804004073143005\n",
      "Batch：14435 | Loss: 0.05198162794113159\n",
      "Batch：14436 | Loss: 0.04750116541981697\n",
      "Batch：14437 | Loss: 0.05409804731607437\n",
      "Batch：14438 | Loss: 0.056658364832401276\n",
      "Batch：14439 | Loss: 0.04206440597772598\n",
      "Batch：14440 | Loss: 0.055682312697172165\n",
      "Batch：14441 | Loss: 0.054738499224185944\n",
      "Batch：14442 | Loss: 0.052218664437532425\n",
      "Batch：14443 | Loss: 0.05148957297205925\n",
      "Batch：14444 | Loss: 0.059161070734262466\n",
      "Batch：14445 | Loss: 0.04416382685303688\n",
      "Batch：14446 | Loss: 0.045057691633701324\n",
      "Batch：14447 | Loss: 0.06066921353340149\n",
      "Batch：14448 | Loss: 0.055893316864967346\n",
      "Batch：14449 | Loss: 0.057607345283031464\n",
      "Batch：14450 | Loss: 0.04980811849236488\n",
      "Batch：14451 | Loss: 0.05988219007849693\n",
      "Batch：14452 | Loss: 0.056323885917663574\n",
      "Batch：14453 | Loss: 0.05217000097036362\n",
      "Batch：14454 | Loss: 0.04971243068575859\n",
      "Batch：14455 | Loss: 0.05194239318370819\n",
      "Batch：14456 | Loss: 0.049605220556259155\n",
      "Batch：14457 | Loss: 0.0563211515545845\n",
      "Batch：14458 | Loss: 0.04537428915500641\n",
      "Batch：14459 | Loss: 0.052323415875434875\n",
      "Batch：14460 | Loss: 0.055168233811855316\n",
      "Batch：14461 | Loss: 0.053370874375104904\n",
      "Batch：14462 | Loss: 0.043519970029592514\n",
      "Batch：14463 | Loss: 0.060204751789569855\n",
      "Batch：14464 | Loss: 0.06367693841457367\n",
      "Batch：14465 | Loss: 0.05249791592359543\n",
      "Batch：14466 | Loss: 0.05196451395750046\n",
      "Batch：14467 | Loss: 0.06210733950138092\n",
      "Batch：14468 | Loss: 0.046749014407396317\n",
      "Batch：14469 | Loss: 0.056061308830976486\n",
      "Batch：14470 | Loss: 0.05551793798804283\n",
      "Batch：14471 | Loss: 0.0564660020172596\n",
      "Batch：14472 | Loss: 0.05614402890205383\n",
      "Batch：14473 | Loss: 0.07083199918270111\n",
      "Batch：14474 | Loss: 0.053034424781799316\n",
      "Batch：14475 | Loss: 0.05273698270320892\n",
      "Batch：14476 | Loss: 0.05768398940563202\n",
      "Batch：14477 | Loss: 0.06428012251853943\n",
      "Batch：14478 | Loss: 0.0615570992231369\n",
      "Batch：14479 | Loss: 0.05156422778964043\n",
      "Batch：14480 | Loss: 0.04501328989863396\n",
      "Batch：14481 | Loss: 0.04677285626530647\n",
      "Batch：14482 | Loss: 0.05651820823550224\n",
      "Batch：14483 | Loss: 0.05384295433759689\n",
      "Batch：14484 | Loss: 0.05169035866856575\n",
      "Batch：14485 | Loss: 0.05235700309276581\n",
      "Batch：14486 | Loss: 0.05248767510056496\n",
      "Batch：14487 | Loss: 0.057646494358778\n",
      "Batch：14488 | Loss: 0.05549023300409317\n",
      "Batch：14489 | Loss: 0.050116974860429764\n",
      "Batch：14490 | Loss: 0.052043527364730835\n",
      "Batch：14491 | Loss: 0.056108508259058\n",
      "Batch：14492 | Loss: 0.054317694157361984\n",
      "Batch：14493 | Loss: 0.05562477558851242\n",
      "Batch：14494 | Loss: 0.06022179126739502\n",
      "Batch：14495 | Loss: 0.05230504274368286\n",
      "Batch：14496 | Loss: 0.06559684127569199\n",
      "Batch：14497 | Loss: 0.06149321421980858\n",
      "Batch：14498 | Loss: 0.049020688980817795\n",
      "Batch：14499 | Loss: 0.056569721549749374\n",
      "Batch：14500 | Loss: 0.05576632544398308\n",
      "Batch：14501 | Loss: 0.06085357069969177\n",
      "Batch：14502 | Loss: 0.061034299433231354\n",
      "Batch：14503 | Loss: 0.05495143681764603\n",
      "Batch：14504 | Loss: 0.04478373005986214\n",
      "Batch：14505 | Loss: 0.059418898075819016\n",
      "Batch：14506 | Loss: 0.05208394303917885\n",
      "Batch：14507 | Loss: 0.06308722496032715\n",
      "Batch：14508 | Loss: 0.061421457678079605\n",
      "Batch：14509 | Loss: 0.06296925246715546\n",
      "Batch：14510 | Loss: 0.05358966067433357\n",
      "Batch：14511 | Loss: 0.057276830077171326\n",
      "Batch：14512 | Loss: 0.04589935392141342\n",
      "Batch：14513 | Loss: 0.05712172016501427\n",
      "Batch：14514 | Loss: 0.05095111206173897\n",
      "Batch：14515 | Loss: 0.05468611419200897\n",
      "Batch：14516 | Loss: 0.05388162285089493\n",
      "Batch：14517 | Loss: 0.058336492627859116\n",
      "Batch：14518 | Loss: 0.04667814448475838\n",
      "Batch：14519 | Loss: 0.05033331736922264\n",
      "Batch：14520 | Loss: 0.060992419719696045\n",
      "Batch：14521 | Loss: 0.051423899829387665\n",
      "Batch：14522 | Loss: 0.05378959700465202\n",
      "Batch：14523 | Loss: 0.04521917551755905\n",
      "Batch：14524 | Loss: 0.07312066853046417\n",
      "Batch：14525 | Loss: 0.05514603480696678\n",
      "Batch：14526 | Loss: 0.06053272262215614\n",
      "Batch：14527 | Loss: 0.06410940736532211\n",
      "Batch：14528 | Loss: 0.06005685031414032\n",
      "Batch：14529 | Loss: 0.05068989843130112\n",
      "Batch：14530 | Loss: 0.05213863402605057\n",
      "Batch：14531 | Loss: 0.050392601639032364\n",
      "Batch：14532 | Loss: 0.058595363050699234\n",
      "Batch：14533 | Loss: 0.05314788222312927\n",
      "Batch：14534 | Loss: 0.05695035681128502\n",
      "Batch：14535 | Loss: 0.05245703458786011\n",
      "Batch：14536 | Loss: 0.05500037595629692\n",
      "Batch：14537 | Loss: 0.057631488889455795\n",
      "Batch：14538 | Loss: 0.06431391090154648\n",
      "Batch：14539 | Loss: 0.055278412997722626\n",
      "Batch：14540 | Loss: 0.06721185892820358\n",
      "Batch：14541 | Loss: 0.04862465709447861\n",
      "Batch：14542 | Loss: 0.0631636455655098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：14543 | Loss: 0.058193448930978775\n",
      "Batch：14544 | Loss: 0.054419972002506256\n",
      "Batch：14545 | Loss: 0.05047512799501419\n",
      "Batch：14546 | Loss: 0.05945132300257683\n",
      "Batch：14547 | Loss: 0.052494414150714874\n",
      "Batch：14548 | Loss: 0.05416586250066757\n",
      "Batch：14549 | Loss: 0.047994405031204224\n",
      "Batch：14550 | Loss: 0.061031412333250046\n",
      "Batch：14551 | Loss: 0.05582042410969734\n",
      "Batch：14552 | Loss: 0.05301947891712189\n",
      "Batch：14553 | Loss: 0.04620983824133873\n",
      "Batch：14554 | Loss: 0.04786098003387451\n",
      "Batch：14555 | Loss: 0.06294041126966476\n",
      "Batch：14556 | Loss: 0.05828983336687088\n",
      "Batch：14557 | Loss: 0.05328572914004326\n",
      "Batch：14558 | Loss: 0.04929666221141815\n",
      "Batch：14559 | Loss: 0.053120728582143784\n",
      "Batch：14560 | Loss: 0.05960638448596001\n",
      "Batch：14561 | Loss: 0.06597709655761719\n",
      "Batch：14562 | Loss: 0.04760585352778435\n",
      "Batch：14563 | Loss: 0.06349000334739685\n",
      "Batch：14564 | Loss: 0.051244936883449554\n",
      "Batch：14565 | Loss: 0.06725510954856873\n",
      "Batch：14566 | Loss: 0.05456011742353439\n",
      "Batch：14567 | Loss: 0.05669296160340309\n",
      "Batch：14568 | Loss: 0.04933658987283707\n",
      "Batch：14569 | Loss: 0.04652058705687523\n",
      "Batch：14570 | Loss: 0.061543580144643784\n",
      "Batch：14571 | Loss: 0.045715220272541046\n",
      "Batch：14572 | Loss: 0.056169819086790085\n",
      "Batch：14573 | Loss: 0.05546516925096512\n",
      "Batch：14574 | Loss: 0.06078873574733734\n",
      "Batch：14575 | Loss: 0.057606618851423264\n",
      "Batch：14576 | Loss: 0.05777464061975479\n",
      "Batch：14577 | Loss: 0.06075593829154968\n",
      "Batch：14578 | Loss: 0.04142440855503082\n",
      "Batch：14579 | Loss: 0.046897996217012405\n",
      "Batch：14580 | Loss: 0.04472429305315018\n",
      "Batch：14581 | Loss: 0.05353902280330658\n",
      "Batch：14582 | Loss: 0.05424588546156883\n",
      "Batch：14583 | Loss: 0.05187946557998657\n",
      "Batch：14584 | Loss: 0.04810163378715515\n",
      "Batch：14585 | Loss: 0.0585605651140213\n",
      "Batch：14586 | Loss: 0.05096930265426636\n",
      "Batch：14587 | Loss: 0.04169795289635658\n",
      "Batch：14588 | Loss: 0.0527452789247036\n",
      "Batch：14589 | Loss: 0.05460475757718086\n",
      "Batch：14590 | Loss: 0.06249965727329254\n",
      "Batch：14591 | Loss: 0.05791498348116875\n",
      "Batch：14592 | Loss: 0.04931826889514923\n",
      "Batch：14593 | Loss: 0.03961428627371788\n",
      "Batch：14594 | Loss: 0.06482618302106857\n",
      "Batch：14595 | Loss: 0.05911938473582268\n",
      "Batch：14596 | Loss: 0.05349336564540863\n",
      "Batch：14597 | Loss: 0.058481790125370026\n",
      "Batch：14598 | Loss: 0.05429299920797348\n",
      "Batch：14599 | Loss: 0.05771994963288307\n",
      "Batch：14600 | Loss: 0.05194093659520149\n",
      "Batch：14601 | Loss: 0.06591296195983887\n",
      "Batch：14602 | Loss: 0.05590381845831871\n",
      "Batch：14603 | Loss: 0.05303186923265457\n",
      "Batch：14604 | Loss: 0.049658600240945816\n",
      "Batch：14605 | Loss: 0.05548083782196045\n",
      "Batch：14606 | Loss: 0.05523773282766342\n",
      "Batch：14607 | Loss: 0.04957691580057144\n",
      "Batch：14608 | Loss: 0.06078610569238663\n",
      "Batch：14609 | Loss: 0.06100235506892204\n",
      "Batch：14610 | Loss: 0.06579127162694931\n",
      "Batch：14611 | Loss: 0.04743674024939537\n",
      "Batch：14612 | Loss: 0.048160370439291\n",
      "Batch：14613 | Loss: 0.05658118799328804\n",
      "Batch：14614 | Loss: 0.0570954792201519\n",
      "Batch：14615 | Loss: 0.0558294877409935\n",
      "Batch：14616 | Loss: 0.049655765295028687\n",
      "Batch：14617 | Loss: 0.049136750400066376\n",
      "Batch：14618 | Loss: 0.05121984705328941\n",
      "Batch：14619 | Loss: 0.060367804020643234\n",
      "Batch：14620 | Loss: 0.05491255223751068\n",
      "Batch：14621 | Loss: 0.06053595989942551\n",
      "Batch：14622 | Loss: 0.05850926786661148\n",
      "Batch：14623 | Loss: 0.055483173578977585\n",
      "Batch：14624 | Loss: 0.05052046477794647\n",
      "Batch：14625 | Loss: 0.06257642805576324\n",
      "Batch：14626 | Loss: 0.06320875138044357\n",
      "Batch：14627 | Loss: 0.06027389317750931\n",
      "Batch：14628 | Loss: 0.053310297429561615\n",
      "Batch：14629 | Loss: 0.06486029177904129\n",
      "Batch：14630 | Loss: 0.05812773108482361\n",
      "Batch：14631 | Loss: 0.0623069703578949\n",
      "Batch：14632 | Loss: 0.045648738741874695\n",
      "Batch：14633 | Loss: 0.059324584901332855\n",
      "Batch：14634 | Loss: 0.06348878145217896\n",
      "Batch：14635 | Loss: 0.05921376124024391\n",
      "Batch：14636 | Loss: 0.05841886252164841\n",
      "Batch：14637 | Loss: 0.05270502716302872\n",
      "Batch：14638 | Loss: 0.05605991184711456\n",
      "Batch：14639 | Loss: 0.057971373200416565\n",
      "Batch：14640 | Loss: 0.059985995292663574\n",
      "Batch：14641 | Loss: 0.05787067487835884\n",
      "Batch：14642 | Loss: 0.05276624113321304\n",
      "Batch：14643 | Loss: 0.05101154372096062\n",
      "Batch：14644 | Loss: 0.057278066873550415\n",
      "Batch：14645 | Loss: 0.051988668739795685\n",
      "Batch：14646 | Loss: 0.057921528816223145\n",
      "Batch：14647 | Loss: 0.06159676983952522\n",
      "Batch：14648 | Loss: 0.041407935321331024\n",
      "Batch：14649 | Loss: 0.05171671509742737\n",
      "Batch：14650 | Loss: 0.0564582422375679\n",
      "Batch：14651 | Loss: 0.04176787659525871\n",
      "Batch：14652 | Loss: 0.04901190102100372\n",
      "Batch：14653 | Loss: 0.051046036183834076\n",
      "Batch：14654 | Loss: 0.053110260516405106\n",
      "Batch：14655 | Loss: 0.06628144532442093\n",
      "Batch：14656 | Loss: 0.052913300693035126\n",
      "Batch：14657 | Loss: 0.04269843548536301\n",
      "Batch：14658 | Loss: 0.061673909425735474\n",
      "Batch：14659 | Loss: 0.05820918828248978\n",
      "Batch：14660 | Loss: 0.044978149235248566\n",
      "Batch：14661 | Loss: 0.04749022796750069\n",
      "Batch：14662 | Loss: 0.07170713692903519\n",
      "Batch：14663 | Loss: 0.05783858150243759\n",
      "Batch：14664 | Loss: 0.05229752138257027\n",
      "Batch：14665 | Loss: 0.05462702363729477\n",
      "Batch：14666 | Loss: 0.04908149689435959\n",
      "Batch：14667 | Loss: 0.051120318472385406\n",
      "Batch：14668 | Loss: 0.05019211769104004\n",
      "Batch：14669 | Loss: 0.05289524421095848\n",
      "Batch：14670 | Loss: 0.047259461134672165\n",
      "Batch：14671 | Loss: 0.053518522530794144\n",
      "Batch：14672 | Loss: 0.048791565001010895\n",
      "Batch：14673 | Loss: 0.04574022814631462\n",
      "Batch：14674 | Loss: 0.0604763887822628\n",
      "Batch：14675 | Loss: 0.05720486864447594\n",
      "Batch：14676 | Loss: 0.052371203899383545\n",
      "Batch：14677 | Loss: 0.05976331606507301\n",
      "Batch：14678 | Loss: 0.04831623658537865\n",
      "Batch：14679 | Loss: 0.06114714592695236\n",
      "Batch：14680 | Loss: 0.049334343522787094\n",
      "Batch：14681 | Loss: 0.053743403404951096\n",
      "Batch：14682 | Loss: 0.05278681218624115\n",
      "Batch：14683 | Loss: 0.05504127964377403\n",
      "Batch：14684 | Loss: 0.0564444363117218\n",
      "Batch：14685 | Loss: 0.044552743434906006\n",
      "Batch：14686 | Loss: 0.050437081605196\n",
      "Batch：14687 | Loss: 0.05895007401704788\n",
      "Batch：14688 | Loss: 0.061068762093782425\n",
      "Batch：14689 | Loss: 0.049339376389980316\n",
      "Batch：14690 | Loss: 0.05385695397853851\n",
      "Batch：14691 | Loss: 0.05086376890540123\n",
      "Batch：14692 | Loss: 0.057793028652668\n",
      "Batch：14693 | Loss: 0.04385126009583473\n",
      "Batch：14694 | Loss: 0.06153266504406929\n",
      "Batch：14695 | Loss: 0.054081741720438004\n",
      "Batch：14696 | Loss: 0.052309367805719376\n",
      "Batch：14697 | Loss: 0.06292586028575897\n",
      "Batch：14698 | Loss: 0.053800713270902634\n",
      "Batch：14699 | Loss: 0.06099797412753105\n",
      "Batch：14700 | Loss: 0.05510212108492851\n",
      "Batch：14701 | Loss: 0.053016263991594315\n",
      "Batch：14702 | Loss: 0.049147069454193115\n",
      "Batch：14703 | Loss: 0.05060400441288948\n",
      "Batch：14704 | Loss: 0.04804084822535515\n",
      "Batch：14705 | Loss: 0.0514017753303051\n",
      "Batch：14706 | Loss: 0.05720609799027443\n",
      "Batch：14707 | Loss: 0.05032191425561905\n",
      "Batch：14708 | Loss: 0.057718344032764435\n",
      "Batch：14709 | Loss: 0.0523558147251606\n",
      "Batch：14710 | Loss: 0.0450817346572876\n",
      "Batch：14711 | Loss: 0.05623331665992737\n",
      "Batch：14712 | Loss: 0.06083153560757637\n",
      "Batch：14713 | Loss: 0.05586579442024231\n",
      "Batch：14714 | Loss: 0.06781569868326187\n",
      "Batch：14715 | Loss: 0.05378954857587814\n",
      "Batch：14716 | Loss: 0.06008533760905266\n",
      "Batch：14717 | Loss: 0.044944971799850464\n",
      "Batch：14718 | Loss: 0.059472065418958664\n",
      "Batch：14719 | Loss: 0.05597614124417305\n",
      "Batch：14720 | Loss: 0.058476679027080536\n",
      "Batch：14721 | Loss: 0.05136502906680107\n",
      "Batch：14722 | Loss: 0.04731224104762077\n",
      "Batch：14723 | Loss: 0.04441250115633011\n",
      "Batch：14724 | Loss: 0.054693251848220825\n",
      "Batch：14725 | Loss: 0.048502858728170395\n",
      "Batch：14726 | Loss: 0.05422743782401085\n",
      "Batch：14727 | Loss: 0.052301473915576935\n",
      "Batch：14728 | Loss: 0.05511871725320816\n",
      "Batch：14729 | Loss: 0.060482434928417206\n",
      "Batch：14730 | Loss: 0.06004997342824936\n",
      "Batch：14731 | Loss: 0.05669669061899185\n",
      "Batch：14732 | Loss: 0.05202999711036682\n",
      "Batch：14733 | Loss: 0.05669235810637474\n",
      "Batch：14734 | Loss: 0.05468084663152695\n",
      "Batch：14735 | Loss: 0.058411214500665665\n",
      "Batch：14736 | Loss: 0.06721525639295578\n",
      "Batch：14737 | Loss: 0.059956640005111694\n",
      "Batch：14738 | Loss: 0.04674558341503143\n",
      "Batch：14739 | Loss: 0.05038122460246086\n",
      "Batch：14740 | Loss: 0.06271225214004517\n",
      "Batch：14741 | Loss: 0.052955109626054764\n",
      "Batch：14742 | Loss: 0.055685855448246\n",
      "Batch：14743 | Loss: 0.05927120894193649\n",
      "Batch：14744 | Loss: 0.05516194552183151\n",
      "Batch：14745 | Loss: 0.04996316507458687\n",
      "Batch：14746 | Loss: 0.07213737815618515\n",
      "Batch：14747 | Loss: 0.06031593680381775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：14748 | Loss: 0.04647309333086014\n",
      "Batch：14749 | Loss: 0.05999196693301201\n",
      "Batch：14750 | Loss: 0.044089801609516144\n",
      "Batch：14751 | Loss: 0.057252805680036545\n",
      "Batch：14752 | Loss: 0.055147163569927216\n",
      "Batch：14753 | Loss: 0.05172576382756233\n",
      "Batch：14754 | Loss: 0.051445938646793365\n",
      "Batch：14755 | Loss: 0.04631922394037247\n",
      "Batch：14756 | Loss: 0.05195054039359093\n",
      "Batch：14757 | Loss: 0.05751234292984009\n",
      "Batch：14758 | Loss: 0.06286941468715668\n",
      "Batch：14759 | Loss: 0.0469222217798233\n",
      "Batch：14760 | Loss: 0.05651112645864487\n",
      "Batch：14761 | Loss: 0.0496787391602993\n",
      "Batch：14762 | Loss: 0.05052709951996803\n",
      "Batch：14763 | Loss: 0.06414295732975006\n",
      "Batch：14764 | Loss: 0.06592779606580734\n",
      "Batch：14765 | Loss: 0.056608837097883224\n",
      "Batch：14766 | Loss: 0.05555105581879616\n",
      "Batch：14767 | Loss: 0.05366215109825134\n",
      "Batch：14768 | Loss: 0.05370232090353966\n",
      "Batch：14769 | Loss: 0.06599849462509155\n",
      "Batch：14770 | Loss: 0.05665114149451256\n",
      "Batch：14771 | Loss: 0.05616234242916107\n",
      "Batch：14772 | Loss: 0.05673542618751526\n",
      "Batch：14773 | Loss: 0.050994984805583954\n",
      "Batch：14774 | Loss: 0.055662404745817184\n",
      "Batch：14775 | Loss: 0.05295305699110031\n",
      "Batch：14776 | Loss: 0.057898588478565216\n",
      "Batch：14777 | Loss: 0.05956265330314636\n",
      "Batch：14778 | Loss: 0.05678829923272133\n",
      "Batch：14779 | Loss: 0.054518625140190125\n",
      "Batch：14780 | Loss: 0.05853072553873062\n",
      "Batch：14781 | Loss: 0.05109553039073944\n",
      "Batch：14782 | Loss: 0.05937528982758522\n",
      "Batch：14783 | Loss: 0.052444975823163986\n",
      "Batch：14784 | Loss: 0.05402171611785889\n",
      "Batch：14785 | Loss: 0.055898915976285934\n",
      "Batch：14786 | Loss: 0.05350504443049431\n",
      "Batch：14787 | Loss: 0.042133551090955734\n",
      "Batch：14788 | Loss: 0.05523681640625\n",
      "Batch：14789 | Loss: 0.058566391468048096\n",
      "Batch：14790 | Loss: 0.060357533395290375\n",
      "Batch：14791 | Loss: 0.04133543744683266\n",
      "Batch：14792 | Loss: 0.05503952503204346\n",
      "Batch：14793 | Loss: 0.05544012412428856\n",
      "Batch：14794 | Loss: 0.05789436772465706\n",
      "Batch：14795 | Loss: 0.05294651910662651\n",
      "Batch：14796 | Loss: 0.04732084274291992\n",
      "Batch：14797 | Loss: 0.05062727630138397\n",
      "Batch：14798 | Loss: 0.05351903662085533\n",
      "Batch：14799 | Loss: 0.06725640594959259\n",
      "Batch：14800 | Loss: 0.051696594804525375\n",
      "Batch：14801 | Loss: 0.048183735460042953\n",
      "Batch：14802 | Loss: 0.05027041956782341\n",
      "Batch：14803 | Loss: 0.052398089319467545\n",
      "Batch：14804 | Loss: 0.055815134197473526\n",
      "Batch：14805 | Loss: 0.05437258258461952\n",
      "Batch：14806 | Loss: 0.05271195247769356\n",
      "Batch：14807 | Loss: 0.052762772887945175\n",
      "Batch：14808 | Loss: 0.04364543780684471\n",
      "Batch：14809 | Loss: 0.05082664266228676\n",
      "Batch：14810 | Loss: 0.056715138256549835\n",
      "Batch：14811 | Loss: 0.048978209495544434\n",
      "Batch：14812 | Loss: 0.052111804485321045\n",
      "Batch：14813 | Loss: 0.05790422484278679\n",
      "Batch：14814 | Loss: 0.05500270053744316\n",
      "Batch：14815 | Loss: 0.057175103574991226\n",
      "Batch：14816 | Loss: 0.055714141577482224\n",
      "Batch：14817 | Loss: 0.05239303410053253\n",
      "Batch：14818 | Loss: 0.05095022916793823\n",
      "Batch：14819 | Loss: 0.05002111196517944\n",
      "Batch：14820 | Loss: 0.05978880822658539\n",
      "Batch：14821 | Loss: 0.047561898827552795\n",
      "Batch：14822 | Loss: 0.06061149388551712\n",
      "Batch：14823 | Loss: 0.053400419652462006\n",
      "Batch：14824 | Loss: 0.05778910219669342\n",
      "Batch：14825 | Loss: 0.05335118994116783\n",
      "Batch：14826 | Loss: 0.06276682764291763\n",
      "Batch：14827 | Loss: 0.04987993836402893\n",
      "Batch：14828 | Loss: 0.05921139568090439\n",
      "Batch：14829 | Loss: 0.05614115297794342\n",
      "Batch：14830 | Loss: 0.061832133680582047\n",
      "Batch：14831 | Loss: 0.0627327635884285\n",
      "Batch：14832 | Loss: 0.05271867662668228\n",
      "Batch：14833 | Loss: 0.05155857279896736\n",
      "Batch：14834 | Loss: 0.05544156953692436\n",
      "Batch：14835 | Loss: 0.05029381811618805\n",
      "Batch：14836 | Loss: 0.050937823951244354\n",
      "Batch：14837 | Loss: 0.05576949939131737\n",
      "Batch：14838 | Loss: 0.05770103260874748\n",
      "Batch：14839 | Loss: 0.055576615035533905\n",
      "Batch：14840 | Loss: 0.05125552788376808\n",
      "Batch：14841 | Loss: 0.061259906738996506\n",
      "Batch：14842 | Loss: 0.049773894250392914\n",
      "Batch：14843 | Loss: 0.05279292166233063\n",
      "Batch：14844 | Loss: 0.046652283519506454\n",
      "Batch：14845 | Loss: 0.06166264787316322\n",
      "Batch：14846 | Loss: 0.05734638497233391\n",
      "Batch：14847 | Loss: 0.05472743138670921\n",
      "Batch：14848 | Loss: 0.05525137111544609\n",
      "Batch：14849 | Loss: 0.04726865515112877\n",
      "Batch：14850 | Loss: 0.05360398441553116\n",
      "Batch：14851 | Loss: 0.05534064769744873\n",
      "Batch：14852 | Loss: 0.05752309039235115\n",
      "Batch：14853 | Loss: 0.05673227831721306\n",
      "Batch：14854 | Loss: 0.05946868285536766\n",
      "Batch：14855 | Loss: 0.04818219318985939\n",
      "Batch：14856 | Loss: 0.048542510718107224\n",
      "Batch：14857 | Loss: 0.049387283623218536\n",
      "Batch：14858 | Loss: 0.06483656167984009\n",
      "Batch：14859 | Loss: 0.06178310513496399\n",
      "Batch：14860 | Loss: 0.061270277947187424\n",
      "Batch：14861 | Loss: 0.0528203621506691\n",
      "Batch：14862 | Loss: 0.06291944533586502\n",
      "Batch：14863 | Loss: 0.04701868072152138\n",
      "Batch：14864 | Loss: 0.05668853595852852\n",
      "Batch：14865 | Loss: 0.05200691148638725\n",
      "Batch：14866 | Loss: 0.05324823036789894\n",
      "Batch：14867 | Loss: 0.056478265672922134\n",
      "Batch：14868 | Loss: 0.06542978435754776\n",
      "Batch：14869 | Loss: 0.05012335628271103\n",
      "Batch：14870 | Loss: 0.052438266575336456\n",
      "Batch：14871 | Loss: 0.04554646834731102\n",
      "Batch：14872 | Loss: 0.055744145065546036\n",
      "Batch：14873 | Loss: 0.057497091591358185\n",
      "Batch：14874 | Loss: 0.062173228710889816\n",
      "Batch：14875 | Loss: 0.05229543149471283\n",
      "Batch：14876 | Loss: 0.055627766996622086\n",
      "Batch：14877 | Loss: 0.04891645163297653\n",
      "Batch：14878 | Loss: 0.06035730987787247\n",
      "Batch：14879 | Loss: 0.05553794652223587\n",
      "Batch：14880 | Loss: 0.07111001759767532\n",
      "Batch：14881 | Loss: 0.05863514542579651\n",
      "Batch：14882 | Loss: 0.0586460679769516\n",
      "Batch：14883 | Loss: 0.06147390604019165\n",
      "Batch：14884 | Loss: 0.04497149586677551\n",
      "Batch：14885 | Loss: 0.045819975435733795\n",
      "Batch：14886 | Loss: 0.06462827324867249\n",
      "Batch：14887 | Loss: 0.046477630734443665\n",
      "Batch：14888 | Loss: 0.048823099583387375\n",
      "Batch：14889 | Loss: 0.05443752557039261\n",
      "Batch：14890 | Loss: 0.050365809351205826\n",
      "Batch：14891 | Loss: 0.05515582114458084\n",
      "Batch：14892 | Loss: 0.05387759208679199\n",
      "Batch：14893 | Loss: 0.05483681708574295\n",
      "Batch：14894 | Loss: 0.056279875338077545\n",
      "Batch：14895 | Loss: 0.055346209555864334\n",
      "Batch：14896 | Loss: 0.0589282289147377\n",
      "Batch：14897 | Loss: 0.05000066012144089\n",
      "Batch：14898 | Loss: 0.058493901044130325\n",
      "Batch：14899 | Loss: 0.05013212189078331\n",
      "Batch：14900 | Loss: 0.04538283124566078\n",
      "Batch：14901 | Loss: 0.0434461273252964\n",
      "Batch：14902 | Loss: 0.060459889471530914\n",
      "Batch：14903 | Loss: 0.04757629334926605\n",
      "Batch：14904 | Loss: 0.05200299620628357\n",
      "Batch：14905 | Loss: 0.05398666858673096\n",
      "Batch：14906 | Loss: 0.055678293108940125\n",
      "Batch：14907 | Loss: 0.05823869630694389\n",
      "Batch：14908 | Loss: 0.060518600046634674\n",
      "Batch：14909 | Loss: 0.051920194178819656\n",
      "Batch：14910 | Loss: 0.0503302700817585\n",
      "Batch：14911 | Loss: 0.04970145970582962\n",
      "Batch：14912 | Loss: 0.0510106235742569\n",
      "Batch：14913 | Loss: 0.061781879514455795\n",
      "Batch：14914 | Loss: 0.05108865350484848\n",
      "Batch：14915 | Loss: 0.04038684442639351\n",
      "Batch：14916 | Loss: 0.05292069539427757\n",
      "Batch：14917 | Loss: 0.061528924852609634\n",
      "Batch：14918 | Loss: 0.055627889931201935\n",
      "Batch：14919 | Loss: 0.05632755532860756\n",
      "Batch：14920 | Loss: 0.047841187566518784\n",
      "Batch：14921 | Loss: 0.05626872554421425\n",
      "Batch：14922 | Loss: 0.05054318159818649\n",
      "Batch：14923 | Loss: 0.043463658541440964\n",
      "Batch：14924 | Loss: 0.052746742963790894\n",
      "Batch：14925 | Loss: 0.054080840200185776\n",
      "Batch：14926 | Loss: 0.04689263179898262\n",
      "Batch：14927 | Loss: 0.050941821187734604\n",
      "Batch：14928 | Loss: 0.05540134012699127\n",
      "Batch：14929 | Loss: 0.055922456085681915\n",
      "Batch：14930 | Loss: 0.04697953164577484\n",
      "Batch：14931 | Loss: 0.05427790805697441\n",
      "Batch：14932 | Loss: 0.052899062633514404\n",
      "Batch：14933 | Loss: 0.05713718757033348\n",
      "Batch：14934 | Loss: 0.05745907500386238\n",
      "Batch：14935 | Loss: 0.05630776286125183\n",
      "Batch：14936 | Loss: 0.05496835336089134\n",
      "Batch：14937 | Loss: 0.04732241854071617\n",
      "Batch：14938 | Loss: 0.05266433209180832\n",
      "Batch：14939 | Loss: 0.047317422926425934\n",
      "Batch：14940 | Loss: 0.05217169225215912\n",
      "Batch：14941 | Loss: 0.049064792692661285\n",
      "Batch：14942 | Loss: 0.047791168093681335\n",
      "Batch：14943 | Loss: 0.05448901280760765\n",
      "Batch：14944 | Loss: 0.056046031415462494\n",
      "Batch：14945 | Loss: 0.04450593888759613\n",
      "Batch：14946 | Loss: 0.054774295538663864\n",
      "Batch：14947 | Loss: 0.05951710417866707\n",
      "Batch：14948 | Loss: 0.054293904453516006\n",
      "Batch：14949 | Loss: 0.05202963203191757\n",
      "Batch：14950 | Loss: 0.05977065861225128\n",
      "Batch：14951 | Loss: 0.052769504487514496\n",
      "Batch：14952 | Loss: 0.04899652674794197\n",
      "Batch：14953 | Loss: 0.050174225121736526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：14954 | Loss: 0.04617192968726158\n",
      "Batch：14955 | Loss: 0.05187424644827843\n",
      "Batch：14956 | Loss: 0.04971863329410553\n",
      "Batch：14957 | Loss: 0.05597206577658653\n",
      "Batch：14958 | Loss: 0.07224251329898834\n",
      "Batch：14959 | Loss: 0.057966794818639755\n",
      "Batch：14960 | Loss: 0.05808836966753006\n",
      "Batch：14961 | Loss: 0.04847966507077217\n",
      "Batch：14962 | Loss: 0.06182004138827324\n",
      "Batch：14963 | Loss: 0.058142486959695816\n",
      "Batch：14964 | Loss: 0.04944492131471634\n",
      "Batch：14965 | Loss: 0.056857991963624954\n",
      "Batch：14966 | Loss: 0.058720558881759644\n",
      "Batch：14967 | Loss: 0.06120593100786209\n",
      "Batch：14968 | Loss: 0.059108663350343704\n",
      "Batch：14969 | Loss: 0.051586445420980453\n",
      "Batch：14970 | Loss: 0.05442948266863823\n",
      "Batch：14971 | Loss: 0.0559130534529686\n",
      "Batch：14972 | Loss: 0.05532896891236305\n",
      "Batch：14973 | Loss: 0.05480804294347763\n",
      "Batch：14974 | Loss: 0.050464630126953125\n",
      "Batch：14975 | Loss: 0.04957665875554085\n",
      "Batch：14976 | Loss: 0.04663137346506119\n",
      "Batch：14977 | Loss: 0.055062223225831985\n",
      "Batch：14978 | Loss: 0.05720766261219978\n",
      "Batch：14979 | Loss: 0.054826561361551285\n",
      "Batch：14980 | Loss: 0.055457133799791336\n",
      "Batch：14981 | Loss: 0.05516022816300392\n",
      "Batch：14982 | Loss: 0.05876784771680832\n",
      "Batch：14983 | Loss: 0.06321097910404205\n",
      "Batch：14984 | Loss: 0.05188760161399841\n",
      "Batch：14985 | Loss: 0.051938384771347046\n",
      "Batch：14986 | Loss: 0.05888591334223747\n",
      "Batch：14987 | Loss: 0.05376797914505005\n",
      "Batch：14988 | Loss: 0.04033482447266579\n",
      "Batch：14989 | Loss: 0.04704475775361061\n",
      "Batch：14990 | Loss: 0.04958164319396019\n",
      "Batch：14991 | Loss: 0.04986606910824776\n",
      "Batch：14992 | Loss: 0.05809973180294037\n",
      "Batch：14993 | Loss: 0.0740913525223732\n",
      "Batch：14994 | Loss: 0.05071888118982315\n",
      "Batch：14995 | Loss: 0.057704050093889236\n",
      "Batch：14996 | Loss: 0.06311101466417313\n",
      "Batch：14997 | Loss: 0.05648474395275116\n",
      "Batch：14998 | Loss: 0.06204209476709366\n",
      "Batch：14999 | Loss: 0.0540287122130394\n",
      "Batch：15000 | Loss: 0.04846043884754181\n",
      "Batch：15001 | Loss: 0.058659981936216354\n",
      "Batch：15002 | Loss: 0.058560870587825775\n",
      "Batch：15003 | Loss: 0.05171491578221321\n",
      "Batch：15004 | Loss: 0.048910196870565414\n",
      "Batch：15005 | Loss: 0.05867735669016838\n",
      "Batch：15006 | Loss: 0.05147803574800491\n",
      "Batch：15007 | Loss: 0.047957081347703934\n",
      "Batch：15008 | Loss: 0.05490049719810486\n",
      "Batch：15009 | Loss: 0.06009991466999054\n",
      "Batch：15010 | Loss: 0.053361572325229645\n",
      "Batch：15011 | Loss: 0.051421090960502625\n",
      "Batch：15012 | Loss: 0.051524579524993896\n",
      "Batch：15013 | Loss: 0.05226167291402817\n",
      "Batch：15014 | Loss: 0.060258690267801285\n",
      "Batch：15015 | Loss: 0.0494302473962307\n",
      "Batch：15016 | Loss: 0.06465230137109756\n",
      "Batch：15017 | Loss: 0.06064559891819954\n",
      "Batch：15018 | Loss: 0.05186201259493828\n",
      "Batch：15019 | Loss: 0.05731739103794098\n",
      "Batch：15020 | Loss: 0.05768795311450958\n",
      "Batch：15021 | Loss: 0.05558155104517937\n",
      "Batch：15022 | Loss: 0.057821664959192276\n",
      "Batch：15023 | Loss: 0.04808543995022774\n",
      "Batch：15024 | Loss: 0.05092311650514603\n",
      "Batch：15025 | Loss: 0.044821035116910934\n",
      "Batch：15026 | Loss: 0.050570227205753326\n",
      "Batch：15027 | Loss: 0.05743337795138359\n",
      "Batch：15028 | Loss: 0.055164236575365067\n",
      "Batch：15029 | Loss: 0.05230523273348808\n",
      "Batch：15030 | Loss: 0.04488872364163399\n",
      "Batch：15031 | Loss: 0.060462888330221176\n",
      "Batch：15032 | Loss: 0.056981343775987625\n",
      "Batch：15033 | Loss: 0.05108877643942833\n",
      "Batch：15034 | Loss: 0.05788786709308624\n",
      "Batch：15035 | Loss: 0.04462368041276932\n",
      "Batch：15036 | Loss: 0.0561147965490818\n",
      "Batch：15037 | Loss: 0.05542169138789177\n",
      "Batch：15038 | Loss: 0.04710116609930992\n",
      "Batch：15039 | Loss: 0.05688290670514107\n",
      "Batch：15040 | Loss: 0.04754719138145447\n",
      "Batch：15041 | Loss: 0.05567288026213646\n",
      "Batch：15042 | Loss: 0.0485268235206604\n",
      "Batch：15043 | Loss: 0.054953087121248245\n",
      "Batch：15044 | Loss: 0.05844436585903168\n",
      "Batch：15045 | Loss: 0.053783658891916275\n",
      "Batch：15046 | Loss: 0.06107339262962341\n",
      "Batch：15047 | Loss: 0.06042741239070892\n",
      "Batch：15048 | Loss: 0.048358362168073654\n",
      "Batch：15049 | Loss: 0.051219843327999115\n",
      "Batch：15050 | Loss: 0.05342727527022362\n",
      "Batch：15051 | Loss: 0.05179949849843979\n",
      "Batch：15052 | Loss: 0.06140825152397156\n",
      "Batch：15053 | Loss: 0.05185066536068916\n",
      "Batch：15054 | Loss: 0.06521472334861755\n",
      "Batch：15055 | Loss: 0.05424781143665314\n",
      "Batch：15056 | Loss: 0.050675585865974426\n",
      "Batch：15057 | Loss: 0.045028187334537506\n",
      "Batch：15058 | Loss: 0.051281657069921494\n",
      "Batch：15059 | Loss: 0.04874315857887268\n",
      "Batch：15060 | Loss: 0.04849553853273392\n",
      "Batch：15061 | Loss: 0.0611005537211895\n",
      "Batch：15062 | Loss: 0.05803656578063965\n",
      "Batch：15063 | Loss: 0.060926731675863266\n",
      "Batch：15064 | Loss: 0.051020100712776184\n",
      "Batch：15065 | Loss: 0.05053499713540077\n",
      "Batch：15066 | Loss: 0.056263845413923264\n",
      "Batch：15067 | Loss: 0.05375858023762703\n",
      "Batch：15068 | Loss: 0.04054167494177818\n",
      "Batch：15069 | Loss: 0.04710087180137634\n",
      "Batch：15070 | Loss: 0.0550069659948349\n",
      "Batch：15071 | Loss: 0.052329208701848984\n",
      "Batch：15072 | Loss: 0.044212788343429565\n",
      "Batch：15073 | Loss: 0.04994216933846474\n",
      "Batch：15074 | Loss: 0.05349671468138695\n",
      "Batch：15075 | Loss: 0.05307487025856972\n",
      "Batch：15076 | Loss: 0.05287196859717369\n",
      "Batch：15077 | Loss: 0.05200055241584778\n",
      "Batch：15078 | Loss: 0.0547991618514061\n",
      "Batch：15079 | Loss: 0.06045635789632797\n",
      "Batch：15080 | Loss: 0.046712737530469894\n",
      "Batch：15081 | Loss: 0.06322114169597626\n",
      "Batch：15082 | Loss: 0.05013308674097061\n",
      "Batch：15083 | Loss: 0.04706280305981636\n",
      "Batch：15084 | Loss: 0.05114290490746498\n",
      "Batch：15085 | Loss: 0.05240016058087349\n",
      "Batch：15086 | Loss: 0.04355357959866524\n",
      "Batch：15087 | Loss: 0.06325726956129074\n",
      "Batch：15088 | Loss: 0.050083644688129425\n",
      "Batch：15089 | Loss: 0.04983877018094063\n",
      "Batch：15090 | Loss: 0.05924786999821663\n",
      "Batch：15091 | Loss: 0.050735220313072205\n",
      "Batch：15092 | Loss: 0.05232328176498413\n",
      "Batch：15093 | Loss: 0.05182129517197609\n",
      "Batch：15094 | Loss: 0.04910824075341225\n",
      "Batch：15095 | Loss: 0.05501293018460274\n",
      "Batch：15096 | Loss: 0.05428438261151314\n",
      "Batch：15097 | Loss: 0.03896790370345116\n",
      "Batch：15098 | Loss: 0.0614948570728302\n",
      "Batch：15099 | Loss: 0.05046389624476433\n",
      "Batch：15100 | Loss: 0.04782972112298012\n",
      "Batch：15101 | Loss: 0.05378397926688194\n",
      "Batch：15102 | Loss: 0.044763412326574326\n",
      "Batch：15103 | Loss: 0.05707348510622978\n",
      "Batch：15104 | Loss: 0.05163833498954773\n",
      "Batch：15105 | Loss: 0.053130362182855606\n",
      "Batch：15106 | Loss: 0.05005388706922531\n",
      "Batch：15107 | Loss: 0.046499013900756836\n",
      "Batch：15108 | Loss: 0.06186395138502121\n",
      "Batch：15109 | Loss: 0.058478448539972305\n",
      "Batch：15110 | Loss: 0.053583987057209015\n",
      "Batch：15111 | Loss: 0.040480319410562515\n",
      "Batch：15112 | Loss: 0.06697474420070648\n",
      "Batch：15113 | Loss: 0.06255879998207092\n",
      "Batch：15114 | Loss: 0.052993327379226685\n",
      "Batch：15115 | Loss: 0.05179082229733467\n",
      "Batch：15116 | Loss: 0.05865936353802681\n",
      "Batch：15117 | Loss: 0.054797232151031494\n",
      "Batch：15118 | Loss: 0.04740201681852341\n",
      "Batch：15119 | Loss: 0.06100878491997719\n",
      "Batch：15120 | Loss: 0.05286548659205437\n",
      "Batch：15121 | Loss: 0.06902214139699936\n",
      "Batch：15122 | Loss: 0.046565763652324677\n",
      "Batch：15123 | Loss: 0.05736621096730232\n",
      "Batch：15124 | Loss: 0.05733746290206909\n",
      "Batch：15125 | Loss: 0.048068225383758545\n",
      "Batch：15126 | Loss: 0.0546560138463974\n",
      "Batch：15127 | Loss: 0.05048344284296036\n",
      "Batch：15128 | Loss: 0.0561155341565609\n",
      "Batch：15129 | Loss: 0.06209917739033699\n",
      "Batch：15130 | Loss: 0.054301850497722626\n",
      "Batch：15131 | Loss: 0.05307098850607872\n",
      "Batch：15132 | Loss: 0.04807092249393463\n",
      "Batch：15133 | Loss: 0.05485408380627632\n",
      "Batch：15134 | Loss: 0.047139689326286316\n",
      "Batch：15135 | Loss: 0.0493675172328949\n",
      "Batch：15136 | Loss: 0.05362783744931221\n",
      "Batch：15137 | Loss: 0.057698413729667664\n",
      "Batch：15138 | Loss: 0.0512540377676487\n",
      "Batch：15139 | Loss: 0.05191253498196602\n",
      "Batch：15140 | Loss: 0.05750390514731407\n",
      "Batch：15141 | Loss: 0.060129404067993164\n",
      "Batch：15142 | Loss: 0.053320616483688354\n",
      "Batch：15143 | Loss: 0.05441257730126381\n",
      "Batch：15144 | Loss: 0.04870956018567085\n",
      "Batch：15145 | Loss: 0.055282969027757645\n",
      "Batch：15146 | Loss: 0.05484748259186745\n",
      "Batch：15147 | Loss: 0.0580233559012413\n",
      "Batch：15148 | Loss: 0.05147929862141609\n",
      "Batch：15149 | Loss: 0.05021913722157478\n",
      "Batch：15150 | Loss: 0.05906382203102112\n",
      "Batch：15151 | Loss: 0.04553496092557907\n",
      "Batch：15152 | Loss: 0.06231711432337761\n",
      "Batch：15153 | Loss: 0.0638890489935875\n",
      "Batch：15154 | Loss: 0.05240386724472046\n",
      "Batch：15155 | Loss: 0.05241576209664345\n",
      "Batch：15156 | Loss: 0.05670087784528732\n",
      "Batch：15157 | Loss: 0.06000922992825508\n",
      "Batch：15158 | Loss: 0.06304282695055008\n",
      "Batch：15159 | Loss: 0.052188996225595474\n",
      "Batch：15160 | Loss: 0.04305072873830795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：15161 | Loss: 0.052853383123874664\n",
      "Batch：15162 | Loss: 0.059274688363075256\n",
      "Batch：15163 | Loss: 0.051416464149951935\n",
      "Batch：15164 | Loss: 0.055829837918281555\n",
      "Batch：15165 | Loss: 0.06036360561847687\n",
      "Batch：15166 | Loss: 0.041965972632169724\n",
      "Batch：15167 | Loss: 0.0551275834441185\n",
      "Batch：15168 | Loss: 0.051903095096349716\n",
      "Batch：15169 | Loss: 0.06499750912189484\n",
      "Batch：15170 | Loss: 0.04637371748685837\n",
      "Batch：15171 | Loss: 0.04685208946466446\n",
      "Batch：15172 | Loss: 0.053320903331041336\n",
      "Batch：15173 | Loss: 0.05261513218283653\n",
      "Batch：15174 | Loss: 0.05596150830388069\n",
      "Batch：15175 | Loss: 0.05073783919215202\n",
      "Batch：15176 | Loss: 0.04736249893903732\n",
      "Batch：15177 | Loss: 0.05931706354022026\n",
      "Batch：15178 | Loss: 0.052255552262067795\n",
      "Batch：15179 | Loss: 0.05009545013308525\n",
      "Batch：15180 | Loss: 0.0481300950050354\n",
      "Batch：15181 | Loss: 0.0529482327401638\n",
      "Batch：15182 | Loss: 0.062287844717502594\n",
      "Batch：15183 | Loss: 0.05318087711930275\n",
      "Batch：15184 | Loss: 0.06290347874164581\n",
      "Batch：15185 | Loss: 0.05420243740081787\n",
      "Batch：15186 | Loss: 0.053010884672403336\n",
      "Batch：15187 | Loss: 0.05464015156030655\n",
      "Batch：15188 | Loss: 0.05160049349069595\n",
      "Batch：15189 | Loss: 0.05403570085763931\n",
      "Batch：15190 | Loss: 0.04303687438368797\n",
      "Batch：15191 | Loss: 0.04508064687252045\n",
      "Batch：15192 | Loss: 0.059735558927059174\n",
      "Batch：15193 | Loss: 0.06477770209312439\n",
      "Batch：15194 | Loss: 0.05081355199217796\n",
      "Batch：15195 | Loss: 0.05501065030694008\n",
      "Batch：15196 | Loss: 0.056074731051921844\n",
      "Batch：15197 | Loss: 0.05621466413140297\n",
      "Batch：15198 | Loss: 0.052910998463630676\n",
      "Batch：15199 | Loss: 0.05376798287034035\n",
      "Batch：15200 | Loss: 0.045406416058540344\n",
      "Batch：15201 | Loss: 0.06010225787758827\n",
      "Batch：15202 | Loss: 0.051572322845458984\n",
      "Batch：15203 | Loss: 0.05730147659778595\n",
      "Batch：15204 | Loss: 0.05594877898693085\n",
      "Batch：15205 | Loss: 0.06021437421441078\n",
      "Batch：15206 | Loss: 0.05244004726409912\n",
      "Batch：15207 | Loss: 0.05149699002504349\n",
      "Batch：15208 | Loss: 0.05618106201291084\n",
      "Batch：15209 | Loss: 0.04928193613886833\n",
      "Batch：15210 | Loss: 0.05002579838037491\n",
      "Batch：15211 | Loss: 0.049410317093133926\n",
      "Batch：15212 | Loss: 0.054773833602666855\n",
      "Batch：15213 | Loss: 0.057146575301885605\n",
      "Batch：15214 | Loss: 0.06332068890333176\n",
      "Batch：15215 | Loss: 0.0686829537153244\n",
      "Batch：15216 | Loss: 0.04582524672150612\n",
      "Batch：15217 | Loss: 0.051439736038446426\n",
      "Batch：15218 | Loss: 0.04190674424171448\n",
      "Batch：15219 | Loss: 0.05688874423503876\n",
      "Batch：15220 | Loss: 0.04492633044719696\n",
      "Batch：15221 | Loss: 0.05668656527996063\n",
      "Batch：15222 | Loss: 0.053425729274749756\n",
      "Batch：15223 | Loss: 0.04453280195593834\n",
      "Batch：15224 | Loss: 0.05154084786772728\n",
      "Batch：15225 | Loss: 0.05309835821390152\n",
      "Batch：15226 | Loss: 0.05549788475036621\n",
      "Batch：15227 | Loss: 0.05734170600771904\n",
      "Batch：15228 | Loss: 0.06069067493081093\n",
      "Batch：15229 | Loss: 0.057141948491334915\n",
      "Batch：15230 | Loss: 0.04380948841571808\n",
      "Batch：15231 | Loss: 0.05819201469421387\n",
      "Batch：15232 | Loss: 0.04749187082052231\n",
      "Batch：15233 | Loss: 0.051759976893663406\n",
      "Batch：15234 | Loss: 0.051074009388685226\n",
      "Batch：15235 | Loss: 0.05551717057824135\n",
      "Batch：15236 | Loss: 0.06570157408714294\n",
      "Batch：15237 | Loss: 0.06056450679898262\n",
      "Batch：15238 | Loss: 0.04679228737950325\n",
      "Batch：15239 | Loss: 0.046083714812994\n",
      "Batch：15240 | Loss: 0.061580393463373184\n",
      "Batch：15241 | Loss: 0.05992969870567322\n",
      "Batch：15242 | Loss: 0.06048781797289848\n",
      "Batch：15243 | Loss: 0.044971685856580734\n",
      "Batch：15244 | Loss: 0.055441781878471375\n",
      "Batch：15245 | Loss: 0.06857188791036606\n",
      "Batch：15246 | Loss: 0.06375700980424881\n",
      "Batch：15247 | Loss: 0.04543327912688255\n",
      "Batch：15248 | Loss: 0.05515303462743759\n",
      "Batch：15249 | Loss: 0.05432538688182831\n",
      "Batch：15250 | Loss: 0.05827401578426361\n",
      "Batch：15251 | Loss: 0.044569335877895355\n",
      "Batch：15252 | Loss: 0.05750776454806328\n",
      "Batch：15253 | Loss: 0.060378920286893845\n",
      "Batch：15254 | Loss: 0.05090252682566643\n",
      "Batch：15255 | Loss: 0.06432227790355682\n",
      "Batch：15256 | Loss: 0.059352125972509384\n",
      "Batch：15257 | Loss: 0.057188730686903\n",
      "Batch：15258 | Loss: 0.05294567346572876\n",
      "Batch：15259 | Loss: 0.05783241242170334\n",
      "Batch：15260 | Loss: 0.05720125138759613\n",
      "Batch：15261 | Loss: 0.05779522284865379\n",
      "Batch：15262 | Loss: 0.05033878609538078\n",
      "Batch：15263 | Loss: 0.055703237652778625\n",
      "Batch：15264 | Loss: 0.05051131173968315\n",
      "Batch：15265 | Loss: 0.04404495283961296\n",
      "Batch：15266 | Loss: 0.050753142684698105\n",
      "Batch：15267 | Loss: 0.0462234728038311\n",
      "Batch：15268 | Loss: 0.04967213422060013\n",
      "Batch：15269 | Loss: 0.06832674890756607\n",
      "Batch：15270 | Loss: 0.0510932058095932\n",
      "Batch：15271 | Loss: 0.04725958779454231\n",
      "Batch：15272 | Loss: 0.05126986652612686\n",
      "Batch：15273 | Loss: 0.05606260150671005\n",
      "Batch：15274 | Loss: 0.053369179368019104\n",
      "Batch：15275 | Loss: 0.06047523021697998\n",
      "Batch：15276 | Loss: 0.05879399925470352\n",
      "Batch：15277 | Loss: 0.048133183270692825\n",
      "Batch：15278 | Loss: 0.048045288771390915\n",
      "Batch：15279 | Loss: 0.05020108446478844\n",
      "Batch：15280 | Loss: 0.05632060021162033\n",
      "Batch：15281 | Loss: 0.048436880111694336\n",
      "Batch：15282 | Loss: 0.05601493641734123\n",
      "Batch：15283 | Loss: 0.05824949964880943\n",
      "Batch：15284 | Loss: 0.04527885839343071\n",
      "Batch：15285 | Loss: 0.05527801811695099\n",
      "Batch：15286 | Loss: 0.04846778139472008\n",
      "Batch：15287 | Loss: 0.054676882922649384\n",
      "Batch：15288 | Loss: 0.05270503833889961\n",
      "Batch：15289 | Loss: 0.05155022069811821\n",
      "Batch：15290 | Loss: 0.05808442085981369\n",
      "Batch：15291 | Loss: 0.052736908197402954\n",
      "Batch：15292 | Loss: 0.05849644914269447\n",
      "Batch：15293 | Loss: 0.05223148688673973\n",
      "Batch：15294 | Loss: 0.06636660546064377\n",
      "Batch：15295 | Loss: 0.05487574636936188\n",
      "Batch：15296 | Loss: 0.04460057616233826\n",
      "Batch：15297 | Loss: 0.054290998727083206\n",
      "Batch：15298 | Loss: 0.059354446828365326\n",
      "Batch：15299 | Loss: 0.05704597011208534\n",
      "Batch：15300 | Loss: 0.06205574423074722\n",
      "Batch：15301 | Loss: 0.05011563003063202\n",
      "Batch：15302 | Loss: 0.05635444447398186\n",
      "Batch：15303 | Loss: 0.052414778620004654\n",
      "Batch：15304 | Loss: 0.05628122761845589\n",
      "Batch：15305 | Loss: 0.04784012213349342\n",
      "Batch：15306 | Loss: 0.05941310152411461\n",
      "Batch：15307 | Loss: 0.0548129677772522\n",
      "Batch：15308 | Loss: 0.054182540625333786\n",
      "Batch：15309 | Loss: 0.04992736130952835\n",
      "Batch：15310 | Loss: 0.058598585426807404\n",
      "Batch：15311 | Loss: 0.04911591485142708\n",
      "Batch：15312 | Loss: 0.05657230690121651\n",
      "Batch：15313 | Loss: 0.04833061620593071\n",
      "Batch：15314 | Loss: 0.05979859456419945\n",
      "Batch：15315 | Loss: 0.054046034812927246\n",
      "Batch：15316 | Loss: 0.04799222946166992\n",
      "Batch：15317 | Loss: 0.05995418131351471\n",
      "Batch：15318 | Loss: 0.06015850603580475\n",
      "Batch：15319 | Loss: 0.06458619982004166\n",
      "Batch：15320 | Loss: 0.06293675303459167\n",
      "Batch：15321 | Loss: 0.053939901292324066\n",
      "Batch：15322 | Loss: 0.0533890575170517\n",
      "Batch：15323 | Loss: 0.0658167228102684\n",
      "Batch：15324 | Loss: 0.06074419245123863\n",
      "Batch：15325 | Loss: 0.05490993708372116\n",
      "Batch：15326 | Loss: 0.05304989591240883\n",
      "Batch：15327 | Loss: 0.05351553112268448\n",
      "Batch：15328 | Loss: 0.05269184708595276\n",
      "Batch：15329 | Loss: 0.058935124427080154\n",
      "Batch：15330 | Loss: 0.056075308471918106\n",
      "Batch：15331 | Loss: 0.054930053651332855\n",
      "Batch：15332 | Loss: 0.05612127482891083\n",
      "Batch：15333 | Loss: 0.04979793727397919\n",
      "Batch：15334 | Loss: 0.055360421538352966\n",
      "Batch：15335 | Loss: 0.054815877228975296\n",
      "Batch：15336 | Loss: 0.048006925731897354\n",
      "Batch：15337 | Loss: 0.05721735581755638\n",
      "Batch：15338 | Loss: 0.06081998720765114\n",
      "Batch：15339 | Loss: 0.05155365914106369\n",
      "Batch：15340 | Loss: 0.05289865657687187\n",
      "Batch：15341 | Loss: 0.05958278477191925\n",
      "Batch：15342 | Loss: 0.05850522220134735\n",
      "Batch：15343 | Loss: 0.055003561079502106\n",
      "Batch：15344 | Loss: 0.05583351477980614\n",
      "Batch：15345 | Loss: 0.04389507323503494\n",
      "Batch：15346 | Loss: 0.05410140007734299\n",
      "Batch：15347 | Loss: 0.060676828026771545\n",
      "Batch：15348 | Loss: 0.056618351489305496\n",
      "Batch：15349 | Loss: 0.06136653572320938\n",
      "Batch：15350 | Loss: 0.05603240430355072\n",
      "Batch：15351 | Loss: 0.051499735563993454\n",
      "Batch：15352 | Loss: 0.057528503239154816\n",
      "Batch：15353 | Loss: 0.042437683790922165\n",
      "Batch：15354 | Loss: 0.049158211797475815\n",
      "Batch：15355 | Loss: 0.05487453192472458\n",
      "Batch：15356 | Loss: 0.047364912927150726\n",
      "Batch：15357 | Loss: 0.04110627993941307\n",
      "Batch：15358 | Loss: 0.0626460537314415\n",
      "Batch：15359 | Loss: 0.05625137314200401\n",
      "Batch：15360 | Loss: 0.053845182061195374\n",
      "Batch：15361 | Loss: 0.04201708734035492\n",
      "Batch：15362 | Loss: 0.053682513535022736\n",
      "Batch：15363 | Loss: 0.03945763036608696\n",
      "Batch：15364 | Loss: 0.05056241899728775\n",
      "Batch：15365 | Loss: 0.05719584971666336\n",
      "Batch：15366 | Loss: 0.049136098474264145\n",
      "Batch：15367 | Loss: 0.05032418668270111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：15368 | Loss: 0.05916910618543625\n",
      "Batch：15369 | Loss: 0.04015783965587616\n",
      "Batch：15370 | Loss: 0.051072388887405396\n",
      "Batch：15371 | Loss: 0.06025586277246475\n",
      "Batch：15372 | Loss: 0.044659536331892014\n",
      "Batch：15373 | Loss: 0.05533740669488907\n",
      "Batch：15374 | Loss: 0.04297812283039093\n",
      "Batch：15375 | Loss: 0.05578242987394333\n",
      "Batch：15376 | Loss: 0.050108402967453\n",
      "Batch：15377 | Loss: 0.0510890856385231\n",
      "Batch：15378 | Loss: 0.04841148853302002\n",
      "Batch：15379 | Loss: 0.05053376033902168\n",
      "Batch：15380 | Loss: 0.047474201768636703\n",
      "Batch：15381 | Loss: 0.045815031975507736\n",
      "Batch：15382 | Loss: 0.05025431141257286\n",
      "Batch：15383 | Loss: 0.05299822986125946\n",
      "Batch：15384 | Loss: 0.05520940199494362\n",
      "Batch：15385 | Loss: 0.050233397632837296\n",
      "Batch：15386 | Loss: 0.03828485682606697\n",
      "Batch：15387 | Loss: 0.05941111594438553\n",
      "Batch：15388 | Loss: 0.06324832886457443\n",
      "Batch：15389 | Loss: 0.05808624252676964\n",
      "Batch：15390 | Loss: 0.06665262579917908\n",
      "Batch：15391 | Loss: 0.06068304553627968\n",
      "Batch：15392 | Loss: 0.061674632132053375\n",
      "Batch：15393 | Loss: 0.05593133345246315\n",
      "Batch：15394 | Loss: 0.0566086508333683\n",
      "Batch：15395 | Loss: 0.0564095713198185\n",
      "Batch：15396 | Loss: 0.05808386206626892\n",
      "Batch：15397 | Loss: 0.05176930874586105\n",
      "Batch：15398 | Loss: 0.05275632068514824\n",
      "Batch：15399 | Loss: 0.05573521926999092\n",
      "Batch：15400 | Loss: 0.054136209189891815\n",
      "Batch：15401 | Loss: 0.04653404653072357\n",
      "Batch：15402 | Loss: 0.053523335605859756\n",
      "Batch：15403 | Loss: 0.04738733544945717\n",
      "Batch：15404 | Loss: 0.0549502819776535\n",
      "Batch：15405 | Loss: 0.04690699279308319\n",
      "Batch：15406 | Loss: 0.04068984091281891\n",
      "Batch：15407 | Loss: 0.06270112842321396\n",
      "Batch：15408 | Loss: 0.05511237680912018\n",
      "Batch：15409 | Loss: 0.055367350578308105\n",
      "Batch：15410 | Loss: 0.05130810663104057\n",
      "Batch：15411 | Loss: 0.06672064960002899\n",
      "Batch：15412 | Loss: 0.046594876796007156\n",
      "Batch：15413 | Loss: 0.05299443379044533\n",
      "Batch：15414 | Loss: 0.05975048616528511\n",
      "Batch：15415 | Loss: 0.05211185663938522\n",
      "Batch：15416 | Loss: 0.05356161296367645\n",
      "Batch：15417 | Loss: 0.05311839282512665\n",
      "Batch：15418 | Loss: 0.04634501412510872\n",
      "Batch：15419 | Loss: 0.053416747599840164\n",
      "Batch：15420 | Loss: 0.05309757590293884\n",
      "Batch：15421 | Loss: 0.04853945970535278\n",
      "Batch：15422 | Loss: 0.051637858152389526\n",
      "Batch：15423 | Loss: 0.050705861300230026\n",
      "Batch：15424 | Loss: 0.05611788481473923\n",
      "Batch：15425 | Loss: 0.062308330088853836\n",
      "Batch：15426 | Loss: 0.04930005222558975\n",
      "Batch：15427 | Loss: 0.04980282112956047\n",
      "Batch：15428 | Loss: 0.048321615904569626\n",
      "Batch：15429 | Loss: 0.05082323029637337\n",
      "Batch：15430 | Loss: 0.052725650370121\n",
      "Batch：15431 | Loss: 0.049505166709423065\n",
      "Batch：15432 | Loss: 0.04994353652000427\n",
      "Batch：15433 | Loss: 0.06059128791093826\n",
      "Batch：15434 | Loss: 0.04774972423911095\n",
      "Batch：15435 | Loss: 0.0507977195084095\n",
      "Batch：15436 | Loss: 0.0560280866920948\n",
      "Batch：15437 | Loss: 0.05924342945218086\n",
      "Batch：15438 | Loss: 0.055826637893915176\n",
      "Batch：15439 | Loss: 0.054690148681402206\n",
      "Batch：15440 | Loss: 0.044658370316028595\n",
      "Batch：15441 | Loss: 0.04854273423552513\n",
      "Batch：15442 | Loss: 0.0570540651679039\n",
      "Batch：15443 | Loss: 0.05380573496222496\n",
      "Batch：15444 | Loss: 0.048125263303518295\n",
      "Batch：15445 | Loss: 0.054372940212488174\n",
      "Batch：15446 | Loss: 0.04806884750723839\n",
      "Batch：15447 | Loss: 0.041784610599279404\n",
      "Batch：15448 | Loss: 0.047163013368844986\n",
      "Batch：15449 | Loss: 0.052313126623630524\n",
      "Batch：15450 | Loss: 0.05256173759698868\n",
      "Batch：15451 | Loss: 0.05227504298090935\n",
      "Batch：15452 | Loss: 0.04540305584669113\n",
      "Batch：15453 | Loss: 0.05059721693396568\n",
      "Batch：15454 | Loss: 0.055805642157793045\n",
      "Batch：15455 | Loss: 0.05986006185412407\n",
      "Batch：15456 | Loss: 0.05291271582245827\n",
      "Batch：15457 | Loss: 0.052889883518218994\n",
      "Batch：15458 | Loss: 0.04891049116849899\n",
      "Batch：15459 | Loss: 0.05172482132911682\n",
      "Batch：15460 | Loss: 0.05138453096151352\n",
      "Batch：15461 | Loss: 0.0586387924849987\n",
      "Batch：15462 | Loss: 0.054232023656368256\n",
      "Batch：15463 | Loss: 0.061368558555841446\n",
      "Batch：15464 | Loss: 0.05272069200873375\n",
      "Batch：15465 | Loss: 0.054727908223867416\n",
      "Batch：15466 | Loss: 0.043897438794374466\n",
      "Batch：15467 | Loss: 0.04817163944244385\n",
      "Batch：15468 | Loss: 0.04819321259856224\n",
      "Batch：15469 | Loss: 0.041921213269233704\n",
      "Batch：15470 | Loss: 0.0491810105741024\n",
      "Batch：15471 | Loss: 0.05156495049595833\n",
      "Batch：15472 | Loss: 0.048170220106840134\n",
      "Batch：15473 | Loss: 0.05660150200128555\n",
      "Batch：15474 | Loss: 0.0652352049946785\n",
      "Batch：15475 | Loss: 0.056698791682720184\n",
      "Batch：15476 | Loss: 0.04910032078623772\n",
      "Batch：15477 | Loss: 0.04956689476966858\n",
      "Batch：15478 | Loss: 0.048850152641534805\n",
      "Batch：15479 | Loss: 0.05125565081834793\n",
      "Batch：15480 | Loss: 0.045393701642751694\n",
      "Batch：15481 | Loss: 0.05590300261974335\n",
      "Batch：15482 | Loss: 0.0494622103869915\n",
      "Batch：15483 | Loss: 0.05653252452611923\n",
      "Batch：15484 | Loss: 0.056117285043001175\n",
      "Batch：15485 | Loss: 0.04656067490577698\n",
      "Batch：15486 | Loss: 0.05402851477265358\n",
      "Batch：15487 | Loss: 0.05473935976624489\n",
      "Batch：15488 | Loss: 0.05983591824769974\n",
      "Batch：15489 | Loss: 0.04662185534834862\n",
      "Batch：15490 | Loss: 0.05877351760864258\n",
      "Batch：15491 | Loss: 0.052377909421920776\n",
      "Batch：15492 | Loss: 0.063260518014431\n",
      "Batch：15493 | Loss: 0.0599675290286541\n",
      "Batch：15494 | Loss: 0.052859172224998474\n",
      "Batch：15495 | Loss: 0.06443683803081512\n",
      "Batch：15496 | Loss: 0.06125294789671898\n",
      "Batch：15497 | Loss: 0.05255439132452011\n",
      "Batch：15498 | Loss: 0.05469300597906113\n",
      "Batch：15499 | Loss: 0.045284438878297806\n",
      "Batch：15500 | Loss: 0.04119188338518143\n",
      "Batch：15501 | Loss: 0.05456703528761864\n",
      "Batch：15502 | Loss: 0.057910073548555374\n",
      "Batch：15503 | Loss: 0.05007285624742508\n",
      "Batch：15504 | Loss: 0.054206255823373795\n",
      "Batch：15505 | Loss: 0.052199091762304306\n",
      "Batch：15506 | Loss: 0.05704698711633682\n",
      "Batch：15507 | Loss: 0.05747288092970848\n",
      "Batch：15508 | Loss: 0.046399444341659546\n",
      "Batch：15509 | Loss: 0.04983580484986305\n",
      "Batch：15510 | Loss: 0.0501309297978878\n",
      "Batch：15511 | Loss: 0.05593155324459076\n",
      "Batch：15512 | Loss: 0.0534549206495285\n",
      "Batch：15513 | Loss: 0.048898808658123016\n",
      "Batch：15514 | Loss: 0.059184588491916656\n",
      "Batch：15515 | Loss: 0.05082837864756584\n",
      "Batch：15516 | Loss: 0.0632164478302002\n",
      "Batch：15517 | Loss: 0.05164315178990364\n",
      "Batch：15518 | Loss: 0.05515369027853012\n",
      "Batch：15519 | Loss: 0.04986189305782318\n",
      "Batch：15520 | Loss: 0.05327225849032402\n",
      "Batch：15521 | Loss: 0.05671095848083496\n",
      "Batch：15522 | Loss: 0.052682045847177505\n",
      "Batch：15523 | Loss: 0.0565648190677166\n",
      "Batch：15524 | Loss: 0.051337722688913345\n",
      "Batch：15525 | Loss: 0.059229470789432526\n",
      "Batch：15526 | Loss: 0.052011605352163315\n",
      "Batch：15527 | Loss: 0.05237468332052231\n",
      "Batch：15528 | Loss: 0.041614145040512085\n",
      "Batch：15529 | Loss: 0.05766795948147774\n",
      "Batch：15530 | Loss: 0.05452243611216545\n",
      "Batch：15531 | Loss: 0.05616693198680878\n",
      "Batch：15532 | Loss: 0.051041483879089355\n",
      "Batch：15533 | Loss: 0.0417921282351017\n",
      "Batch：15534 | Loss: 0.05457404628396034\n",
      "Batch：15535 | Loss: 0.046561349183321\n",
      "Batch：15536 | Loss: 0.048183899372816086\n",
      "Batch：15537 | Loss: 0.044256702065467834\n",
      "Batch：15538 | Loss: 0.05713316798210144\n",
      "Batch：15539 | Loss: 0.05887914076447487\n",
      "Batch：15540 | Loss: 0.04801878705620766\n",
      "Batch：15541 | Loss: 0.04920770227909088\n",
      "Batch：15542 | Loss: 0.04655198007822037\n",
      "Batch：15543 | Loss: 0.05302494391798973\n",
      "Batch：15544 | Loss: 0.04731368273496628\n",
      "Batch：15545 | Loss: 0.055608056485652924\n",
      "Batch：15546 | Loss: 0.0546756386756897\n",
      "Batch：15547 | Loss: 0.05644768103957176\n",
      "Batch：15548 | Loss: 0.05545585975050926\n",
      "Batch：15549 | Loss: 0.060244832187891006\n",
      "Batch：15550 | Loss: 0.05421082675457001\n",
      "Batch：15551 | Loss: 0.05031212419271469\n",
      "Batch：15552 | Loss: 0.04774794355034828\n",
      "Batch：15553 | Loss: 0.05069425329566002\n",
      "Batch：15554 | Loss: 0.05747705698013306\n",
      "Batch：15555 | Loss: 0.05100873112678528\n",
      "Batch：15556 | Loss: 0.05453014746308327\n",
      "Batch：15557 | Loss: 0.045142434537410736\n",
      "Batch：15558 | Loss: 0.044592004269361496\n",
      "Batch：15559 | Loss: 0.051524993032217026\n",
      "Batch：15560 | Loss: 0.05195701867341995\n",
      "Batch：15561 | Loss: 0.051542069762945175\n",
      "Batch：15562 | Loss: 0.05900288000702858\n",
      "Batch：15563 | Loss: 0.04777557775378227\n",
      "Batch：15564 | Loss: 0.04974205046892166\n",
      "Batch：15565 | Loss: 0.0472773015499115\n",
      "Batch：15566 | Loss: 0.04844282567501068\n",
      "Batch：15567 | Loss: 0.05038826912641525\n",
      "Batch：15568 | Loss: 0.0532819926738739\n",
      "Batch：15569 | Loss: 0.05815308541059494\n",
      "Batch：15570 | Loss: 0.06549538671970367\n",
      "Batch：15571 | Loss: 0.04903688654303551\n",
      "Batch：15572 | Loss: 0.051449004560709\n",
      "Batch：15573 | Loss: 0.04981188848614693\n",
      "Batch：15574 | Loss: 0.051083628088235855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：15575 | Loss: 0.051179010421037674\n",
      "Batch：15576 | Loss: 0.04829566553235054\n",
      "Batch：15577 | Loss: 0.04907432571053505\n",
      "Batch：15578 | Loss: 0.04401006922125816\n",
      "Batch：15579 | Loss: 0.048505738377571106\n",
      "Batch：15580 | Loss: 0.051424138247966766\n",
      "Batch：15581 | Loss: 0.04618745297193527\n",
      "Batch：15582 | Loss: 0.053411997854709625\n",
      "Batch：15583 | Loss: 0.05414239317178726\n",
      "Batch：15584 | Loss: 0.050132766366004944\n",
      "Batch：15585 | Loss: 0.05057317018508911\n",
      "Batch：15586 | Loss: 0.05344397574663162\n",
      "Batch：15587 | Loss: 0.05250049754977226\n",
      "Batch：15588 | Loss: 0.052187010645866394\n",
      "Batch：15589 | Loss: 0.054866138845682144\n",
      "Batch：15590 | Loss: 0.057053159922361374\n",
      "Batch：15591 | Loss: 0.0462130643427372\n",
      "Batch：15592 | Loss: 0.050592295825481415\n",
      "Batch：15593 | Loss: 0.05251830071210861\n",
      "Batch：15594 | Loss: 0.04879682511091232\n",
      "Batch：15595 | Loss: 0.06103937700390816\n",
      "Batch：15596 | Loss: 0.04167202115058899\n",
      "Batch：15597 | Loss: 0.04919372871518135\n",
      "Batch：15598 | Loss: 0.06138119101524353\n",
      "Batch：15599 | Loss: 0.054430041462183\n",
      "Batch：15600 | Loss: 0.042472247034311295\n",
      "Batch：15601 | Loss: 0.05055631324648857\n",
      "Batch：15602 | Loss: 0.058564167469739914\n",
      "Batch：15603 | Loss: 0.05169978737831116\n",
      "Batch：15604 | Loss: 0.05101475119590759\n",
      "Batch：15605 | Loss: 0.04247377812862396\n",
      "Batch：15606 | Loss: 0.0503990463912487\n",
      "Batch：15607 | Loss: 0.04987597465515137\n",
      "Batch：15608 | Loss: 0.04828238859772682\n",
      "Batch：15609 | Loss: 0.059029266238212585\n",
      "Batch：15610 | Loss: 0.0543220192193985\n",
      "Batch：15611 | Loss: 0.0545029491186142\n",
      "Batch：15612 | Loss: 0.048966359347105026\n",
      "Batch：15613 | Loss: 0.058262765407562256\n",
      "Batch：15614 | Loss: 0.06365498900413513\n",
      "Batch：15615 | Loss: 0.05025535076856613\n",
      "Batch：15616 | Loss: 0.0517672523856163\n",
      "Batch：15617 | Loss: 0.05705832690000534\n",
      "Batch：15618 | Loss: 0.05463358387351036\n",
      "Batch：15619 | Loss: 0.0575670562684536\n",
      "Batch：15620 | Loss: 0.043197039514780045\n",
      "Batch：15621 | Loss: 0.05204157903790474\n",
      "Batch：15622 | Loss: 0.040788475424051285\n",
      "Batch：15623 | Loss: 0.052479639649391174\n",
      "Batch：15624 | Loss: 0.051628101617097855\n",
      "Batch：15625 | Loss: 0.06184033304452896\n",
      "Batch：15626 | Loss: 0.059484872967004776\n",
      "Batch：15627 | Loss: 0.05282477289438248\n",
      "Batch：15628 | Loss: 0.05619055777788162\n",
      "Batch：15629 | Loss: 0.05278275907039642\n",
      "Batch：15630 | Loss: 0.059773705899715424\n",
      "Batch：15631 | Loss: 0.05502738058567047\n",
      "Batch：15632 | Loss: 0.05301491171121597\n",
      "Batch：15633 | Loss: 0.048613544553518295\n",
      "Batch：15634 | Loss: 0.05456743389368057\n",
      "Batch：15635 | Loss: 0.051918040961027145\n",
      "Batch：15636 | Loss: 0.05304863303899765\n",
      "Batch：15637 | Loss: 0.041455332189798355\n",
      "Batch：15638 | Loss: 0.043760914355516434\n",
      "Batch：15639 | Loss: 0.05830727517604828\n",
      "Batch：15640 | Loss: 0.06302675604820251\n",
      "Batch：15641 | Loss: 0.046245552599430084\n",
      "Batch：15642 | Loss: 0.054216835647821426\n",
      "Batch：15643 | Loss: 0.06504952162504196\n",
      "Batch：15644 | Loss: 0.0524732768535614\n",
      "Batch：15645 | Loss: 0.053559884428977966\n",
      "Batch：15646 | Loss: 0.058369237929582596\n",
      "Batch：15647 | Loss: 0.04933830723166466\n",
      "Batch：15648 | Loss: 0.053678836673498154\n",
      "Batch：15649 | Loss: 0.041639965027570724\n",
      "Batch：15650 | Loss: 0.0712074264883995\n",
      "Batch：15651 | Loss: 0.05966780707240105\n",
      "Batch：15652 | Loss: 0.055673226714134216\n",
      "Batch：15653 | Loss: 0.05075421184301376\n",
      "Batch：15654 | Loss: 0.04837752878665924\n",
      "Batch：15655 | Loss: 0.04638858512043953\n",
      "Batch：15656 | Loss: 0.051721446216106415\n",
      "Batch：15657 | Loss: 0.04983411729335785\n",
      "Batch：15658 | Loss: 0.054902415722608566\n",
      "Batch：15659 | Loss: 0.04729442298412323\n",
      "Batch：15660 | Loss: 0.05120693892240524\n",
      "Batch：15661 | Loss: 0.047231219708919525\n",
      "Batch：15662 | Loss: 0.05124775692820549\n",
      "Batch：15663 | Loss: 0.046143606305122375\n",
      "Batch：15664 | Loss: 0.06286529451608658\n",
      "Batch：15665 | Loss: 0.05356855317950249\n",
      "Batch：15666 | Loss: 0.04992688074707985\n",
      "Batch：15667 | Loss: 0.045316506177186966\n",
      "Batch：15668 | Loss: 0.04718337580561638\n",
      "Batch：15669 | Loss: 0.043665871024131775\n",
      "Batch：15670 | Loss: 0.05922100692987442\n",
      "Batch：15671 | Loss: 0.03852241858839989\n",
      "Batch：15672 | Loss: 0.0519687682390213\n",
      "Batch：15673 | Loss: 0.048348601907491684\n",
      "Batch：15674 | Loss: 0.05977347865700722\n",
      "Batch：15675 | Loss: 0.05598603934049606\n",
      "Batch：15676 | Loss: 0.04669126495718956\n",
      "Batch：15677 | Loss: 0.04971577972173691\n",
      "Batch：15678 | Loss: 0.05203184485435486\n",
      "Batch：15679 | Loss: 0.05758751183748245\n",
      "Batch：15680 | Loss: 0.050104476511478424\n",
      "Batch：15681 | Loss: 0.046277791261672974\n",
      "Batch：15682 | Loss: 0.04798050969839096\n",
      "Batch：15683 | Loss: 0.050987374037504196\n",
      "Batch：15684 | Loss: 0.05660184100270271\n",
      "Batch：15685 | Loss: 0.04814087972044945\n",
      "Batch：15686 | Loss: 0.040919963270425797\n",
      "Batch：15687 | Loss: 0.04610856994986534\n",
      "Batch：15688 | Loss: 0.0564822293817997\n",
      "Batch：15689 | Loss: 0.046843137592077255\n",
      "Batch：15690 | Loss: 0.06039583310484886\n",
      "Batch：15691 | Loss: 0.058704618364572525\n",
      "Batch：15692 | Loss: 0.04733463004231453\n",
      "Batch：15693 | Loss: 0.05992341414093971\n",
      "Batch：15694 | Loss: 0.05096392706036568\n",
      "Batch：15695 | Loss: 0.04400835186243057\n",
      "Batch：15696 | Loss: 0.05311058461666107\n",
      "Batch：15697 | Loss: 0.0542847141623497\n",
      "Batch：15698 | Loss: 0.05692499876022339\n",
      "Batch：15699 | Loss: 0.05048719048500061\n",
      "Batch：15700 | Loss: 0.045604050159454346\n",
      "Batch：15701 | Loss: 0.05494081601500511\n",
      "Batch：15702 | Loss: 0.05280497297644615\n",
      "Batch：15703 | Loss: 0.05737920105457306\n",
      "Batch：15704 | Loss: 0.050594981759786606\n",
      "Batch：15705 | Loss: 0.04552567005157471\n",
      "Batch：15706 | Loss: 0.05664920061826706\n",
      "Batch：15707 | Loss: 0.05019465088844299\n",
      "Batch：15708 | Loss: 0.05277087911963463\n",
      "Batch：15709 | Loss: 0.04648951068520546\n",
      "Batch：15710 | Loss: 0.05368019640445709\n",
      "Batch：15711 | Loss: 0.05706019699573517\n",
      "Batch：15712 | Loss: 0.05151820927858353\n",
      "Batch：15713 | Loss: 0.054420407861471176\n",
      "Batch：15714 | Loss: 0.052811186760663986\n",
      "Batch：15715 | Loss: 0.04820756986737251\n",
      "Batch：15716 | Loss: 0.0444527268409729\n",
      "Batch：15717 | Loss: 0.0528302900493145\n",
      "Batch：15718 | Loss: 0.051021330058574677\n",
      "Batch：15719 | Loss: 0.04840334877371788\n",
      "Batch：15720 | Loss: 0.054109591990709305\n",
      "Batch：15721 | Loss: 0.052097614854574203\n",
      "Batch：15722 | Loss: 0.05142020434141159\n",
      "Batch：15723 | Loss: 0.04898448288440704\n",
      "Batch：15724 | Loss: 0.051249921321868896\n",
      "Batch：15725 | Loss: 0.055243510752916336\n",
      "Batch：15726 | Loss: 0.06469704955816269\n",
      "Batch：15727 | Loss: 0.04529014602303505\n",
      "Batch：15728 | Loss: 0.04763728752732277\n",
      "Batch：15729 | Loss: 0.04876628518104553\n",
      "Batch：15730 | Loss: 0.04492713510990143\n",
      "Batch：15731 | Loss: 0.04442683979868889\n",
      "Batch：15732 | Loss: 0.04952820762991905\n",
      "Batch：15733 | Loss: 0.0499105229973793\n",
      "Batch：15734 | Loss: 0.04661588370800018\n",
      "Batch：15735 | Loss: 0.057064905762672424\n",
      "Batch：15736 | Loss: 0.04614531993865967\n",
      "Batch：15737 | Loss: 0.04603980854153633\n",
      "Batch：15738 | Loss: 0.049919452518224716\n",
      "Batch：15739 | Loss: 0.04783974215388298\n",
      "Batch：15740 | Loss: 0.04883301630616188\n",
      "Batch：15741 | Loss: 0.04167041555047035\n",
      "Batch：15742 | Loss: 0.0676267221570015\n",
      "Batch：15743 | Loss: 0.045218709856271744\n",
      "Batch：15744 | Loss: 0.04578368738293648\n",
      "Batch：15745 | Loss: 0.05950576812028885\n",
      "Batch：15746 | Loss: 0.04779670760035515\n",
      "Batch：15747 | Loss: 0.04440586641430855\n",
      "Batch：15748 | Loss: 0.044910334050655365\n",
      "Batch：15749 | Loss: 0.04276040941476822\n",
      "Batch：15750 | Loss: 0.053342919796705246\n",
      "Batch：15751 | Loss: 0.05959344282746315\n",
      "Batch：15752 | Loss: 0.049987055361270905\n",
      "Batch：15753 | Loss: 0.04900706931948662\n",
      "Batch：15754 | Loss: 0.051846541464328766\n",
      "Batch：15755 | Loss: 0.05642823874950409\n",
      "Batch：15756 | Loss: 0.0434633232653141\n",
      "Batch：15757 | Loss: 0.05645156651735306\n",
      "Batch：15758 | Loss: 0.03838139399886131\n",
      "Batch：15759 | Loss: 0.047516997903585434\n",
      "Batch：15760 | Loss: 0.0509856678545475\n",
      "Batch：15761 | Loss: 0.05031280592083931\n",
      "Batch：15762 | Loss: 0.047903671860694885\n",
      "Batch：15763 | Loss: 0.052492644637823105\n",
      "Batch：15764 | Loss: 0.05303698033094406\n",
      "Batch：15765 | Loss: 0.04708902910351753\n",
      "Batch：15766 | Loss: 0.05241161957383156\n",
      "Batch：15767 | Loss: 0.05163697153329849\n",
      "Batch：15768 | Loss: 0.051652368158102036\n",
      "Batch：15769 | Loss: 0.05222850665450096\n",
      "Batch：15770 | Loss: 0.05552982911467552\n",
      "Batch：15771 | Loss: 0.05458017811179161\n",
      "Batch：15772 | Loss: 0.05488727614283562\n",
      "Batch：15773 | Loss: 0.0558047890663147\n",
      "Batch：15774 | Loss: 0.05201258137822151\n",
      "Batch：15775 | Loss: 0.05734890326857567\n",
      "Batch：15776 | Loss: 0.047110673040151596\n",
      "Batch：15777 | Loss: 0.04034949094057083\n",
      "Batch：15778 | Loss: 0.051972925662994385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：15779 | Loss: 0.05473506450653076\n",
      "Batch：15780 | Loss: 0.0542769655585289\n",
      "Batch：15781 | Loss: 0.05389056354761124\n",
      "Batch：15782 | Loss: 0.06688759475946426\n",
      "Batch：15783 | Loss: 0.0595703125\n",
      "Batch：15784 | Loss: 0.05887793004512787\n",
      "Batch：15785 | Loss: 0.06769172847270966\n",
      "Batch：15786 | Loss: 0.04668989032506943\n",
      "Batch：15787 | Loss: 0.04435662925243378\n",
      "Batch：15788 | Loss: 0.043811310082674026\n",
      "Batch：15789 | Loss: 0.06188126653432846\n",
      "Batch：15790 | Loss: 0.049556173384189606\n",
      "Batch：15791 | Loss: 0.05878138169646263\n",
      "Batch：15792 | Loss: 0.04532485827803612\n",
      "Batch：15793 | Loss: 0.05807908624410629\n",
      "Batch：15794 | Loss: 0.05853629484772682\n",
      "Batch：15795 | Loss: 0.05161428824067116\n",
      "Batch：15796 | Loss: 0.05147027596831322\n",
      "Batch：15797 | Loss: 0.04793023690581322\n",
      "Batch：15798 | Loss: 0.061405278742313385\n",
      "Batch：15799 | Loss: 0.04942217841744423\n",
      "Batch：15800 | Loss: 0.051199156790971756\n",
      "Batch：15801 | Loss: 0.04564168304204941\n",
      "Batch：15802 | Loss: 0.05398448556661606\n",
      "Batch：15803 | Loss: 0.05002669245004654\n",
      "Batch：15804 | Loss: 0.05232919752597809\n",
      "Batch：15805 | Loss: 0.054660093039274216\n",
      "Batch：15806 | Loss: 0.0556153729557991\n",
      "Batch：15807 | Loss: 0.05325377359986305\n",
      "Batch：15808 | Loss: 0.06875947117805481\n",
      "Batch：15809 | Loss: 0.04446391761302948\n",
      "Batch：15810 | Loss: 0.06087163835763931\n",
      "Batch：15811 | Loss: 0.06583629548549652\n",
      "Batch：15812 | Loss: 0.06886468082666397\n",
      "Batch：15813 | Loss: 0.053902290761470795\n",
      "Batch：15814 | Loss: 0.050537679344415665\n",
      "Batch：15815 | Loss: 0.05599825084209442\n",
      "Batch：15816 | Loss: 0.048663388937711716\n",
      "Batch：15817 | Loss: 0.053655751049518585\n",
      "Batch：15818 | Loss: 0.058300476521253586\n",
      "Batch：15819 | Loss: 0.05277763307094574\n",
      "Batch：15820 | Loss: 0.05463108792901039\n",
      "Batch：15821 | Loss: 0.059146951884031296\n",
      "Batch：15822 | Loss: 0.06708585470914841\n",
      "Batch：15823 | Loss: 0.04010569676756859\n",
      "Batch：15824 | Loss: 0.04892459511756897\n",
      "Batch：15825 | Loss: 0.04828738421201706\n",
      "Batch：15826 | Loss: 0.054484520107507706\n",
      "Batch：15827 | Loss: 0.06242678314447403\n",
      "Batch：15828 | Loss: 0.06158342584967613\n",
      "Batch：15829 | Loss: 0.05477342754602432\n",
      "Batch：15830 | Loss: 0.05967219918966293\n",
      "Batch：15831 | Loss: 0.05108797177672386\n",
      "Batch：15832 | Loss: 0.054431792348623276\n",
      "Batch：15833 | Loss: 0.057958975434303284\n",
      "Batch：15834 | Loss: 0.05241003260016441\n",
      "Batch：15835 | Loss: 0.0592203326523304\n",
      "Batch：15836 | Loss: 0.048127103596925735\n",
      "Batch：15837 | Loss: 0.05621830001473427\n",
      "Batch：15838 | Loss: 0.04561515152454376\n",
      "Batch：15839 | Loss: 0.04886709526181221\n",
      "Batch：15840 | Loss: 0.044357430189847946\n",
      "Batch：15841 | Loss: 0.052566464990377426\n",
      "Batch：15842 | Loss: 0.04721621051430702\n",
      "Batch：15843 | Loss: 0.05139334127306938\n",
      "Batch：15844 | Loss: 0.0533950999379158\n",
      "Batch：15845 | Loss: 0.047517579048871994\n",
      "Batch：15846 | Loss: 0.05120842903852463\n",
      "Batch：15847 | Loss: 0.05157576501369476\n",
      "Batch：15848 | Loss: 0.047212015837430954\n",
      "Batch：15849 | Loss: 0.05097551271319389\n",
      "Batch：15850 | Loss: 0.04714083671569824\n",
      "Batch：15851 | Loss: 0.057948820292949677\n",
      "Batch：15852 | Loss: 0.07030704617500305\n",
      "Batch：15853 | Loss: 0.04707643762230873\n",
      "Batch：15854 | Loss: 0.04885132983326912\n",
      "Batch：15855 | Loss: 0.04563722759485245\n",
      "Batch：15856 | Loss: 0.04477531462907791\n",
      "Batch：15857 | Loss: 0.043056000024080276\n",
      "Batch：15858 | Loss: 0.04589807987213135\n",
      "Batch：15859 | Loss: 0.05358446016907692\n",
      "Batch：15860 | Loss: 0.046585794538259506\n",
      "Batch：15861 | Loss: 0.04427313804626465\n",
      "Batch：15862 | Loss: 0.06176850199699402\n",
      "Batch：15863 | Loss: 0.04554072394967079\n",
      "Batch：15864 | Loss: 0.05257907882332802\n",
      "Batch：15865 | Loss: 0.048573993146419525\n",
      "Batch：15866 | Loss: 0.05707778409123421\n",
      "Batch：15867 | Loss: 0.049840785562992096\n",
      "Batch：15868 | Loss: 0.047216128557920456\n",
      "Batch：15869 | Loss: 0.051306676119565964\n",
      "Batch：15870 | Loss: 0.042477793991565704\n",
      "Batch：15871 | Loss: 0.04962525516748428\n",
      "Batch：15872 | Loss: 0.05407866835594177\n",
      "Batch：15873 | Loss: 0.0565752238035202\n",
      "Batch：15874 | Loss: 0.0427360013127327\n",
      "Batch：15875 | Loss: 0.05343357101082802\n",
      "Batch：15876 | Loss: 0.05463340878486633\n",
      "Batch：15877 | Loss: 0.05250685662031174\n",
      "Batch：15878 | Loss: 0.05221153795719147\n",
      "Batch：15879 | Loss: 0.041892390698194504\n",
      "Batch：15880 | Loss: 0.057061776518821716\n",
      "Batch：15881 | Loss: 0.04801760986447334\n",
      "Batch：15882 | Loss: 0.05115506052970886\n",
      "Batch：15883 | Loss: 0.05127536132931709\n",
      "Batch：15884 | Loss: 0.0514395646750927\n",
      "Batch：15885 | Loss: 0.059055835008621216\n",
      "Batch：15886 | Loss: 0.05773106962442398\n",
      "Batch：15887 | Loss: 0.05035294592380524\n",
      "Batch：15888 | Loss: 0.04371197521686554\n",
      "Batch：15889 | Loss: 0.043725281953811646\n",
      "Batch：15890 | Loss: 0.051682088524103165\n",
      "Batch：15891 | Loss: 0.0481412336230278\n",
      "Batch：15892 | Loss: 0.05417204648256302\n",
      "Batch：15893 | Loss: 0.051517609506845474\n",
      "Batch：15894 | Loss: 0.0435241274535656\n",
      "Batch：15895 | Loss: 0.05257462337613106\n",
      "Batch：15896 | Loss: 0.046733591705560684\n",
      "Batch：15897 | Loss: 0.05638623982667923\n",
      "Batch：15898 | Loss: 0.043395526707172394\n",
      "Batch：15899 | Loss: 0.05479033291339874\n",
      "Batch：15900 | Loss: 0.05910995602607727\n",
      "Batch：15901 | Loss: 0.04300517588853836\n",
      "Batch：15902 | Loss: 0.055328067392110825\n",
      "Batch：15903 | Loss: 0.05648137256503105\n",
      "Batch：15904 | Loss: 0.04501725360751152\n",
      "Batch：15905 | Loss: 0.051861196756362915\n",
      "Batch：15906 | Loss: 0.04988543689250946\n",
      "Batch：15907 | Loss: 0.050031427294015884\n",
      "Batch：15908 | Loss: 0.06247836351394653\n",
      "Batch：15909 | Loss: 0.04878515750169754\n",
      "Batch：15910 | Loss: 0.04437582194805145\n",
      "Batch：15911 | Loss: 0.043725259602069855\n",
      "Batch：15912 | Loss: 0.052934203296899796\n",
      "Batch：15913 | Loss: 0.05244133621454239\n",
      "Batch：15914 | Loss: 0.042026180773973465\n",
      "Batch：15915 | Loss: 0.05519219487905502\n",
      "Batch：15916 | Loss: 0.0516606830060482\n",
      "Batch：15917 | Loss: 0.055752526968717575\n",
      "Batch：15918 | Loss: 0.05252321437001228\n",
      "Batch：15919 | Loss: 0.06974400579929352\n",
      "Batch：15920 | Loss: 0.04724059998989105\n",
      "Batch：15921 | Loss: 0.047629669308662415\n",
      "Batch：15922 | Loss: 0.04892753064632416\n",
      "Batch：15923 | Loss: 0.05672634392976761\n",
      "Batch：15924 | Loss: 0.049052055925130844\n",
      "Batch：15925 | Loss: 0.052183087915182114\n",
      "Batch：15926 | Loss: 0.04380667954683304\n",
      "Batch：15927 | Loss: 0.04920412227511406\n",
      "Batch：15928 | Loss: 0.060202062129974365\n",
      "Batch：15929 | Loss: 0.04617031663656235\n",
      "Batch：15930 | Loss: 0.047858692705631256\n",
      "Batch：15931 | Loss: 0.05903303995728493\n",
      "Batch：15932 | Loss: 0.0465511791408062\n",
      "Batch：15933 | Loss: 0.051193416118621826\n",
      "Batch：15934 | Loss: 0.04608391225337982\n",
      "Batch：15935 | Loss: 0.04400436207652092\n",
      "Batch：15936 | Loss: 0.039230916649103165\n",
      "Batch：15937 | Loss: 0.057000067085027695\n",
      "Batch：15938 | Loss: 0.049360208213329315\n",
      "Batch：15939 | Loss: 0.0481753945350647\n",
      "Batch：15940 | Loss: 0.056471556425094604\n",
      "Batch：15941 | Loss: 0.047752782702445984\n",
      "Batch：15942 | Loss: 0.043365590274333954\n",
      "Batch：15943 | Loss: 0.05725456029176712\n",
      "Batch：15944 | Loss: 0.053305480629205704\n",
      "Batch：15945 | Loss: 0.04895232245326042\n",
      "Batch：15946 | Loss: 0.05616369470953941\n",
      "Batch：15947 | Loss: 0.05795225128531456\n",
      "Batch：15948 | Loss: 0.04737931117415428\n",
      "Batch：15949 | Loss: 0.05420570820569992\n",
      "Batch：15950 | Loss: 0.05201997980475426\n",
      "Batch：15951 | Loss: 0.0484209805727005\n",
      "Batch：15952 | Loss: 0.053854625672101974\n",
      "Batch：15953 | Loss: 0.05551782622933388\n",
      "Batch：15954 | Loss: 0.051397159695625305\n",
      "Batch：15955 | Loss: 0.03896910324692726\n",
      "Batch：15956 | Loss: 0.04730276018381119\n",
      "Batch：15957 | Loss: 0.05135729908943176\n",
      "Batch：15958 | Loss: 0.04626468941569328\n",
      "Batch：15959 | Loss: 0.04547930881381035\n",
      "Batch：15960 | Loss: 0.06258165091276169\n",
      "Batch：15961 | Loss: 0.050626982003450394\n",
      "Batch：15962 | Loss: 0.045545950531959534\n",
      "Batch：15963 | Loss: 0.034004710614681244\n",
      "Batch：15964 | Loss: 0.0545254647731781\n",
      "Batch：15965 | Loss: 0.052178170531988144\n",
      "Batch：15966 | Loss: 0.05024845153093338\n",
      "Batch：15967 | Loss: 0.05917177349328995\n",
      "Batch：15968 | Loss: 0.04564511030912399\n",
      "Batch：15969 | Loss: 0.052119750529527664\n",
      "Batch：15970 | Loss: 0.05883488804101944\n",
      "Batch：15971 | Loss: 0.05011874437332153\n",
      "Batch：15972 | Loss: 0.045991282910108566\n",
      "Batch：15973 | Loss: 0.05134722962975502\n",
      "Batch：15974 | Loss: 0.05244793742895126\n",
      "Batch：15975 | Loss: 0.050765424966812134\n",
      "Batch：15976 | Loss: 0.045268405228853226\n",
      "Batch：15977 | Loss: 0.05256519839167595\n",
      "Batch：15978 | Loss: 0.05134834349155426\n",
      "Batch：15979 | Loss: 0.0551062673330307\n",
      "Batch：15980 | Loss: 0.03935271129012108\n",
      "Batch：15981 | Loss: 0.05064423754811287\n",
      "Batch：15982 | Loss: 0.06108972430229187\n",
      "Batch：15983 | Loss: 0.06300751864910126\n",
      "Batch：15984 | Loss: 0.06067357212305069\n",
      "Batch：15985 | Loss: 0.046027250587940216\n",
      "Batch：15986 | Loss: 0.05472226068377495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：15987 | Loss: 0.05366482958197594\n",
      "Batch：15988 | Loss: 0.047636259347200394\n",
      "Batch：15989 | Loss: 0.05496171861886978\n",
      "Batch：15990 | Loss: 0.043824005872011185\n",
      "Batch：15991 | Loss: 0.0531480610370636\n",
      "Batch：15992 | Loss: 0.053807225078344345\n",
      "Batch：15993 | Loss: 0.05330133065581322\n",
      "Batch：15994 | Loss: 0.04133541136980057\n",
      "Batch：15995 | Loss: 0.059974100440740585\n",
      "Batch：15996 | Loss: 0.048577696084976196\n",
      "Batch：15997 | Loss: 0.052065104246139526\n",
      "Batch：15998 | Loss: 0.05456242337822914\n",
      "Batch：15999 | Loss: 0.04384658858180046\n",
      "Batch：16000 | Loss: 0.05005266144871712\n",
      "Batch：16001 | Loss: 0.043814484030008316\n",
      "Batch：16002 | Loss: 0.054840169847011566\n",
      "Batch：16003 | Loss: 0.04666408151388168\n",
      "Batch：16004 | Loss: 0.060317300260066986\n",
      "Batch：16005 | Loss: 0.052451811730861664\n",
      "Batch：16006 | Loss: 0.05207532271742821\n",
      "Batch：16007 | Loss: 0.04949329420924187\n",
      "Batch：16008 | Loss: 0.05444672703742981\n",
      "Batch：16009 | Loss: 0.04578489065170288\n",
      "Batch：16010 | Loss: 0.04833528771996498\n",
      "Batch：16011 | Loss: 0.043133512139320374\n",
      "Batch：16012 | Loss: 0.04728410392999649\n",
      "Batch：16013 | Loss: 0.05357832834124565\n",
      "Batch：16014 | Loss: 0.057365573942661285\n",
      "Batch：16015 | Loss: 0.051649730652570724\n",
      "Batch：16016 | Loss: 0.04671013355255127\n",
      "Batch：16017 | Loss: 0.05925904959440231\n",
      "Batch：16018 | Loss: 0.04651661962270737\n",
      "Batch：16019 | Loss: 0.06497985124588013\n",
      "Batch：16020 | Loss: 0.057200368493795395\n",
      "Batch：16021 | Loss: 0.0644630491733551\n",
      "Batch：16022 | Loss: 0.0507146492600441\n",
      "Batch：16023 | Loss: 0.04806949943304062\n",
      "Batch：16024 | Loss: 0.05496605858206749\n",
      "Batch：16025 | Loss: 0.05039693042635918\n",
      "Batch：16026 | Loss: 0.051140960305929184\n",
      "Batch：16027 | Loss: 0.05061967298388481\n",
      "Batch：16028 | Loss: 0.046775829046964645\n",
      "Batch：16029 | Loss: 0.05097232386469841\n",
      "Batch：16030 | Loss: 0.041629645973443985\n",
      "Batch：16031 | Loss: 0.05171375349164009\n",
      "Batch：16032 | Loss: 0.04557804390788078\n",
      "Batch：16033 | Loss: 0.06420710682868958\n",
      "Batch：16034 | Loss: 0.04462272673845291\n",
      "Batch：16035 | Loss: 0.05555950850248337\n",
      "Batch：16036 | Loss: 0.05017111822962761\n",
      "Batch：16037 | Loss: 0.0524679496884346\n",
      "Batch：16038 | Loss: 0.05679977312684059\n",
      "Batch：16039 | Loss: 0.0521678663790226\n",
      "Batch：16040 | Loss: 0.05696931853890419\n",
      "Batch：16041 | Loss: 0.059463974088430405\n",
      "Batch：16042 | Loss: 0.0509895421564579\n",
      "Batch：16043 | Loss: 0.04483448341488838\n",
      "Batch：16044 | Loss: 0.05545102432370186\n",
      "Batch：16045 | Loss: 0.05637197941541672\n",
      "Batch：16046 | Loss: 0.058569539338350296\n",
      "Batch：16047 | Loss: 0.05115048214793205\n",
      "Batch：16048 | Loss: 0.052491702139377594\n",
      "Batch：16049 | Loss: 0.05251160264015198\n",
      "Batch：16050 | Loss: 0.04839594289660454\n",
      "Batch：16051 | Loss: 0.055419452488422394\n",
      "Batch：16052 | Loss: 0.05528944358229637\n",
      "Batch：16053 | Loss: 0.05331018194556236\n",
      "Batch：16054 | Loss: 0.06378649920225143\n",
      "Batch：16055 | Loss: 0.044349391013383865\n",
      "Batch：16056 | Loss: 0.05819877237081528\n",
      "Batch：16057 | Loss: 0.05681836977601051\n",
      "Batch：16058 | Loss: 0.05981921777129173\n",
      "Batch：16059 | Loss: 0.04737202823162079\n",
      "Batch：16060 | Loss: 0.05590558424592018\n",
      "Batch：16061 | Loss: 0.04583680257201195\n",
      "Batch：16062 | Loss: 0.051062777638435364\n",
      "Batch：16063 | Loss: 0.054529596120119095\n",
      "Batch：16064 | Loss: 0.05578285828232765\n",
      "Batch：16065 | Loss: 0.04684264957904816\n",
      "Batch：16066 | Loss: 0.04304039850831032\n",
      "Batch：16067 | Loss: 0.06583186984062195\n",
      "Batch：16068 | Loss: 0.04901908338069916\n",
      "Batch：16069 | Loss: 0.05547799542546272\n",
      "Batch：16070 | Loss: 0.04644591733813286\n",
      "Batch：16071 | Loss: 0.04403349384665489\n",
      "Batch：16072 | Loss: 0.0540040023624897\n",
      "Batch：16073 | Loss: 0.038038548082113266\n",
      "Batch：16074 | Loss: 0.051906973123550415\n",
      "Batch：16075 | Loss: 0.048673115670681\n",
      "Batch：16076 | Loss: 0.045815132558345795\n",
      "Batch：16077 | Loss: 0.04058351740241051\n",
      "Batch：16078 | Loss: 0.05617541819810867\n",
      "Batch：16079 | Loss: 0.05398258566856384\n",
      "Batch：16080 | Loss: 0.040508463978767395\n",
      "Batch：16081 | Loss: 0.04937822371721268\n",
      "Batch：16082 | Loss: 0.045566584914922714\n",
      "Batch：16083 | Loss: 0.05919111520051956\n",
      "Batch：16084 | Loss: 0.044984735548496246\n",
      "Batch：16085 | Loss: 0.048954639583826065\n",
      "Batch：16086 | Loss: 0.05079039931297302\n",
      "Batch：16087 | Loss: 0.048605985939502716\n",
      "Batch：16088 | Loss: 0.055188294500112534\n",
      "Batch：16089 | Loss: 0.05370313301682472\n",
      "Batch：16090 | Loss: 0.04670749977231026\n",
      "Batch：16091 | Loss: 0.04868949204683304\n",
      "Batch：16092 | Loss: 0.06508713960647583\n",
      "Batch：16093 | Loss: 0.05300978198647499\n",
      "Batch：16094 | Loss: 0.05612194165587425\n",
      "Batch：16095 | Loss: 0.05503896623849869\n",
      "Batch：16096 | Loss: 0.047440122812986374\n",
      "Batch：16097 | Loss: 0.054184697568416595\n",
      "Batch：16098 | Loss: 0.054232921451330185\n",
      "Batch：16099 | Loss: 0.04760366678237915\n",
      "Batch：16100 | Loss: 0.054656535387039185\n",
      "Batch：16101 | Loss: 0.06019178032875061\n",
      "Batch：16102 | Loss: 0.05550768971443176\n",
      "Batch：16103 | Loss: 0.05296923592686653\n",
      "Batch：16104 | Loss: 0.059416405856609344\n",
      "Batch：16105 | Loss: 0.049559757113456726\n",
      "Batch：16106 | Loss: 0.050484221428632736\n",
      "Batch：16107 | Loss: 0.056683897972106934\n",
      "Batch：16108 | Loss: 0.05575595423579216\n",
      "Batch：16109 | Loss: 0.05178024247288704\n",
      "Batch：16110 | Loss: 0.04509403929114342\n",
      "Batch：16111 | Loss: 0.06372950971126556\n",
      "Batch：16112 | Loss: 0.059843678027391434\n",
      "Batch：16113 | Loss: 0.05005596950650215\n",
      "Batch：16114 | Loss: 0.054206714034080505\n",
      "Batch：16115 | Loss: 0.05546044930815697\n",
      "Batch：16116 | Loss: 0.05465216934680939\n",
      "Batch：16117 | Loss: 0.05739181488752365\n",
      "Batch：16118 | Loss: 0.059886012226343155\n",
      "Batch：16119 | Loss: 0.05829409137368202\n",
      "Batch：16120 | Loss: 0.05194074288010597\n",
      "Batch：16121 | Loss: 0.04530465230345726\n",
      "Batch：16122 | Loss: 0.044293951243162155\n",
      "Batch：16123 | Loss: 0.04320700094103813\n",
      "Batch：16124 | Loss: 0.058253441005945206\n",
      "Batch：16125 | Loss: 0.050986964255571365\n",
      "Batch：16126 | Loss: 0.054807983338832855\n",
      "Batch：16127 | Loss: 0.048941608518362045\n",
      "Batch：16128 | Loss: 0.0622963048517704\n",
      "Batch：16129 | Loss: 0.05112256854772568\n",
      "Batch：16130 | Loss: 0.043586187064647675\n",
      "Batch：16131 | Loss: 0.055882006883621216\n",
      "Batch：16132 | Loss: 0.037402380257844925\n",
      "Batch：16133 | Loss: 0.06550997495651245\n",
      "Batch：16134 | Loss: 0.05154216289520264\n",
      "Batch：16135 | Loss: 0.04593667387962341\n",
      "Batch：16136 | Loss: 0.056371331214904785\n",
      "Batch：16137 | Loss: 0.05162295326590538\n",
      "Batch：16138 | Loss: 0.054205913096666336\n",
      "Batch：16139 | Loss: 0.05150565877556801\n",
      "Batch：16140 | Loss: 0.06295882165431976\n",
      "Batch：16141 | Loss: 0.05603298544883728\n",
      "Batch：16142 | Loss: 0.0471135750412941\n",
      "Batch：16143 | Loss: 0.04632832109928131\n",
      "Batch：16144 | Loss: 0.04865497350692749\n",
      "Batch：16145 | Loss: 0.045741647481918335\n",
      "Batch：16146 | Loss: 0.05410954728722572\n",
      "Batch：16147 | Loss: 0.0443095862865448\n",
      "Batch：16148 | Loss: 0.06224324554204941\n",
      "Batch：16149 | Loss: 0.056230757385492325\n",
      "Batch：16150 | Loss: 0.04551614448428154\n",
      "Batch：16151 | Loss: 0.05557103082537651\n",
      "Batch：16152 | Loss: 0.049878183752298355\n",
      "Batch：16153 | Loss: 0.0452110692858696\n",
      "Batch：16154 | Loss: 0.05341913923621178\n",
      "Batch：16155 | Loss: 0.05259906128048897\n",
      "Batch：16156 | Loss: 0.050733182579278946\n",
      "Batch：16157 | Loss: 0.05683285370469093\n",
      "Batch：16158 | Loss: 0.05607084929943085\n",
      "Batch：16159 | Loss: 0.052036188542842865\n",
      "Batch：16160 | Loss: 0.04964526742696762\n",
      "Batch：16161 | Loss: 0.04932782053947449\n",
      "Batch：16162 | Loss: 0.04652135819196701\n",
      "Batch：16163 | Loss: 0.04792043939232826\n",
      "Batch：16164 | Loss: 0.058697301894426346\n",
      "Batch：16165 | Loss: 0.052691467106342316\n",
      "Batch：16166 | Loss: 0.04789803922176361\n",
      "Batch：16167 | Loss: 0.05038511008024216\n",
      "Batch：16168 | Loss: 0.05462620034813881\n",
      "Batch：16169 | Loss: 0.0612361915409565\n",
      "Batch：16170 | Loss: 0.04878696799278259\n",
      "Batch：16171 | Loss: 0.05575776472687721\n",
      "Batch：16172 | Loss: 0.05548465996980667\n",
      "Batch：16173 | Loss: 0.046134237200021744\n",
      "Batch：16174 | Loss: 0.05217137560248375\n",
      "Batch：16175 | Loss: 0.04962098225951195\n",
      "Batch：16176 | Loss: 0.06389347463846207\n",
      "Batch：16177 | Loss: 0.05426173284649849\n",
      "Batch：16178 | Loss: 0.04482053592801094\n",
      "Batch：16179 | Loss: 0.054159361869096756\n",
      "Batch：16180 | Loss: 0.04998942092061043\n",
      "Batch：16181 | Loss: 0.03973172605037689\n",
      "Batch：16182 | Loss: 0.04884691163897514\n",
      "Batch：16183 | Loss: 0.05952640622854233\n",
      "Batch：16184 | Loss: 0.0465596504509449\n",
      "Batch：16185 | Loss: 0.04759917035698891\n",
      "Batch：16186 | Loss: 0.04937031865119934\n",
      "Batch：16187 | Loss: 0.05989930033683777\n",
      "Batch：16188 | Loss: 0.03996341675519943\n",
      "Batch：16189 | Loss: 0.04666663706302643\n",
      "Batch：16190 | Loss: 0.05103815719485283\n",
      "Batch：16191 | Loss: 0.05587330460548401\n",
      "Batch：16192 | Loss: 0.05572916567325592\n",
      "Batch：16193 | Loss: 0.048082076013088226\n",
      "Batch：16194 | Loss: 0.05226057395339012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：16195 | Loss: 0.053516190499067307\n",
      "Batch：16196 | Loss: 0.05185401439666748\n",
      "Batch：16197 | Loss: 0.05540928617119789\n",
      "Batch：16198 | Loss: 0.053275227546691895\n",
      "Batch：16199 | Loss: 0.047786369919776917\n",
      "Batch：16200 | Loss: 0.055430348962545395\n",
      "Batch：16201 | Loss: 0.05433891713619232\n",
      "Batch：16202 | Loss: 0.05543721467256546\n",
      "Batch：16203 | Loss: 0.06173860281705856\n",
      "Batch：16204 | Loss: 0.04227316379547119\n",
      "Batch：16205 | Loss: 0.045643649995326996\n",
      "Batch：16206 | Loss: 0.05475524812936783\n",
      "Batch：16207 | Loss: 0.05561668425798416\n",
      "Batch：16208 | Loss: 0.04139239713549614\n",
      "Batch：16209 | Loss: 0.048904310911893845\n",
      "Batch：16210 | Loss: 0.043535273522138596\n",
      "Batch：16211 | Loss: 0.04751519113779068\n",
      "Batch：16212 | Loss: 0.06355404108762741\n",
      "Batch：16213 | Loss: 0.05094388872385025\n",
      "Batch：16214 | Loss: 0.051686856895685196\n",
      "Batch：16215 | Loss: 0.054366666823625565\n",
      "Batch：16216 | Loss: 0.05199911445379257\n",
      "Batch：16217 | Loss: 0.05208924785256386\n",
      "Batch：16218 | Loss: 0.03690436854958534\n",
      "Batch：16219 | Loss: 0.04453301802277565\n",
      "Batch：16220 | Loss: 0.05337034910917282\n",
      "Batch：16221 | Loss: 0.04873276874423027\n",
      "Batch：16222 | Loss: 0.052033934742212296\n",
      "Batch：16223 | Loss: 0.06174848973751068\n",
      "Batch：16224 | Loss: 0.05430443212389946\n",
      "Batch：16225 | Loss: 0.05139302462339401\n",
      "Batch：16226 | Loss: 0.05024280771613121\n",
      "Batch：16227 | Loss: 0.05714302510023117\n",
      "Batch：16228 | Loss: 0.04719403013586998\n",
      "Batch：16229 | Loss: 0.045690394937992096\n",
      "Batch：16230 | Loss: 0.04718777537345886\n",
      "Batch：16231 | Loss: 0.04794175177812576\n",
      "Batch：16232 | Loss: 0.050672534853219986\n",
      "Batch：16233 | Loss: 0.05266287177801132\n",
      "Batch：16234 | Loss: 0.05445129796862602\n",
      "Batch：16235 | Loss: 0.053374145179986954\n",
      "Batch：16236 | Loss: 0.04962993785738945\n",
      "Batch：16237 | Loss: 0.047179579734802246\n",
      "Batch：16238 | Loss: 0.05755525827407837\n",
      "Batch：16239 | Loss: 0.05402321740984917\n",
      "Batch：16240 | Loss: 0.05105212330818176\n",
      "Batch：16241 | Loss: 0.048675958067178726\n",
      "Batch：16242 | Loss: 0.05168984457850456\n",
      "Batch：16243 | Loss: 0.053535863757133484\n",
      "Batch：16244 | Loss: 0.04723021015524864\n",
      "Batch：16245 | Loss: 0.06880530714988708\n",
      "Batch：16246 | Loss: 0.05375344678759575\n",
      "Batch：16247 | Loss: 0.056643273681402206\n",
      "Batch：16248 | Loss: 0.057683348655700684\n",
      "Batch：16249 | Loss: 0.06174037605524063\n",
      "Batch：16250 | Loss: 0.050103068351745605\n",
      "Batch：16251 | Loss: 0.05490082874894142\n",
      "Batch：16252 | Loss: 0.043370217084884644\n",
      "Batch：16253 | Loss: 0.06011783331632614\n",
      "Batch：16254 | Loss: 0.045809291303157806\n",
      "Batch：16255 | Loss: 0.05119817703962326\n",
      "Batch：16256 | Loss: 0.05065605044364929\n",
      "Batch：16257 | Loss: 0.049180787056684494\n",
      "Batch：16258 | Loss: 0.0418609157204628\n",
      "Batch：16259 | Loss: 0.049437157809734344\n",
      "Batch：16260 | Loss: 0.049892038106918335\n",
      "Batch：16261 | Loss: 0.04806124418973923\n",
      "Batch：16262 | Loss: 0.047069888561964035\n",
      "Batch：16263 | Loss: 0.05663866549730301\n",
      "Batch：16264 | Loss: 0.057869575917720795\n",
      "Batch：16265 | Loss: 0.04139323905110359\n",
      "Batch：16266 | Loss: 0.04802623391151428\n",
      "Batch：16267 | Loss: 0.04751795530319214\n",
      "Batch：16268 | Loss: 0.04710523411631584\n",
      "Batch：16269 | Loss: 0.04757237806916237\n",
      "Batch：16270 | Loss: 0.04754433035850525\n",
      "Batch：16271 | Loss: 0.04553072154521942\n",
      "Batch：16272 | Loss: 0.04793843626976013\n",
      "Batch：16273 | Loss: 0.053474411368370056\n",
      "Batch：16274 | Loss: 0.05117795616388321\n",
      "Batch：16275 | Loss: 0.050203051418066025\n",
      "Batch：16276 | Loss: 0.0546412467956543\n",
      "Batch：16277 | Loss: 0.0465809628367424\n",
      "Batch：16278 | Loss: 0.05628299340605736\n",
      "Batch：16279 | Loss: 0.0539063885807991\n",
      "Batch：16280 | Loss: 0.05132700502872467\n",
      "Batch：16281 | Loss: 0.0470992736518383\n",
      "Batch：16282 | Loss: 0.04337465763092041\n",
      "Batch：16283 | Loss: 0.052446573972702026\n",
      "Batch：16284 | Loss: 0.06873816251754761\n",
      "Batch：16285 | Loss: 0.055009663105010986\n",
      "Batch：16286 | Loss: 0.04960999637842178\n",
      "Batch：16287 | Loss: 0.05248018354177475\n",
      "Batch：16288 | Loss: 0.05132016912102699\n",
      "Batch：16289 | Loss: 0.05480477213859558\n",
      "Batch：16290 | Loss: 0.05705814063549042\n",
      "Batch：16291 | Loss: 0.05734977126121521\n",
      "Batch：16292 | Loss: 0.054326802492141724\n",
      "Batch：16293 | Loss: 0.04493502154946327\n",
      "Batch：16294 | Loss: 0.05584736540913582\n",
      "Batch：16295 | Loss: 0.054958831518888474\n",
      "Batch：16296 | Loss: 0.05568813160061836\n",
      "Batch：16297 | Loss: 0.056207120418548584\n",
      "Batch：16298 | Loss: 0.05642101913690567\n",
      "Batch：16299 | Loss: 0.05203663930296898\n",
      "Batch：16300 | Loss: 0.04823034256696701\n",
      "Batch：16301 | Loss: 0.047215890139341354\n",
      "Batch：16302 | Loss: 0.04065047949552536\n",
      "Batch：16303 | Loss: 0.05581754446029663\n",
      "Batch：16304 | Loss: 0.06311648339033127\n",
      "Batch：16305 | Loss: 0.04995361715555191\n",
      "Batch：16306 | Loss: 0.0442972406744957\n",
      "Batch：16307 | Loss: 0.0473354198038578\n",
      "Batch：16308 | Loss: 0.05078715831041336\n",
      "Batch：16309 | Loss: 0.053618233650922775\n",
      "Batch：16310 | Loss: 0.05932401865720749\n",
      "Batch：16311 | Loss: 0.05673918500542641\n",
      "Batch：16312 | Loss: 0.05659717693924904\n",
      "Batch：16313 | Loss: 0.05107885226607323\n",
      "Batch：16314 | Loss: 0.045467574149370193\n",
      "Batch：16315 | Loss: 0.04580969735980034\n",
      "Batch：16316 | Loss: 0.05906228721141815\n",
      "Batch：16317 | Loss: 0.0515754371881485\n",
      "Batch：16318 | Loss: 0.04461655765771866\n",
      "Batch：16319 | Loss: 0.03714216500520706\n",
      "Batch：16320 | Loss: 0.04738011583685875\n",
      "Batch：16321 | Loss: 0.048903338611125946\n",
      "Batch：16322 | Loss: 0.04698978736996651\n",
      "Batch：16323 | Loss: 0.03727195784449577\n",
      "Batch：16324 | Loss: 0.047957390546798706\n",
      "Batch：16325 | Loss: 0.04691864922642708\n",
      "Batch：16326 | Loss: 0.04153959080576897\n",
      "Batch：16327 | Loss: 0.05484180524945259\n",
      "Batch：16328 | Loss: 0.05053010955452919\n",
      "Batch：16329 | Loss: 0.03924034908413887\n",
      "Batch：16330 | Loss: 0.05155467242002487\n",
      "Batch：16331 | Loss: 0.04387599974870682\n",
      "Batch：16332 | Loss: 0.050957418978214264\n",
      "Batch：16333 | Loss: 0.047906920313835144\n",
      "Batch：16334 | Loss: 0.059591878205537796\n",
      "Batch：16335 | Loss: 0.0553978830575943\n",
      "Batch：16336 | Loss: 0.05206850543618202\n",
      "Batch：16337 | Loss: 0.043656472116708755\n",
      "Batch：16338 | Loss: 0.04782184958457947\n",
      "Batch：16339 | Loss: 0.05480906739830971\n",
      "Batch：16340 | Loss: 0.05541989207267761\n",
      "Batch：16341 | Loss: 0.05487843602895737\n",
      "Batch：16342 | Loss: 0.05539019778370857\n",
      "Batch：16343 | Loss: 0.04712286219000816\n",
      "Batch：16344 | Loss: 0.05303499475121498\n",
      "Batch：16345 | Loss: 0.06281228363513947\n",
      "Batch：16346 | Loss: 0.046718697994947433\n",
      "Batch：16347 | Loss: 0.05135401338338852\n",
      "Batch：16348 | Loss: 0.0526447594165802\n",
      "Batch：16349 | Loss: 0.05012303218245506\n",
      "Batch：16350 | Loss: 0.05861268565058708\n",
      "Batch：16351 | Loss: 0.05504219979047775\n",
      "Batch：16352 | Loss: 0.052798859775066376\n",
      "Batch：16353 | Loss: 0.052003733813762665\n",
      "Batch：16354 | Loss: 0.05491388216614723\n",
      "Batch：16355 | Loss: 0.04669952020049095\n",
      "Batch：16356 | Loss: 0.0442466177046299\n",
      "Batch：16357 | Loss: 0.05418863520026207\n",
      "Batch：16358 | Loss: 0.05822297930717468\n",
      "Batch：16359 | Loss: 0.0456966869533062\n",
      "Batch：16360 | Loss: 0.053754791617393494\n",
      "Batch：16361 | Loss: 0.04499124735593796\n",
      "Batch：16362 | Loss: 0.04611930623650551\n",
      "Batch：16363 | Loss: 0.050411783158779144\n",
      "Batch：16364 | Loss: 0.04842279106378555\n",
      "Batch：16365 | Loss: 0.0462045855820179\n",
      "Batch：16366 | Loss: 0.04678475856781006\n",
      "Batch：16367 | Loss: 0.05910251662135124\n",
      "Batch：16368 | Loss: 0.04584106430411339\n",
      "Batch：16369 | Loss: 0.05245792493224144\n",
      "Batch：16370 | Loss: 0.04015861824154854\n",
      "Batch：16371 | Loss: 0.04875023290514946\n",
      "Batch：16372 | Loss: 0.0475480854511261\n",
      "Batch：16373 | Loss: 0.05594409257173538\n",
      "Batch：16374 | Loss: 0.04467141255736351\n",
      "Batch：16375 | Loss: 0.04726804420351982\n",
      "Batch：16376 | Loss: 0.0512816496193409\n",
      "Batch：16377 | Loss: 0.05153227224946022\n",
      "Batch：16378 | Loss: 0.05091631039977074\n",
      "Batch：16379 | Loss: 0.06072789430618286\n",
      "Batch：16380 | Loss: 0.04717562720179558\n",
      "Batch：16381 | Loss: 0.052243396639823914\n",
      "Batch：16382 | Loss: 0.05392322689294815\n",
      "Batch：16383 | Loss: 0.05617288127541542\n",
      "Batch：16384 | Loss: 0.05828984081745148\n",
      "Batch：16385 | Loss: 0.04194723069667816\n",
      "Batch：16386 | Loss: 0.05164703354239464\n",
      "Batch：16387 | Loss: 0.048595886677503586\n",
      "Batch：16388 | Loss: 0.04118309170007706\n",
      "Batch：16389 | Loss: 0.048463668674230576\n",
      "Batch：16390 | Loss: 0.04575826972723007\n",
      "Batch：16391 | Loss: 0.05133941024541855\n",
      "Batch：16392 | Loss: 0.045829132199287415\n",
      "Batch：16393 | Loss: 0.04914430156350136\n",
      "Batch：16394 | Loss: 0.04456442594528198\n",
      "Batch：16395 | Loss: 0.046800799667835236\n",
      "Batch：16396 | Loss: 0.04453530162572861\n",
      "Batch：16397 | Loss: 0.039743296802043915\n",
      "Batch：16398 | Loss: 0.04508994519710541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：16399 | Loss: 0.046695586293935776\n",
      "Batch：16400 | Loss: 0.04048275947570801\n",
      "Batch：16401 | Loss: 0.04904896393418312\n",
      "Batch：16402 | Loss: 0.045551396906375885\n",
      "Batch：16403 | Loss: 0.05128995701670647\n",
      "Batch：16404 | Loss: 0.04523864760994911\n",
      "Batch：16405 | Loss: 0.04768931865692139\n",
      "Batch：16406 | Loss: 0.049193501472473145\n",
      "Batch：16407 | Loss: 0.051336150616407394\n",
      "Batch：16408 | Loss: 0.04510742798447609\n",
      "Batch：16409 | Loss: 0.05137142911553383\n",
      "Batch：16410 | Loss: 0.045453187078237534\n",
      "Batch：16411 | Loss: 0.05024989694356918\n",
      "Batch：16412 | Loss: 0.04463011771440506\n",
      "Batch：16413 | Loss: 0.0515330508351326\n",
      "Batch：16414 | Loss: 0.05983828753232956\n",
      "Batch：16415 | Loss: 0.055776361376047134\n",
      "Batch：16416 | Loss: 0.04344593733549118\n",
      "Batch：16417 | Loss: 0.04855286702513695\n",
      "Batch：16418 | Loss: 0.04825723171234131\n",
      "Batch：16419 | Loss: 0.05554733797907829\n",
      "Batch：16420 | Loss: 0.06363444775342941\n",
      "Batch：16421 | Loss: 0.05921114981174469\n",
      "Batch：16422 | Loss: 0.050678517669439316\n",
      "Batch：16423 | Loss: 0.04362111911177635\n",
      "Batch：16424 | Loss: 0.05455994978547096\n",
      "Batch：16425 | Loss: 0.04501909390091896\n",
      "Batch：16426 | Loss: 0.04647244140505791\n",
      "Batch：16427 | Loss: 0.05275564640760422\n",
      "Batch：16428 | Loss: 0.046275969594717026\n",
      "Batch：16429 | Loss: 0.04718815162777901\n",
      "Batch：16430 | Loss: 0.0443061925470829\n",
      "Batch：16431 | Loss: 0.0420072115957737\n",
      "Batch：16432 | Loss: 0.044888559728860855\n",
      "Batch：16433 | Loss: 0.04525577649474144\n",
      "Batch：16434 | Loss: 0.04403725638985634\n",
      "Batch：16435 | Loss: 0.04735970124602318\n",
      "Batch：16436 | Loss: 0.04011297971010208\n",
      "Batch：16437 | Loss: 0.05531637370586395\n",
      "Batch：16438 | Loss: 0.05238441750407219\n",
      "Batch：16439 | Loss: 0.0464015007019043\n",
      "Batch：16440 | Loss: 0.05417057126760483\n",
      "Batch：16441 | Loss: 0.055529236793518066\n",
      "Batch：16442 | Loss: 0.050415996462106705\n",
      "Batch：16443 | Loss: 0.04114234820008278\n",
      "Batch：16444 | Loss: 0.04960089921951294\n",
      "Batch：16445 | Loss: 0.04925432428717613\n",
      "Batch：16446 | Loss: 0.05537215620279312\n",
      "Batch：16447 | Loss: 0.04588226228952408\n",
      "Batch：16448 | Loss: 0.04693513363599777\n",
      "Batch：16449 | Loss: 0.043849628418684006\n",
      "Batch：16450 | Loss: 0.05034675449132919\n",
      "Batch：16451 | Loss: 0.04261358827352524\n",
      "Batch：16452 | Loss: 0.05436304211616516\n",
      "Batch：16453 | Loss: 0.05162739008665085\n",
      "Batch：16454 | Loss: 0.05033880099654198\n",
      "Batch：16455 | Loss: 0.05464605242013931\n",
      "Batch：16456 | Loss: 0.045223917812108994\n",
      "Batch：16457 | Loss: 0.04686199873685837\n",
      "Batch：16458 | Loss: 0.05376420170068741\n",
      "Batch：16459 | Loss: 0.04641573876142502\n",
      "Batch：16460 | Loss: 0.05934394896030426\n",
      "Batch：16461 | Loss: 0.045529406517744064\n",
      "Batch：16462 | Loss: 0.048551712185144424\n",
      "Batch：16463 | Loss: 0.05313628911972046\n",
      "Batch：16464 | Loss: 0.04456985369324684\n",
      "Batch：16465 | Loss: 0.05264446884393692\n",
      "Batch：16466 | Loss: 0.05301755666732788\n",
      "Batch：16467 | Loss: 0.050379857420921326\n",
      "Batch：16468 | Loss: 0.05125526711344719\n",
      "Batch：16469 | Loss: 0.04105808585882187\n",
      "Batch：16470 | Loss: 0.059387288987636566\n",
      "Batch：16471 | Loss: 0.05470370501279831\n",
      "Batch：16472 | Loss: 0.0453924760222435\n",
      "Batch：16473 | Loss: 0.05359058454632759\n",
      "Batch：16474 | Loss: 0.0479574128985405\n",
      "Batch：16475 | Loss: 0.046156980097293854\n",
      "Batch：16476 | Loss: 0.05075644701719284\n",
      "Batch：16477 | Loss: 0.05546358600258827\n",
      "Batch：16478 | Loss: 0.043507639318704605\n",
      "Batch：16479 | Loss: 0.057592716068029404\n",
      "Batch：16480 | Loss: 0.06035513058304787\n",
      "Batch：16481 | Loss: 0.05382230505347252\n",
      "Batch：16482 | Loss: 0.05187278240919113\n",
      "Batch：16483 | Loss: 0.06503384560346603\n",
      "Batch：16484 | Loss: 0.06479911506175995\n",
      "Batch：16485 | Loss: 0.05356908217072487\n",
      "Batch：16486 | Loss: 0.04269018396735191\n",
      "Batch：16487 | Loss: 0.05029550567269325\n",
      "Batch：16488 | Loss: 0.04753413423895836\n",
      "Batch：16489 | Loss: 0.04319721460342407\n",
      "Batch：16490 | Loss: 0.04994381591677666\n",
      "Batch：16491 | Loss: 0.04909771680831909\n",
      "Batch：16492 | Loss: 0.053432684391736984\n",
      "Batch：16493 | Loss: 0.052451081573963165\n",
      "Batch：16494 | Loss: 0.04488988220691681\n",
      "Batch：16495 | Loss: 0.04884675145149231\n",
      "Batch：16496 | Loss: 0.05136215686798096\n",
      "Batch：16497 | Loss: 0.0543321929872036\n",
      "Batch：16498 | Loss: 0.045664429664611816\n",
      "Batch：16499 | Loss: 0.05360652506351471\n",
      "Batch：16500 | Loss: 0.04572856426239014\n",
      "Batch：16501 | Loss: 0.05621545389294624\n",
      "Batch：16502 | Loss: 0.041929930448532104\n",
      "Batch：16503 | Loss: 0.04620528966188431\n",
      "Batch：16504 | Loss: 0.04952140152454376\n",
      "Batch：16505 | Loss: 0.0446106493473053\n",
      "Batch：16506 | Loss: 0.04772924259305\n",
      "Batch：16507 | Loss: 0.051857106387615204\n",
      "Batch：16508 | Loss: 0.05362413451075554\n",
      "Batch：16509 | Loss: 0.06260379403829575\n",
      "Batch：16510 | Loss: 0.06084085628390312\n",
      "Batch：16511 | Loss: 0.050654876977205276\n",
      "Batch：16512 | Loss: 0.052350521087646484\n",
      "Batch：16513 | Loss: 0.06303144991397858\n",
      "Batch：16514 | Loss: 0.046111155301332474\n",
      "Batch：16515 | Loss: 0.04653017967939377\n",
      "Batch：16516 | Loss: 0.0458841510117054\n",
      "Batch：16517 | Loss: 0.04827258363366127\n",
      "Batch：16518 | Loss: 0.044262006878852844\n",
      "Batch：16519 | Loss: 0.05781349539756775\n",
      "Batch：16520 | Loss: 0.05769987031817436\n",
      "Batch：16521 | Loss: 0.04638983681797981\n",
      "Batch：16522 | Loss: 0.046608682721853256\n",
      "Batch：16523 | Loss: 0.047155801206827164\n",
      "Batch：16524 | Loss: 0.05790853872895241\n",
      "Batch：16525 | Loss: 0.045330844819545746\n",
      "Batch：16526 | Loss: 0.04496648162603378\n",
      "Batch：16527 | Loss: 0.05434392765164375\n",
      "Batch：16528 | Loss: 0.04024770110845566\n",
      "Batch：16529 | Loss: 0.050616972148418427\n",
      "Batch：16530 | Loss: 0.051695920526981354\n",
      "Batch：16531 | Loss: 0.05184662714600563\n",
      "Batch：16532 | Loss: 0.03921354189515114\n",
      "Batch：16533 | Loss: 0.055894240736961365\n",
      "Batch：16534 | Loss: 0.05038895457983017\n",
      "Batch：16535 | Loss: 0.041537728160619736\n",
      "Batch：16536 | Loss: 0.05453304946422577\n",
      "Batch：16537 | Loss: 0.05472410097718239\n",
      "Batch：16538 | Loss: 0.0577235110104084\n",
      "Batch：16539 | Loss: 0.049275029450654984\n",
      "Batch：16540 | Loss: 0.045163024216890335\n",
      "Batch：16541 | Loss: 0.05813558027148247\n",
      "Batch：16542 | Loss: 0.04528066888451576\n",
      "Batch：16543 | Loss: 0.047882553189992905\n",
      "Batch：16544 | Loss: 0.05382798612117767\n",
      "Batch：16545 | Loss: 0.04402311518788338\n",
      "Batch：16546 | Loss: 0.04418126493692398\n",
      "Batch：16547 | Loss: 0.05772285908460617\n",
      "Batch：16548 | Loss: 0.048938922584056854\n",
      "Batch：16549 | Loss: 0.05662466213107109\n",
      "Batch：16550 | Loss: 0.057914696633815765\n",
      "Batch：16551 | Loss: 0.041444603353738785\n",
      "Batch：16552 | Loss: 0.0456630140542984\n",
      "Batch：16553 | Loss: 0.05748806148767471\n",
      "Batch：16554 | Loss: 0.047446221113204956\n",
      "Batch：16555 | Loss: 0.05144380033016205\n",
      "Batch：16556 | Loss: 0.051095280796289444\n",
      "Batch：16557 | Loss: 0.048023518174886703\n",
      "Batch：16558 | Loss: 0.04824712127447128\n",
      "Batch：16559 | Loss: 0.05329357832670212\n",
      "Batch：16560 | Loss: 0.0473051555454731\n",
      "Batch：16561 | Loss: 0.056840747594833374\n",
      "Batch：16562 | Loss: 0.051073841750621796\n",
      "Batch：16563 | Loss: 0.0535871796309948\n",
      "Batch：16564 | Loss: 0.05203716456890106\n",
      "Batch：16565 | Loss: 0.04289139807224274\n",
      "Batch：16566 | Loss: 0.05047699809074402\n",
      "Batch：16567 | Loss: 0.04813719540834427\n",
      "Batch：16568 | Loss: 0.05220763012766838\n",
      "Batch：16569 | Loss: 0.044137369841337204\n",
      "Batch：16570 | Loss: 0.04283123090863228\n",
      "Batch：16571 | Loss: 0.05118445307016373\n",
      "Batch：16572 | Loss: 0.05076096951961517\n",
      "Batch：16573 | Loss: 0.055433277040719986\n",
      "Batch：16574 | Loss: 0.04580037295818329\n",
      "Batch：16575 | Loss: 0.050537921488285065\n",
      "Batch：16576 | Loss: 0.053173430263996124\n",
      "Batch：16577 | Loss: 0.04436104744672775\n",
      "Batch：16578 | Loss: 0.05854739248752594\n",
      "Batch：16579 | Loss: 0.04670935124158859\n",
      "Batch：16580 | Loss: 0.0688081830739975\n",
      "Batch：16581 | Loss: 0.04769210144877434\n",
      "Batch：16582 | Loss: 0.046285126358270645\n",
      "Batch：16583 | Loss: 0.044584956020116806\n",
      "Batch：16584 | Loss: 0.04914531484246254\n",
      "Batch：16585 | Loss: 0.055379536002874374\n",
      "Batch：16586 | Loss: 0.04483645409345627\n",
      "Batch：16587 | Loss: 0.052972644567489624\n",
      "Batch：16588 | Loss: 0.04513759911060333\n",
      "Batch：16589 | Loss: 0.03929976746439934\n",
      "Batch：16590 | Loss: 0.0646568164229393\n",
      "Batch：16591 | Loss: 0.04918275028467178\n",
      "Batch：16592 | Loss: 0.043925270438194275\n",
      "Batch：16593 | Loss: 0.04959915205836296\n",
      "Batch：16594 | Loss: 0.05329397693276405\n",
      "Batch：16595 | Loss: 0.039830684661865234\n",
      "Batch：16596 | Loss: 0.05653635784983635\n",
      "Batch：16597 | Loss: 0.054672036319971085\n",
      "Batch：16598 | Loss: 0.05536511167883873\n",
      "Batch：16599 | Loss: 0.05506163462996483\n",
      "Batch：16600 | Loss: 0.05450797453522682\n",
      "Batch：16601 | Loss: 0.04366285726428032\n",
      "Batch：16602 | Loss: 0.05451297014951706\n",
      "Batch：16603 | Loss: 0.0489124096930027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：16604 | Loss: 0.050925545394420624\n",
      "Batch：16605 | Loss: 0.04362335056066513\n",
      "Batch：16606 | Loss: 0.05302785336971283\n",
      "Batch：16607 | Loss: 0.04175844043493271\n",
      "Batch：16608 | Loss: 0.04798761010169983\n",
      "Batch：16609 | Loss: 0.03785603493452072\n",
      "Batch：16610 | Loss: 0.04322531074285507\n",
      "Batch：16611 | Loss: 0.04110313951969147\n",
      "Batch：16612 | Loss: 0.049850717186927795\n",
      "Batch：16613 | Loss: 0.04987809807062149\n",
      "Batch：16614 | Loss: 0.05122824013233185\n",
      "Batch：16615 | Loss: 0.055375631898641586\n",
      "Batch：16616 | Loss: 0.05729132145643234\n",
      "Batch：16617 | Loss: 0.04825078696012497\n",
      "Batch：16618 | Loss: 0.05449818819761276\n",
      "Batch：16619 | Loss: 0.048929471522569656\n",
      "Batch：16620 | Loss: 0.047863900661468506\n",
      "Batch：16621 | Loss: 0.05822479724884033\n",
      "Batch：16622 | Loss: 0.049104273319244385\n",
      "Batch：16623 | Loss: 0.04005618765950203\n",
      "Batch：16624 | Loss: 0.0519062764942646\n",
      "Batch：16625 | Loss: 0.051745448261499405\n",
      "Batch：16626 | Loss: 0.04189864918589592\n",
      "Batch：16627 | Loss: 0.05948714166879654\n",
      "Batch：16628 | Loss: 0.0570506788790226\n",
      "Batch：16629 | Loss: 0.056048136204481125\n",
      "Batch：16630 | Loss: 0.05095396935939789\n",
      "Batch：16631 | Loss: 0.04415196552872658\n",
      "Batch：16632 | Loss: 0.05647774040699005\n",
      "Batch：16633 | Loss: 0.04419311136007309\n",
      "Batch：16634 | Loss: 0.047221094369888306\n",
      "Batch：16635 | Loss: 0.044359151273965836\n",
      "Batch：16636 | Loss: 0.056166406720876694\n",
      "Batch：16637 | Loss: 0.05133804678916931\n",
      "Batch：16638 | Loss: 0.04788197949528694\n",
      "Batch：16639 | Loss: 0.05064469203352928\n",
      "Batch：16640 | Loss: 0.05407366529107094\n",
      "Batch：16641 | Loss: 0.05339866131544113\n",
      "Batch：16642 | Loss: 0.05562819540500641\n",
      "Batch：16643 | Loss: 0.05623165890574455\n",
      "Batch：16644 | Loss: 0.0555494986474514\n",
      "Batch：16645 | Loss: 0.055776458233594894\n",
      "Batch：16646 | Loss: 0.043116021901369095\n",
      "Batch：16647 | Loss: 0.045892588794231415\n",
      "Batch：16648 | Loss: 0.05019085481762886\n",
      "Batch：16649 | Loss: 0.04676133021712303\n",
      "Batch：16650 | Loss: 0.061990611255168915\n",
      "Batch：16651 | Loss: 0.05373675376176834\n",
      "Batch：16652 | Loss: 0.05685205012559891\n",
      "Batch：16653 | Loss: 0.050059232860803604\n",
      "Batch：16654 | Loss: 0.049653492867946625\n",
      "Batch：16655 | Loss: 0.04868482053279877\n",
      "Batch：16656 | Loss: 0.04783683642745018\n",
      "Batch：16657 | Loss: 0.04792529344558716\n",
      "Batch：16658 | Loss: 0.052941471338272095\n",
      "Batch：16659 | Loss: 0.0383896604180336\n",
      "Batch：16660 | Loss: 0.04828450456261635\n",
      "Batch：16661 | Loss: 0.05747469514608383\n",
      "Batch：16662 | Loss: 0.06023300439119339\n",
      "Batch：16663 | Loss: 0.05128015577793121\n",
      "Batch：16664 | Loss: 0.04745486006140709\n",
      "Batch：16665 | Loss: 0.04838448390364647\n",
      "Batch：16666 | Loss: 0.05308743566274643\n",
      "Batch：16667 | Loss: 0.048773255199193954\n",
      "Batch：16668 | Loss: 0.04842286556959152\n",
      "Batch：16669 | Loss: 0.05094222351908684\n",
      "Batch：16670 | Loss: 0.04430334270000458\n",
      "Batch：16671 | Loss: 0.050370410084724426\n",
      "Batch：16672 | Loss: 0.0477658212184906\n",
      "Batch：16673 | Loss: 0.04968917742371559\n",
      "Batch：16674 | Loss: 0.05818739905953407\n",
      "Batch：16675 | Loss: 0.04768221825361252\n",
      "Batch：16676 | Loss: 0.04948651045560837\n",
      "Batch：16677 | Loss: 0.05620553344488144\n",
      "Batch：16678 | Loss: 0.04709003120660782\n",
      "Batch：16679 | Loss: 0.046283237636089325\n",
      "Batch：16680 | Loss: 0.05225491151213646\n",
      "Batch：16681 | Loss: 0.05363154038786888\n",
      "Batch：16682 | Loss: 0.04484778270125389\n",
      "Batch：16683 | Loss: 0.05608803778886795\n",
      "Batch：16684 | Loss: 0.054308149963617325\n",
      "Batch：16685 | Loss: 0.04904745891690254\n",
      "Batch：16686 | Loss: 0.04739111289381981\n",
      "Batch：16687 | Loss: 0.04587510973215103\n",
      "Batch：16688 | Loss: 0.04770703613758087\n",
      "Batch：16689 | Loss: 0.0426451601088047\n",
      "Batch：16690 | Loss: 0.045027587562799454\n",
      "Batch：16691 | Loss: 0.05126570910215378\n",
      "Batch：16692 | Loss: 0.05375773087143898\n",
      "Batch：16693 | Loss: 0.05370933562517166\n",
      "Batch：16694 | Loss: 0.05811326578259468\n",
      "Batch：16695 | Loss: 0.05196906998753548\n",
      "Batch：16696 | Loss: 0.0563003234565258\n",
      "Batch：16697 | Loss: 0.044757816940546036\n",
      "Batch：16698 | Loss: 0.04400040581822395\n",
      "Batch：16699 | Loss: 0.05290348827838898\n",
      "Batch：16700 | Loss: 0.05053533986210823\n",
      "Batch：16701 | Loss: 0.0518617108464241\n",
      "Batch：16702 | Loss: 0.053655412048101425\n",
      "Batch：16703 | Loss: 0.0526493638753891\n",
      "Batch：16704 | Loss: 0.046748965978622437\n",
      "Batch：16705 | Loss: 0.046157319098711014\n",
      "Batch：16706 | Loss: 0.051173482090234756\n",
      "Batch：16707 | Loss: 0.05142703652381897\n",
      "Batch：16708 | Loss: 0.05973991006612778\n",
      "Batch：16709 | Loss: 0.055688515305519104\n",
      "Batch：16710 | Loss: 0.04274583235383034\n",
      "Batch：16711 | Loss: 0.04178157448768616\n",
      "Batch：16712 | Loss: 0.054844487458467484\n",
      "Batch：16713 | Loss: 0.06280215829610825\n",
      "Batch：16714 | Loss: 0.056296397000551224\n",
      "Batch：16715 | Loss: 0.05113142356276512\n",
      "Batch：16716 | Loss: 0.04550265520811081\n",
      "Batch：16717 | Loss: 0.050322044640779495\n",
      "Batch：16718 | Loss: 0.04887254908680916\n",
      "Batch：16719 | Loss: 0.04880525544285774\n",
      "Batch：16720 | Loss: 0.04962681978940964\n",
      "Batch：16721 | Loss: 0.045571278780698776\n",
      "Batch：16722 | Loss: 0.05254790186882019\n",
      "Batch：16723 | Loss: 0.05054973438382149\n",
      "Batch：16724 | Loss: 0.0445932112634182\n",
      "Batch：16725 | Loss: 0.041870102286338806\n",
      "Batch：16726 | Loss: 0.055446501821279526\n",
      "Batch：16727 | Loss: 0.04520406574010849\n",
      "Batch：16728 | Loss: 0.05189729854464531\n",
      "Batch：16729 | Loss: 0.05888514593243599\n",
      "Batch：16730 | Loss: 0.044734373688697815\n",
      "Batch：16731 | Loss: 0.05130983516573906\n",
      "Batch：16732 | Loss: 0.048725392669439316\n",
      "Batch：16733 | Loss: 0.04307636618614197\n",
      "Batch：16734 | Loss: 0.042496804147958755\n",
      "Batch：16735 | Loss: 0.05419100448489189\n",
      "Batch：16736 | Loss: 0.049559012055397034\n",
      "Batch：16737 | Loss: 0.05537897348403931\n",
      "Batch：16738 | Loss: 0.04833045229315758\n",
      "Batch：16739 | Loss: 0.05210915580391884\n",
      "Batch：16740 | Loss: 0.05064643174409866\n",
      "Batch：16741 | Loss: 0.056154944002628326\n",
      "Batch：16742 | Loss: 0.04357382282614708\n",
      "Batch：16743 | Loss: 0.041890211403369904\n",
      "Batch：16744 | Loss: 0.04335065558552742\n",
      "Batch：16745 | Loss: 0.05926666781306267\n",
      "Batch：16746 | Loss: 0.05817795917391777\n",
      "Batch：16747 | Loss: 0.06807601451873779\n",
      "Batch：16748 | Loss: 0.0530458502471447\n",
      "Batch：16749 | Loss: 0.052240148186683655\n",
      "Batch：16750 | Loss: 0.0421522855758667\n",
      "Batch：16751 | Loss: 0.04732831194996834\n",
      "Batch：16752 | Loss: 0.05113665759563446\n",
      "Batch：16753 | Loss: 0.04415729269385338\n",
      "Batch：16754 | Loss: 0.04510115087032318\n",
      "Batch：16755 | Loss: 0.04502354562282562\n",
      "Batch：16756 | Loss: 0.05286308377981186\n",
      "Batch：16757 | Loss: 0.049977194517850876\n",
      "Batch：16758 | Loss: 0.05069081485271454\n",
      "Batch：16759 | Loss: 0.05835224315524101\n",
      "Batch：16760 | Loss: 0.05487418547272682\n",
      "Batch：16761 | Loss: 0.05817285180091858\n",
      "Batch：16762 | Loss: 0.04842975735664368\n",
      "Batch：16763 | Loss: 0.05542212724685669\n",
      "Batch：16764 | Loss: 0.0576205737888813\n",
      "Batch：16765 | Loss: 0.059818632900714874\n",
      "Batch：16766 | Loss: 0.050814636051654816\n",
      "Batch：16767 | Loss: 0.04802582785487175\n",
      "Batch：16768 | Loss: 0.04989905655384064\n",
      "Batch：16769 | Loss: 0.05047508701682091\n",
      "Batch：16770 | Loss: 0.05023188889026642\n",
      "Batch：16771 | Loss: 0.047102171927690506\n",
      "Batch：16772 | Loss: 0.05024516209959984\n",
      "Batch：16773 | Loss: 0.04374340921640396\n",
      "Batch：16774 | Loss: 0.05405772849917412\n",
      "Batch：16775 | Loss: 0.04890746995806694\n",
      "Batch：16776 | Loss: 0.04817675054073334\n",
      "Batch：16777 | Loss: 0.040035538375377655\n",
      "Batch：16778 | Loss: 0.0485948882997036\n",
      "Batch：16779 | Loss: 0.051090799272060394\n",
      "Batch：16780 | Loss: 0.057771749794483185\n",
      "Batch：16781 | Loss: 0.03692195937037468\n",
      "Batch：16782 | Loss: 0.0600414015352726\n",
      "Batch：16783 | Loss: 0.0491807721555233\n",
      "Batch：16784 | Loss: 0.049156900495290756\n",
      "Batch：16785 | Loss: 0.050679080188274384\n",
      "Batch：16786 | Loss: 0.05079084634780884\n",
      "Batch：16787 | Loss: 0.05905976891517639\n",
      "Batch：16788 | Loss: 0.04807958006858826\n",
      "Batch：16789 | Loss: 0.05309172347187996\n",
      "Batch：16790 | Loss: 0.051223788410425186\n",
      "Batch：16791 | Loss: 0.04689604789018631\n",
      "Batch：16792 | Loss: 0.049689166247844696\n",
      "Batch：16793 | Loss: 0.05002165585756302\n",
      "Batch：16794 | Loss: 0.06579260528087616\n",
      "Batch：16795 | Loss: 0.04484019801020622\n",
      "Batch：16796 | Loss: 0.04662502929568291\n",
      "Batch：16797 | Loss: 0.049844592809677124\n",
      "Batch：16798 | Loss: 0.048238128423690796\n",
      "Batch：16799 | Loss: 0.045988213270902634\n",
      "Batch：16800 | Loss: 0.058735787868499756\n",
      "Batch：16801 | Loss: 0.04363825544714928\n",
      "Batch：16802 | Loss: 0.05468245968222618\n",
      "Batch：16803 | Loss: 0.04520142078399658\n",
      "Batch：16804 | Loss: 0.05236330255866051\n",
      "Batch：16805 | Loss: 0.04887600988149643\n",
      "Batch：16806 | Loss: 0.04472000151872635\n",
      "Batch：16807 | Loss: 0.049851369112730026\n",
      "Batch：16808 | Loss: 0.05118948966264725\n",
      "Batch：16809 | Loss: 0.05153757706284523\n",
      "Batch：16810 | Loss: 0.051573771983385086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：16811 | Loss: 0.04799111559987068\n",
      "Batch：16812 | Loss: 0.03975357115268707\n",
      "Batch：16813 | Loss: 0.04739416390657425\n",
      "Batch：16814 | Loss: 0.049941159784793854\n",
      "Batch：16815 | Loss: 0.048960160464048386\n",
      "Batch：16816 | Loss: 0.0461307018995285\n",
      "Batch：16817 | Loss: 0.052842069417238235\n",
      "Batch：16818 | Loss: 0.05685187876224518\n",
      "Batch：16819 | Loss: 0.04896882176399231\n",
      "Batch：16820 | Loss: 0.04600830376148224\n",
      "Batch：16821 | Loss: 0.04715147241950035\n",
      "Batch：16822 | Loss: 0.05448330566287041\n",
      "Batch：16823 | Loss: 0.04866552725434303\n",
      "Batch：16824 | Loss: 0.04872046411037445\n",
      "Batch：16825 | Loss: 0.0539713129401207\n",
      "Batch：16826 | Loss: 0.058526407927274704\n",
      "Batch：16827 | Loss: 0.05688212439417839\n",
      "Batch：16828 | Loss: 0.04803144931793213\n",
      "Batch：16829 | Loss: 0.05186181142926216\n",
      "Batch：16830 | Loss: 0.05286567658185959\n",
      "Batch：16831 | Loss: 0.04842371493577957\n",
      "Batch：16832 | Loss: 0.05782194435596466\n",
      "Batch：16833 | Loss: 0.05696165934205055\n",
      "Batch：16834 | Loss: 0.04617103189229965\n",
      "Batch：16835 | Loss: 0.05464328080415726\n",
      "Batch：16836 | Loss: 0.06653344631195068\n",
      "Batch：16837 | Loss: 0.05045034736394882\n",
      "Batch：16838 | Loss: 0.04919356107711792\n",
      "Batch：16839 | Loss: 0.04235626384615898\n",
      "Batch：16840 | Loss: 0.04279454052448273\n",
      "Batch：16841 | Loss: 0.04117840528488159\n",
      "Batch：16842 | Loss: 0.04917321726679802\n",
      "Batch：16843 | Loss: 0.0406951867043972\n",
      "Batch：16844 | Loss: 0.05174988880753517\n",
      "Batch：16845 | Loss: 0.05104438588023186\n",
      "Batch：16846 | Loss: 0.04219786077737808\n",
      "Batch：16847 | Loss: 0.05775567889213562\n",
      "Batch：16848 | Loss: 0.06531533598899841\n",
      "Batch：16849 | Loss: 0.04485957697033882\n",
      "Batch：16850 | Loss: 0.04500829055905342\n",
      "Batch：16851 | Loss: 0.04403412714600563\n",
      "Batch：16852 | Loss: 0.056296564638614655\n",
      "Batch：16853 | Loss: 0.05831555277109146\n",
      "Batch：16854 | Loss: 0.04639044776558876\n",
      "Batch：16855 | Loss: 0.04204947501420975\n",
      "Batch：16856 | Loss: 0.0482289120554924\n",
      "Batch：16857 | Loss: 0.04916978254914284\n",
      "Batch：16858 | Loss: 0.03565233200788498\n",
      "Batch：16859 | Loss: 0.040783755481243134\n",
      "Batch：16860 | Loss: 0.053653422743082047\n",
      "Batch：16861 | Loss: 0.05074742063879967\n",
      "Batch：16862 | Loss: 0.060057926923036575\n",
      "Batch：16863 | Loss: 0.049369022250175476\n",
      "Batch：16864 | Loss: 0.05062965303659439\n",
      "Batch：16865 | Loss: 0.04274500906467438\n",
      "Batch：16866 | Loss: 0.04914172366261482\n",
      "Batch：16867 | Loss: 0.058272164314985275\n",
      "Batch：16868 | Loss: 0.059469420462846756\n",
      "Batch：16869 | Loss: 0.05500050261616707\n",
      "Batch：16870 | Loss: 0.03964767977595329\n",
      "Batch：16871 | Loss: 0.05025240406394005\n",
      "Batch：16872 | Loss: 0.05378522723913193\n",
      "Batch：16873 | Loss: 0.04171851649880409\n",
      "Batch：16874 | Loss: 0.0449504479765892\n",
      "Batch：16875 | Loss: 0.04780546948313713\n",
      "Batch：16876 | Loss: 0.04461962729692459\n",
      "Batch：16877 | Loss: 0.041828006505966187\n",
      "Batch：16878 | Loss: 0.04191618412733078\n",
      "Batch：16879 | Loss: 0.04205229505896568\n",
      "Batch：16880 | Loss: 0.04521296173334122\n",
      "Batch：16881 | Loss: 0.051415231078863144\n",
      "Batch：16882 | Loss: 0.0432695597410202\n",
      "Batch：16883 | Loss: 0.05512755364179611\n",
      "Batch：16884 | Loss: 0.05866004899144173\n",
      "Batch：16885 | Loss: 0.044321563094854355\n",
      "Batch：16886 | Loss: 0.052301086485385895\n",
      "Batch：16887 | Loss: 0.04963738098740578\n",
      "Batch：16888 | Loss: 0.04392831027507782\n",
      "Batch：16889 | Loss: 0.04800787195563316\n",
      "Batch：16890 | Loss: 0.04942114278674126\n",
      "Batch：16891 | Loss: 0.05001246556639671\n",
      "Batch：16892 | Loss: 0.051093414425849915\n",
      "Batch：16893 | Loss: 0.053243041038513184\n",
      "Batch：16894 | Loss: 0.06183993071317673\n",
      "Batch：16895 | Loss: 0.048995502293109894\n",
      "Batch：16896 | Loss: 0.039836447685956955\n",
      "Batch：16897 | Loss: 0.06214920058846474\n",
      "Batch：16898 | Loss: 0.05368371680378914\n",
      "Batch：16899 | Loss: 0.052296288311481476\n",
      "Batch：16900 | Loss: 0.047453105449676514\n",
      "Batch：16901 | Loss: 0.04920065402984619\n",
      "Batch：16902 | Loss: 0.04904564842581749\n",
      "Batch：16903 | Loss: 0.04965619370341301\n",
      "Batch：16904 | Loss: 0.05544358119368553\n",
      "Batch：16905 | Loss: 0.05626846104860306\n",
      "Batch：16906 | Loss: 0.04815026372671127\n",
      "Batch：16907 | Loss: 0.05248456820845604\n",
      "Batch：16908 | Loss: 0.05007188022136688\n",
      "Batch：16909 | Loss: 0.04894167184829712\n",
      "Batch：16910 | Loss: 0.05930386111140251\n",
      "Batch：16911 | Loss: 0.05036165192723274\n",
      "Batch：16912 | Loss: 0.04792270436882973\n",
      "Batch：16913 | Loss: 0.05117778852581978\n",
      "Batch：16914 | Loss: 0.04355673864483833\n",
      "Batch：16915 | Loss: 0.04819679632782936\n",
      "Batch：16916 | Loss: 0.04989604651927948\n",
      "Batch：16917 | Loss: 0.04745066165924072\n",
      "Batch：16918 | Loss: 0.04498749598860741\n",
      "Batch：16919 | Loss: 0.046406131237745285\n",
      "Batch：16920 | Loss: 0.04631908982992172\n",
      "Batch：16921 | Loss: 0.0385177806019783\n",
      "Batch：16922 | Loss: 0.053363967686891556\n",
      "Batch：16923 | Loss: 0.046928294003009796\n",
      "Batch：16924 | Loss: 0.058048978447914124\n",
      "Batch：16925 | Loss: 0.04627986624836922\n",
      "Batch：16926 | Loss: 0.04688592627644539\n",
      "Batch：16927 | Loss: 0.0472770519554615\n",
      "Batch：16928 | Loss: 0.05187506973743439\n",
      "Batch：16929 | Loss: 0.054533421993255615\n",
      "Batch：16930 | Loss: 0.053024113178253174\n",
      "Batch：16931 | Loss: 0.0560893751680851\n",
      "Batch：16932 | Loss: 0.04088304564356804\n",
      "Batch：16933 | Loss: 0.04528055340051651\n",
      "Batch：16934 | Loss: 0.05846818536520004\n",
      "Batch：16935 | Loss: 0.0507013276219368\n",
      "Batch：16936 | Loss: 0.04733322933316231\n",
      "Batch：16937 | Loss: 0.050651706755161285\n",
      "Batch：16938 | Loss: 0.043438833206892014\n",
      "Batch：16939 | Loss: 0.04589105024933815\n",
      "Batch：16940 | Loss: 0.05569610372185707\n",
      "Batch：16941 | Loss: 0.05184780806303024\n",
      "Batch：16942 | Loss: 0.051901936531066895\n",
      "Batch：16943 | Loss: 0.04557768255472183\n",
      "Batch：16944 | Loss: 0.050516560673713684\n",
      "Batch：16945 | Loss: 0.044598937034606934\n",
      "Batch：16946 | Loss: 0.05573355033993721\n",
      "Batch：16947 | Loss: 0.058043234050273895\n",
      "Batch：16948 | Loss: 0.039209455251693726\n",
      "Batch：16949 | Loss: 0.04201388731598854\n",
      "Batch：16950 | Loss: 0.047115642577409744\n",
      "Batch：16951 | Loss: 0.058800652623176575\n",
      "Batch：16952 | Loss: 0.04956179857254028\n",
      "Batch：16953 | Loss: 0.04516385868191719\n",
      "Batch：16954 | Loss: 0.052787430584430695\n",
      "Batch：16955 | Loss: 0.042578425258398056\n",
      "Batch：16956 | Loss: 0.042592667043209076\n",
      "Batch：16957 | Loss: 0.05581409111618996\n",
      "Batch：16958 | Loss: 0.05057419836521149\n",
      "Batch：16959 | Loss: 0.04609113931655884\n",
      "Batch：16960 | Loss: 0.04904818534851074\n",
      "Batch：16961 | Loss: 0.05750039592385292\n",
      "Batch：16962 | Loss: 0.05101259425282478\n",
      "Batch：16963 | Loss: 0.053825315088033676\n",
      "Batch：16964 | Loss: 0.053522989153862\n",
      "Batch：16965 | Loss: 0.044056862592697144\n",
      "Batch：16966 | Loss: 0.044554997235536575\n",
      "Batch：16967 | Loss: 0.04955137148499489\n",
      "Batch：16968 | Loss: 0.05166792869567871\n",
      "Batch：16969 | Loss: 0.04767429456114769\n",
      "Batch：16970 | Loss: 0.05443313717842102\n",
      "Batch：16971 | Loss: 0.05004999786615372\n",
      "Batch：16972 | Loss: 0.04514556750655174\n",
      "Batch：16973 | Loss: 0.05450979620218277\n",
      "Batch：16974 | Loss: 0.047657083719968796\n",
      "Batch：16975 | Loss: 0.05594359710812569\n",
      "Batch：16976 | Loss: 0.05114785209298134\n",
      "Batch：16977 | Loss: 0.056507937610149384\n",
      "Batch：16978 | Loss: 0.0569438636302948\n",
      "Batch：16979 | Loss: 0.04299360513687134\n",
      "Batch：16980 | Loss: 0.049047864973545074\n",
      "Batch：16981 | Loss: 0.054815102368593216\n",
      "Batch：16982 | Loss: 0.050350312143564224\n",
      "Batch：16983 | Loss: 0.046208906918764114\n",
      "Batch：16984 | Loss: 0.055587008595466614\n",
      "Batch：16985 | Loss: 0.04630618169903755\n",
      "Batch：16986 | Loss: 0.05462316796183586\n",
      "Batch：16987 | Loss: 0.06369149684906006\n",
      "Batch：16988 | Loss: 0.052917901426553726\n",
      "Batch：16989 | Loss: 0.04611877351999283\n",
      "Batch：16990 | Loss: 0.05106867477297783\n",
      "Batch：16991 | Loss: 0.04261985048651695\n",
      "Batch：16992 | Loss: 0.05072110518813133\n",
      "Batch：16993 | Loss: 0.03920511528849602\n",
      "Batch：16994 | Loss: 0.05039931833744049\n",
      "Batch：16995 | Loss: 0.04520714655518532\n",
      "Batch：16996 | Loss: 0.05447633937001228\n",
      "Batch：16997 | Loss: 0.04645776376128197\n",
      "Batch：16998 | Loss: 0.05672193691134453\n",
      "Batch：16999 | Loss: 0.057963378727436066\n",
      "Batch：17000 | Loss: 0.04287455230951309\n",
      "Batch：17001 | Loss: 0.048060134053230286\n",
      "Batch：17002 | Loss: 0.05905580520629883\n",
      "Batch：17003 | Loss: 0.058183200657367706\n",
      "Batch：17004 | Loss: 0.04307578504085541\n",
      "Batch：17005 | Loss: 0.04941220581531525\n",
      "Batch：17006 | Loss: 0.03960733860731125\n",
      "Batch：17007 | Loss: 0.04980582743883133\n",
      "Batch：17008 | Loss: 0.03957156464457512\n",
      "Batch：17009 | Loss: 0.048364002257585526\n",
      "Batch：17010 | Loss: 0.05936885625123978\n",
      "Batch：17011 | Loss: 0.051573943346738815\n",
      "Batch：17012 | Loss: 0.04165427014231682\n",
      "Batch：17013 | Loss: 0.047739069908857346\n",
      "Batch：17014 | Loss: 0.048949964344501495\n",
      "Batch：17015 | Loss: 0.04805363342165947\n",
      "Batch：17016 | Loss: 0.044574178755283356\n",
      "Batch：17017 | Loss: 0.04531051963567734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：17018 | Loss: 0.04935111850500107\n",
      "Batch：17019 | Loss: 0.05502120032906532\n",
      "Batch：17020 | Loss: 0.04402296990156174\n",
      "Batch：17021 | Loss: 0.047852952033281326\n",
      "Batch：17022 | Loss: 0.05559432879090309\n",
      "Batch：17023 | Loss: 0.045100849121809006\n",
      "Batch：17024 | Loss: 0.05053401738405228\n",
      "Batch：17025 | Loss: 0.04711877927184105\n",
      "Batch：17026 | Loss: 0.05336228385567665\n",
      "Batch：17027 | Loss: 0.03565547242760658\n",
      "Batch：17028 | Loss: 0.052646931260824203\n",
      "Batch：17029 | Loss: 0.05632340908050537\n",
      "Batch：17030 | Loss: 0.048280566930770874\n",
      "Batch：17031 | Loss: 0.06245812401175499\n",
      "Batch：17032 | Loss: 0.04446648433804512\n",
      "Batch：17033 | Loss: 0.04829736799001694\n",
      "Batch：17034 | Loss: 0.045157358050346375\n",
      "Batch：17035 | Loss: 0.060707151889801025\n",
      "Batch：17036 | Loss: 0.0498201884329319\n",
      "Batch：17037 | Loss: 0.048153653740882874\n",
      "Batch：17038 | Loss: 0.05339732766151428\n",
      "Batch：17039 | Loss: 0.03943457826972008\n",
      "Batch：17040 | Loss: 0.04654502868652344\n",
      "Batch：17041 | Loss: 0.04570968076586723\n",
      "Batch：17042 | Loss: 0.04950074106454849\n",
      "Batch：17043 | Loss: 0.053013112396001816\n",
      "Batch：17044 | Loss: 0.044134583324193954\n",
      "Batch：17045 | Loss: 0.04380317032337189\n",
      "Batch：17046 | Loss: 0.047940969467163086\n",
      "Batch：17047 | Loss: 0.05525483191013336\n",
      "Batch：17048 | Loss: 0.04088031128048897\n",
      "Batch：17049 | Loss: 0.041950978338718414\n",
      "Batch：17050 | Loss: 0.04823356121778488\n",
      "Batch：17051 | Loss: 0.042521633207798004\n",
      "Batch：17052 | Loss: 0.04714619740843773\n",
      "Batch：17053 | Loss: 0.04375406354665756\n",
      "Batch：17054 | Loss: 0.04427623003721237\n",
      "Batch：17055 | Loss: 0.05050751194357872\n",
      "Batch：17056 | Loss: 0.056319013237953186\n",
      "Batch：17057 | Loss: 0.05231345072388649\n",
      "Batch：17058 | Loss: 0.05105706676840782\n",
      "Batch：17059 | Loss: 0.04850168898701668\n",
      "Batch：17060 | Loss: 0.05411192774772644\n",
      "Batch：17061 | Loss: 0.047025468200445175\n",
      "Batch：17062 | Loss: 0.051500365138053894\n",
      "Batch：17063 | Loss: 0.04605508968234062\n",
      "Batch：17064 | Loss: 0.052813414484262466\n",
      "Batch：17065 | Loss: 0.06328046321868896\n",
      "Batch：17066 | Loss: 0.05273395776748657\n",
      "Batch：17067 | Loss: 0.04952333867549896\n",
      "Batch：17068 | Loss: 0.05158797279000282\n",
      "Batch：17069 | Loss: 0.049512505531311035\n",
      "Batch：17070 | Loss: 0.04570841044187546\n",
      "Batch：17071 | Loss: 0.04893411323428154\n",
      "Batch：17072 | Loss: 0.05316230654716492\n",
      "Batch：17073 | Loss: 0.047023747116327286\n",
      "Batch：17074 | Loss: 0.05217988044023514\n",
      "Batch：17075 | Loss: 0.05001083388924599\n",
      "Batch：17076 | Loss: 0.053504202514886856\n",
      "Batch：17077 | Loss: 0.044459711760282516\n",
      "Batch：17078 | Loss: 0.046081047505140305\n",
      "Batch：17079 | Loss: 0.03589963912963867\n",
      "Batch：17080 | Loss: 0.0503191314637661\n",
      "Batch：17081 | Loss: 0.047377556562423706\n",
      "Batch：17082 | Loss: 0.05502758547663689\n",
      "Batch：17083 | Loss: 0.049359362572431564\n",
      "Batch：17084 | Loss: 0.052013713866472244\n",
      "Batch：17085 | Loss: 0.051954641938209534\n",
      "Batch：17086 | Loss: 0.06263340264558792\n",
      "Batch：17087 | Loss: 0.05531523749232292\n",
      "Batch：17088 | Loss: 0.04433438926935196\n",
      "Batch：17089 | Loss: 0.04914257302880287\n",
      "Batch：17090 | Loss: 0.04562299698591232\n",
      "Batch：17091 | Loss: 0.0445881225168705\n",
      "Batch：17092 | Loss: 0.04485567659139633\n",
      "Batch：17093 | Loss: 0.047914065420627594\n",
      "Batch：17094 | Loss: 0.051816631108522415\n",
      "Batch：17095 | Loss: 0.040792617946863174\n",
      "Batch：17096 | Loss: 0.039756543934345245\n",
      "Batch：17097 | Loss: 0.045891378074884415\n",
      "Batch：17098 | Loss: 0.053985822945833206\n",
      "Batch：17099 | Loss: 0.05044535920023918\n",
      "Batch：17100 | Loss: 0.039866749197244644\n",
      "Batch：17101 | Loss: 0.04294518381357193\n",
      "Batch：17102 | Loss: 0.0441833958029747\n",
      "Batch：17103 | Loss: 0.05451995134353638\n",
      "Batch：17104 | Loss: 0.050900500267744064\n",
      "Batch：17105 | Loss: 0.04578603059053421\n",
      "Batch：17106 | Loss: 0.056544363498687744\n",
      "Batch：17107 | Loss: 0.050480421632528305\n",
      "Batch：17108 | Loss: 0.05883525684475899\n",
      "Batch：17109 | Loss: 0.05054406076669693\n",
      "Batch：17110 | Loss: 0.051554352045059204\n",
      "Batch：17111 | Loss: 0.05407802388072014\n",
      "Batch：17112 | Loss: 0.05365101993083954\n",
      "Batch：17113 | Loss: 0.05222819000482559\n",
      "Batch：17114 | Loss: 0.0451345220208168\n",
      "Batch：17115 | Loss: 0.04801822826266289\n",
      "Batch：17116 | Loss: 0.0454014390707016\n",
      "Batch：17117 | Loss: 0.04515713453292847\n",
      "Batch：17118 | Loss: 0.05686835199594498\n",
      "Batch：17119 | Loss: 0.04969031736254692\n",
      "Batch：17120 | Loss: 0.05635274574160576\n",
      "Batch：17121 | Loss: 0.04873541742563248\n",
      "Batch：17122 | Loss: 0.046205829828977585\n",
      "Batch：17123 | Loss: 0.05429762601852417\n",
      "Batch：17124 | Loss: 0.05200393497943878\n",
      "Batch：17125 | Loss: 0.04080631956458092\n",
      "Batch：17126 | Loss: 0.05112734064459801\n",
      "Batch：17127 | Loss: 0.05474192276597023\n",
      "Batch：17128 | Loss: 0.046320438385009766\n",
      "Batch：17129 | Loss: 0.04671063274145126\n",
      "Batch：17130 | Loss: 0.04552366957068443\n",
      "Batch：17131 | Loss: 0.04991757124662399\n",
      "Batch：17132 | Loss: 0.04370352625846863\n",
      "Batch：17133 | Loss: 0.053609948605298996\n",
      "Batch：17134 | Loss: 0.04152505472302437\n",
      "Batch：17135 | Loss: 0.05103043466806412\n",
      "Batch：17136 | Loss: 0.04878965765237808\n",
      "Batch：17137 | Loss: 0.0493442639708519\n",
      "Batch：17138 | Loss: 0.05201616510748863\n",
      "Batch：17139 | Loss: 0.04261874407529831\n",
      "Batch：17140 | Loss: 0.050873398780822754\n",
      "Batch：17141 | Loss: 0.057105112820863724\n",
      "Batch：17142 | Loss: 0.053813740611076355\n",
      "Batch：17143 | Loss: 0.06032213941216469\n",
      "Batch：17144 | Loss: 0.05427921563386917\n",
      "Batch：17145 | Loss: 0.041286978870630264\n",
      "Batch：17146 | Loss: 0.04354473203420639\n",
      "Batch：17147 | Loss: 0.06429870426654816\n",
      "Batch：17148 | Loss: 0.05065639317035675\n",
      "Batch：17149 | Loss: 0.04665505513548851\n",
      "Batch：17150 | Loss: 0.05091627314686775\n",
      "Batch：17151 | Loss: 0.04977283626794815\n",
      "Batch：17152 | Loss: 0.054567258805036545\n",
      "Batch：17153 | Loss: 0.048196401447057724\n",
      "Batch：17154 | Loss: 0.05675680562853813\n",
      "Batch：17155 | Loss: 0.05516264960169792\n",
      "Batch：17156 | Loss: 0.052639804780483246\n",
      "Batch：17157 | Loss: 0.05511736124753952\n",
      "Batch：17158 | Loss: 0.06004096567630768\n",
      "Batch：17159 | Loss: 0.04664772376418114\n",
      "Batch：17160 | Loss: 0.04254046082496643\n",
      "Batch：17161 | Loss: 0.057013362646102905\n",
      "Batch：17162 | Loss: 0.05100144445896149\n",
      "Batch：17163 | Loss: 0.04826630651950836\n",
      "Batch：17164 | Loss: 0.048252567648887634\n",
      "Batch：17165 | Loss: 0.04626663029193878\n",
      "Batch：17166 | Loss: 0.05237583816051483\n",
      "Batch：17167 | Loss: 0.04596889019012451\n",
      "Batch：17168 | Loss: 0.045809630304574966\n",
      "Batch：17169 | Loss: 0.04609822481870651\n",
      "Batch：17170 | Loss: 0.03595016524195671\n",
      "Batch：17171 | Loss: 0.043295808136463165\n",
      "Batch：17172 | Loss: 0.05229564011096954\n",
      "Batch：17173 | Loss: 0.04728911444544792\n",
      "Batch：17174 | Loss: 0.04580793157219887\n",
      "Batch：17175 | Loss: 0.041785553097724915\n",
      "Batch：17176 | Loss: 0.050413407385349274\n",
      "Batch：17177 | Loss: 0.045231301337480545\n",
      "Batch：17178 | Loss: 0.046188581734895706\n",
      "Batch：17179 | Loss: 0.052455876022577286\n",
      "Batch：17180 | Loss: 0.040043383836746216\n",
      "Batch：17181 | Loss: 0.04930347576737404\n",
      "Batch：17182 | Loss: 0.041460469365119934\n",
      "Batch：17183 | Loss: 0.04964110255241394\n",
      "Batch：17184 | Loss: 0.04416191577911377\n",
      "Batch：17185 | Loss: 0.050907816737890244\n",
      "Batch：17186 | Loss: 0.052674826234579086\n",
      "Batch：17187 | Loss: 0.04529917985200882\n",
      "Batch：17188 | Loss: 0.04779837653040886\n",
      "Batch：17189 | Loss: 0.04018251970410347\n",
      "Batch：17190 | Loss: 0.040518682450056076\n",
      "Batch：17191 | Loss: 0.04558979347348213\n",
      "Batch：17192 | Loss: 0.05607376992702484\n",
      "Batch：17193 | Loss: 0.048487238585948944\n",
      "Batch：17194 | Loss: 0.04788091033697128\n",
      "Batch：17195 | Loss: 0.04595717787742615\n",
      "Batch：17196 | Loss: 0.0569264180958271\n",
      "Batch：17197 | Loss: 0.04797891527414322\n",
      "Batch：17198 | Loss: 0.04821823909878731\n",
      "Batch：17199 | Loss: 0.04324006661772728\n",
      "Batch：17200 | Loss: 0.049100372940301895\n",
      "Batch：17201 | Loss: 0.05752333626151085\n",
      "Batch：17202 | Loss: 0.05239304527640343\n",
      "Batch：17203 | Loss: 0.04119065776467323\n",
      "Batch：17204 | Loss: 0.05545254424214363\n",
      "Batch：17205 | Loss: 0.055892668664455414\n",
      "Batch：17206 | Loss: 0.04876067116856575\n",
      "Batch：17207 | Loss: 0.04535304754972458\n",
      "Batch：17208 | Loss: 0.0545419417321682\n",
      "Batch：17209 | Loss: 0.0498223602771759\n",
      "Batch：17210 | Loss: 0.06161307543516159\n",
      "Batch：17211 | Loss: 0.05823369696736336\n",
      "Batch：17212 | Loss: 0.05834252014756203\n",
      "Batch：17213 | Loss: 0.04787785932421684\n",
      "Batch：17214 | Loss: 0.049267251044511795\n",
      "Batch：17215 | Loss: 0.048367343842983246\n",
      "Batch：17216 | Loss: 0.0472104474902153\n",
      "Batch：17217 | Loss: 0.04545185714960098\n",
      "Batch：17218 | Loss: 0.05310233682394028\n",
      "Batch：17219 | Loss: 0.047150734812021255\n",
      "Batch：17220 | Loss: 0.046614184975624084\n",
      "Batch：17221 | Loss: 0.052963465452194214\n",
      "Batch：17222 | Loss: 0.04912133887410164\n",
      "Batch：17223 | Loss: 0.049947671592235565\n",
      "Batch：17224 | Loss: 0.043083760887384415\n",
      "Batch：17225 | Loss: 0.04321211203932762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：17226 | Loss: 0.046100739389657974\n",
      "Batch：17227 | Loss: 0.03857358917593956\n",
      "Batch：17228 | Loss: 0.04829000309109688\n",
      "Batch：17229 | Loss: 0.045424703508615494\n",
      "Batch：17230 | Loss: 0.060945842415094376\n",
      "Batch：17231 | Loss: 0.049002114683389664\n",
      "Batch：17232 | Loss: 0.04734312370419502\n",
      "Batch：17233 | Loss: 0.04588593542575836\n",
      "Batch：17234 | Loss: 0.04614534601569176\n",
      "Batch：17235 | Loss: 0.05417880043387413\n",
      "Batch：17236 | Loss: 0.04755304381251335\n",
      "Batch：17237 | Loss: 0.04649451747536659\n",
      "Batch：17238 | Loss: 0.0469561442732811\n",
      "Batch：17239 | Loss: 0.049427714198827744\n",
      "Batch：17240 | Loss: 0.03828795999288559\n",
      "Batch：17241 | Loss: 0.05860419198870659\n",
      "Batch：17242 | Loss: 0.04676011949777603\n",
      "Batch：17243 | Loss: 0.05476173013448715\n",
      "Batch：17244 | Loss: 0.045798856765031815\n",
      "Batch：17245 | Loss: 0.056345485150814056\n",
      "Batch：17246 | Loss: 0.042248040437698364\n",
      "Batch：17247 | Loss: 0.04959169402718544\n",
      "Batch：17248 | Loss: 0.049163736402988434\n",
      "Batch：17249 | Loss: 0.04726876690983772\n",
      "Batch：17250 | Loss: 0.04843693971633911\n",
      "Batch：17251 | Loss: 0.039715539664030075\n",
      "Batch：17252 | Loss: 0.05157582089304924\n",
      "Batch：17253 | Loss: 0.043337903916835785\n",
      "Batch：17254 | Loss: 0.049751732498407364\n",
      "Batch：17255 | Loss: 0.052920032292604446\n",
      "Batch：17256 | Loss: 0.04348384216427803\n",
      "Batch：17257 | Loss: 0.03968912363052368\n",
      "Batch：17258 | Loss: 0.05651336535811424\n",
      "Batch：17259 | Loss: 0.059261057525873184\n",
      "Batch：17260 | Loss: 0.05269089713692665\n",
      "Batch：17261 | Loss: 0.06065455451607704\n",
      "Batch：17262 | Loss: 0.0395454503595829\n",
      "Batch：17263 | Loss: 0.04837111756205559\n",
      "Batch：17264 | Loss: 0.05020080506801605\n",
      "Batch：17265 | Loss: 0.04464727267622948\n",
      "Batch：17266 | Loss: 0.043068449944257736\n",
      "Batch：17267 | Loss: 0.051879968494176865\n",
      "Batch：17268 | Loss: 0.05423131212592125\n",
      "Batch：17269 | Loss: 0.05174073204398155\n",
      "Batch：17270 | Loss: 0.04084889218211174\n",
      "Batch：17271 | Loss: 0.04640597477555275\n",
      "Batch：17272 | Loss: 0.053466685116291046\n",
      "Batch：17273 | Loss: 0.045293740928173065\n",
      "Batch：17274 | Loss: 0.04768391698598862\n",
      "Batch：17275 | Loss: 0.048169657588005066\n",
      "Batch：17276 | Loss: 0.053049489855766296\n",
      "Batch：17277 | Loss: 0.05213233456015587\n",
      "Batch：17278 | Loss: 0.055849190801382065\n",
      "Batch：17279 | Loss: 0.054894592612981796\n",
      "Batch：17280 | Loss: 0.060548022389411926\n",
      "Batch：17281 | Loss: 0.04708714783191681\n",
      "Batch：17282 | Loss: 0.052940841764211655\n",
      "Batch：17283 | Loss: 0.04469572752714157\n",
      "Batch：17284 | Loss: 0.052858177572488785\n",
      "Batch：17285 | Loss: 0.041091736406087875\n",
      "Batch：17286 | Loss: 0.03845467418432236\n",
      "Batch：17287 | Loss: 0.050044119358062744\n",
      "Batch：17288 | Loss: 0.053934548050165176\n",
      "Batch：17289 | Loss: 0.04249489679932594\n",
      "Batch：17290 | Loss: 0.04493411257863045\n",
      "Batch：17291 | Loss: 0.0489165224134922\n",
      "Batch：17292 | Loss: 0.05768253654241562\n",
      "Batch：17293 | Loss: 0.05027741938829422\n",
      "Batch：17294 | Loss: 0.05009488761425018\n",
      "Batch：17295 | Loss: 0.0493377186357975\n",
      "Batch：17296 | Loss: 0.043218888342380524\n",
      "Batch：17297 | Loss: 0.05464122071862221\n",
      "Batch：17298 | Loss: 0.045724302530288696\n",
      "Batch：17299 | Loss: 0.044842518866062164\n",
      "Batch：17300 | Loss: 0.05883875489234924\n",
      "Batch：17301 | Loss: 0.04265080392360687\n",
      "Batch：17302 | Loss: 0.050248388200998306\n",
      "Batch：17303 | Loss: 0.04848230257630348\n",
      "Batch：17304 | Loss: 0.04609626159071922\n",
      "Batch：17305 | Loss: 0.04286709055304527\n",
      "Batch：17306 | Loss: 0.04679170623421669\n",
      "Batch：17307 | Loss: 0.05382784083485603\n",
      "Batch：17308 | Loss: 0.04448720067739487\n",
      "Batch：17309 | Loss: 0.051259662955999374\n",
      "Batch：17310 | Loss: 0.05028599873185158\n",
      "Batch：17311 | Loss: 0.04811901971697807\n",
      "Batch：17312 | Loss: 0.048778753727674484\n",
      "Batch：17313 | Loss: 0.049698807299137115\n",
      "Batch：17314 | Loss: 0.043484415858983994\n",
      "Batch：17315 | Loss: 0.03656758368015289\n",
      "Batch：17316 | Loss: 0.04865306615829468\n",
      "Batch：17317 | Loss: 0.05067810043692589\n",
      "Batch：17318 | Loss: 0.05220211669802666\n",
      "Batch：17319 | Loss: 0.0510382242500782\n",
      "Batch：17320 | Loss: 0.05345539376139641\n",
      "Batch：17321 | Loss: 0.04996112361550331\n",
      "Batch：17322 | Loss: 0.045679230242967606\n",
      "Batch：17323 | Loss: 0.04848022758960724\n",
      "Batch：17324 | Loss: 0.059174153953790665\n",
      "Batch：17325 | Loss: 0.0482945591211319\n",
      "Batch：17326 | Loss: 0.047141335904598236\n",
      "Batch：17327 | Loss: 0.05481235682964325\n",
      "Batch：17328 | Loss: 0.05372833088040352\n",
      "Batch：17329 | Loss: 0.05346442013978958\n",
      "Batch：17330 | Loss: 0.04046123847365379\n",
      "Batch：17331 | Loss: 0.04262670874595642\n",
      "Batch：17332 | Loss: 0.04137600213289261\n",
      "Batch：17333 | Loss: 0.056629668921232224\n",
      "Batch：17334 | Loss: 0.05251273512840271\n",
      "Batch：17335 | Loss: 0.04648929834365845\n",
      "Batch：17336 | Loss: 0.04475489258766174\n",
      "Batch：17337 | Loss: 0.05244462192058563\n",
      "Batch：17338 | Loss: 0.04492921009659767\n",
      "Batch：17339 | Loss: 0.040697131305933\n",
      "Batch：17340 | Loss: 0.04330737888813019\n",
      "Batch：17341 | Loss: 0.04103114828467369\n",
      "Batch：17342 | Loss: 0.0555863119661808\n",
      "Batch：17343 | Loss: 0.04978075996041298\n",
      "Batch：17344 | Loss: 0.049020130187273026\n",
      "Batch：17345 | Loss: 0.04555901512503624\n",
      "Batch：17346 | Loss: 0.04519619047641754\n",
      "Batch：17347 | Loss: 0.04630535840988159\n",
      "Batch：17348 | Loss: 0.049758922308683395\n",
      "Batch：17349 | Loss: 0.05370688810944557\n",
      "Batch：17350 | Loss: 0.05204426869750023\n",
      "Batch：17351 | Loss: 0.05278956517577171\n",
      "Batch：17352 | Loss: 0.043251194059848785\n",
      "Batch：17353 | Loss: 0.048083338886499405\n",
      "Batch：17354 | Loss: 0.045148298144340515\n",
      "Batch：17355 | Loss: 0.051641687750816345\n",
      "Batch：17356 | Loss: 0.043422188609838486\n",
      "Batch：17357 | Loss: 0.04537588357925415\n",
      "Batch：17358 | Loss: 0.05246637761592865\n",
      "Batch：17359 | Loss: 0.04655176401138306\n",
      "Batch：17360 | Loss: 0.05077729374170303\n",
      "Batch：17361 | Loss: 0.04872596263885498\n",
      "Batch：17362 | Loss: 0.0457720085978508\n",
      "Batch：17363 | Loss: 0.0424211286008358\n",
      "Batch：17364 | Loss: 0.04694874957203865\n",
      "Batch：17365 | Loss: 0.048742856830358505\n",
      "Batch：17366 | Loss: 0.04444552958011627\n",
      "Batch：17367 | Loss: 0.04691473767161369\n",
      "Batch：17368 | Loss: 0.04591881111264229\n",
      "Batch：17369 | Loss: 0.05356830358505249\n",
      "Batch：17370 | Loss: 0.0531819649040699\n",
      "Batch：17371 | Loss: 0.05004778876900673\n",
      "Batch：17372 | Loss: 0.04642315208911896\n",
      "Batch：17373 | Loss: 0.04884914681315422\n",
      "Batch：17374 | Loss: 0.05645759031176567\n",
      "Batch：17375 | Loss: 0.05871700868010521\n",
      "Batch：17376 | Loss: 0.0516824908554554\n",
      "Batch：17377 | Loss: 0.049534279853105545\n",
      "Batch：17378 | Loss: 0.05545204132795334\n",
      "Batch：17379 | Loss: 0.04838135838508606\n",
      "Batch：17380 | Loss: 0.05213063582777977\n",
      "Batch：17381 | Loss: 0.05579518526792526\n",
      "Batch：17382 | Loss: 0.0552586168050766\n",
      "Batch：17383 | Loss: 0.048178985714912415\n",
      "Batch：17384 | Loss: 0.051129039376974106\n",
      "Batch：17385 | Loss: 0.04355987161397934\n",
      "Batch：17386 | Loss: 0.045695316046476364\n",
      "Batch：17387 | Loss: 0.05598025396466255\n",
      "Batch：17388 | Loss: 0.040518369525671005\n",
      "Batch：17389 | Loss: 0.05213933438062668\n",
      "Batch：17390 | Loss: 0.04369262605905533\n",
      "Batch：17391 | Loss: 0.04565375670790672\n",
      "Batch：17392 | Loss: 0.047061603516340256\n",
      "Batch：17393 | Loss: 0.049212850630283356\n",
      "Batch：17394 | Loss: 0.040627263486385345\n",
      "Batch：17395 | Loss: 0.04558315500617027\n",
      "Batch：17396 | Loss: 0.041188910603523254\n",
      "Batch：17397 | Loss: 0.05009296163916588\n",
      "Batch：17398 | Loss: 0.054216623306274414\n",
      "Batch：17399 | Loss: 0.04441872239112854\n",
      "Batch：17400 | Loss: 0.05519507825374603\n",
      "Batch：17401 | Loss: 0.04905756935477257\n",
      "Batch：17402 | Loss: 0.05406458303332329\n",
      "Batch：17403 | Loss: 0.0442705899477005\n",
      "Batch：17404 | Loss: 0.051426395773887634\n",
      "Batch：17405 | Loss: 0.05608271062374115\n",
      "Batch：17406 | Loss: 0.044301167130470276\n",
      "Batch：17407 | Loss: 0.04496866837143898\n",
      "Batch：17408 | Loss: 0.04616975411772728\n",
      "Batch：17409 | Loss: 0.04549894109368324\n",
      "Batch：17410 | Loss: 0.05696191266179085\n",
      "Batch：17411 | Loss: 0.04870857670903206\n",
      "Batch：17412 | Loss: 0.057965707033872604\n",
      "Batch：17413 | Loss: 0.06004531309008598\n",
      "Batch：17414 | Loss: 0.05407117307186127\n",
      "Batch：17415 | Loss: 0.050082769244909286\n",
      "Batch：17416 | Loss: 0.04914623498916626\n",
      "Batch：17417 | Loss: 0.04874991625547409\n",
      "Batch：17418 | Loss: 0.04584980756044388\n",
      "Batch：17419 | Loss: 0.04050559177994728\n",
      "Batch：17420 | Loss: 0.05460312217473984\n",
      "Batch：17421 | Loss: 0.053366608917713165\n",
      "Batch：17422 | Loss: 0.04458804801106453\n",
      "Batch：17423 | Loss: 0.044809091836214066\n",
      "Batch：17424 | Loss: 0.05817295238375664\n",
      "Batch：17425 | Loss: 0.04612303525209427\n",
      "Batch：17426 | Loss: 0.046904999762773514\n",
      "Batch：17427 | Loss: 0.04207649081945419\n",
      "Batch：17428 | Loss: 0.04597533494234085\n",
      "Batch：17429 | Loss: 0.051885221153497696\n",
      "Batch：17430 | Loss: 0.05675911903381348\n",
      "Batch：17431 | Loss: 0.05747642368078232\n",
      "Batch：17432 | Loss: 0.04681481793522835\n",
      "Batch：17433 | Loss: 0.0561661571264267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch：17434 | Loss: 0.04447963461279869\n",
      "Batch：17435 | Loss: 0.049389082938432693\n",
      "Batch：17436 | Loss: 0.04811195284128189\n",
      "Batch：17437 | Loss: 0.04072337597608566\n",
      "Batch：17438 | Loss: 0.04433668032288551\n",
      "Batch：17439 | Loss: 0.049897387623786926\n",
      "Batch：17440 | Loss: 0.0408644825220108\n",
      "Batch：17441 | Loss: 0.05432410538196564\n",
      "Batch：17442 | Loss: 0.043965380638837814\n",
      "Batch：17443 | Loss: 0.05408589169383049\n",
      "Batch：17444 | Loss: 0.04236462339758873\n",
      "Batch：17445 | Loss: 0.03792206943035126\n",
      "Batch：17446 | Loss: 0.04987972974777222\n",
      "Batch：17447 | Loss: 0.047718048095703125\n",
      "Batch：17448 | Loss: 0.056390970945358276\n",
      "Batch：17449 | Loss: 0.050664469599723816\n",
      "Batch：17450 | Loss: 0.0506933368742466\n",
      "Batch：17451 | Loss: 0.04810728877782822\n",
      "Batch：17452 | Loss: 0.0521053671836853\n",
      "Batch：17453 | Loss: 0.04317699000239372\n",
      "Batch：17454 | Loss: 0.050702158361673355\n",
      "Batch：17455 | Loss: 0.04568443074822426\n",
      "Batch：17456 | Loss: 0.043824829161167145\n",
      "Batch：17457 | Loss: 0.0475710891187191\n",
      "Batch：17458 | Loss: 0.05084637552499771\n",
      "Batch：17459 | Loss: 0.05923235043883324\n",
      "Batch：17460 | Loss: 0.04942072927951813\n",
      "Batch：17461 | Loss: 0.05757040157914162\n",
      "Batch：17462 | Loss: 0.04712250828742981\n",
      "Batch：17463 | Loss: 0.04743914678692818\n",
      "Batch：17464 | Loss: 0.057011835277080536\n",
      "Batch：17465 | Loss: 0.043235547840595245\n",
      "Batch：17466 | Loss: 0.04592185467481613\n",
      "Batch：17467 | Loss: 0.04852737858891487\n",
      "Batch：17468 | Loss: 0.035126302391290665\n",
      "Batch：17469 | Loss: 0.04695766791701317\n",
      "Batch：17470 | Loss: 0.056847888976335526\n",
      "Batch：17471 | Loss: 0.05137912556529045\n",
      "Batch：17472 | Loss: 0.0493992418050766\n",
      "Batch：17473 | Loss: 0.04376605525612831\n",
      "Batch：17474 | Loss: 0.04737471044063568\n",
      "Batch：17475 | Loss: 0.04479466378688812\n",
      "Batch：17476 | Loss: 0.05166736617684364\n",
      "Batch：17477 | Loss: 0.05183601751923561\n",
      "Batch：17478 | Loss: 0.04952439293265343\n",
      "Batch：17479 | Loss: 0.05200990289449692\n",
      "Batch：17480 | Loss: 0.048094939440488815\n",
      "Batch：17481 | Loss: 0.060668040066957474\n",
      "Batch：17482 | Loss: 0.04134882986545563\n",
      "Batch：17483 | Loss: 0.044526975601911545\n",
      "Batch：17484 | Loss: 0.05305831879377365\n",
      "Batch：17485 | Loss: 0.04532920941710472\n",
      "Batch：17486 | Loss: 0.049469511955976486\n",
      "Batch：17487 | Loss: 0.05776042491197586\n",
      "Batch：17488 | Loss: 0.043862346559762955\n",
      "Batch：17489 | Loss: 0.05420130491256714\n",
      "Batch：17490 | Loss: 0.04745374619960785\n",
      "Batch：17491 | Loss: 0.05177261680364609\n",
      "Batch：17492 | Loss: 0.05461181700229645\n",
      "Batch：17493 | Loss: 0.05242614820599556\n",
      "Batch：17494 | Loss: 0.045109063386917114\n",
      "Batch：17495 | Loss: 0.050767943263053894\n",
      "Batch：17496 | Loss: 0.05638141930103302\n",
      "Batch：17497 | Loss: 0.04142876714468002\n",
      "Batch：17498 | Loss: 0.041187725961208344\n",
      "Batch：17499 | Loss: 0.05297815799713135\n",
      "Batch：17500 | Loss: 0.04968126490712166\n",
      "Batch：17501 | Loss: 0.04840501770377159\n",
      "Batch：17502 | Loss: 0.04407056048512459\n",
      "Batch：17503 | Loss: 0.04625796899199486\n",
      "Batch：17504 | Loss: 0.04740242287516594\n",
      "Batch：17505 | Loss: 0.049565207213163376\n",
      "Batch：17506 | Loss: 0.06000344827771187\n",
      "Batch：17507 | Loss: 0.052923522889614105\n",
      "Batch：17508 | Loss: 0.04972871020436287\n",
      "Batch：17509 | Loss: 0.05558457970619202\n",
      "Batch：17510 | Loss: 0.05558079853653908\n",
      "Batch：17511 | Loss: 0.0488937571644783\n",
      "Batch：17512 | Loss: 0.06377466768026352\n",
      "Batch：17513 | Loss: 0.057349976152181625\n",
      "Batch：17514 | Loss: 0.04741121456027031\n",
      "Batch：17515 | Loss: 0.04300840571522713\n",
      "Batch：17516 | Loss: 0.045081011950969696\n",
      "Batch：17517 | Loss: 0.04222211241722107\n",
      "Batch：17518 | Loss: 0.056554798036813736\n",
      "Batch：17519 | Loss: 0.04644389823079109\n",
      "Batch：17520 | Loss: 0.05342966690659523\n",
      "Batch：17521 | Loss: 0.04286355525255203\n",
      "Batch：17522 | Loss: 0.04924803972244263\n",
      "Batch：17523 | Loss: 0.057000331580638885\n",
      "Batch：17524 | Loss: 0.04691233113408089\n",
      "Batch：17525 | Loss: 0.043263163417577744\n",
      "Batch：17526 | Loss: 0.05196370556950569\n",
      "Batch：17527 | Loss: 0.043188516050577164\n",
      "Batch：17528 | Loss: 0.04701115936040878\n",
      "Batch：17529 | Loss: 0.04042641073465347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13338477108401223"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLIP = 1\n",
    "train(model0, trainiter, optimizer, criterion, CLIP,  device, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model0.state_dict(), 'ae01.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.load_state_dict(torch.load('ae01.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 5m 49s\n",
      "\tTrain Loss: 0.038 | Train PPL:   1.039\n",
      "Epoch: 02 | Time: 5m 52s\n",
      "\tTrain Loss: 0.028 | Train PPL:   1.028\n",
      "Epoch: 03 | Time: 5m 43s\n",
      "\tTrain Loss: 0.022 | Train PPL:   1.023\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model0, trainiter, optimizer, criterion, CLIP,  device, maxlen)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    " \n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model0.state_dict(), 'aep4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model10.state_dict(), 'ae01.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.load_state_dict(torch.load('aep4.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start inferencing\n",
    "# data cannot be shuffled, build new loader\n",
    "evl = {'batch_size': 256,\n",
    "          'shuffle': False}\n",
    "\n",
    "filteriter = DataLoader(train_X, **evl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionf  = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flt(model, iterator, criterion, device, maxlen):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    losst = np.zeros(1)\n",
    "           \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            tin = batch.to(device)\n",
    "\n",
    "            target, recons = model(tin, maxlen)\n",
    "            \n",
    "            loss = torch.sum(criterionf(target,recons),[1,2])\n",
    "            \n",
    "            losst = np.append(losst,loss.cpu().numpy())\n",
    "        \n",
    "    return losst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "losst = flt(model0, filteriter, criterionf, device, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = losst[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = pd.DataFrame(error, index=traintitle.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>292.566956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>244.851639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>217.494537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344431</th>\n",
       "      <td>214.971603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344432</th>\n",
       "      <td>0.419960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344433</th>\n",
       "      <td>423.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344434</th>\n",
       "      <td>169.982880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344435</th>\n",
       "      <td>280.898407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2243679 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0        292.566956\n",
       "2          0.060529\n",
       "4          0.044393\n",
       "5        244.851639\n",
       "6        217.494537\n",
       "...             ...\n",
       "2344431  214.971603\n",
       "2344432    0.419960\n",
       "2344433  423.000916\n",
       "2344434  169.982880\n",
       "2344435  280.898407\n",
       "\n",
       "[2243679 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "toshow = error.sort_values(by=[0],ascending = False)[0:50].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1756484, 2334546, 1694752,  677822,  318932, 1465770,  232808,\n",
       "        285304,  331794,  318186])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1756484    brainwashing begin brainwashing begin real tal...\n",
       "2334546    sfesgrtugiyhi rer5t6y7hu8hjy7e##rt6y##ujhy7gt#...\n",
       "1694752    kirtasi̇ye kopyalama baski kopyalama sektörün ...\n",
       "677822     promo code free io app download download tell ...\n",
       "318932     akcesoria elektryknet poszukujesz porządnie wy...\n",
       "1465770    dbhfyjnn dhdrhjf ddhddwe sdd sddss shfgd hsbee...\n",
       "232808     nakit ogledlce nakit online ogledalce nudi vel...\n",
       "285304     oryginalna srebrna nasze produkty autorskie po...\n",
       "331794     http katalog budowlany budowlane przetargi bud...\n",
       "318186     puertas abatibles puertas abatibles fabricacio...\n",
       "319994     monday development stolica wielkopolski szybko...\n",
       "1105807    decryption challenge dwi##tytyfn8yqv+3mo2i+1we...\n",
       "1419643    unawezaje kumridhisha mpenzi nimekuwa kwenye m...\n",
       "1463853    meetup use massively long identifier email ver...\n",
       "298472     ray dolap mobilya tasarımında firmalar arasınd...\n",
       "167662     halı altı camii altı karbon film sektöründe hi...\n",
       "111711     demonte prefabrik yapı ofis konteyner evler de...\n",
       "2211127    money spell recieve money account money flow a...\n",
       "1324389    phone number turn email address mailcell launc...\n",
       "1284403    yurtlar evimiz karşılaştığı yurt arama problem...\n",
       "363568     zemin kaplama ahref= quot http www.sporzeminka...\n",
       "1529238    sdhvbicb sldkjchsdiuochndsi sdhvbicb sldkjchsd...\n",
       "433414     sanarwa daga bky medium aranar bky medium zata...\n",
       "296625     http echipamente ortopedice este magazin onlin...\n",
       "1614017    rafting giyilir nehir giyin kuru mayo koruması...\n",
       "187201     mineraludens nabeghlavi dabigais mineraludens ...\n",
       "1320013    booking.com blocked turkey association turkish...\n",
       "118858     show degree accurate weather io app promo code...\n",
       "1108970    lara araba http www.elparsrentacar.com haber-a...\n",
       "740566     yangin alarm yangını anda tespit edip edilmesi...\n",
       "227328     avocat balan marian braila daca sunteti implic...\n",
       "27474      armarios empotrados instalamos tarima parquet ...\n",
       "319663     dokumentacje podatkowe jesteś zarządcą firmy p...\n",
       "1099278    antalya asma tavan antalya asma tavan herkes e...\n",
       "1308708    rafti̇ngo rafting antalya rafting turizmi tari...\n",
       "1473989    sha家族 hash algorithm，缩写为sha）是一个密码散列函数家族，是fips所...\n",
       "311745     widler gartenbau gmbh widler gartenbau sorgt s...\n",
       "2276480    apple apple edilən bir yeniləməsi araşdırması ...\n",
       "2171423    gadis tergamam tunang terima mesej sayang dari...\n",
       "36341      ropa bebé tienda infantil princesas venta onli...\n",
       "249700     hackerlar bin amerika sitesini hackledi grup a...\n",
       "1316939    kanyonda rafting rafti̇ng bir rehber tarafında...\n",
       "122650     cursul perfectionare achizitiile publice roman...\n",
       "2230676    keybase keybase benim olmadığını kanıtlamamı i...\n",
       "588448     prirodno lecenje|prirodni lekovi|bronhitis|akn...\n",
       "543953     prirodno lecenje|prirodni lekovi|bronhitis|akn...\n",
       "1906846    polisten terörist cenazesine giden hdp'li veki...\n",
       "343198     selidbe beograd agencija selidbe beograd kombi...\n",
       "244276     build system using html tool iphone web server...\n",
       "511392     razotkriven srpski haker/i koji objavili podat...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintitle.loc[toshow]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL0",
   "language": "python",
   "name": "tdi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
