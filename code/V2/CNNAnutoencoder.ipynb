{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "#import tldextract\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure reproductivity\n",
    "SEED = 6745\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pding/anaconda3/envs/tdi/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#traintitle.to_csv('traintae.csv')\n",
    "traintitle = pd.read_csv(\"traintae.csv\", index_col=0)\n",
    "traintitle = traintitle['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(traintitle))\n",
    "train_X = tokenizer.texts_to_sequences(traintitle)\n",
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that most of the titles+texts have very little words, and the longest posts are much longer than the average ones. This is probably\n",
    "# Because most of the posts only contain a title and no other contents\n",
    "maxlen = 10\n",
    "## Pad the sentences (same length input), texts_to_matrix would be too large\n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.as_tensor(train_X, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use local rtx 2080\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build input iterator, create minibatches\n",
    "trn = {'batch_size': 1024,\n",
    "          'shuffle': True}\n",
    "evl = {'batch_size': 1024,\n",
    "          'shuffle': False}\n",
    "\n",
    "trainiter = DataLoader(train_X, **trn)\n",
    "#next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncC(nn.Module):\n",
    "    def __init__(self, input_dim,emb_dim,hid_dim,kernel_size,dropout,device,maxlen):\n",
    "        super().__init__()\n",
    "        \n",
    "        #assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.pos_embedding = nn.Embedding(maxlen, emb_dim)\n",
    "        \n",
    "        self.emb2hid = nn.Linear(emb_dim, hid_dim)\n",
    "        \n",
    "        self.conv = nn.Conv1d(in_channels = hid_dim, out_channels = 2 * hid_dim, \n",
    "                                              kernel_size = kernel_size, \n",
    "                                              padding = (kernel_size - 1) // 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, tin):\n",
    "        \n",
    "        batch_size = tin.shape[0]\n",
    "        t_len = tin.shape[1]\n",
    "        \n",
    "        #create position tensor\n",
    "        pos = torch.arange(0, t_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        \n",
    "        tok_embedded = self.tok_embedding(tin)\n",
    "        pos_embedded = self.pos_embedding(pos)\n",
    "        \n",
    "      \n",
    "        #combine embeddings by elementwise summing\n",
    "        embedded = self.dropout(tok_embedded + pos_embedded)\n",
    "        \n",
    "        conv_input = self.emb2hid(embedded)\n",
    "        \n",
    "     \n",
    "        #len should be in the last dim, (batch, channel(hid), lenght)\n",
    "        #permute for convolutional layer\n",
    "        conv_input = conv_input.permute(0, 2, 1) \n",
    "        \n",
    "        #pass through convolutional layer\n",
    "        conved = self.conv(self.dropout(conv_input))\n",
    "\n",
    "        #conved = [batch size, 2 * hid dim, src len]\n",
    "\n",
    "        #pass through GLU activation function\n",
    "        conved = F.glu(conved, dim = 1)\n",
    "\n",
    "        #apply residual connection\n",
    "        conved = (conved + conv_input) * self.scale\n",
    "\n",
    "        \n",
    "        #permute\n",
    "        conved = conved.permute(0, 2, 1)\n",
    "\n",
    "        \n",
    "        return tok_embedded, conved\n",
    "\n",
    "class DecC(nn.Module):\n",
    "    def __init__(self, emb_dim,hid_dim,kernel_size,dropout,device):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\n",
    "        \n",
    "   \n",
    "       \n",
    "\n",
    "        self.hid2emb = nn.Linear(hid_dim, emb_dim)\n",
    "        \n",
    "        self.conv = nn.Conv1d(in_channels = hid_dim, out_channels = 2 * hid_dim, \n",
    "                              kernel_size = kernel_size, padding = (kernel_size - 1) // 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, tin):\n",
    "        \n",
    "     \n",
    "        #len should be in the last dim, (batch, channel(hid), lenght)\n",
    "        #permute for convolutional layer\n",
    "        conv_input = tin.permute(0, 2, 1) \n",
    "        \n",
    "        #pass through convolutional layer\n",
    "        conved = self.conv(self.dropout(conv_input))\n",
    "\n",
    "        #conved = [batch size, 2 * hid dim, src len]\n",
    "\n",
    "        #pass through GLU activation function\n",
    "        conved = F.glu(conved, dim = 1)\n",
    "\n",
    "        #apply residual connection\n",
    "        conved = (conved + conv_input)\n",
    "\n",
    "        #conved = [batch size, hid dim, src len]\n",
    "\n",
    "        \n",
    "        #...end convolutional blocks\n",
    "        \n",
    "        #permute and convert back to emb dim\n",
    "        conved = self.hid2emb(conved.permute(0, 2, 1))\n",
    "\n",
    "        \n",
    "        return conved\n",
    "\n",
    "class AEC(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, tin):\n",
    "        embedded, outputs = self.encoder(tin)\n",
    "\n",
    "        recons = self.decoder(outputs)\n",
    "        \n",
    "        return embedded, recons      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM  = len(word_index) + 1\n",
    "OUTPUT_DIM  = maxlen\n",
    "EMB_DIM  = 300\n",
    "HID_DIM  = 100 \n",
    "ENC_KERNEL_SIZE  = 3 \n",
    "DEC_KERNEL_SIZE = 3 \n",
    "ENC_DROPOUT  = 0\n",
    "DEC_DROPOUT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = EncC(INPUT_DIM, EMB_DIM, HID_DIM, ENC_KERNEL_SIZE, ENC_DROPOUT, device, maxlen)\n",
    "dec = DecC(EMB_DIM, HID_DIM, DEC_KERNEL_SIZE, DEC_DROPOUT, device)\n",
    "\n",
    "modelC = AEC(enc, dec).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(modelC.parameters())\n",
    "criterion  = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device, maxlen):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        tin = batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        target, recons = model(tin)\n",
    "        \n",
    "        loss = criterion(recons, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        #print(f'Batch：{i+1} | Loss: {loss.item()}')\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 5m 24s\n",
      "\tTrain Loss: 0.025 | Train PPL:   1.026\n",
      "Epoch: 02 | Time: 5m 25s\n",
      "\tTrain Loss: 0.017 | Train PPL:   1.017\n",
      "Epoch: 03 | Time: 5m 28s\n",
      "\tTrain Loss: 0.013 | Train PPL:   1.014\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(modelC, trainiter, optimizer, criterion,  device, maxlen)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    " \n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelC.state_dict(), 'aec4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change batch size to 1024 and rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 31s\n",
      "\tTrain Loss: 0.011 | Train PPL:   1.012\n",
      "Epoch: 02 | Time: 1m 31s\n",
      "\tTrain Loss: 0.010 | Train PPL:   1.011\n",
      "Epoch: 03 | Time: 1m 32s\n",
      "\tTrain Loss: 0.010 | Train PPL:   1.010\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(modelC, trainiter, optimizer, criterion,  device, maxlen)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    " \n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelC.state_dict(), 'aec7.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start inferencing\n",
    "# data cannot be shuffled, build new loader\n",
    "evl = {'batch_size': 1024,\n",
    "          'shuffle': False}\n",
    "\n",
    "filteriter = DataLoader(train_X, **evl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionf  = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flt(model, iterator, criterion, device, maxlen):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    losst = np.zeros(1)\n",
    "           \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            tin = batch.to(device)\n",
    "\n",
    "            target, recons = model(tin)\n",
    "            \n",
    "            loss = torch.sum(criterionf(target,recons),[1,2])\n",
    "            \n",
    "            losst = np.append(losst,loss.cpu().numpy())\n",
    "        \n",
    "    return losst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "losst = flt(modelC, filteriter, criterionf, device, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = losst[1:]\n",
    "error = pd.DataFrame(error, index=traintitle.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "toshow = error.sort_values(by=[0],ascending = False)[0:50].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318932     akcesoria elektryknet poszukujesz porządnie wy...\n",
       "1756484    brainwashing begin brainwashing begin real tal...\n",
       "285304     oryginalna srebrna nasze produkty autorskie po...\n",
       "2334546    sfesgrtugiyhi rer5t6y7hu8hjy7e##rt6y##ujhy7gt#...\n",
       "319994     monday development stolica wielkopolski szybko...\n",
       "232808     nakit ogledlce nakit online ogledalce nudi vel...\n",
       "296625     http echipamente ortopedice este magazin onlin...\n",
       "2211127    money spell recieve money account money flow a...\n",
       "677822     promo code free io app download download tell ...\n",
       "1105807    decryption challenge dwi##tytyfn8yqv+3mo2i+1we...\n",
       "1465770    dbhfyjnn dhdrhjf ddhddwe sdd sddss shfgd hsbee...\n",
       "1694752    kirtasi̇ye kopyalama baski kopyalama sektörün ...\n",
       "1473989    sha家族 hash algorithm，缩写为sha）是一个密码散列函数家族，是fips所...\n",
       "1463853    meetup use massively long identifier email ver...\n",
       "331794     http katalog budowlany budowlane przetargi bud...\n",
       "1284403    yurtlar evimiz karşılaştığı yurt arama problem...\n",
       "167662     halı altı camii altı karbon film sektöründe hi...\n",
       "1419643    unawezaje kumridhisha mpenzi nimekuwa kwenye m...\n",
       "226247     youtube internal server error sorry something ...\n",
       "111711     demonte prefabrik yapı ofis konteyner evler de...\n",
       "1320013    booking.com blocked turkey association turkish...\n",
       "298472     ray dolap mobilya tasarımında firmalar arasınd...\n",
       "118858     show degree accurate weather io app promo code...\n",
       "128075     trener personalny lifefit.pl najlepszy trener ...\n",
       "1108970    lara araba http www.elparsrentacar.com haber-a...\n",
       "187201     mineraludens nabeghlavi dabigais mineraludens ...\n",
       "318186     puertas abatibles puertas abatibles fabricacio...\n",
       "363568     zemin kaplama ahref= quot http www.sporzeminka...\n",
       "14427      released first io app xaos promo code xaos htt...\n",
       "319663     dokumentacje podatkowe jesteś zarządcą firmy p...\n",
       "1736494    fuinf fttzhggvsvfwgzvhzcfjvr jbzgjbzuskjrbkfa ...\n",
       "1529238    sdhvbicb sldkjchsdiuochndsi sdhvbicb sldkjchsd...\n",
       "1316939    kanyonda rafting rafti̇ng bir rehber tarafında...\n",
       "498        tespiti tespiti kameralar tespit cihazları aku...\n",
       "850860     tlhingan mah ghom siqpu bogh programmer barat ...\n",
       "1308708    rafti̇ngo rafting antalya rafting turizmi tari...\n",
       "2171423    gadis tergamam tunang terima mesej sayang dari...\n",
       "2230676    keybase keybase benim olmadığını kanıtlamamı i...\n",
       "249700     hackerlar bin amerika sitesini hackledi grup a...\n",
       "153420     youtube internal server error sorry something ...\n",
       "311745     widler gartenbau gmbh widler gartenbau sorgt s...\n",
       "1176520    one apple watch app help concentrated develop ...\n",
       "2276480    apple apple edilən bir yeniləməsi araşdırması ...\n",
       "1324389    phone number turn email address mailcell launc...\n",
       "36341      ropa bebé tienda infantil princesas venta onli...\n",
       "1906846    polisten terörist cenazesine giden hdp'li veki...\n",
       "1614017    rafting giyilir nehir giyin kuru mayo koruması...\n",
       "124231     ip medellín ip acicme centro excelencia usted ...\n",
       "122650     cursul perfectionare achizitiile publice roman...\n",
       "27474      armarios empotrados instalamos tarima parquet ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintitle.loc[toshow]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL0",
   "language": "python",
   "name": "tdi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
